This is
/home/melpa/melpa/working/python-info-20130916.1420/python.info,
produced by makeinfo version 4.13 from
/home/melpa/melpa/working/python-info/python.texi.

Generated by Sphinx 1.1.3.
INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY

     Python 2.7.5, September 16, 2013

     Georg Brandl

     Copyright (C) 1990-2013, Python Software Foundation


File: python.info,  Node: Set Objects<2>,  Next: Code Objects<2>,  Prev: DateTime Objects<2>,  Up: Other Objects

7.7.5.15 Set Objects
....................

New in version 2.5.

  This section details the public API for *note set: 363. and *note
frozenset: 364.  objects.  Any functionality not listed below is best
accessed using the either the abstract object protocol (including *note
PyObject_CallMethod(): 2aff, *note PyObject_RichCompareBool(): 2af5,
*note PyObject_Hash(): 2b01, *note PyObject_Repr(): 2af6, *note
PyObject_IsTrue(): 2b02, *note PyObject_Print(): 2aea, and *note
PyObject_GetIter(): 2b0a.) or the abstract number protocol (including
*note PyNumber_And(): 2b1e, *note PyNumber_Subtract(): 2b10, *note
PyNumber_Or(): 2b20, *note PyNumber_Xor(): 2b1f, *note
PyNumber_InPlaceAnd(): 2b2b, *note PyNumber_InPlaceSubtract(): 2b22,
*note PyNumber_InPlaceOr(): 2b2d, and *note PyNumber_InPlaceXor():
2b2c.).

 -- C Type: PySetObject
     This subtype of *note PyObject: 39f. is used to hold the internal
     data for both *note set: 363. and *note frozenset: 364. objects.
     It is like a *note PyDictObject: 2cb4.  in that it is a fixed size
     for small sets (much like tuple storage) and will point to a
     separate, variable sized block of memory for medium and large sized
     sets (much like list storage). None of the fields of this
     structure should be considered public and are subject to change.
     All access should be done through the documented API rather than
     by manipulating the values in the structure.

 -- C Variable: PyTypeObject PySet_Type
     This is an instance of *note PyTypeObject: 29b9. representing the
     Python *note set: 363. type.

 -- C Variable: PyTypeObject PyFrozenSet_Type
     This is an instance of *note PyTypeObject: 29b9. representing the
     Python *note frozenset: 364. type.

  The following type check macros work on pointers to any Python
object. Likewise, the constructor functions work with any iterable
Python object.

 -- C Function: int PySet_Check (PyObject *p)
     Return true if _p_ is a *note set: 363. object or an instance of a
     subtype.

     New in version 2.6.

 -- C Function: int PyFrozenSet_Check (PyObject *p)
     Return true if _p_ is a *note frozenset: 364. object or an
     instance of a subtype.

     New in version 2.6.

 -- C Function: int PyAnySet_Check (PyObject *p)
     Return true if _p_ is a *note set: 363. object, a *note frozenset:
     364. object, or an instance of a subtype.

 -- C Function: int PyAnySet_CheckExact (PyObject *p)
     Return true if _p_ is a *note set: 363. object or a *note
     frozenset: 364. object but not an instance of a subtype.

 -- C Function: int PyFrozenSet_CheckExact (PyObject *p)
     Return true if _p_ is a *note frozenset: 364. object but not an
     instance of a subtype.

 -- C Function: PyObject* PySet_New (PyObject *iterable)
     Return value: New reference.

     Return a new *note set: 363. containing objects returned by the
     _iterable_.  The _iterable_ may be _NULL_ to create a new empty
     set.  Return the new set on success or _NULL_ on failure.  Raise
     *note TypeError: 215. if _iterable_ is not actually iterable.  The
     constructor is also useful for copying a set (`c=set(s)').

 -- C Function: PyObject* PyFrozenSet_New (PyObject *iterable)
     Return value: New reference.

     Return a new *note frozenset: 364. containing objects returned by
     the _iterable_.  The _iterable_ may be _NULL_ to create a new
     empty frozenset.  Return the new set on success or _NULL_ on
     failure.  Raise *note TypeError: 215. if _iterable_ is not
     actually iterable.

     Changed in version 2.6: Now guaranteed to return a brand-new *note
     frozenset: 364.  Formerly, frozensets of zero-length were a
     singleton.  This got in the way of building-up new frozensets with
     `PySet_Add()'.

  The following functions and macros are available for instances of
*note set: 363.  or *note frozenset: 364. or instances of their
subtypes.

 -- C Function: Py_ssize_t PySet_Size (PyObject *anyset)
     Return the length of a *note set: 363. or *note frozenset: 364.
     object. Equivalent to `len(anyset)'.  Raises a `PyExc_SystemError'
     if _anyset_ is not a *note set: 363, *note frozenset: 364, or an
     instance of a subtype.

     Changed in version 2.5: This function returned an `int'. This
     might require changes in your code for properly supporting 64-bit
     systems.

 -- C Function: Py_ssize_t PySet_GET_SIZE (PyObject *anyset)
     Macro form of *note PySet_Size(): 3de. without error checking.

 -- C Function: int PySet_Contains (PyObject *anyset, PyObject *key)
     Return 1 if found, 0 if not found, and -1 if an error is
     encountered.  Unlike the Python *note __contains__(): 31b. method,
     this function does not automatically convert unhashable sets into
     temporary frozensets.  Raise a *note TypeError: 215. if the _key_
     is unhashable. Raise `PyExc_SystemError' if _anyset_ is not a
     *note set: 363, *note frozenset: 364, or an instance of a subtype.

 -- C Function: int PySet_Add (PyObject *set, PyObject *key)
     Add _key_ to a *note set: 363. instance.  Does not apply to *note
     frozenset: 364.  instances.  Return 0 on success or -1 on failure.
     Raise a *note TypeError: 215. if the _key_ is unhashable. Raise a
     *note MemoryError: 93a. if there is no room to grow.  Raise a
     *note SystemError: 93d. if _set_ is an not an instance of *note
     set: 363. or its subtype.

     Changed in version 2.6: Now works with instances of *note
     frozenset: 364. or its subtypes.  Like *note PyTuple_SetItem():
     29a5. in that it can be used to fill-in the values of brand new
     frozensets before they are exposed to other code.

  The following functions are available for instances of *note set:
363. or its subtypes but not for instances of *note frozenset: 364. or
its subtypes.

 -- C Function: int PySet_Discard (PyObject *set, PyObject *key)
     Return 1 if found and removed, 0 if not found (no action taken),
     and -1 if an error is encountered.  Does not raise *note KeyError:
     202. for missing keys.  Raise a *note TypeError: 215. if the _key_
     is unhashable.  Unlike the Python `discard()' method, this
     function does not automatically convert unhashable sets into
     temporary frozensets. Raise `PyExc_SystemError' if _set_ is an not
     an instance of *note set: 363. or its subtype.

 -- C Function: PyObject* PySet_Pop (PyObject *set)
     Return value: New reference.

     Return a new reference to an arbitrary object in the _set_, and
     removes the object from the _set_.  Return _NULL_ on failure.
     Raise *note KeyError: 202. if the set is empty. Raise a *note
     SystemError: 93d. if _set_ is an not an instance of *note set:
     363. or its subtype.

 -- C Function: int PySet_Clear (PyObject *set)
     Empty an existing set of all elements.


File: python.info,  Node: Code Objects<2>,  Prev: Set Objects<2>,  Up: Other Objects

7.7.5.16 Code Objects
.....................

Code objects are a low-level detail of the CPython implementation.
Each one represents a chunk of executable code that hasn't yet been
bound into a function.

 -- C Type: PyCodeObject
     The C structure of the objects used to describe code objects.  The
     fields of this type are subject to change at any time.

 -- C Variable: PyTypeObject PyCode_Type
     This is an instance of *note PyTypeObject: 29b9. representing the
     Python *note code: 62. type.

 -- C Function: int PyCode_Check (PyObject *co)
     Return true if _co_ is a *note code: 62. object

 -- C Function: int PyCode_GetNumFree (PyObject *co)
     Return the number of free variables in _co_.

 -- C Function: PyCodeObject *PyCode_New (int argcount, int nlocals,
          int stacksize, int flags, PyObject *code, PyObject *consts,
          PyObject *names, PyObject *varnames, PyObject *freevars,
          PyObject *cellvars, PyObject *filename, PyObject *name,
          int firstlineno, PyObject *lnotab)
     Return a new code object.  If you need a dummy code object to
     create a frame, use *note PyCode_NewEmpty(): 2b4. instead.  Calling
     *note PyCode_New(): 2b5. directly can bind you to a precise Python
     version since the definition of the bytecode changes often.

 -- C Function: int PyCode_NewEmpty (const char *filename, const
          char *funcname, int firstlineno)
     Return a new empty code object with the specified filename,
     function name, and first line number.  It is illegal to *note
     exec: 3fd. or *note eval(): 359. the resulting code object.


File: python.info,  Node: Initialization Finalization and Threads,  Next: Memory Management,  Prev: Concrete Objects Layer,  Up: Python/C API Reference Manual

7.8 Initialization, Finalization, and Threads
=============================================

* Menu:

* Initializing and finalizing the interpreter::
* Process-wide parameters::
* Thread State and the Global Interpreter Lock::
* Sub-interpreter support::
* Asynchronous Notifications::
* Profiling and Tracing::
* Advanced Debugger Support::


File: python.info,  Node: Initializing and finalizing the interpreter,  Next: Process-wide parameters,  Up: Initialization Finalization and Threads

7.8.1 Initializing and finalizing the interpreter
-------------------------------------------------

 -- C Function: void Py_Initialize ()
     Initialize the Python interpreter.  In an application embedding
     Python, this should be called before using any other Python/C API
     functions; with the exception of *note Py_SetProgramName(): 29ef,
     *note Py_SetPythonHome(): 2d94, *note PyEval_InitThreads(): 2d95,
     *note PyEval_ReleaseLock(): 2d96, and *note PyEval_AcquireLock():
     2d97. This initializes the table of loaded modules
     (`sys.modules'), and creates the fundamental modules *note
     __builtin__: 0, *note __main__: 2. and *note sys: 16d.  It also
     initializes the module search path (`sys.path'). It does not set
     `sys.argv'; use *note PySys_SetArgvEx(): 2bd. for that.  This is a
     no-op when called for a second time (without calling *note
     Py_Finalize(): 2c0. first).  There is no return value; it is a
     fatal error if the initialization fails.

 -- C Function: void Py_InitializeEx (int initsigs)
     This function works like *note Py_Initialize(): 2989. if
     _initsigs_ is 1. If _initsigs_ is 0, it skips initialization
     registration of signal handlers, which might be useful when Python
     is embedded.

     New in version 2.4.

 -- C Function: int Py_IsInitialized ()
     Return true (nonzero) when the Python interpreter has been
     initialized, false (zero) if not.  After *note Py_Finalize(): 2c0.
     is called, this returns false until *note Py_Initialize(): 2989.
     is called again.

 -- C Function: void Py_Finalize ()
     Undo all initializations made by *note Py_Initialize(): 2989. and
     subsequent use of Python/C API functions, and destroy all
     sub-interpreters (see *note Py_NewInterpreter(): 2d99. below) that
     were created and not yet destroyed since the last call to *note
     Py_Initialize(): 2989.  Ideally, this frees all memory allocated
     by the Python interpreter.  This is a no-op when called for a
     second time (without calling *note Py_Initialize(): 2989. again
     first).  There is no return value; errors during finalization are
     ignored.

     This function is provided for a number of reasons.  An embedding
     application might want to restart Python without having to restart
     the application itself.  An application that has loaded the Python
     interpreter from a dynamically loadable library (or DLL) might
     want to free all memory allocated by Python before unloading the
     DLL. During a hunt for memory leaks in an application a developer
     might want to free all memory allocated by Python before exiting
     from the application.

     *Bugs and caveats:* The destruction of modules and objects in
     modules is done in random order; this may cause destructors (*note
     __del__(): 6f6. methods) to fail when they depend on other objects
     (even functions) or modules.  Dynamically loaded extension modules
     loaded by Python are not unloaded.  Small amounts of memory
     allocated by the Python interpreter may not be freed (if you find
     a leak, please report it).  Memory tied up in circular references
     between objects is not freed.  Some memory allocated by extension
     modules may not be freed.  Some extensions may not work properly
     if their initialization routine is called more than once; this can
     happen if an application calls *note Py_Initialize(): 2989. and
     *note Py_Finalize(): 2c0. more than once.


File: python.info,  Node: Process-wide parameters,  Next: Thread State and the Global Interpreter Lock,  Prev: Initializing and finalizing the interpreter,  Up: Initialization Finalization and Threads

7.8.2 Process-wide parameters
-----------------------------

 -- C Function: void Py_SetProgramName (char *name)
     This function should be called before *note Py_Initialize(): 2989.
     is called for the first time, if it is called at all.  It tells
     the interpreter the value of the `argv[0]' argument to the
     `main()' function of the program.  This is used by *note
     Py_GetPath(): 2a14. and some other functions below to find the
     Python run-time libraries relative to the interpreter executable.
     The default value is `'python''.  The argument should point to a
     zero-terminated character string in static storage whose contents
     will not change for the duration of the program's execution.  No
     code in the Python interpreter will change the contents of this
     storage.

 -- C Function: char* Py_GetProgramName ()
     Return the program name set with *note Py_SetProgramName(): 29ef,
     or the default.  The returned string points into static storage;
     the caller should not modify its value.

 -- C Function: char* Py_GetPrefix ()
     Return the _prefix_ for installed platform-independent files. This
     is derived through a number of complicated rules from the program
     name set with *note Py_SetProgramName(): 29ef. and some
     environment variables; for example, if the program name is
     `'/usr/local/bin/python'', the prefix is `'/usr/local''. The
     returned string points into static storage; the caller should not
     modify its value.  This corresponds to the *prefix* variable in
     the top-level `Makefile' and the `--prefix' argument to the
     *configure* script at build time.  The value is available to
     Python code as `sys.prefix'.  It is only useful on Unix.  See also
     the next function.

 -- C Function: char* Py_GetExecPrefix ()
     Return the _exec-prefix_ for installed platform-_dependent_ files.
     This is derived through a number of complicated rules from the
     program name set with *note Py_SetProgramName(): 29ef. and some
     environment variables; for example, if the program name is
     `'/usr/local/bin/python'', the exec-prefix is `'/usr/local''.  The
     returned string points into static storage; the caller should not
     modify its value.  This corresponds to the *exec_prefix* variable
     in the top-level `Makefile' and the `--exec-prefix' argument to
     the *configure* script at build  time.  The value is available to
     Python code as `sys.exec_prefix'.  It is only useful on Unix.

     Background: The exec-prefix differs from the prefix when platform
     dependent files (such as executables and shared libraries) are
     installed in a different directory tree.  In a typical
     installation, platform dependent files may be installed in the
     `/usr/local/plat' subtree while platform independent may be
     installed in `/usr/local'.

     Generally speaking, a platform is a combination of hardware and
     software families, e.g.  Sparc machines running the Solaris 2.x
     operating system are considered the same platform, but Intel
     machines running Solaris 2.x are another platform, and Intel
     machines running Linux are yet another platform.  Different major
     revisions of the same operating system generally also form
     different platforms.  Non-Unix operating systems are a different
     story; the installation strategies on those systems are so
     different that the prefix and exec-prefix are meaningless, and set
     to the empty string. Note that compiled Python bytecode files are
     platform independent (but not independent from the Python version
     by which they were compiled!).

     System administrators will know how to configure the *mount* or
     *automount* programs to share `/usr/local' between platforms while
     having `/usr/local/plat' be a different filesystem for each
     platform.

 -- C Function: char* Py_GetProgramFullPath ()
     Return the full program name of the Python executable; this is
     computed as a side-effect of deriving the default module search
     path  from the program name (set by *note Py_SetProgramName():
     29ef. above). The returned string points into static storage; the
     caller should not modify its value.  The value is available to
     Python code as `sys.executable'.

 -- C Function: char* Py_GetPath ()
     Return the default module search path; this is computed from the
     program name (set by *note Py_SetProgramName(): 29ef. above) and
     some environment variables.  The returned string consists of a
     series of directory names separated by a platform dependent
     delimiter character.  The delimiter character is `':'' on Unix and
     Mac OS X, `';'' on Windows.  The returned string points into
     static storage; the caller should not modify its value.  The list
     *note sys.path: 576. is initialized with this value on interpreter
     startup; it can be (and usually is) modified later to change the
     search path for loading modules.


 -- C Function: const char* Py_GetVersion ()
     Return the version of this Python interpreter.  This is a string
     that looks something like

         "1.5 (#67, Dec 31 1997, 22:34:28) [GCC 2.7.2.2]"

     
     The first word (up to the first space character) is the current
     Python version; the first three characters are the major and minor
     version separated by a period.  The returned string points into
     static storage; the caller should not modify its value.  The value
     is available to Python code as `sys.version'.

 -- C Function: const char* Py_GetPlatform ()
     Return the platform identifier for the current platform.  On Unix,
     this is formed from the "official" name of the operating system,
     converted to lower case, followed by the major revision number;
     e.g., for Solaris 2.x, which is also known as SunOS 5.x, the value
     is `'sunos5''.  On Mac OS X, it is `'darwin''.  On Windows, it is
     `'win''.  The returned string points into static storage; the
     caller should not modify its value.  The value is available to
     Python code as `sys.platform'.

 -- C Function: const char* Py_GetCopyright ()
     Return the official copyright string for the current Python
     version, for example

     `'Copyright 1991-1995 Stichting Mathematisch Centrum, Amsterdam''

     The returned string points into static storage; the caller should
     not modify its value.  The value is available to Python code as
     `sys.copyright'.

 -- C Function: const char* Py_GetCompiler ()
     Return an indication of the compiler used to build the current
     Python version, in square brackets, for example:

         "[GCC 2.7.2.2]"

     
     The returned string points into static storage; the caller should
     not modify its value.  The value is available to Python code as
     part of the variable `sys.version'.

 -- C Function: const char* Py_GetBuildInfo ()
     Return information about the sequence number and build date and
     time  of the current Python interpreter instance, for example

         "#67, Aug  1 1997, 22:34:28"

     
     The returned string points into static storage; the caller should
     not modify its value.  The value is available to Python code as
     part of the variable `sys.version'.

 -- C Function: void PySys_SetArgvEx (int argc, char **argv,
          int updatepath)
     Set *note sys.argv: 621. based on _argc_ and _argv_.  These
     parameters are similar to those passed to the program's `main()'
     function with the difference that the first entry should refer to
     the script file to be executed rather than the executable hosting
     the Python interpreter.  If there isn't a script that will be run,
     the first entry in _argv_ can be an empty string.  If this
     function fails to initialize *note sys.argv: 621, a fatal
     condition is signalled using *note Py_FatalError(): 2a95.

     If _updatepath_ is zero, this is all the function does.  If
     _updatepath_ is non-zero, the function also modifies *note
     sys.path: 576. according to the following algorithm:

        - If the name of an existing script is passed in `argv[0]', the
          absolute path of the directory where the script is located is
          prepended to *note sys.path: 576.

        - Otherwise (that is, if _argc_ is 0 or `argv[0]' doesn't point
          to an existing file name), an empty string is prepended to
          *note sys.path: 576, which is the same as prepending the
          current working directory (`"."').

          Note: It is recommended that applications embedding the
          Python interpreter for purposes other than executing a single
          script pass 0 as _updatepath_, and update *note sys.path:
          576. themselves if desired.  See CVE-2008-5983(1).

          On versions before 2.6.6, you can achieve the same effect by
          manually popping the first *note sys.path: 576. element after
          having called *note PySys_SetArgv(): 2be, for example using:

              PyRun_SimpleString("import sys; sys.path.pop(0)\n");



     New in version 2.6.6.


 -- C Function: void PySys_SetArgv (int argc, char **argv)
     This function works like *note PySys_SetArgvEx(): 2bd. with
     _updatepath_ set to 1.

 -- C Function: void Py_SetPythonHome (char *home)
     Set the default "home" directory, that is, the location of the
     standard Python libraries.  See *note PYTHONHOME: 62a. for the
     meaning of the argument string.

     The argument should point to a zero-terminated character string in
     static storage whose contents will not change for the duration of
     the program's execution.  No code in the Python interpreter will
     change the contents of this storage.

 -- C Function: char* Py_GetPythonHome ()
     Return the default "home", that is, the value set by a previous
     call to *note Py_SetPythonHome(): 2d94, or the value of the *note
     PYTHONHOME: 62a.  environment variable if it is set.

  ---------- Footnotes ----------

  (1) http://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2008-5983


File: python.info,  Node: Thread State and the Global Interpreter Lock,  Next: Sub-interpreter support,  Prev: Process-wide parameters,  Up: Initialization Finalization and Threads

7.8.3 Thread State and the Global Interpreter Lock
--------------------------------------------------

The Python interpreter is not fully thread-safe.  In order to support
multi-threaded Python programs, there's a global lock, called the *note
global interpreter lock: 1523. or *note GIL: 2cf9, that must be held by
the current thread before it can safely access Python objects. Without
the lock, even the simplest operations could cause problems in a
multi-threaded program: for example, when two threads simultaneously
increment the reference count of the same object, the reference count
could end up being incremented only once instead of twice.

  Therefore, the rule exists that only the thread that has acquired the
*note GIL: 2cf9. may operate on Python objects or call Python/C API
functions.  In order to emulate concurrency of execution, the
interpreter regularly tries to switch threads (see *note
sys.setcheckinterval(): 239f.).  The lock is also released around
potentially blocking I/O operations like reading or writing a file, so
that other Python threads can run in the meantime.

  The Python interpreter keeps some thread-specific bookkeeping
information inside a data structure called *note PyThreadState: 2da3.
There's also one global variable pointing to the current *note
PyThreadState: 2da3.: it can be retrieved using *note
PyThreadState_Get(): 2da4.

* Menu:

* Releasing the GIL from extension code::
* Non-Python created threads::
* High-level API::
* Low-level API::


File: python.info,  Node: Releasing the GIL from extension code,  Next: Non-Python created threads,  Up: Thread State and the Global Interpreter Lock

7.8.3.1 Releasing the GIL from extension code
.............................................

Most extension code manipulating the *note GIL: 2cf9. has the following
simple structure:

    Save the thread state in a local variable.
    Release the global interpreter lock.
    ... Do some blocking I/O operation ...
    Reacquire the global interpreter lock.
    Restore the thread state from the local variable.

This is so common that a pair of macros exists to simplify it:

    Py_BEGIN_ALLOW_THREADS
    ... Do some blocking I/O operation ...
    Py_END_ALLOW_THREADS


  The *note Py_BEGIN_ALLOW_THREADS: 29aa. macro opens a new block and
declares a hidden local variable; the *note Py_END_ALLOW_THREADS: 29ab.
macro closes the block.  These two macros are still available when
Python is compiled without thread support (they simply have an empty
expansion).

  When thread support is enabled, the block above expands to the
following code:

    PyThreadState *_save;

    _save = PyEval_SaveThread();
    ...Do some blocking I/O operation...
    PyEval_RestoreThread(_save);


  Here is how these functions work: the global interpreter lock is used
to protect the pointer to the current thread state.  When releasing the
lock and saving the thread state, the current thread state pointer must
be retrieved before the lock is released (since another thread could
immediately acquire the lock and store its own thread state in the
global variable). Conversely, when acquiring the lock and restoring the
thread state, the lock must be acquired before storing the thread state
pointer.

     Note: Calling system I/O functions is the most common use case for
     releasing the GIL, but it can also be useful before calling
     long-running computations which don't need access to Python
     objects, such as compression or cryptographic functions operating
     over memory buffers.  For example, the standard *note zlib: 1ad.
     and *note hashlib: e6. modules release the GIL when compressing or
     hashing data.


File: python.info,  Node: Non-Python created threads,  Next: High-level API,  Prev: Releasing the GIL from extension code,  Up: Thread State and the Global Interpreter Lock

7.8.3.2 Non-Python created threads
..................................

When threads are created using the dedicated Python APIs (such as the
*note threading: 179. module), a thread state is automatically
associated to them and the code showed above is therefore correct.
However, when threads are created from C (for example by a third-party
library with its own thread management), they don't hold the GIL, nor
is there a thread state structure for them.

  If you need to call Python code from these threads (often this will
be part of a callback API provided by the aforementioned third-party
library), you must first register these threads with the interpreter by
creating a thread state data structure, then acquiring the GIL, and
finally storing their thread state pointer, before you can start using
the Python/C API.  When you are done, you should reset the thread state
pointer, release the GIL, and finally free the thread state data
structure.

  The *note PyGILState_Ensure(): 2da7. and *note PyGILState_Release():
2da8. functions do all of the above automatically.  The typical idiom
for calling into Python from a C thread is:

    PyGILState_STATE gstate;
    gstate = PyGILState_Ensure();

    /* Perform Python actions here. */
    result = CallSomeFunction();
    /* evaluate result or handle exception */

    /* Release the thread. No Python API allowed beyond this point. */
    PyGILState_Release(gstate);

Note that the `PyGILState_*()' functions assume there is only one global
interpreter (created automatically by *note Py_Initialize(): 2989.).
Python supports the creation of additional interpreters (using *note
Py_NewInterpreter(): 2d99.), but mixing multiple interpreters and the
`PyGILState_*()' API is unsupported.

  Another important thing to note about threads is their behaviour in
the face of the C `fork()' call. On most systems with `fork()', after a
process forks only the thread that issued the fork will exist. That also
means any locks held by other threads will never be released. Python
solves this for *note os.fork(): 241. by acquiring the locks it uses
internally before the fork, and releasing them afterwards. In addition,
it resets any *note Lock Objects: 15a2. in the child. When extending or
embedding Python, there is no way to inform Python of additional
(non-Python) locks that need to be acquired before or reset after a
fork. OS facilities such as `pthread_atfork()' would need to be used to
accomplish the same thing.  Additionally, when extending or embedding
Python, calling `fork()' directly rather than through *note os.fork():
241. (and returning to or calling into Python) may result in a deadlock
by one of Python's internal locks being held by a thread that is
defunct after the fork.  *note PyOS_AfterFork(): 2a86. tries to reset
the necessary locks, but is not always able to.


File: python.info,  Node: High-level API,  Next: Low-level API,  Prev: Non-Python created threads,  Up: Thread State and the Global Interpreter Lock

7.8.3.3 High-level API
......................

These are the most commonly used types and functions when writing C
extension code, or when embedding the Python interpreter:

 -- C Type: PyInterpreterState
     This data structure represents the state shared by a number of
     cooperating threads.  Threads belonging to the same interpreter
     share their module administration and a few other internal items.
     There are no public members in this structure.

     Threads belonging to different interpreters initially share
     nothing, except process state like available memory, open file
     descriptors and such.  The global interpreter lock is also shared
     by all threads, regardless of to which interpreter they belong.

 -- C Type: PyThreadState
     This data structure represents the state of a single thread.  The
     only public data member is *note PyInterpreterState *:
     2daa.`interp', which points to this thread's interpreter state.

 -- C Function: void PyEval_InitThreads ()
     Initialize and acquire the global interpreter lock.  It should be
     called in the main thread before creating a second thread or
     engaging in any other thread operations such as *note
     PyEval_ReleaseLock(): 2d96. or `PyEval_ReleaseThread(tstate)'. It
     is not needed before calling *note PyEval_SaveThread(): 2dab. or
     *note PyEval_RestoreThread(): 2dac.

     This is a no-op when called for a second time.  It is safe to call
     this function before calling *note Py_Initialize(): 2989.

          Note: When only the main thread exists, no GIL operations are
          needed. This is a common situation (most Python programs do
          not use threads), and the lock operations slow the
          interpreter down a bit. Therefore, the lock is not created
          initially.  This situation is equivalent to having acquired
          the lock: when there is only a single thread, all object
          accesses are safe.  Therefore, when this function initializes
          the global interpreter lock, it also acquires it.  Before the
          Python `_thread' module creates a new thread, knowing that
          either it has the lock or the lock hasn't been created yet,
          it calls *note PyEval_InitThreads(): 2d95.  When this call
          returns, it is guaranteed that the lock has been created and
          that the calling thread has acquired it.

          It is *not* safe to call this function when it is unknown
          which thread (if any) currently has the global interpreter
          lock.

          This function is not available when thread support is
          disabled at compile time.

 -- C Function: int PyEval_ThreadsInitialized ()
     Returns a non-zero value if *note PyEval_InitThreads(): 2d95. has
     been called.  This function can be called without holding the GIL,
     and therefore can be used to avoid calls to the locking API when
     running single-threaded.  This function is not available when
     thread support is disabled at compile time.

     New in version 2.4.

 -- C Function: PyThreadState* PyEval_SaveThread ()
     Release the global interpreter lock (if it has been created and
     thread support is enabled) and reset the thread state to _NULL_,
     returning the previous thread state (which is not _NULL_).  If the
     lock has been created, the current thread must have acquired it.
     (This function is available even when thread support is disabled
     at compile time.)

 -- C Function: void PyEval_RestoreThread (PyThreadState *tstate)
     Acquire the global interpreter lock (if it has been created and
     thread support is enabled) and set the thread state to _tstate_,
     which must not be _NULL_.  If the lock has been created, the
     current thread must not have acquired it, otherwise deadlock
     ensues.  (This function is available even when thread support is
     disabled at compile time.)

 -- C Function: PyThreadState* PyThreadState_Get ()
     Return the current thread state.  The global interpreter lock must
     be held.  When the current thread state is _NULL_, this issues a
     fatal error (so that the caller needn't check for _NULL_).

 -- C Function: PyThreadState* PyThreadState_Swap
          (PyThreadState *tstate)
     Swap the current thread state with the thread state given by the
     argument _tstate_, which may be _NULL_.  The global interpreter
     lock must be held and is not released.

 -- C Function: void PyEval_ReInitThreads ()
     This function is called from *note PyOS_AfterFork(): 2a86. to
     ensure that newly created child processes don't hold locks
     referring to threads which are not running in the child process.

  The following functions use thread-local storage, and are not
compatible with sub-interpreters:

 -- C Function: PyGILState_STATE PyGILState_Ensure ()
     Ensure that the current thread is ready to call the Python C API
     regardless of the current state of Python, or of the global
     interpreter lock. This may be called as many times as desired by a
     thread as long as each call is matched with a call to *note
     PyGILState_Release(): 2da8. In general, other thread-related APIs
     may be used between *note PyGILState_Ensure(): 2da7. and *note
     PyGILState_Release(): 2da8. calls as long as the thread state is
     restored to its previous state before the Release().  For example,
     normal usage of the *note Py_BEGIN_ALLOW_THREADS: 29aa. and *note
     Py_END_ALLOW_THREADS: 29ab. macros is acceptable.

     The return value is an opaque "handle" to the thread state when
     *note PyGILState_Ensure(): 2da7. was called, and must be passed to
     *note PyGILState_Release(): 2da8. to ensure Python is left in the
     same state. Even though recursive calls are allowed, these handles
     _cannot_ be shared - each unique call to *note
     PyGILState_Ensure(): 2da7. must save the handle for its call to
     *note PyGILState_Release(): 2da8.

     When the function returns, the current thread will hold the GIL
     and be able to call arbitrary Python code.  Failure is a fatal
     error.

     New in version 2.3.

 -- C Function: void PyGILState_Release (PyGILState_STATE)
     Release any resources previously acquired.  After this call,
     Python's state will be the same as it was prior to the
     corresponding *note PyGILState_Ensure(): 2da7. call (but generally
     this state will be unknown to the caller, hence the use of the
     GILState API).

     Every call to *note PyGILState_Ensure(): 2da7. must be matched by
     a call to *note PyGILState_Release(): 2da8. on the same thread.

     New in version 2.3.

 -- C Function: PyThreadState PyGILState_GetThisThreadState ()
     Get the current thread state for this thread.  May return `NULL'
     if no GILState API has been used on the current thread.  Note that
     the main thread always has such a thread-state, even if no
     auto-thread-state call has been made on the main thread.  This is
     mainly a helper/diagnostic function.

     New in version 2.3.

  The following macros are normally used without a trailing semicolon;
look for example usage in the Python source distribution.

 -- C Macro: Py_BEGIN_ALLOW_THREADS
     This macro expands to `{ PyThreadState *_save; _save =
     PyEval_SaveThread();'.  Note that it contains an opening brace; it
     must be matched with a following *note Py_END_ALLOW_THREADS: 29ab.
     macro.  See above for further discussion of this macro.  It is a
     no-op when thread support is disabled at compile time.

 -- C Macro: Py_END_ALLOW_THREADS
     This macro expands to `PyEval_RestoreThread(_save); }'. Note that
     it contains a closing brace; it must be matched with an earlier
     *note Py_BEGIN_ALLOW_THREADS: 29aa. macro.  See above for further
     discussion of this macro.  It is a no-op when thread support is
     disabled at compile time.

 -- C Macro: Py_BLOCK_THREADS
     This macro expands to `PyEval_RestoreThread(_save);': it is
     equivalent to *note Py_END_ALLOW_THREADS: 29ab. without the
     closing brace.  It is a no-op when thread support is disabled at
     compile time.

 -- C Macro: Py_UNBLOCK_THREADS
     This macro expands to `_save = PyEval_SaveThread();': it is
     equivalent to *note Py_BEGIN_ALLOW_THREADS: 29aa. without the
     opening brace and variable declaration.  It is a no-op when thread
     support is disabled at compile time.


File: python.info,  Node: Low-level API,  Prev: High-level API,  Up: Thread State and the Global Interpreter Lock

7.8.3.4 Low-level API
.....................

All of the following functions are only available when thread support
is enabled at compile time, and must be called only when the global
interpreter lock has been created.

 -- C Function: PyInterpreterState* PyInterpreterState_New ()
     Create a new interpreter state object.  The global interpreter
     lock need not be held, but may be held if it is necessary to
     serialize calls to this function.

 -- C Function: void PyInterpreterState_Clear
          (PyInterpreterState *interp)
     Reset all information in an interpreter state object.  The global
     interpreter lock must be held.

 -- C Function: void PyInterpreterState_Delete
          (PyInterpreterState *interp)
     Destroy an interpreter state object.  The global interpreter lock
     need not be held.  The interpreter state must have been reset with
     a previous call to *note PyInterpreterState_Clear(): 2db4.

 -- C Function: PyThreadState* PyThreadState_New
          (PyInterpreterState *interp)
     Create a new thread state object belonging to the given
     interpreter object.  The global interpreter lock need not be held,
     but may be held if it is necessary to serialize calls to this
     function.

 -- C Function: void PyThreadState_Clear (PyThreadState *tstate)
     Reset all information in a thread state object.  The global
     interpreter lock must be held.

 -- C Function: void PyThreadState_Delete (PyThreadState *tstate)
     Destroy a thread state object.  The global interpreter lock need
     not be held.  The thread state must have been reset with a
     previous call to *note PyThreadState_Clear(): 2db7.

 -- C Function: PyObject* PyThreadState_GetDict ()
     Return value: Borrowed reference.

     Return a dictionary in which extensions can store thread-specific
     state information.  Each extension should use a unique key to use
     to store state in the dictionary.  It is okay to call this
     function when no current thread state is available. If this
     function returns _NULL_, no exception has been raised and the
     caller should assume no current thread state is available.

     Changed in version 2.3: Previously this could only be called when
     a current thread is active, and _NULL_ meant that an exception was
     raised.

 -- C Function: int PyThreadState_SetAsyncExc (long id, PyObject *exc)
     Asynchronously raise an exception in a thread. The _id_ argument
     is the thread id of the target thread; _exc_ is the exception
     object to be raised. This function does not steal any references
     to _exc_. To prevent naive misuse, you must write your own C
     extension to call this.  Must be called with the GIL held.
     Returns the number of thread states modified; this is normally
     one, but will be zero if the thread id isn't found.  If _exc_ is
     `NULL', the pending exception (if any) for the thread is cleared.
     This raises no exceptions.

     New in version 2.3.

 -- C Function: void PyEval_AcquireThread (PyThreadState *tstate)
     Acquire the global interpreter lock and set the current thread
     state to _tstate_, which should not be _NULL_.  The lock must have
     been created earlier.  If this thread already has the lock,
     deadlock ensues.

     *note PyEval_RestoreThread(): 2dac. is a higher-level function
     which is always available (even when thread support isn't enabled
     or when threads have not been initialized).

 -- C Function: void PyEval_ReleaseThread (PyThreadState *tstate)
     Reset the current thread state to _NULL_ and release the global
     interpreter lock.  The lock must have been created earlier and
     must be held by the current thread.  The _tstate_ argument, which
     must not be _NULL_, is only used to check that it represents the
     current thread state -- if it isn't, a fatal error is reported.

     *note PyEval_SaveThread(): 2dab. is a higher-level function which
     is always available (even when thread support isn't enabled or
     when threads have not been initialized).

 -- C Function: void PyEval_AcquireLock ()
     Acquire the global interpreter lock.  The lock must have been
     created earlier.  If this thread already has the lock, a deadlock
     ensues.

          Warning: This function does not change the current thread
          state.  Please use *note PyEval_RestoreThread(): 2dac. or
          *note PyEval_AcquireThread(): 2dbb.  instead.

 -- C Function: void PyEval_ReleaseLock ()
     Release the global interpreter lock.  The lock must have been
     created earlier.

          Warning: This function does not change the current thread
          state.  Please use *note PyEval_SaveThread(): 2dab. or *note
          PyEval_ReleaseThread(): 2dbc.  instead.


File: python.info,  Node: Sub-interpreter support,  Next: Asynchronous Notifications,  Prev: Thread State and the Global Interpreter Lock,  Up: Initialization Finalization and Threads

7.8.4 Sub-interpreter support
-----------------------------

While in most uses, you will only embed a single Python interpreter,
there are cases where you need to create several independent
interpreters in the same process and perhaps even in the same thread.
Sub-interpreters allow you to do that.  You can switch between
sub-interpreters using the *note PyThreadState_Swap(): 2dad. function.
You can create and destroy them using the following functions:

 -- C Function: PyThreadState* Py_NewInterpreter ()
     Create a new sub-interpreter.  This is an (almost) totally
     separate environment for the execution of Python code.  In
     particular, the new interpreter has separate, independent versions
     of all imported modules, including the fundamental modules
     `builtins', *note __main__: 2. and *note sys: 16d.  The table of
     loaded modules (`sys.modules') and the module search path
     (`sys.path') are also separate.  The new environment has no
     `sys.argv' variable.  It has new standard I/O stream file objects
     `sys.stdin', `sys.stdout' and `sys.stderr' (however these refer to
     the same underlying file descriptors).

     The return value points to the first thread state created in the
     new sub-interpreter.  This thread state is made in the current
     thread state.  Note that no actual thread is created; see the
     discussion of thread states below.  If creation of the new
     interpreter is unsuccessful, _NULL_ is returned; no exception is
     set since the exception state is stored in the current thread
     state and there may not be a current thread state.  (Like all
     other Python/C API functions, the global interpreter lock must be
     held before calling this function and is still held when it
     returns; however, unlike most other Python/C API functions, there
     needn't be a current thread state on entry.)

     Extension modules are shared between (sub-)interpreters as
     follows: the first time a particular extension is imported, it is
     initialized normally, and a (shallow) copy of its module's
     dictionary is squirreled away.  When the same extension is
     imported by another (sub-)interpreter, a new module is initialized
     and filled with the contents of this copy; the extension's `init'
     function is not called.  Note that this is different from what
     happens when an extension is imported after the interpreter has
     been completely re-initialized by calling *note Py_Finalize():
     2c0. and *note Py_Initialize(): 2989.; in that case, the
     extension's `initmodule' function _is_ called again.


 -- C Function: void Py_EndInterpreter (PyThreadState *tstate)
     Destroy the (sub-)interpreter represented by the given thread
     state. The given thread state must be the current thread state.
     See the discussion of thread states below.  When the call returns,
     the current thread state is _NULL_.  All thread states associated
     with this interpreter are destroyed.  (The global interpreter lock
     must be held before calling this function and is still held when
     it returns.)  *note Py_Finalize(): 2c0. will destroy all
     sub-interpreters that haven't been explicitly destroyed at that
     point.

* Menu:

* Bugs and caveats::


File: python.info,  Node: Bugs and caveats,  Up: Sub-interpreter support

7.8.4.1 Bugs and caveats
........................

Because sub-interpreters (and the main interpreter) are part of the same
process, the insulation between them isn't perfect -- for example, using
low-level file operations like  *note os.close(): 10ea. they can
(accidentally or maliciously) affect each other's open files.  Because
of the way extensions are shared between (sub-)interpreters, some
extensions may not work properly; this is especially likely when the
extension makes use of (static) global variables, or when the extension
manipulates its module's dictionary after its initialization.  It is
possible to insert objects created in one sub-interpreter into a
namespace of another sub-interpreter; this should be done with great
care to avoid sharing user-defined functions, methods, instances or
classes between sub-interpreters, since import operations executed by
such objects may affect the wrong (sub-)interpreter's dictionary of
loaded modules.

  Also note that combining this functionality with `PyGILState_*()' APIs
is delicate, because these APIs assume a bijection between Python
thread states and OS-level threads, an assumption broken by the
presence of sub-interpreters.  It is highly recommended that you don't
switch sub-interpreters between a pair of matching *note
PyGILState_Ensure(): 2da7. and *note PyGILState_Release(): 2da8. calls.
Furthermore, extensions (such as *note ctypes: 78.) using these APIs to
allow calling of Python code from non-Python created threads will
probably be broken when using sub-interpreters.


File: python.info,  Node: Asynchronous Notifications,  Next: Profiling and Tracing,  Prev: Sub-interpreter support,  Up: Initialization Finalization and Threads

7.8.5 Asynchronous Notifications
--------------------------------

A mechanism is provided to make asynchronous notifications to the main
interpreter thread.  These notifications take the form of a function
pointer and a void argument.

  Every check interval, when the global interpreter lock is released and
reacquired, Python will also call any such provided functions.  This
can be used for example by asynchronous IO handlers.  The notification
can be scheduled from a worker thread and the actual call than made at
the earliest convenience by the main thread where it has possession of
the global interpreter lock and can perform any Python API calls.

 -- C Function: int Py_AddPendingCall (int (*func)(void *), void *arg)
     Post a notification to the Python main thread.  If successful,
     _func_ will be called with the argument _arg_ at the earliest
     convenience.  _func_ will be called having the global interpreter
     lock held and can thus use the full Python API and can take any
     action such as setting object attributes to signal IO completion.
     It must return 0 on success, or -1 signalling an exception.  The
     notification function won't be interrupted to perform another
     asynchronous notification recursively, but it can still be
     interrupted to switch threads if the global interpreter lock is
     released, for example, if it calls back into Python code.

     This function returns 0 on success in which case the notification
     has been scheduled.  Otherwise, for example if the notification
     buffer is full, it returns -1 without setting any exception.

     This function can be called on any thread, be it a Python thread
     or some other system thread.  If it is a Python thread, it doesn't
     matter if it holds the global interpreter lock or not.

     New in version 2.7.


File: python.info,  Node: Profiling and Tracing,  Next: Advanced Debugger Support,  Prev: Asynchronous Notifications,  Up: Initialization Finalization and Threads

7.8.6 Profiling and Tracing
---------------------------

The Python interpreter provides some low-level support for attaching
profiling and execution tracing facilities.  These are used for
profiling, debugging, and coverage analysis tools.

  Starting with Python 2.2, the implementation of this facility was
substantially revised, and an interface from C was added.  This C
interface allows the profiling or tracing code to avoid the overhead of
calling through Python-level callable objects, making a direct C
function call instead.  The essential attributes of the facility have
not changed; the interface allows trace functions to be installed
per-thread, and the basic events reported to the trace function are the
same as had been reported to the Python-level trace functions in
previous versions.

 -- C Type: int (*Py_tracefunc) (PyObject *obj, PyFrameObject *frame,
          int what, PyObject *arg)
     The type of the trace function registered using *note
     PyEval_SetProfile(): 494. and *note PyEval_SetTrace(): 495. The
     first parameter is the object passed to the registration function
     as _obj_, _frame_ is the frame object to which the event pertains,
     _what_ is one of the constants `PyTrace_CALL',
     `PyTrace_EXCEPTION', `PyTrace_LINE', `PyTrace_RETURN',
     `PyTrace_C_CALL', `PyTrace_C_EXCEPTION', or `PyTrace_C_RETURN',
     and _arg_ depends on the value of _what_:

     Value of _what_                    Meaning of _arg_
     ------------------------------------------------------------------------------ 
     `PyTrace_CALL'                     Always _NULL_.
     `PyTrace_EXCEPTION'                Exception information as returned by
                                        *note sys.exc_info(): 2ec.
     `PyTrace_LINE'                     Always _NULL_.
     `PyTrace_RETURN'                   Value being returned to the caller, or
                                        _NULL_ if caused by an exception.
     `PyTrace_C_CALL'                   Function object being called.
     `PyTrace_C_EXCEPTION'              Function object being called.
     `PyTrace_C_RETURN'                 Function object being called.


 -- C Variable: int PyTrace_CALL
     The value of the _what_ parameter to a *note Py_tracefunc: 2dc3.
     function when a new call to a function or method is being
     reported, or a new entry into a generator.  Note that the creation
     of the iterator for a generator function is not reported as there
     is no control transfer to the Python bytecode in the corresponding
     frame.

 -- C Variable: int PyTrace_EXCEPTION
     The value of the _what_ parameter to a *note Py_tracefunc: 2dc3.
     function when an exception has been raised.  The callback function
     is called with this value for _what_ when after any bytecode is
     processed after which the exception becomes set within the frame
     being executed.  The effect of this is that as exception
     propagation causes the Python stack to unwind, the callback is
     called upon return to each frame as the exception propagates.
     Only trace functions receives these events; they are not needed by
     the profiler.

 -- C Variable: int PyTrace_LINE
     The value passed as the _what_ parameter to a trace function (but
     not a profiling function) when a line-number event is being
     reported.

 -- C Variable: int PyTrace_RETURN
     The value for the _what_ parameter to *note Py_tracefunc: 2dc3.
     functions when a call is returning without propagating an
     exception.

 -- C Variable: int PyTrace_C_CALL
     The value for the _what_ parameter to *note Py_tracefunc: 2dc3.
     functions when a C function is about to be called.

 -- C Variable: int PyTrace_C_EXCEPTION
     The value for the _what_ parameter to *note Py_tracefunc: 2dc3.
     functions when a C function has raised an exception.

 -- C Variable: int PyTrace_C_RETURN
     The value for the _what_ parameter to *note Py_tracefunc: 2dc3.
     functions when a C function has returned.

 -- C Function: void PyEval_SetProfile (Py_tracefunc func,
          PyObject *obj)
     Set the profiler function to _func_.  The _obj_ parameter is
     passed to the function as its first parameter, and may be any
     Python object, or _NULL_.  If the profile function needs to
     maintain state, using a different value for _obj_ for each thread
     provides a convenient and thread-safe place to store it.  The
     profile function is called for all monitored events except the
     line-number events.

 -- C Function: void PyEval_SetTrace (Py_tracefunc func, PyObject *obj)
     Set the tracing function to _func_.  This is similar to *note
     PyEval_SetProfile(): 494, except the tracing function does receive
     line-number events.

 -- C Function: PyObject* PyEval_GetCallStats (PyObject *self)
     Return a tuple of function call counts.  There are constants
     defined for the positions within the tuple:

     Name                                Value
     ------------------------------------------------ 
     `PCALL_ALL'                         0
     `PCALL_FUNCTION'                    1
     `PCALL_FAST_FUNCTION'               2
     `PCALL_FASTER_FUNCTION'             3
     `PCALL_METHOD'                      4
     `PCALL_BOUND_METHOD'                5
     `PCALL_CFUNCTION'                   6
     `PCALL_TYPE'                        7
     `PCALL_GENERATOR'                   8
     `PCALL_OTHER'                       9
     `PCALL_POP'                         10

     `PCALL_FAST_FUNCTION' means no argument tuple needs to be created.
     `PCALL_FASTER_FUNCTION' means that the fast-path frame setup code
     is used.

     If there is a method call where the call can be optimized by
     changing the argument tuple and calling the function directly, it
     gets recorded twice.

     This function is only present if Python is compiled with
     `CALL_PROFILE' defined.


File: python.info,  Node: Advanced Debugger Support,  Prev: Profiling and Tracing,  Up: Initialization Finalization and Threads

7.8.7 Advanced Debugger Support
-------------------------------

These functions are only intended to be used by advanced debugging
tools.

 -- C Function: PyInterpreterState* PyInterpreterState_Head ()
     Return the interpreter state object at the head of the list of all
     such objects.

     New in version 2.2.

 -- C Function: PyInterpreterState* PyInterpreterState_Next
          (PyInterpreterState *interp)
     Return the next interpreter state object after _interp_ from the
     list of all such objects.

     New in version 2.2.

 -- C Function: PyThreadState * PyInterpreterState_ThreadHead
          (PyInterpreterState *interp)
     Return the a pointer to the first *note PyThreadState: 2da3.
     object in the list of threads associated with the interpreter
     _interp_.

     New in version 2.2.

 -- C Function: PyThreadState* PyThreadState_Next
          (PyThreadState *tstate)
     Return the next thread state object after _tstate_ from the list
     of all such objects belonging to the same *note
     PyInterpreterState: 2daa. object.

     New in version 2.2.


File: python.info,  Node: Memory Management,  Next: Object Implementation Support,  Prev: Initialization Finalization and Threads,  Up: Python/C API Reference Manual

7.9 Memory Management
=====================

* Menu:

* Overview::
* Memory Interface::
* Examples: Examples<23>.


File: python.info,  Node: Overview,  Next: Memory Interface,  Up: Memory Management

7.9.1 Overview
--------------

Memory management in Python involves a private heap containing all
Python objects and data structures. The management of this private heap
is ensured internally by the _Python memory manager_.  The Python
memory manager has different components which deal with various dynamic
storage management aspects, like sharing, segmentation, preallocation
or caching.

  At the lowest level, a raw memory allocator ensures that there is
enough room in the private heap for storing all Python-related data by
interacting with the memory manager of the operating system. On top of
the raw memory allocator, several object-specific allocators operate on
the same heap and implement distinct memory management policies adapted
to the peculiarities of every object type. For example, integer objects
are managed differently within the heap than strings, tuples or
dictionaries because integers imply different storage requirements and
speed/space tradeoffs. The Python memory manager thus delegates some of
the work to the object-specific allocators, but ensures that the latter
operate within the bounds of the private heap.

  It is important to understand that the management of the Python heap
is performed by the interpreter itself and that the user has no control
over it, even if she regularly manipulates object pointers to memory
blocks inside that heap.  The allocation of heap space for Python
objects and other internal buffers is performed on demand by the Python
memory manager through the Python/C API functions listed in this
document.

  To avoid memory corruption, extension writers should never try to
operate on Python objects with the functions exported by the C library:
`malloc()', `calloc()', `realloc()' and `free()'.  This will result in
mixed calls between the C allocator and the Python memory manager with
fatal consequences, because they implement different algorithms and
operate on different heaps.  However, one may safely allocate and
release memory blocks with the C library allocator for individual
purposes, as shown in the following example:

    PyObject *res;
    char *buf = (char *) malloc(BUFSIZ); /* for I/O */

    if (buf == NULL)
        return PyErr_NoMemory();
    ...Do some I/O operation involving buf...
    res = PyString_FromString(buf);
    free(buf); /* malloc'ed */
    return res;

In this example, the memory request for the I/O buffer is handled by
the C library allocator. The Python memory manager is involved only in
the allocation of the string object returned as a result.

  In most situations, however, it is recommended to allocate memory
from the Python heap specifically because the latter is under control
of the Python memory manager. For example, this is required when the
interpreter is extended with new object types written in C. Another
reason for using the Python heap is the desire to _inform_ the Python
memory manager about the memory needs of the extension module. Even
when the requested memory is used exclusively for internal,
highly-specific purposes, delegating all memory requests to the Python
memory manager causes the interpreter to have a more accurate image of
its memory footprint as a whole. Consequently, under certain
circumstances, the Python memory manager may or may not trigger
appropriate actions, like garbage collection, memory compaction or
other preventive procedures. Note that by using the C library allocator
as shown in the previous example, the allocated memory for the I/O
buffer escapes completely the Python memory manager.


File: python.info,  Node: Memory Interface,  Next: Examples<23>,  Prev: Overview,  Up: Memory Management

7.9.2 Memory Interface
----------------------

The following function sets, modeled after the ANSI C standard, but
specifying behavior when requesting zero bytes, are available for
allocating and releasing memory from the Python heap:

 -- C Function: void* PyMem_Malloc (size_t n)
     Allocates _n_ bytes and returns a pointer of type `void*' to the
     allocated memory, or _NULL_ if the request fails. Requesting zero
     bytes returns a distinct non-_NULL_ pointer if possible, as if
     `PyMem_Malloc(1)' had been called instead. The memory will not
     have been initialized in any way.

 -- C Function: void* PyMem_Realloc (void *p, size_t n)
     Resizes the memory block pointed to by _p_ to _n_ bytes. The
     contents will be unchanged to the minimum of the old and the new
     sizes. If _p_ is _NULL_, the call is equivalent to
     `PyMem_Malloc(n)'; else if _n_ is equal to zero, the memory block
     is resized but is not freed, and the returned pointer is
     non-_NULL_.  Unless _p_ is _NULL_, it must have been returned by a
     previous call to *note PyMem_Malloc(): 3d6. or *note
     PyMem_Realloc(): 3d7. If the request fails, *note PyMem_Realloc():
     3d7. returns _NULL_ and _p_ remains a valid pointer to the
     previous memory area.

 -- C Function: void PyMem_Free (void *p)
     Frees the memory block pointed to by _p_, which must have been
     returned by a previous call to *note PyMem_Malloc(): 3d6. or *note
     PyMem_Realloc(): 3d7.  Otherwise, or if `PyMem_Free(p)' has been
     called before, undefined behavior occurs. If _p_ is _NULL_, no
     operation is performed.

  The following type-oriented macros are provided for convenience.
Note  that _TYPE_ refers to any C type.

 -- C Function: TYPE* PyMem_New (TYPE, size_t n)
     Same as *note PyMem_Malloc(): 3d6, but allocates `(n *
     sizeof(TYPE))' bytes of memory.  Returns a pointer cast to
     `TYPE*'.  The memory will not have been initialized in any way.

 -- C Function: TYPE* PyMem_Resize (void *p, TYPE, size_t n)
     Same as *note PyMem_Realloc(): 3d7, but the memory block is
     resized to `(n * sizeof(TYPE))' bytes.  Returns a pointer cast to
     `TYPE*'. On return, _p_ will be a pointer to the new memory area,
     or _NULL_ in the event of failure.  This is a C preprocessor
     macro; p is always reassigned.  Save the original value of p to
     avoid losing memory when handling errors.

 -- C Function: void PyMem_Del (void *p)
     Same as *note PyMem_Free(): 3d8.

  In addition, the following macro sets are provided for calling the
Python memory allocator directly, without involving the C API functions
listed above. However, note that their use does not preserve binary
compatibility across Python versions and is therefore deprecated in
extension modules.

  `PyMem_MALLOC()', `PyMem_REALLOC()', `PyMem_FREE()'.

  `PyMem_NEW()', `PyMem_RESIZE()', `PyMem_DEL()'.


File: python.info,  Node: Examples<23>,  Prev: Memory Interface,  Up: Memory Management

7.9.3 Examples
--------------

Here is the example from section *note Overview: 2dd2, rewritten so
that the I/O buffer is allocated from the Python heap by using the
first function set:

    PyObject *res;
    char *buf = (char *) PyMem_Malloc(BUFSIZ); /* for I/O */

    if (buf == NULL)
        return PyErr_NoMemory();
    /* ...Do some I/O operation involving buf... */
    res = PyString_FromString(buf);
    PyMem_Free(buf); /* allocated with PyMem_Malloc */
    return res;

The same code using the type-oriented function set:

    PyObject *res;
    char *buf = PyMem_New(char, BUFSIZ); /* for I/O */

    if (buf == NULL)
        return PyErr_NoMemory();
    /* ...Do some I/O operation involving buf... */
    res = PyString_FromString(buf);
    PyMem_Del(buf); /* allocated with PyMem_New */
    return res;

Note that in the two examples above, the buffer is always manipulated
via functions belonging to the same set. Indeed, it is required to use
the same memory API family for a given memory block, so that the risk
of mixing different allocators is reduced to a minimum. The following
code sequence contains two errors, one of which is labeled as _fatal_
because it mixes two different allocators operating on different heaps.

    char *buf1 = PyMem_New(char, BUFSIZ);
    char *buf2 = (char *) malloc(BUFSIZ);
    char *buf3 = (char *) PyMem_Malloc(BUFSIZ);
    ...
    PyMem_Del(buf3);  /* Wrong -- should be PyMem_Free() */
    free(buf2);       /* Right -- allocated via malloc() */
    free(buf1);       /* Fatal -- should be PyMem_Del()  */

In addition to the functions aimed at handling raw memory blocks from
the Python heap, objects in Python are allocated and released with
*note PyObject_New(): 464, *note PyObject_NewVar(): 465. and *note
PyObject_Del(): 466.

  These will be explained in the next chapter on defining and
implementing new object types in C.


File: python.info,  Node: Object Implementation Support,  Prev: Memory Management,  Up: Python/C API Reference Manual

7.10 Object Implementation Support
==================================

This chapter describes the functions, types, and macros used when
defining new object types.

* Menu:

* Allocating Objects on the Heap::
* Common Object Structures::
* Type Objects: Type Objects<3>.
* Number Object Structures::
* Mapping Object Structures::
* Sequence Object Structures::
* Buffer Object Structures::
* Supporting Cyclic Garbage Collection::


File: python.info,  Node: Allocating Objects on the Heap,  Next: Common Object Structures,  Up: Object Implementation Support

7.10.1 Allocating Objects on the Heap
-------------------------------------

 -- C Function: PyObject* _PyObject_New (PyTypeObject *type)
     Return value: New reference.

 -- C Function: PyVarObject* _PyObject_NewVar (PyTypeObject *type,
          Py_ssize_t size)
     Return value: New reference.

     Changed in version 2.5: This function used an `int' type for
     _size_. This might require changes in your code for properly
     supporting 64-bit systems.

 -- C Function: void _PyObject_Del (PyObject *op)

 -- C Function: PyObject* PyObject_Init (PyObject *op,
          PyTypeObject *type)
     Return value: Borrowed reference.

     Initialize a newly-allocated object _op_ with its type and initial
     reference.  Returns the initialized object.  If _type_ indicates
     that the object participates in the cyclic garbage detector, it is
     added to the detector's set of observed objects. Other fields of
     the object are not affected.

 -- C Function: PyVarObject* PyObject_InitVar (PyVarObject *op,
          PyTypeObject *type, Py_ssize_t size)
     Return value: Borrowed reference.

     This does everything *note PyObject_Init(): 2de3. does, and also
     initializes the length information for a variable-size object.

     Changed in version 2.5: This function used an `int' type for
     _size_. This might require changes in your code for properly
     supporting 64-bit systems.

 -- C Function: TYPE* PyObject_New (TYPE, PyTypeObject *type)
     Return value: New reference.

     Allocate a new Python object using the C structure type _TYPE_ and
     the Python type object _type_.  Fields not defined by the Python
     object header are not initialized; the object's reference count
     will be one.  The size of the memory allocation is determined from
     the `tp_basicsize' field of the type object.

 -- C Function: TYPE* PyObject_NewVar (TYPE, PyTypeObject *type,
          Py_ssize_t size)
     Return value: New reference.

     Allocate a new Python object using the C structure type _TYPE_ and
     the Python type object _type_.  Fields not defined by the Python
     object header are not initialized.  The allocated memory allows
     for the _TYPE_ structure plus _size_ fields of the size given by
     the `tp_itemsize' field of _type_.  This is useful for
     implementing objects like tuples, which are able to determine
     their size at construction time.  Embedding the array of fields
     into the same allocation decreases the number of allocations,
     improving the memory management efficiency.

     Changed in version 2.5: This function used an `int' type for
     _size_. This might require changes in your code for properly
     supporting 64-bit systems.

 -- C Function: void PyObject_Del (PyObject *op)
     Releases memory allocated to an object using *note PyObject_New():
     464. or *note PyObject_NewVar(): 465.  This is normally called
     from the `tp_dealloc' handler specified in the object's type.  The
     fields of the object should not be accessed after this call as the
     memory is no longer a valid Python object.

 -- C Function: PyObject* Py_InitModule (char *name,
          PyMethodDef *methods)
     Return value: Borrowed reference.

     Create a new module object based on a name and table of functions,
     returning the new module object.

     Changed in version 2.3: Older versions of Python did not support
     _NULL_ as the value for the _methods_ argument.

 -- C Function: PyObject* Py_InitModule3 (char *name,
          PyMethodDef *methods, char *doc)
     Return value: Borrowed reference.

     Create a new module object based on a name and table of functions,
     returning the new module object.  If _doc_ is non-_NULL_, it will
     be used to define the docstring for the module.

     Changed in version 2.3: Older versions of Python did not support
     _NULL_ as the value for the _methods_ argument.

 -- C Function: PyObject* Py_InitModule4 (char *name,
          PyMethodDef *methods, char *doc, PyObject *self, int apiver)
     Return value: Borrowed reference.

     Create a new module object based on a name and table of functions,
     returning the new module object.  If _doc_ is non-_NULL_, it will
     be used to define the docstring for the module.  If _self_ is
     non-_NULL_, it will passed to the functions of the module as their
     (otherwise _NULL_) first parameter.  (This was added as an
     experimental feature, and there are no known uses in the current
     version of Python.)  For _apiver_, the only value which should be
     passed is defined by the constant `PYTHON_API_VERSION'.

          Note: Most uses of this function should probably be using the
          *note Py_InitModule3(): 29c0. instead; only use this if you
          are sure you need it.

     Changed in version 2.3: Older versions of Python did not support
     _NULL_ as the value for the _methods_ argument.

 -- C Variable: PyObject _Py_NoneStruct
     Object which is visible in Python as `None'.  This should only be
     accessed using the `Py_None' macro, which evaluates to a pointer
     to this object.


File: python.info,  Node: Common Object Structures,  Next: Type Objects<3>,  Prev: Allocating Objects on the Heap,  Up: Object Implementation Support

7.10.2 Common Object Structures
-------------------------------

There are a large number of structures which are used in the definition
of object types for Python.  This section describes these structures
and how they are used.

  All Python objects ultimately share a small number of fields at the
beginning of the object's representation in memory.  These are
represented by the *note PyObject: 39f. and *note PyVarObject: 2dea.
types, which are defined, in turn, by the expansions of some macros
also used, whether directly or indirectly, in the definition of all
other Python objects.

 -- C Type: PyObject
     All object types are extensions of this type.  This is a type which
     contains the information Python needs to treat a pointer to an
     object as an object.  In a normal "release" build, it contains
     only the object's reference count and a pointer to the
     corresponding type object.  It corresponds to the fields defined
     by the expansion of the `PyObject_HEAD' macro.

 -- C Type: PyVarObject
     This is an extension of *note PyObject: 39f. that adds the
     `ob_size' field.  This is only used for objects that have some
     notion of _length_.  This type does not often appear in the
     Python/C API.  It corresponds to the fields defined by the
     expansion of the `PyObject_VAR_HEAD' macro.

  These macros are used in the definition of *note PyObject: 39f. and
*note PyVarObject: 2dea.:

 -- C Macro: PyObject_HEAD
     This is a macro which expands to the declarations of the fields of
     the *note PyObject: 39f. type; it is used when declaring new types
     which represent objects without a varying length.  The specific
     fields it expands to depend on the definition of `Py_TRACE_REFS'.
     By default, that macro is not defined, and *note PyObject_HEAD:
     29c7. expands to:

         Py_ssize_t ob_refcnt;
         PyTypeObject *ob_type;

     When `Py_TRACE_REFS' is defined, it expands to:

         PyObject *_ob_next, *_ob_prev;
         Py_ssize_t ob_refcnt;
         PyTypeObject *ob_type;



 -- C Macro: PyObject_VAR_HEAD
     This is a macro which expands to the declarations of the fields of
     the *note PyVarObject: 2dea. type; it is used when declaring new
     types which represent objects with a length that varies from
     instance to instance.  This macro always expands to:

         PyObject_HEAD
         Py_ssize_t ob_size;

     Note that *note PyObject_HEAD: 29c7. is part of the expansion, and
     that its own expansion varies depending on the definition of
     `Py_TRACE_REFS'.

 -- C Macro: PyObject_HEAD_INIT (type)
     This is a macro which expands to initialization values for a new
     *note PyObject: 39f. type.  This macro expands to:

         _PyObject_EXTRA_INIT
         1, type,



 -- C Macro: PyVarObject_HEAD_INIT (type, size)
     This is a macro which expands to initialization values for a new
     *note PyVarObject: 2dea. type, including the `ob_size' field.
     This macro expands to:

         _PyObject_EXTRA_INIT
         1, type, size,



 -- C Type: PyCFunction
     Type of the functions used to implement most Python callables in C.
     Functions of this type take two *note PyObject*: 39f. parameters
     and return one such value.  If the return value is _NULL_, an
     exception shall have been set.  If not _NULL_, the return value is
     interpreted as the return value of the function as exposed in
     Python.  The function must return a new reference.

 -- C Type: PyMethodDef
     Structure used to describe a method of an extension type.  This
     structure has four fields:

     Field                  C Type            Meaning
     ----------------------------------------------------------------------------- 
     `ml_name'              char *            name of the method
     `ml_meth'              PyCFunction       pointer to the C implementation
     `ml_flags'             int               flag bits indicating how the call
                                              should be constructed
     `ml_doc'               char *            points to the contents of the
                                              docstring


  The `ml_meth' is a C function pointer.  The functions may be of
different types, but they always return *note PyObject*: 39f.  If the
function is not of the *note PyCFunction: 416, the compiler will
require a cast in the method table.  Even though *note PyCFunction:
416. defines the first parameter as *note PyObject*: 39f, it is common
that the method implementation uses a the specific C type of the _self_
object.

  The `ml_flags' field is a bitfield which can include the following
flags.  The individual flags indicate either a calling convention or a
binding convention.  Of the calling convention flags, only *note
METH_VARARGS: 4a3. and *note METH_KEYWORDS: 2987. can be combined (but
note that *note METH_KEYWORDS: 2987.  alone is equivalent to
`METH_VARARGS | METH_KEYWORDS'). Any of the calling convention flags
can be combined with a binding flag.

 -- Data: METH_VARARGS
     This is the typical calling convention, where the methods have the
     type *note PyCFunction: 416. The function expects two *note
     PyObject*: 39f. values.  The first one is the _self_ object for
     methods; for module functions, it is the module object.  The
     second parameter (often called _args_) is a tuple object
     representing all arguments.  This parameter is typically processed
     using *note PyArg_ParseTuple(): 314. or *note PyArg_UnpackTuple():
     4a1.

 -- Data: METH_KEYWORDS
     Methods with these flags must be of type `PyCFunctionWithKeywords'.
     The function expects three parameters: _self_, _args_, and a
     dictionary of all the keyword arguments.  The flag is typically
     combined with *note METH_VARARGS: 4a3, and the parameters are
     typically processed using *note PyArg_ParseTupleAndKeywords(): 415.

 -- Data: METH_NOARGS
     Methods without parameters don't need to check whether arguments
     are given if they are listed with the *note METH_NOARGS: 468.
     flag.  They need to be of type *note PyCFunction: 416.  The first
     parameter is typically named `self' and will hold a reference to
     the module or object instance.  In all cases the second parameter
     will be _NULL_.

 -- Data: METH_O
     Methods with a single object argument can be listed with the *note
     METH_O: 4a2.  flag, instead of invoking *note PyArg_ParseTuple():
     314. with a `"O"' argument.  They have the type *note PyCFunction:
     416, with the _self_ parameter, and a *note PyObject*: 39f.
     parameter representing the single argument.

 -- Data: METH_OLDARGS
     This calling convention is deprecated.  The method must be of type
     *note PyCFunction: 416.  The second argument is _NULL_ if no
     arguments are given, a single object if exactly one argument is
     given, and a tuple of objects if more than one argument is given.
     There is no way for a function using this convention to
     distinguish between a call with multiple arguments and a call with
     a tuple as the only argument.

  These two constants are not used to indicate the calling convention
but the binding when use with methods of classes.  These may not be
used for functions defined for modules.  At most one of these flags may
be set for any given method.

 -- Data: METH_CLASS
     The method will be passed the type object as the first parameter
     rather than an instance of the type.  This is used to create
     _class methods_, similar to what is created when using the *note
     classmethod(): 3ef. built-in function.

     New in version 2.3.

 -- Data: METH_STATIC
     The method will be passed _NULL_ as the first parameter rather
     than an instance of the type.  This is used to create _static
     methods_, similar to what is created when using the *note
     staticmethod(): 3ee. built-in function.

     New in version 2.3.

  One other constant controls whether a method is loaded in place of
another definition with the same method name.

 -- Data: METH_COEXIST
     The method will be loaded in place of existing definitions.
     Without _METH_COEXIST_, the default is to skip repeated
     definitions.  Since slot wrappers are loaded before the method
     table, the existence of a _sq_contains_ slot, for example, would
     generate a wrapped method named *note __contains__(): 31b. and
     preclude the loading of a corresponding PyCFunction with the same
     name.  With the flag defined, the PyCFunction will be loaded in
     place of the wrapper object and will co-exist with the slot.  This
     is helpful because calls to PyCFunctions are optimized more than
     wrapper object calls.

     New in version 2.4.

 -- C Type: PyMemberDef
     Structure which describes an attribute of a type which corresponds
     to a C struct member.  Its fields are:

     Field                  C Type            Meaning
     ----------------------------------------------------------------------------- 
     `name'                 char *            name of the member
     *note type: 487.       int               the type of the member in the C
                                              struct
     `offset'               Py_ssize_t        the offset in bytes that the
                                              member is located on the type's
                                              object struct
     `flags'                int               flag bits indicating if the field
                                              should be read-only or writable
     `doc'                  char *            points to the contents of the
                                              docstring

     *note type: 487. can be one of many `T_' macros corresponding to
     various C types.  When the member is accessed in Python, it will
     be converted to the equivalent Python type.

     Macro name          C type
     ------------------------------------------- 
     T_SHORT             short
     T_INT               int
     T_LONG              long
     T_FLOAT             float
     T_DOUBLE            double
     T_STRING            char *
     T_OBJECT            PyObject *
     T_OBJECT_EX         PyObject *
     T_CHAR              char
     T_BYTE              char
     T_UBYTE             unsigned char
     T_UINT              unsigned int
     T_USHORT            unsigned short
     T_ULONG             unsigned long
     T_BOOL              char
     T_LONGLONG          long long
     T_ULONGLONG         unsigned long long
     T_PYSSIZET          Py_ssize_t

     `T_OBJECT' and `T_OBJECT_EX' differ in that `T_OBJECT' returns
     `None' if the member is _NULL_ and `T_OBJECT_EX' raises an *note
     AttributeError: 1f5.  Try to use `T_OBJECT_EX' over `T_OBJECT'
     because `T_OBJECT_EX' handles use of the *note del: 55f. statement
     on that attribute more correctly than `T_OBJECT'.

     `flags' can be 0 for write and read access or `READONLY' for
     read-only access.  Using `T_STRING' for *note type: 487. implies
     `READONLY'.  Only `T_OBJECT' and `T_OBJECT_EX' members can be
     deleted.  (They are set to _NULL_).

 -- C Function: PyObject* Py_FindMethod (PyMethodDef table[],
          PyObject *ob, char *name)
     Return value: New reference.

     Return a bound method object for an extension type implemented in
     C.  This can be useful in the implementation of a `tp_getattro' or
     `tp_getattr' handler that does not use the *note
     PyObject_GenericGetAttr(): 2aee. function.


File: python.info,  Node: Type Objects<3>,  Next: Number Object Structures,  Prev: Common Object Structures,  Up: Object Implementation Support

7.10.3 Type Objects
-------------------

Perhaps one of the most important structures of the Python object
system is the structure that defines a new type: the *note
PyTypeObject: 29b9. structure.  Type objects can be handled using any
of the `PyObject_*()' or `PyType_*()' functions, but do not offer much
that's interesting to most Python applications. These objects are
fundamental to how objects behave, so they are very important to the
interpreter itself and to any extension module that implements new
types.

  Type objects are fairly large compared to most of the standard types.
The reason for the size is that each type object stores a large number
of values, mostly C function pointers, each of which implements a small
part of the type's functionality.  The fields of the type object are
examined in detail in this section.  The fields will be described in
the order in which they occur in the structure.

  Typedefs: unaryfunc, binaryfunc, ternaryfunc, inquiry, coercion,
intargfunc, intintargfunc, intobjargproc, intintobjargproc,
objobjargproc, destructor, freefunc, printfunc, getattrfunc,
getattrofunc, setattrfunc, setattrofunc, cmpfunc, reprfunc, hashfunc

  The structure definition for *note PyTypeObject: 29b9. can be found in
`Include/object.h'.  For convenience of reference, this repeats the
definition found there:

    typedef struct _typeobject {
        PyObject_VAR_HEAD
        char *tp_name; /* For printing, in format "<module>.<name>" */
        int tp_basicsize, tp_itemsize; /* For allocation */

        /* Methods to implement standard operations */

        destructor tp_dealloc;
        printfunc tp_print;
        getattrfunc tp_getattr;
        setattrfunc tp_setattr;
        cmpfunc tp_compare;
        reprfunc tp_repr;

        /* Method suites for standard classes */

        PyNumberMethods *tp_as_number;
        PySequenceMethods *tp_as_sequence;
        PyMappingMethods *tp_as_mapping;

        /* More standard operations (here for binary compatibility) */

        hashfunc tp_hash;
        ternaryfunc tp_call;
        reprfunc tp_str;
        getattrofunc tp_getattro;
        setattrofunc tp_setattro;

        /* Functions to access object as input/output buffer */
        PyBufferProcs *tp_as_buffer;

        /* Flags to define presence of optional/expanded features */
        long tp_flags;

        char *tp_doc; /* Documentation string */

        /* Assigned meaning in release 2.0 */
        /* call function for all accessible objects */
        traverseproc tp_traverse;

        /* delete references to contained objects */
        inquiry tp_clear;

        /* Assigned meaning in release 2.1 */
        /* rich comparisons */
        richcmpfunc tp_richcompare;

        /* weak reference enabler */
        long tp_weaklistoffset;

        /* Added in release 2.2 */
        /* Iterators */
        getiterfunc tp_iter;
        iternextfunc tp_iternext;

        /* Attribute descriptor and subclassing stuff */
        struct PyMethodDef *tp_methods;
        struct PyMemberDef *tp_members;
        struct PyGetSetDef *tp_getset;
        struct _typeobject *tp_base;
        PyObject *tp_dict;
        descrgetfunc tp_descr_get;
        descrsetfunc tp_descr_set;
        long tp_dictoffset;
        initproc tp_init;
        allocfunc tp_alloc;
        newfunc tp_new;
        freefunc tp_free; /* Low-level free-memory routine */
        inquiry tp_is_gc; /* For PyObject_IS_GC */
        PyObject *tp_bases;
        PyObject *tp_mro; /* method resolution order */
        PyObject *tp_cache;
        PyObject *tp_subclasses;
        PyObject *tp_weaklist;

    } PyTypeObject;

The type object structure extends the *note PyVarObject: 2dea.
structure. The `ob_size' field is used for dynamic types (created by
`type_new()', usually called from a class statement). Note that *note
PyType_Type: 2b73. (the metatype) initializes `tp_itemsize', which
means that its instances (i.e.  type objects) _must_ have the `ob_size'
field.

 -- C Member: PyObject* PyObject._ob_next
 -- C Member: PyObject* PyObject._ob_prev
     These fields are only present when the macro `Py_TRACE_REFS' is
     defined.  Their initialization to _NULL_ is taken care of by the
     `PyObject_HEAD_INIT' macro.  For statically allocated objects,
     these fields always remain _NULL_.  For dynamically allocated
     objects, these two fields are used to link the object into a
     doubly-linked list of _all_ live objects on the heap.  This could
     be used for various debugging purposes; currently the only use is
     to print the objects that are still alive at the end of a run when
     the environment variable *note PYTHONDUMPREFS: 649. is set.

     These fields are not inherited by subtypes.

 -- C Member: Py_ssize_t PyObject.ob_refcnt
     This is the type object's reference count, initialized to `1' by
     the `PyObject_HEAD_INIT' macro.  Note that for statically
     allocated type objects, the type's instances (objects whose
     `ob_type' points back to the type) do _not_ count as references.
     But for dynamically allocated type objects, the instances _do_
     count as references.

     This field is not inherited by subtypes.

     Changed in version 2.5: This field used to be an `int' type. This
     might require changes in your code for properly supporting 64-bit
     systems.

 -- C Member: PyTypeObject* PyObject.ob_type
     This is the type's type, in other words its metatype.  It is
     initialized by the argument to the `PyObject_HEAD_INIT' macro, and
     its value should normally be `&PyType_Type'.  However, for
     dynamically loadable extension modules that must be usable on
     Windows (at least), the compiler complains that this is not a valid
     initializer.  Therefore, the convention is to pass _NULL_ to the
     `PyObject_HEAD_INIT' macro and to initialize this field explicitly
     at the start of the module's initialization function, before doing
     anything else.  This is typically done like this:

         Foo_Type.ob_type = &PyType_Type;

     This should be done before any instances of the type are created.
     *note PyType_Ready(): 29ba. checks if `ob_type' is _NULL_, and if
     so, initializes it: in Python 2.2, it is set to `&PyType_Type'; in
     Python 2.2.1 and later it is initialized to the `ob_type' field of
     the base class.  *note PyType_Ready(): 29ba. will not change this
     field if it is non-zero.

     In Python 2.2, this field is not inherited by subtypes.  In 2.2.1,
     and in 2.3 and beyond, it is inherited by subtypes.

 -- C Member: Py_ssize_t PyVarObject.ob_size
     For statically allocated type objects, this should be initialized
     to zero.  For dynamically allocated type objects, this field has a
     special internal meaning.

     This field is not inherited by subtypes.

 -- C Member: char* PyTypeObject.tp_name
     Pointer to a NUL-terminated string containing the name of the
     type. For types that are accessible as module globals, the string
     should be the full module name, followed by a dot, followed by the
     type name; for built-in types, it should be just the type name.
     If the module is a submodule of a package, the full package name
     is part of the full module name.  For example, a type named `T'
     defined in module `M' in subpackage `Q' in package `P' should have
     the `tp_name' initializer `"P.Q.M.T"'.

     For dynamically allocated type objects, this should just be the
     type name, and the module name explicitly stored in the type dict
     as the value for key `'__module__''.

     For statically allocated type objects, the tp_name field should
     contain a dot.  Everything before the last dot is made accessible
     as the `__module__' attribute, and everything after the last dot
     is made accessible as the `__name__' attribute.

     If no dot is present, the entire `tp_name' field is made
     accessible as the `__name__' attribute, and the `__module__'
     attribute is undefined (unless explicitly set in the dictionary,
     as explained above).  This means your type will be impossible to
     pickle.

     This field is not inherited by subtypes.

 -- C Member: Py_ssize_t PyTypeObject.tp_basicsize
 -- C Member: Py_ssize_t PyTypeObject.tp_itemsize
     These fields allow calculating the size in bytes of instances of
     the type.

     There are two kinds of types: types with fixed-length instances
     have a zero `tp_itemsize' field, types with variable-length
     instances have a non-zero `tp_itemsize' field.  For a type with
     fixed-length instances, all instances have the same size, given in
     `tp_basicsize'.

     For a type with variable-length instances, the instances must have
     an `ob_size' field, and the instance size is `tp_basicsize' plus N
     times `tp_itemsize', where N is the "length" of the object.  The
     value of N is typically stored in the instance's `ob_size' field.
     There are exceptions:  for example, long ints use a negative
     `ob_size' to indicate a negative number, and N is `abs(ob_size)'
     there.  Also, the presence of an `ob_size' field in the instance
     layout doesn't mean that the instance structure is variable-length
     (for example, the structure for the list type has fixed-length
     instances, yet those instances have a meaningful `ob_size' field).

     The basic size includes the fields in the instance declared by the
     macro *note PyObject_HEAD: 29c7. or *note PyObject_VAR_HEAD: 2deb.
     (whichever is used to declare the instance struct) and this in
     turn includes the `_ob_prev' and `_ob_next' fields if they are
     present.  This means that the only correct way to get an
     initializer for the `tp_basicsize' is to use the `sizeof' operator
     on the struct used to declare the instance layout.  The basic size
     does not include the GC header size (this is new in Python 2.2; in
     2.1 and 2.0, the GC header size was included in `tp_basicsize').

     These fields are inherited separately by subtypes.  If the base
     type has a non-zero `tp_itemsize', it is generally not safe to set
     `tp_itemsize' to a different non-zero value in a subtype (though
     this depends on the implementation of the base type).

     A note about alignment: if the variable items require a particular
     alignment, this should be taken care of by the value of
     `tp_basicsize'.  Example: suppose a type implements an array of
     `double'. `tp_itemsize' is `sizeof(double)'. It is the
     programmer's responsibility that `tp_basicsize' is a multiple of
     `sizeof(double)' (assuming this is the alignment requirement for
     `double').

 -- C Member: destructor PyTypeObject.tp_dealloc
     A pointer to the instance destructor function.  This function must
     be defined unless the type guarantees that its instances will
     never be deallocated (as is the case for the singletons `None' and
     `Ellipsis').

     The destructor function is called by the *note Py_DECREF(): 2981.
     and *note Py_XDECREF(): 2980. macros when the new reference count
     is zero.  At this point, the instance is still in existence, but
     there are no references to it.  The destructor function should
     free all references which the instance owns, free all memory
     buffers owned by the instance (using the freeing function
     corresponding to the allocation function used to allocate the
     buffer), and finally (as its last action) call the type's
     `tp_free' function.  If the type is not subtypable (doesn't have
     the *note Py_TPFLAGS_BASETYPE: 29bf. flag bit set), it is
     permissible to call the object deallocator directly instead of via
     `tp_free'.  The object deallocator should be the one used to
     allocate the instance; this is normally *note PyObject_Del(): 466.
     if the instance was allocated using *note PyObject_New(): 464. or
     `PyObject_VarNew()', or *note PyObject_GC_Del(): 49e. if the
     instance was allocated using *note PyObject_GC_New(): 49c. or
     *note PyObject_GC_NewVar(): 49d.

     This field is inherited by subtypes.

 -- C Member: printfunc PyTypeObject.tp_print
     An optional pointer to the instance print function.

     The print function is only called when the instance is printed to
     a _real_ file; when it is printed to a pseudo-file (like a *note
     StringIO: 164. instance), the instance's `tp_repr' or `tp_str'
     function is called to convert it to a string.  These are also
     called when the type's `tp_print' field is _NULL_.  A type should
     never implement `tp_print' in a way that produces different output
     than `tp_repr' or `tp_str' would.

     The print function is called with the same signature as *note
     PyObject_Print(): 2aea.: `int tp_print(PyObject *self, FILE *file,
     int flags)'.  The _self_ argument is the instance to be printed.
     The _file_ argument is the stdio file to which it is to be
     printed.  The _flags_ argument is composed of flag bits. The only
     flag bit currently defined is `Py_PRINT_RAW'. When the
     `Py_PRINT_RAW' flag bit is set, the instance should be printed the
     same way as `tp_str' would format it; when the `Py_PRINT_RAW' flag
     bit is clear, the instance should be printed the same was as
     `tp_repr' would format it. It should return `-1' and set an
     exception condition when an error occurred during the comparison.

     It is possible that the `tp_print' field will be deprecated. In
     any case, it is recommended not to define `tp_print', but instead
     to rely on `tp_repr' and `tp_str' for printing.

     This field is inherited by subtypes.

 -- C Member: getattrfunc PyTypeObject.tp_getattr
     An optional pointer to the get-attribute-string function.

     This field is deprecated.  When it is defined, it should point to
     a function that acts the same as the `tp_getattro' function, but
     taking a C string instead of a Python string object to give the
     attribute name.  The signature is the same as for *note
     PyObject_GetAttrString(): 299f.

     This field is inherited by subtypes together with `tp_getattro': a
     subtype inherits both `tp_getattr' and `tp_getattro' from its base
     type when the subtype's `tp_getattr' and `tp_getattro' are both
     _NULL_.

 -- C Member: setattrfunc PyTypeObject.tp_setattr
     An optional pointer to the set-attribute-string function.

     This field is deprecated.  When it is defined, it should point to
     a function that acts the same as the `tp_setattro' function, but
     taking a C string instead of a Python string object to give the
     attribute name.  The signature is the same as for *note
     PyObject_SetAttrString(): 2af0.

     This field is inherited by subtypes together with `tp_setattro': a
     subtype inherits both `tp_setattr' and `tp_setattro' from its base
     type when the subtype's `tp_setattr' and `tp_setattro' are both
     _NULL_.

 -- C Member: cmpfunc PyTypeObject.tp_compare
     An optional pointer to the three-way comparison function.

     The signature is the same as for *note PyObject_Compare(): 29d3.
     The function should return `1' if _self_ greater than _other_, `0'
     if _self_ is equal to _other_, and `-1' if _self_ less than
     _other_.  It should return `-1' and set an exception condition
     when an error occurred during the comparison.

     This field is inherited by subtypes together with `tp_richcompare'
     and `tp_hash': a subtypes inherits all three of `tp_compare',
     `tp_richcompare', and `tp_hash' when the subtype's `tp_compare',
     `tp_richcompare', and `tp_hash' are all _NULL_.

 -- C Member: reprfunc PyTypeObject.tp_repr
     An optional pointer to a function that implements the built-in
     function *note repr(): 145.

     The signature is the same as for *note PyObject_Repr(): 2af6.; it
     must return a string or a Unicode object.  Ideally, this function
     should return a string that, when passed to *note eval(): 359,
     given a suitable environment, returns an object with the same
     value.  If this is not feasible, it should return a string
     starting with `'<'' and ending with `'>'' from which both the type
     and the value of the object can be deduced.

     When this field is not set, a string of the form `<%s object at
     %p>' is returned, where `%s' is replaced by the type name, and
     `%p' by the object's memory address.

     This field is inherited by subtypes.

 -- C Member: PyNumberMethods* tp_as_number
     Pointer to an additional structure that contains fields relevant
     only to objects which implement the number protocol.  These fields
     are documented in *note Number Object Structures: 2e02.

     The `tp_as_number' field is not inherited, but the contained
     fields are inherited individually.

 -- C Member: PySequenceMethods* tp_as_sequence
     Pointer to an additional structure that contains fields relevant
     only to objects which implement the sequence protocol.  These
     fields are documented in *note Sequence Object Structures: 2e04.

     The `tp_as_sequence' field is not inherited, but the contained
     fields are inherited individually.

 -- C Member: PyMappingMethods* tp_as_mapping
     Pointer to an additional structure that contains fields relevant
     only to objects which implement the mapping protocol.  These
     fields are documented in *note Mapping Object Structures: 2e06.

     The `tp_as_mapping' field is not inherited, but the contained
     fields are inherited individually.

 -- C Member: hashfunc PyTypeObject.tp_hash
     An optional pointer to a function that implements the built-in
     function *note hash(): 6f8.

     The signature is the same as for *note PyObject_Hash(): 2b01.; it
     must return a C long.  The value `-1' should not be returned as a
     normal return value; when an error occurs during the computation
     of the hash value, the function should set an exception and return
     `-1'.

     This field can be set explicitly to *note
     PyObject_HashNotImplemented(): 32f. to block inheritance of the
     hash method from a parent type. This is interpreted as the
     equivalent of `__hash__ = None' at the Python level, causing
     `isinstance(o, collections.Hashable)' to correctly return `False'.
     Note that the converse is also true - setting `__hash__ = None' on
     a class at the Python level will result in the `tp_hash' slot
     being set to *note PyObject_HashNotImplemented(): 32f.

     When this field is not set, two possibilities exist: if the
     `tp_compare' and `tp_richcompare' fields are both _NULL_, a
     default hash value based on the object's address is returned;
     otherwise, a *note TypeError: 215. is raised.

     This field is inherited by subtypes together with `tp_richcompare'
     and `tp_compare': a subtypes inherits all three of `tp_compare',
     `tp_richcompare', and `tp_hash', when the subtype's `tp_compare',
     `tp_richcompare' and `tp_hash' are all _NULL_.

 -- C Member: ternaryfunc PyTypeObject.tp_call
     An optional pointer to a function that implements calling the
     object.  This should be _NULL_ if the object is not callable.  The
     signature is the same as for *note PyObject_Call(): 2993.

     This field is inherited by subtypes.

 -- C Member: reprfunc PyTypeObject.tp_str
     An optional pointer to a function that implements the built-in
     operation *note str(): 1e7.  (Note that *note str: 1e7. is a type
     now, and *note str(): 1e7. calls the constructor for that type.
     This constructor calls *note PyObject_Str(): 2af7. to do the
     actual work, and *note PyObject_Str(): 2af7. will call this
     handler.)

     The signature is the same as for *note PyObject_Str(): 2af7.; it
     must return a string or a Unicode object.  This function should
     return a "friendly" string representation of the object, as this
     is the representation that will be used by the print statement.

     When this field is not set, *note PyObject_Repr(): 2af6. is called
     to return a string representation.

     This field is inherited by subtypes.

 -- C Member: getattrofunc PyTypeObject.tp_getattro
     An optional pointer to the get-attribute function.

     The signature is the same as for *note PyObject_GetAttr(): 2aed.
     It is usually convenient to set this field to *note
     PyObject_GenericGetAttr(): 2aee, which implements the normal way
     of looking for object attributes.

     This field is inherited by subtypes together with `tp_getattr': a
     subtype inherits both `tp_getattr' and `tp_getattro' from its base
     type when the subtype's `tp_getattr' and `tp_getattro' are both
     _NULL_.

 -- C Member: setattrofunc PyTypeObject.tp_setattro
     An optional pointer to the set-attribute function.

     The signature is the same as for *note PyObject_SetAttr(): 2aef.
     It is usually convenient to set this field to *note
     PyObject_GenericSetAttr(): 2af1, which implements the normal way
     of setting object attributes.

     This field is inherited by subtypes together with `tp_setattr': a
     subtype inherits both `tp_setattr' and `tp_setattro' from its base
     type when the subtype's `tp_setattr' and `tp_setattro' are both
     _NULL_.

 -- C Member: PyBufferProcs* PyTypeObject.tp_as_buffer
     Pointer to an additional structure that contains fields relevant
     only to objects which implement the buffer interface.  These
     fields are documented in *note Buffer Object Structures: 2c85.

     The `tp_as_buffer' field is not inherited, but the contained
     fields are inherited individually.

 -- C Member: long PyTypeObject.tp_flags
     This field is a bit mask of various flags.  Some flags indicate
     variant semantics for certain situations; others are used to
     indicate that certain fields in the type object (or in the
     extension structures referenced via `tp_as_number',
     `tp_as_sequence', `tp_as_mapping', and `tp_as_buffer') that were
     historically not always present are valid; if such a flag bit is
     clear, the type fields it guards must not be accessed and must be
     considered to have a zero or _NULL_ value instead.

     Inheritance of this field is complicated.  Most flag bits are
     inherited individually, i.e. if the base type has a flag bit set,
     the subtype inherits this flag bit.  The flag bits that pertain to
     extension structures are strictly inherited if the extension
     structure is inherited, i.e. the base type's value of the flag bit
     is copied into the subtype together with a pointer to the extension
     structure.  The *note Py_TPFLAGS_HAVE_GC: 29c5. flag bit is
     inherited together with the `tp_traverse' and `tp_clear' fields,
     i.e. if the *note Py_TPFLAGS_HAVE_GC: 29c5. flag bit is clear in
     the subtype and the `tp_traverse' and `tp_clear' fields in the
     subtype exist (as indicated by the *note
     Py_TPFLAGS_HAVE_RICHCOMPARE: 2e0e. flag bit) and have _NULL_
     values.

     The following bit masks are currently defined; these can be ORed
     together using the `|' operator to form the value of the
     `tp_flags' field.  The macro *note PyType_HasFeature(): 2b78.
     takes a type and a flags value, _tp_ and _f_, and checks whether
     `tp->tp_flags & f' is non-zero.

      -- Data: Py_TPFLAGS_HAVE_GETCHARBUFFER
          If this bit is set, the *note PyBufferProcs: 2c86. struct
          referenced by `tp_as_buffer' has the `bf_getcharbuffer' field.

      -- Data: Py_TPFLAGS_HAVE_SEQUENCE_IN
          If this bit is set, the *note PySequenceMethods: 29d7. struct
          referenced by `tp_as_sequence' has the `sq_contains' field.

      -- Data: Py_TPFLAGS_GC
          This bit is obsolete.  The bit it used to name is no longer
          in use.  The symbol is now defined as zero.

      -- Data: Py_TPFLAGS_HAVE_INPLACEOPS
          If this bit is set, the *note PySequenceMethods: 29d7. struct
          referenced by `tp_as_sequence' and the *note PyNumberMethods:
          3a4. structure referenced by `tp_as_number' contain the
          fields for in-place operators. In particular, this means that
          the *note PyNumberMethods: 3a4. structure has the fields
          `nb_inplace_add', `nb_inplace_subtract',
          `nb_inplace_multiply', `nb_inplace_divide',
          `nb_inplace_remainder', `nb_inplace_power',
          `nb_inplace_lshift', `nb_inplace_rshift', `nb_inplace_and',
          `nb_inplace_xor', and `nb_inplace_or'; and the *note
          PySequenceMethods: 29d7. struct has the fields
          `sq_inplace_concat' and `sq_inplace_repeat'.

      -- Data: Py_TPFLAGS_CHECKTYPES
          If this bit is set, the binary and ternary operations in the
          *note PyNumberMethods: 3a4. structure referenced by
          `tp_as_number' accept arguments of arbitrary object types,
          and do their own type conversions if needed.  If this bit is
          clear, those operations require that all arguments have the
          current type as their type, and the caller is supposed to
          perform a coercion operation first.  This applies to
          `nb_add', `nb_subtract', `nb_multiply', `nb_divide',
          `nb_remainder', `nb_divmod', `nb_power', `nb_lshift',
          `nb_rshift', `nb_and', `nb_xor', and `nb_or'.

      -- Data: Py_TPFLAGS_HAVE_RICHCOMPARE
          If this bit is set, the type object has the `tp_richcompare'
          field, as well as the `tp_traverse' and the `tp_clear' fields.

      -- Data: Py_TPFLAGS_HAVE_WEAKREFS
          If this bit is set, the `tp_weaklistoffset' field is defined.
          Instances of a type are weakly referenceable if the type's
          `tp_weaklistoffset' field has a value greater than zero.

      -- Data: Py_TPFLAGS_HAVE_ITER
          If this bit is set, the type object has the `tp_iter' and
          `tp_iternext' fields.

      -- Data: Py_TPFLAGS_HAVE_CLASS
          If this bit is set, the type object has several new fields
          defined starting in Python 2.2: `tp_methods', `tp_members',
          `tp_getset', `tp_base', `tp_dict', `tp_descr_get',
          `tp_descr_set', `tp_dictoffset', `tp_init', `tp_alloc',
          `tp_new', `tp_free', `tp_is_gc', `tp_bases', `tp_mro',
          `tp_cache', `tp_subclasses', and `tp_weaklist'.

      -- Data: Py_TPFLAGS_HEAPTYPE
          This bit is set when the type object itself is allocated on
          the heap.  In this case, the `ob_type' field of its instances
          is considered a reference to the type, and the type object is
          INCREF'ed when a new instance is created, and DECREF'ed when
          an instance is destroyed (this does not apply to instances of
          subtypes; only the type referenced by the instance's ob_type
          gets INCREF'ed or DECREF'ed).

      -- Data: Py_TPFLAGS_BASETYPE
          This bit is set when the type can be used as the base type of
          another type.  If this bit is clear, the type cannot be
          subtyped (similar to a "final" class in Java).

      -- Data: Py_TPFLAGS_READY
          This bit is set when the type object has been fully
          initialized by *note PyType_Ready(): 29ba.

      -- Data: Py_TPFLAGS_READYING
          This bit is set while *note PyType_Ready(): 29ba. is in the
          process of initializing the type object.

      -- Data: Py_TPFLAGS_HAVE_GC
          This bit is set when the object supports garbage collection.
          If this bit is set, instances must be created using *note
          PyObject_GC_New(): 49c. and destroyed using *note
          PyObject_GC_Del(): 49e.  More information in section *note
          Supporting Cyclic Garbage Collection: 2e1a.  This bit also
          implies that the GC-related fields `tp_traverse' and
          `tp_clear' are present in the type object; but those fields
          also exist when *note Py_TPFLAGS_HAVE_GC: 29c5. is clear but
          *note Py_TPFLAGS_HAVE_RICHCOMPARE: 2e0e. is set.

      -- Data: Py_TPFLAGS_DEFAULT
          This is a bitmask of all the bits that pertain to the
          existence of certain fields in the type object and its
          extension structures. Currently, it includes the following
          bits: *note Py_TPFLAGS_HAVE_GETCHARBUFFER: 2e0f, *note
          Py_TPFLAGS_HAVE_SEQUENCE_IN: 2e10, *note
          Py_TPFLAGS_HAVE_INPLACEOPS: 2e12, *note
          Py_TPFLAGS_HAVE_RICHCOMPARE: 2e0e, *note
          Py_TPFLAGS_HAVE_WEAKREFS: 2e14, *note Py_TPFLAGS_HAVE_ITER:
          2e15, and *note Py_TPFLAGS_HAVE_CLASS: 2e16.

 -- C Member: char* PyTypeObject.tp_doc
     An optional pointer to a NUL-terminated C string giving the
     docstring for this type object.  This is exposed as the `__doc__'
     attribute on the type and instances of the type.

     This field is _not_ inherited by subtypes.

  The following three fields only exist if the *note
Py_TPFLAGS_HAVE_RICHCOMPARE: 2e0e. flag bit is set.

 -- C Member: traverseproc PyTypeObject.tp_traverse
     An optional pointer to a traversal function for the garbage
     collector.  This is only used if the *note Py_TPFLAGS_HAVE_GC:
     29c5. flag bit is set.  More information about Python's garbage
     collection scheme can be found in section *note Supporting Cyclic
     Garbage Collection: 2e1a.

     The `tp_traverse' pointer is used by the garbage collector to
     detect reference cycles. A typical implementation of a
     `tp_traverse' function simply calls *note Py_VISIT(): 29c3. on
     each of the instance's members that are Python objects.  For
     example, this is function `local_traverse()' from the *note
     thread: 178. extension module:

         static int
         local_traverse(localobject *self, visitproc visit, void *arg)
         {
             Py_VISIT(self->args);
             Py_VISIT(self->kw);
             Py_VISIT(self->dict);
             return 0;
         }

     Note that *note Py_VISIT(): 29c3. is called only on those members
     that can participate in reference cycles.  Although there is also
     a `self->key' member, it can only be _NULL_ or a Python string and
     therefore cannot be part of a reference cycle.

     On the other hand, even if you know a member can never be part of
     a cycle, as a debugging aid you may want to visit it anyway just
     so the *note gc: db. module's `get_referents()' function will
     include it.

     Note that *note Py_VISIT(): 29c3. requires the _visit_ and _arg_
     parameters to `local_traverse()' to have these specific names;
     don't name them just anything.

     This field is inherited by subtypes together with `tp_clear' and
     the *note Py_TPFLAGS_HAVE_GC: 29c5. flag bit: the flag bit,
     `tp_traverse', and `tp_clear' are all inherited from the base type
     if they are all zero in the subtype _and_ the subtype has the
     *note Py_TPFLAGS_HAVE_RICHCOMPARE: 2e0e. flag bit set.

 -- C Member: inquiry PyTypeObject.tp_clear
     An optional pointer to a clear function for the garbage collector.
     This is only used if the *note Py_TPFLAGS_HAVE_GC: 29c5. flag bit
     is set.

     The `tp_clear' member function is used to break reference cycles
     in cyclic garbage detected by the garbage collector.  Taken
     together, all `tp_clear' functions in the system must combine to
     break all reference cycles.  This is subtle, and if in any doubt
     supply a `tp_clear' function.  For example, the tuple type does
     not implement a `tp_clear' function, because it's possible to
     prove that no reference cycle can be composed entirely of tuples.
     Therefore the `tp_clear' functions of other types must be
     sufficient to break any cycle containing a tuple.  This isn't
     immediately obvious, and there's rarely a good reason to avoid
     implementing `tp_clear'.

     Implementations of `tp_clear' should drop the instance's
     references to those of its members that may be Python objects, and
     set its pointers to those members to _NULL_, as in the following
     example:

         static int
         local_clear(localobject *self)
         {
             Py_CLEAR(self->key);
             Py_CLEAR(self->args);
             Py_CLEAR(self->kw);
             Py_CLEAR(self->dict);
             return 0;
         }

     The *note Py_CLEAR(): 29c4. macro should be used, because clearing
     references is delicate:  the reference to the contained object
     must not be decremented until after the pointer to the contained
     object is set to _NULL_.  This is because decrementing the
     reference count may cause the contained object to become trash,
     triggering a chain of reclamation activity that may include
     invoking arbitrary Python code (due to finalizers, or weakref
     callbacks, associated with the contained object). If it's possible
     for such code to reference _self_ again, it's important that the
     pointer to the contained object be _NULL_ at that time, so that
     _self_ knows the contained object can no longer be used.  The
     *note Py_CLEAR(): 29c4. macro performs the operations in a safe
     order.

     Because the goal of `tp_clear' functions is to break reference
     cycles, it's not necessary to clear contained objects like Python
     strings or Python integers, which can't participate in reference
     cycles. On the other hand, it may be convenient to clear all
     contained Python objects, and write the type's `tp_dealloc'
     function to invoke `tp_clear'.

     More information about Python's garbage collection scheme can be
     found in section *note Supporting Cyclic Garbage Collection: 2e1a.

     This field is inherited by subtypes together with `tp_traverse'
     and the *note Py_TPFLAGS_HAVE_GC: 29c5. flag bit: the flag bit,
     `tp_traverse', and `tp_clear' are all inherited from the base type
     if they are all zero in the subtype _and_ the subtype has the
     *note Py_TPFLAGS_HAVE_RICHCOMPARE: 2e0e. flag bit set.

 -- C Member: richcmpfunc PyTypeObject.tp_richcompare
     An optional pointer to the rich comparison function, whose
     signature is `PyObject *tp_richcompare(PyObject *a, PyObject *b,
     int op)'.

     The function should return the result of the comparison (usually
     `Py_True' or `Py_False').  If the comparison is undefined, it must
     return `Py_NotImplemented', if another error occurred it must
     return `NULL' and set an exception condition.

          Note: If you want to implement a type for which only a
          limited set of comparisons makes sense (e.g. `==' and `!=',
          but not `<' and friends), directly raise *note TypeError:
          215. in the rich comparison function.

     This field is inherited by subtypes together with `tp_compare' and
     `tp_hash': a subtype inherits all three of `tp_compare',
     `tp_richcompare', and `tp_hash', when the subtype's `tp_compare',
     `tp_richcompare', and `tp_hash' are all _NULL_.

     The following constants are defined to be used as the third
     argument for `tp_richcompare' and for *note
     PyObject_RichCompare(): 2af4.:

     Constant             Comparison
     -------------------------------------- 
     `Py_LT'              `<'
     `Py_LE'              `<='
     `Py_EQ'              `=='
     `Py_NE'              `!='
     `Py_GT'              `>'
     `Py_GE'              `>='


  The next field only exists if the *note Py_TPFLAGS_HAVE_WEAKREFS:
2e14. flag bit is set.

 -- C Member: long PyTypeObject.tp_weaklistoffset
     If the instances of this type are weakly referenceable, this field
     is greater than zero and contains the offset in the instance
     structure of the weak reference list head (ignoring the GC header,
     if present); this offset is used by `PyObject_ClearWeakRefs()' and
     the `PyWeakref_*()' functions.  The instance structure needs to
     include a field of type *note PyObject*: 39f. which is initialized
     to _NULL_.

     Do not confuse this field with `tp_weaklist'; that is the list
     head for weak references to the type object itself.

     This field is inherited by subtypes, but see the rules listed
     below. A subtype may override this offset; this means that the
     subtype uses a different weak reference list head than the base
     type.  Since the list head is always found via
     `tp_weaklistoffset', this should not be a problem.

     When a type defined by a class statement has no *note __slots__:
     482. declaration, and none of its base types are weakly
     referenceable, the type is made weakly referenceable by adding a
     weak reference list head slot to the instance layout and setting
     the `tp_weaklistoffset' of that slot's offset.

     When a type's *note __slots__: 482. declaration contains a slot
     named `__weakref__', that slot becomes the weak reference list
     head for instances of the type, and the slot's offset is stored in
     the type's `tp_weaklistoffset'.

     When a type's *note __slots__: 482. declaration does not contain a
     slot named `__weakref__', the type inherits its
     `tp_weaklistoffset' from its base type.

  The next two fields only exist if the *note Py_TPFLAGS_HAVE_ITER:
2e15. flag bit is set.

 -- C Member: getiterfunc PyTypeObject.tp_iter
     An optional pointer to a function that returns an iterator for the
     object.  Its presence normally signals that the instances of this
     type are iterable (although sequences may be iterable without this
     function, and classic instances always have this function, even if
     they don't define an *note __iter__(): 31a. method).

     This function has the same signature as *note PyObject_GetIter():
     2b0a.

     This field is inherited by subtypes.

 -- C Member: iternextfunc PyTypeObject.tp_iternext
     An optional pointer to a function that returns the next item in an
     iterator.  When the iterator is exhausted, it must return _NULL_;
     a *note StopIteration: 32c.  exception may or may not be set.
     When another error occurs, it must return _NULL_ too.  Its
     presence normally signals that the instances of this type are
     iterators (although classic instances always have this function,
     even if they don't define a *note next(): 392. method).

     Iterator types should also define the `tp_iter' function, and that
     function should return the iterator instance itself (not a new
     iterator instance).

     This function has the same signature as *note PyIter_Next(): 2b62.

     This field is inherited by subtypes.

  The next fields, up to and including `tp_weaklist', only exist if the
*note Py_TPFLAGS_HAVE_CLASS: 2e16. flag bit is set.

 -- C Member: struct PyMethodDef* PyTypeObject.tp_methods
     An optional pointer to a static _NULL_-terminated array of *note
     PyMethodDef: 46b.  structures, declaring regular methods of this
     type.

     For each entry in the array, an entry is added to the type's
     dictionary (see `tp_dict' below) containing a method descriptor.

     This field is not inherited by subtypes (methods are inherited
     through a different mechanism).

 -- C Member: struct PyMemberDef* PyTypeObject.tp_members
     An optional pointer to a static _NULL_-terminated array of *note
     PyMemberDef: 2c1.  structures, declaring regular data members
     (fields or slots) of instances of this type.

     For each entry in the array, an entry is added to the type's
     dictionary (see `tp_dict' below) containing a member descriptor.

     This field is not inherited by subtypes (members are inherited
     through a different mechanism).

 -- C Member: struct PyGetSetDef* PyTypeObject.tp_getset
     An optional pointer to a static _NULL_-terminated array of
     `PyGetSetDef' structures, declaring computed attributes of
     instances of this type.

     For each entry in the array, an entry is added to the type's
     dictionary (see `tp_dict' below) containing a getset descriptor.

     This field is not inherited by subtypes (computed attributes are
     inherited through a different mechanism).

     Docs for PyGetSetDef:

         typedef PyObject *(*getter)(PyObject *, void *);
         typedef int (*setter)(PyObject *, PyObject *, void *);

         typedef struct PyGetSetDef {
             char *name;    /* attribute name */
             getter get;    /* C function to get the attribute */
             setter set;    /* C function to set the attribute */
             char *doc;     /* optional doc string */
             void *closure; /* optional additional data for getter and setter */
         } PyGetSetDef;



 -- C Member: PyTypeObject* PyTypeObject.tp_base
     An optional pointer to a base type from which type properties are
     inherited.  At this level, only single inheritance is supported;
     multiple inheritance require dynamically creating a type object by
     calling the metatype.

     This field is not inherited by subtypes (obviously), but it
     defaults to `&PyBaseObject_Type' (which to Python programmers is
     known as the type *note object: 1ee.).

 -- C Member: PyObject* PyTypeObject.tp_dict
     The type's dictionary is stored here by *note PyType_Ready(): 29ba.

     This field should normally be initialized to _NULL_ before
     PyType_Ready is called; it may also be initialized to a dictionary
     containing initial attributes for the type.  Once *note
     PyType_Ready(): 29ba. has initialized the type, extra attributes
     for the type may be added to this dictionary only if they don't
     correspond to overloaded operations (like *note __add__(): 712.).

     This field is not inherited by subtypes (though the attributes
     defined in here are inherited through a different mechanism).

 -- C Member: descrgetfunc PyTypeObject.tp_descr_get
     An optional pointer to a "descriptor get" function.

     The function signature is

         PyObject * tp_descr_get(PyObject *self, PyObject *obj, PyObject *type);


     This field is inherited by subtypes.

 -- C Member: descrsetfunc PyTypeObject.tp_descr_set
     An optional pointer to a "descriptor set" function.

     The function signature is

         int tp_descr_set(PyObject *self, PyObject *obj, PyObject *value);

     This field is inherited by subtypes.


 -- C Member: long PyTypeObject.tp_dictoffset
     If the instances of this type have a dictionary containing
     instance variables, this field is non-zero and contains the offset
     in the instances of the type of the instance variable dictionary;
     this offset is used by *note PyObject_GenericGetAttr(): 2aee.

     Do not confuse this field with `tp_dict'; that is the dictionary
     for attributes of the type object itself.

     If the value of this field is greater than zero, it specifies the
     offset from the start of the instance structure.  If the value is
     less than zero, it specifies the offset from the _end_ of the
     instance structure.  A negative offset is more expensive to use,
     and should only be used when the instance structure contains a
     variable-length part.  This is used for example to add an instance
     variable dictionary to subtypes of *note str: 1e7. or *note tuple:
     401. Note that the `tp_basicsize' field should account for the
     dictionary added to the end in that case, even though the
     dictionary is not included in the basic object layout.  On a
     system with a pointer size of 4 bytes, `tp_dictoffset' should be
     set to `-4' to indicate that the dictionary is at the very end of
     the structure.

     The real dictionary offset in an instance can be computed from a
     negative `tp_dictoffset' as follows:

         dictoffset = tp_basicsize + abs(ob_size)*tp_itemsize + tp_dictoffset
         if dictoffset is not aligned on sizeof(void*):
             round up to sizeof(void*)

     where `tp_basicsize', `tp_itemsize' and `tp_dictoffset' are taken
     from the type object, and `ob_size' is taken from the instance.
     The absolute value is taken because long ints use the sign of
     `ob_size' to store the sign of the number.  (There's never a need
     to do this calculation yourself; it is done for you by
     `_PyObject_GetDictPtr()'.)

     This field is inherited by subtypes, but see the rules listed
     below. A subtype may override this offset; this means that the
     subtype instances store the dictionary at a difference offset than
     the base type.  Since the dictionary is always found via
     `tp_dictoffset', this should not be a problem.

     When a type defined by a class statement has no *note __slots__:
     482. declaration, and none of its base types has an instance
     variable dictionary, a dictionary slot is added to the instance
     layout and the `tp_dictoffset' is set to that slot's offset.

     When a type defined by a class statement has a *note __slots__:
     482. declaration, the type inherits its `tp_dictoffset' from its
     base type.

     (Adding a slot named `__dict__' to the *note __slots__: 482.
     declaration does not have the expected effect, it just causes
     confusion.  Maybe this should be added as a feature just like
     `__weakref__' though.)

 -- C Member: initproc PyTypeObject.tp_init
     An optional pointer to an instance initialization function.

     This function corresponds to the *note __init__(): 375. method of
     classes.  Like *note __init__(): 375, it is possible to create an
     instance without calling *note __init__(): 375, and it is possible
     to reinitialize an instance by calling its *note __init__(): 375.
     method again.

     The function signature is

         int tp_init(PyObject *self, PyObject *args, PyObject *kwds)

     The self argument is the instance to be initialized; the _args_
     and _kwds_ arguments represent positional and keyword arguments of
     the call to *note __init__(): 375.

     The `tp_init' function, if not _NULL_, is called when an instance
     is created normally by calling its type, after the type's `tp_new'
     function has returned an instance of the type.  If the `tp_new'
     function returns an instance of some other type that is not a
     subtype of the original type, no `tp_init' function is called; if
     `tp_new' returns an instance of a subtype of the original type,
     the subtype's `tp_init' is called.  (VERSION NOTE: described here
     is what is implemented in Python 2.2.1 and later.  In Python 2.2,
     the `tp_init' of the type of the object returned by `tp_new' was
     always called, if not _NULL_.)

     This field is inherited by subtypes.

 -- C Member: allocfunc PyTypeObject.tp_alloc
     An optional pointer to an instance allocation function.

     The function signature is

         PyObject *tp_alloc(PyTypeObject *self, Py_ssize_t nitems)

     The purpose of this function is to separate memory allocation from
     memory initialization.  It should return a pointer to a block of
     memory of adequate length for the instance, suitably aligned, and
     initialized to zeros, but with `ob_refcnt' set to `1' and
     `ob_type' set to the type argument.  If the type's `tp_itemsize'
     is non-zero, the object's `ob_size' field should be initialized to
     _nitems_ and the length of the allocated memory block should be
     `tp_basicsize + nitems*tp_itemsize', rounded up to a multiple of
     `sizeof(void*)'; otherwise, _nitems_ is not used and the length of
     the block should be `tp_basicsize'.

     Do not use this function to do any other instance initialization,
     not even to allocate additional memory; that should be done by
     `tp_new'.

     This field is inherited by static subtypes, but not by dynamic
     subtypes (subtypes created by a class statement); in the latter,
     this field is always set to *note PyType_GenericAlloc(): 2b7b, to
     force a standard heap allocation strategy.  That is also the
     recommended value for statically defined types.

 -- C Member: newfunc PyTypeObject.tp_new
     An optional pointer to an instance creation function.

     If this function is _NULL_ for a particular type, that type cannot
     be called to create new instances; presumably there is some other
     way to create instances, like a factory function.

     The function signature is

         PyObject *tp_new(PyTypeObject *subtype, PyObject *args, PyObject *kwds)

     The subtype argument is the type of the object being created; the
     _args_ and _kwds_ arguments represent positional and keyword
     arguments of the call to the type.  Note that subtype doesn't have
     to equal the type whose `tp_new' function is called; it may be a
     subtype of that type (but not an unrelated type).

     The `tp_new' function should call `subtype->tp_alloc(subtype,
     nitems)' to allocate space for the object, and then do only as
     much further initialization as is absolutely necessary.
     Initialization that can safely be ignored or repeated should be
     placed in the `tp_init' handler.  A good rule of thumb is that for
     immutable types, all initialization should take place in `tp_new',
     while for mutable types, most initialization should be deferred to
     `tp_init'.

     This field is inherited by subtypes, except it is not inherited by
     static types whose `tp_base' is _NULL_ or `&PyBaseObject_Type'.
     The latter exception is a precaution so that old extension types
     don't become callable simply by being linked with Python 2.2.

 -- C Member: destructor PyTypeObject.tp_free
     An optional pointer to an instance deallocation function.

     The signature of this function has changed slightly: in Python 2.2
     and 2.2.1, its signature is `destructor':

         void tp_free(PyObject *)

     In Python 2.3 and beyond, its signature is `freefunc':

         void tp_free(void *)

     The only initializer that is compatible with both versions is
     `_PyObject_Del', whose definition has suitably adapted in Python
     2.3.

     This field is inherited by static subtypes, but not by dynamic
     subtypes (subtypes created by a class statement); in the latter,
     this field is set to a deallocator suitable to match *note
     PyType_GenericAlloc(): 2b7b. and the value of the *note
     Py_TPFLAGS_HAVE_GC: 29c5. flag bit.

 -- C Member: inquiry PyTypeObject.tp_is_gc
     An optional pointer to a function called by the garbage collector.

     The garbage collector needs to know whether a particular object is
     collectible or not.  Normally, it is sufficient to look at the
     object's type's `tp_flags' field, and check the *note
     Py_TPFLAGS_HAVE_GC: 29c5. flag bit.  But some types have a mixture
     of statically and dynamically allocated instances, and the
     statically allocated instances are not collectible.  Such types
     should define this function; it should return `1' for a
     collectible instance, and `0' for a non-collectible instance. The
     signature is

         int tp_is_gc(PyObject *self)

     (The only example of this are types themselves.  The metatype,
     *note PyType_Type: 2b73, defines this function to distinguish
     between statically and dynamically allocated types.)

     This field is inherited by subtypes.  (VERSION NOTE: in Python
     2.2, it was not inherited.  It is inherited in 2.2.1 and later
     versions.)

 -- C Member: PyObject* PyTypeObject.tp_bases
     Tuple of base types.

     This is set for types created by a class statement.  It should be
     _NULL_ for statically defined types.

     This field is not inherited.

 -- C Member: PyObject* PyTypeObject.tp_mro
     Tuple containing the expanded set of base types, starting with the
     type itself and ending with *note object: 1ee, in Method
     Resolution Order.

     This field is not inherited; it is calculated fresh by *note
     PyType_Ready(): 29ba.

 -- C Member: PyObject* PyTypeObject.tp_cache
     Unused.  Not inherited.  Internal use only.

 -- C Member: PyObject* PyTypeObject.tp_subclasses
     List of weak references to subclasses.  Not inherited.  Internal
     use only.

 -- C Member: PyObject* PyTypeObject.tp_weaklist
     Weak reference list head, for weak references to this type object.
     Not inherited.  Internal use only.

  The remaining fields are only defined if the feature test macro
`COUNT_ALLOCS' is defined, and are for internal use only. They are
documented here for completeness.  None of these fields are inherited by
subtypes.

 -- C Member: Py_ssize_t PyTypeObject.tp_allocs
     Number of allocations.

 -- C Member: Py_ssize_t PyTypeObject.tp_frees
     Number of frees.

 -- C Member: Py_ssize_t PyTypeObject.tp_maxalloc
     Maximum simultaneously allocated objects.

 -- C Member: PyTypeObject* PyTypeObject.tp_next
     Pointer to the next type object with a non-zero `tp_allocs' field.

  Also, note that, in a garbage collected Python, tp_dealloc may be
called from any Python thread, not just the thread which created the
object (if the object becomes part of a refcount cycle, that cycle
might be collected by a garbage collection on any thread).  This is not
a problem for Python API calls, since the thread on which tp_dealloc is
called will own the Global Interpreter Lock (GIL). However, if the
object being destroyed in turn destroys objects from some other C or
C++ library, care should be taken to ensure that destroying those
objects on the thread which called tp_dealloc will not violate any
assumptions of the library.


File: python.info,  Node: Number Object Structures,  Next: Mapping Object Structures,  Prev: Type Objects<3>,  Up: Object Implementation Support

7.10.4 Number Object Structures
-------------------------------

 -- C Type: PyNumberMethods
     This structure holds pointers to the functions which an object
     uses to implement the number protocol.  Almost every function
     below is used by the function of similar name documented in the
     *note Number Protocol: 2b0c. section.

     Here is the structure definition:

         typedef struct {
              binaryfunc nb_add;
              binaryfunc nb_subtract;
              binaryfunc nb_multiply;
              binaryfunc nb_divide;
              binaryfunc nb_remainder;
              binaryfunc nb_divmod;
              ternaryfunc nb_power;
              unaryfunc nb_negative;
              unaryfunc nb_positive;
              unaryfunc nb_absolute;
              inquiry nb_nonzero;       /* Used by PyObject_IsTrue */
              unaryfunc nb_invert;
              binaryfunc nb_lshift;
              binaryfunc nb_rshift;
              binaryfunc nb_and;
              binaryfunc nb_xor;
              binaryfunc nb_or;
              coercion nb_coerce;       /* Used by the coerce() function */
              unaryfunc nb_int;
              unaryfunc nb_long;
              unaryfunc nb_float;
              unaryfunc nb_oct;
              unaryfunc nb_hex;

              /* Added in release 2.0 */
              binaryfunc nb_inplace_add;
              binaryfunc nb_inplace_subtract;
              binaryfunc nb_inplace_multiply;
              binaryfunc nb_inplace_divide;
              binaryfunc nb_inplace_remainder;
              ternaryfunc nb_inplace_power;
              binaryfunc nb_inplace_lshift;
              binaryfunc nb_inplace_rshift;
              binaryfunc nb_inplace_and;
              binaryfunc nb_inplace_xor;
              binaryfunc nb_inplace_or;

              /* Added in release 2.2 */
              binaryfunc nb_floor_divide;
              binaryfunc nb_true_divide;
              binaryfunc nb_inplace_floor_divide;
              binaryfunc nb_inplace_true_divide;

              /* Added in release 2.5 */
              unaryfunc nb_index;
         } PyNumberMethods;



  Binary and ternary functions may receive different kinds of
arguments, depending on the flag bit *note Py_TPFLAGS_CHECKTYPES: 2e13.:

   - If *note Py_TPFLAGS_CHECKTYPES: 2e13. is not set, the function
     arguments are guaranteed to be of the object's type; the caller is
     responsible for calling the coercion method specified by the
     `nb_coerce' member to convert the arguments:

      -- C Member: coercion PyNumberMethods.nb_coerce
          This function is used by *note PyNumber_CoerceEx(): 2b2f. and
          has the same signature.  The first argument is always a
          pointer to an object of the defined type.  If the conversion
          to a common "larger" type is possible, the function replaces
          the pointers with new references to the converted objects and
          returns `0'.  If the conversion is not possible, the function
          returns `1'.  If an error condition is set, it will return
          `-1'.

   - If the *note Py_TPFLAGS_CHECKTYPES: 2e13. flag is set, binary and
     ternary functions must check the type of all their operands, and
     implement the necessary conversions (at least one of the operands
     is an instance of the defined type).  This is the recommended way;
     with Python 3 coercion will disappear completely.

  If the operation is not defined for the given operands, binary and
ternary functions must return `Py_NotImplemented', if another error
occurred they must return `NULL' and set an exception.


File: python.info,  Node: Mapping Object Structures,  Next: Sequence Object Structures,  Prev: Number Object Structures,  Up: Object Implementation Support

7.10.5 Mapping Object Structures
--------------------------------

 -- C Type: PyMappingMethods
     This structure holds pointers to the functions which an object
     uses to implement the mapping protocol.  It has three members:

 -- C Member: lenfunc PyMappingMethods.mp_length
     This function is used by *note PyMapping_Length(): 2b54. and *note
     PyObject_Size(): 2b06, and has the same signature.  This slot may
     be set to _NULL_ if the object has no defined length.

 -- C Member: binaryfunc PyMappingMethods.mp_subscript
     This function is used by *note PyObject_GetItem(): 2a0b. and has
     the same signature.  This slot must be filled for the *note
     PyMapping_Check(): 2b52.  function to return `1', it can be _NULL_
     otherwise.

 -- C Member: objobjargproc PyMappingMethods.mp_ass_subscript
     This function is used by *note PyObject_SetItem(): 2a09. and has
     the same signature.  If this slot is _NULL_, the object does not
     support item assignment.


File: python.info,  Node: Sequence Object Structures,  Next: Buffer Object Structures,  Prev: Mapping Object Structures,  Up: Object Implementation Support

7.10.6 Sequence Object Structures
---------------------------------

 -- C Type: PySequenceMethods
     This structure holds pointers to the functions which an object
     uses to implement the sequence protocol.

 -- C Member: lenfunc PySequenceMethods.sq_length
     This function is used by *note PySequence_Size(): 2b3b. and *note
     PyObject_Size(): 2b06, and has the same signature.

 -- C Member: binaryfunc PySequenceMethods.sq_concat
     This function is used by *note PySequence_Concat(): 2b3d. and has
     the same signature.  It is also used by the `+' operator, after
     trying the numeric addition via the `tp_as_number.nb_add' slot.

 -- C Member: ssizeargfunc PySequenceMethods.sq_repeat
     This function is used by *note PySequence_Repeat(): 2b3e. and has
     the same signature.  It is also used by the `*' operator, after
     trying numeric multiplication via the `tp_as_number.nb_mul' slot.

 -- C Member: ssizeargfunc PySequenceMethods.sq_item
     This function is used by *note PySequence_GetItem(): 2a0c. and has
     the same signature.  This slot must be filled for the *note
     PySequence_Check(): 2b3a.  function to return `1', it can be
     _NULL_ otherwise.

     Negative indexes are handled as follows: if the `sq_length' slot is
     filled, it is called and the sequence length is used to compute a
     positive index which is passed to `sq_item'.  If `sq_length' is
     _NULL_, the index is passed as is to the function.

 -- C Member: ssizeobjargproc PySequenceMethods.sq_ass_item
     This function is used by *note PySequence_SetItem(): 2a08. and has
     the same signature.  This slot may be left to _NULL_ if the object
     does not support item assignment.

 -- C Member: objobjproc PySequenceMethods.sq_contains
     This function may be used by *note PySequence_Contains(): 2b46.
     and has the same signature.  This slot may be left to _NULL_, in
     this case *note PySequence_Contains(): 2b46. simply traverses the
     sequence until it finds a match.

 -- C Member: binaryfunc PySequenceMethods.sq_inplace_concat
     This function is used by *note PySequence_InPlaceConcat(): 2b3f.
     and has the same signature.  It should modify its first operand,
     and return it.

 -- C Member: ssizeargfunc PySequenceMethods.sq_inplace_repeat
     This function is used by *note PySequence_InPlaceRepeat(): 2b40.
     and has the same signature.  It should modify its first operand,
     and return it.


File: python.info,  Node: Buffer Object Structures,  Next: Supporting Cyclic Garbage Collection,  Prev: Sequence Object Structures,  Up: Object Implementation Support

7.10.7 Buffer Object Structures
-------------------------------

The buffer interface exports a model where an object can expose its
internal data as a set of chunks of data, where each chunk is specified
as a pointer/length pair.  These chunks are called _segments_ and are
presumed to be non-contiguous in memory.

  If an object does not export the buffer interface, then its
`tp_as_buffer' member in the *note PyTypeObject: 29b9. structure should
be _NULL_.  Otherwise, the `tp_as_buffer' will point to a *note
PyBufferProcs: 2c86. structure.

     Note: It is very important that your *note PyTypeObject: 29b9.
     structure uses *note Py_TPFLAGS_DEFAULT: 29bb. for the value of
     the `tp_flags' member rather than `0'.  This tells the Python
     runtime that your *note PyBufferProcs: 2c86.  structure contains
     the `bf_getcharbuffer' slot. Older versions of Python did not have
     this member, so a new Python interpreter using an old extension
     needs to be able to test for its presence before using it.

 -- C Type: PyBufferProcs
     Structure used to hold the function pointers which define an
     implementation of the buffer protocol.

     The first slot is `bf_getreadbuffer', of type `getreadbufferproc'.
     If this slot is _NULL_, then the object does not support reading
     from the internal data.  This is non-sensical, so implementors
     should fill this in, but callers should test that the slot
     contains a non-_NULL_ value.

     The next slot is `bf_getwritebuffer' having type
     `getwritebufferproc'.  This slot may be _NULL_ if the object does
     not allow writing into its returned buffers.

     The third slot is `bf_getsegcount', with type `getsegcountproc'.
     This slot must not be _NULL_ and is used to inform the caller how
     many segments the object contains.  Simple objects such as *note
     PyString_Type: 2be9. and *note PyBuffer_Type: 2c88. objects
     contain a single segment.

     The last slot is `bf_getcharbuffer', of type `getcharbufferproc'.
     This slot will only be present if the *note
     Py_TPFLAGS_HAVE_GETCHARBUFFER: 2e0f.  flag is present in the
     `tp_flags' field of the object's *note PyTypeObject: 29b9. Before
     using this slot, the caller should test whether it is present by
     using the *note PyType_HasFeature(): 2b78. function.  If the flag
     is present, `bf_getcharbuffer' may be _NULL_, indicating that the
     object's contents cannot be used as _8-bit characters_. The slot
     function may also raise an error if the object's contents cannot
     be interpreted as 8-bit characters.  For example, if the object is
     an array which is configured to hold floating point values, an
     exception may be raised if a caller attempts to use
     `bf_getcharbuffer' to fetch a sequence of 8-bit characters. This
     notion of exporting the internal buffers as "text" is used to
     distinguish between objects that are binary in nature, and those
     which have character-based content.

          Note: The current policy seems to state that these characters
          may be multi-byte characters. This implies that a buffer size
          of _N_ does not mean there are _N_ characters present.

 -- Data: Py_TPFLAGS_HAVE_GETCHARBUFFER
     Flag bit set in the type structure to indicate that the
     `bf_getcharbuffer' slot is known.  This being set does not
     indicate that the object supports the buffer interface or that the
     `bf_getcharbuffer' slot is non-_NULL_.

 -- C Type: Py_ssize_t (*readbufferproc) (PyObject *self,
          Py_ssize_t segment, void **ptrptr)
     Return a pointer to a readable segment of the buffer in `*ptrptr'.
     This function is allowed to raise an exception, in which case it
     must return `-1'.  The _segment_ which is specified must be zero
     or positive, and strictly less than the number of segments
     returned by the `bf_getsegcount' slot function.  On success, it
     returns the length of the segment, and sets `*ptrptr' to a pointer
     to that memory.

 -- C Type: Py_ssize_t (*writebufferproc) (PyObject *self,
          Py_ssize_t segment, void **ptrptr)
     Return a pointer to a writable memory buffer in `*ptrptr', and the
     length of that segment as the function return value.  The memory
     buffer must correspond to buffer segment _segment_.  Must return
     `-1' and set an exception on error.  *note TypeError: 215. should
     be raised if the object only supports read-only buffers, and *note
     SystemError: 93d. should be raised when _segment_ specifies a
     segment that doesn't exist.


 -- C Type: Py_ssize_t (*segcountproc) (PyObject *self,
          Py_ssize_t *lenp)
     Return the number of memory segments which comprise the buffer.
     If _lenp_ is not _NULL_, the implementation must report the sum of
     the sizes (in bytes) of all segments in `*lenp'. The function
     cannot fail.

 -- C Type: Py_ssize_t (*charbufferproc) (PyObject *self,
          Py_ssize_t segment, const char **ptrptr)
     Return the size of the segment _segment_ that _ptrptr_  is set to.
     `*ptrptr' is set to the memory buffer. Returns `-1' on error.


File: python.info,  Node: Supporting Cyclic Garbage Collection,  Prev: Buffer Object Structures,  Up: Object Implementation Support

7.10.8 Supporting Cyclic Garbage Collection
-------------------------------------------

Python's support for detecting and collecting garbage which involves
circular references requires support from object types which are
"containers" for other objects which may also be containers.  Types
which do not store references to other objects, or which only store
references to atomic types (such as numbers or strings), do not need to
provide any explicit support for garbage collection.

  To create a container type, the `tp_flags' field of the type object
must include the *note Py_TPFLAGS_HAVE_GC: 29c5. and provide an
implementation of the `tp_traverse' handler.  If instances of the type
are mutable, a `tp_clear' implementation must also be provided.

 -- Data: Py_TPFLAGS_HAVE_GC
     Objects with a type with this flag set must conform with the rules
     documented here.  For convenience these objects will be referred
     to as container objects.

  Constructors for container types must conform to two rules:

  1. The memory for the object must be allocated using *note
     PyObject_GC_New(): 49c.  or *note PyObject_GC_NewVar(): 49d.

  2. Once all the fields which may contain references to other
     containers are initialized, it must call *note
     PyObject_GC_Track(): 49f.

 -- C Function: TYPE* PyObject_GC_New (TYPE, PyTypeObject *type)
     Analogous to *note PyObject_New(): 464. but for container objects
     with the *note Py_TPFLAGS_HAVE_GC: 29c5. flag set.

 -- C Function: TYPE* PyObject_GC_NewVar (TYPE, PyTypeObject *type,
          Py_ssize_t size)
     Analogous to *note PyObject_NewVar(): 465. but for container
     objects with the *note Py_TPFLAGS_HAVE_GC: 29c5. flag set.

     Changed in version 2.5: This function used an `int' type for
     _size_. This might require changes in your code for properly
     supporting 64-bit systems.

 -- C Function: TYPE* PyObject_GC_Resize (TYPE, PyVarObject *op,
          Py_ssize_t newsize)
     Resize an object allocated by *note PyObject_NewVar(): 465.
     Returns the resized object or _NULL_ on failure.

     Changed in version 2.5: This function used an `int' type for
     _newsize_. This might require changes in your code for properly
     supporting 64-bit systems.

 -- C Function: void PyObject_GC_Track (PyObject *op)
     Adds the object _op_ to the set of container objects tracked by the
     collector.  The collector can run at unexpected times so objects
     must be valid while being tracked.  This should be called once all
     the fields followed by the `tp_traverse' handler become valid,
     usually near the end of the constructor.

 -- C Function: void _PyObject_GC_TRACK (PyObject *op)
     A macro version of *note PyObject_GC_Track(): 49f.  It should not
     be used for extension modules.

  Similarly, the deallocator for the object must conform to a similar
pair of rules:

  1. Before fields which refer to other containers are invalidated,
     *note PyObject_GC_UnTrack(): 4a0. must be called.

  2. The object's memory must be deallocated using *note
     PyObject_GC_Del(): 49e.

 -- C Function: void PyObject_GC_Del (void *op)
     Releases memory allocated to an object using *note
     PyObject_GC_New(): 49c. or *note PyObject_GC_NewVar(): 49d.

 -- C Function: void PyObject_GC_UnTrack (void *op)
     Remove the object _op_ from the set of container objects tracked
     by the collector.  Note that *note PyObject_GC_Track(): 49f. can
     be called again on this object to add it back to the set of
     tracked objects.  The deallocator (`tp_dealloc' handler) should
     call this for the object before any of the fields used by the
     `tp_traverse' handler become invalid.

 -- C Function: void _PyObject_GC_UNTRACK (PyObject *op)
     A macro version of *note PyObject_GC_UnTrack(): 4a0.  It should
     not be used for extension modules.

  The `tp_traverse' handler accepts a function parameter of this type:

 -- C Type: int (*visitproc) (PyObject *object, void *arg)
     Type of the visitor function passed to the `tp_traverse' handler.
     The function should be called with an object to traverse as
     _object_ and the third parameter to the `tp_traverse' handler as
     _arg_.  The Python core uses several visitor functions to
     implement cyclic garbage detection; it's not expected that users
     will need to write their own visitor functions.

  The `tp_traverse' handler must have the following type:

 -- C Type: int (*traverseproc) (PyObject *self, visitproc visit,
          void *arg)
     Traversal function for a container object.  Implementations must
     call the _visit_ function for each object directly contained by
     _self_, with the parameters to _visit_ being the contained object
     and the _arg_ value passed to the handler.  The _visit_ function
     must not be called with a _NULL_ object argument.  If _visit_
     returns a non-zero value that value should be returned immediately.

  To simplify writing `tp_traverse' handlers, a *note Py_VISIT(): 29c3.
macro is provided.  In order to use this macro, the `tp_traverse'
implementation must name its arguments exactly _visit_ and _arg_:

 -- C Function: void Py_VISIT (PyObject *o)
     Call the _visit_ callback, with arguments _o_ and _arg_. If
     _visit_ returns a non-zero value, then return it.  Using this
     macro, `tp_traverse' handlers look like:

         static int
         my_traverse(Noddy *self, visitproc visit, void *arg)
         {
             Py_VISIT(self->foo);
             Py_VISIT(self->bar);
             return 0;
         }

     New in version 2.4.

  The `tp_clear' handler must be of the *note inquiry: 2e53. type, or
_NULL_ if the object is immutable.

 -- C Type: int (*inquiry) (PyObject *self)
     Drop references that may have created reference cycles.  Immutable
     objects do not have to define this method since they can never
     directly create reference cycles.  Note that the object must still
     be valid after calling this method (don't just call *note
     Py_DECREF(): 2981. on a reference).  The collector will call this
     method if it detects that this object is involved in a reference
     cycle.


File: python.info,  Node: Distributing Python Modules,  Next: Installing Python Modules,  Prev: Python/C API Reference Manual,  Up: Top

8 Distributing Python Modules
*****************************

     Authors: Greg Ward, Anthony Baxter

     Email: <distutils-sig@python.org>

  This document describes the Python Distribution Utilities
("Distutils") from the module developer's point of view, describing how
to use the Distutils to make Python modules and extensions easily
available to a wider audience with very little overhead for
build/release/install mechanics.

* Menu:

* An Introduction to Distutils::
* Writing the Setup Script::
* Writing the Setup Configuration File::
* Creating a Source Distribution::
* Creating Built Distributions::
* The Python Package Index (PyPI): The Python Package Index PyPI.
* Examples: Examples<24>.
* Extending Distutils::
* Command Reference::
* API Reference::

An Introduction to Distutils

* Concepts & Terminology::
* A Simple Example: A Simple Example<2>.
* General Python terminology::
* Distutils-specific terminology::

Writing the Setup Script

* Listing whole packages::
* Listing individual modules::
* Describing extension modules::
* Relationships between Distributions and Packages::
* Installing Scripts::
* Installing Package Data::
* Installing Additional Files::
* Additional meta-data::
* Debugging the setup script::

Describing extension modules

* Extension names and packages::
* Extension source files::
* Preprocessor options::
* Library options::
* Other options::

Creating a Source Distribution

* Specifying the files to distribute::
* Manifest-related options::
* The MANIFEST.in template: The MANIFEST in template.

The MANIFEST.in template

* Principle::
* Commands::

Creating Built Distributions

* Creating dumb built distributions::
* Creating RPM packages::
* Creating Windows Installers::
* Cross-compiling on Windows::
* Vista User Access Control (UAC): Vista User Access Control UAC.

Cross-compiling on Windows

* The Postinstallation script::

The Python Package Index (PyPI)

* Registering Packages::
* Uploading Packages::
* The .pypirc file: The pypirc file.
* PyPI package display::

Examples

* Pure Python distribution (by module): Pure Python distribution by module.
* Pure Python distribution (by package): Pure Python distribution by package.
* Single extension module::

Extending Distutils

* Integrating new commands::
* Adding new distribution types::

Command Reference

* Installing modules; the install command family: Installing modules the install command family.

Installing modules: the install command family

* install_data::
* install_scripts::

API Reference

* distutils.core: distutils core --- Core Distutils functionality. Core Distutils functionality
* distutils.ccompiler: distutils ccompiler --- CCompiler base class. CCompiler base class
* distutils.unixccompiler: distutils unixccompiler --- Unix C Compiler. Unix C Compiler
* distutils.msvccompiler: distutils msvccompiler --- Microsoft Compiler. Microsoft Compiler
* distutils.bcppcompiler: distutils bcppcompiler --- Borland Compiler. Borland Compiler
* distutils.cygwincompiler: distutils cygwincompiler --- Cygwin Compiler. Cygwin Compiler
* distutils.emxccompiler: distutils emxccompiler --- OS/2 EMX Compiler. OS/2 EMX Compiler
* distutils.archive_util: distutils archive_util --- Archiving utilities. Archiving utilities
* distutils.dep_util: distutils dep_util --- Dependency checking. Dependency checking
* distutils.dir_util: distutils dir_util --- Directory tree operations. Directory tree operations
* distutils.file_util: distutils file_util --- Single file operations. Single file operations
* distutils.util: distutils util --- Miscellaneous other utility functions. Miscellaneous other utility functions
* distutils.dist: distutils dist --- The Distribution class. The Distribution class
* distutils.extension: distutils extension --- The Extension class. The Extension class
* distutils.debug: distutils debug --- Distutils debug mode. Distutils debug mode
* distutils.errors: distutils errors --- Distutils exceptions. Distutils exceptions
* distutils.fancy_getopt: distutils fancy_getopt --- Wrapper around the standard getopt module. Wrapper around the standard getopt module
* distutils.filelist: distutils filelist --- The FileList class. The FileList class
* distutils.log: distutils log --- Simple PEP 282-style logging. Simple PEP 282-style logging
* distutils.spawn: distutils spawn --- Spawn a sub-process. Spawn a sub-process
* distutils.sysconfig: distutils sysconfig --- System configuration information. System configuration information
* distutils.text_file: distutils text_file --- The TextFile class. The TextFile class
* distutils.version: distutils version --- Version number classes. Version number classes
* distutils.cmd: distutils cmd --- Abstract base class for Distutils commands. Abstract base class for Distutils commands
* Creating a new Distutils command::
* distutils.command: distutils command --- Individual Distutils commands. Individual Distutils commands
* distutils.command.bdist: distutils command bdist --- Build a binary installer. Build a binary installer
* distutils.command.bdist_packager: distutils command bdist_packager --- Abstract base class for packagers. Abstract base class for packagers
* distutils.command.bdist_dumb: distutils command bdist_dumb --- Build a "dumb" installer. Build a "dumb" installer
* distutils.command.bdist_msi: distutils command bdist_msi --- Build a Microsoft Installer binary package. Build a Microsoft Installer binary package
* distutils.command.bdist_rpm: distutils command bdist_rpm --- Build a binary distribution as a Redhat RPM and SRPM. Build a binary distribution as a Redhat RPM and
                               SRPM
* distutils.command.bdist_wininst: distutils command bdist_wininst --- Build a Windows installer. Build a Windows installer
* distutils.command.sdist: distutils command sdist --- Build a source distribution. Build a source distribution
* distutils.command.build: distutils command build --- Build all files of a package. Build all files of a package
* distutils.command.build_clib: distutils command build_clib --- Build any C libraries in a package. Build any C libraries in a package
* distutils.command.build_ext: distutils command build_ext --- Build any extensions in a package. Build any extensions in a package
* distutils.command.build_py: distutils command build_py --- Build the py/ pyc files of a package. Build the .py/.pyc files of a package
* distutils.command.build_scripts: distutils command build_scripts --- Build the scripts of a package. Build the scripts of a package
* distutils.command.clean: distutils command clean --- Clean a package build area. Clean a package build area
* distutils.command.config: distutils command config --- Perform package configuration. Perform package configuration
* distutils.command.install: distutils command install --- Install a package. Install a package
* distutils.command.install_data: distutils command install_data --- Install data files from a package. Install data files from a package
* distutils.command.install_headers: distutils command install_headers --- Install C/C++ header files from a package. Install C/C++ header files from a package
* distutils.command.install_lib: distutils command install_lib --- Install library files from a package. Install library files from a package
* distutils.command.install_scripts: distutils command install_scripts --- Install script files from a package. Install script files from a package
* distutils.command.register: distutils command register --- Register a module with the Python Package Index. Register a module with the Python Package Index
* distutils.command.check: distutils command check --- Check the meta-data of a package. Check the meta-data of a package


File: python.info,  Node: An Introduction to Distutils,  Next: Writing the Setup Script,  Up: Distributing Python Modules

8.1 An Introduction to Distutils
================================

This document covers using the Distutils to distribute your Python
modules, concentrating on the role of developer/distributor: if you're
looking for information on installing Python modules, you should refer
to the *note Installing Python Modules: 604. chapter.

* Menu:

* Concepts & Terminology::
* A Simple Example: A Simple Example<2>.
* General Python terminology::
* Distutils-specific terminology::


File: python.info,  Node: Concepts & Terminology,  Next: A Simple Example<2>,  Up: An Introduction to Distutils

8.1.1 Concepts & Terminology
----------------------------

Using the Distutils is quite simple, both for module developers and for
users/administrators installing third-party modules.  As a developer,
your responsibilities (apart from writing solid, well-documented and
well-tested code, of course!) are:

   * write a setup script (`setup.py' by convention)

   * (optional) write a setup configuration file

   * create a source distribution

   * (optional) create one or more built (binary) distributions

  Each of these tasks is covered in this document.

  Not all module developers have access to a multitude of platforms, so
it's not always feasible to expect them to create a multitude of built
distributions.  It is hoped that a class of intermediaries, called
_packagers_, will arise to address this need.  Packagers will take
source distributions released by module developers, build them on one
or more platforms, and release the resulting built distributions.
Thus, users on the most popular platforms will be able to install most
popular Python module distributions in the most natural way for their
platform, without having to run a single setup script or compile a line
of code.


File: python.info,  Node: A Simple Example<2>,  Next: General Python terminology,  Prev: Concepts & Terminology,  Up: An Introduction to Distutils

8.1.2 A Simple Example
----------------------

The setup script is usually quite simple, although since it's written
in Python, there are no arbitrary limits to what you can do with it,
though you should be careful about putting arbitrarily expensive
operations in your setup script.  Unlike, say, Autoconf-style configure
scripts, the setup script may be run multiple times in the course of
building and installing your module distribution.

  If all you want to do is distribute a module called `foo', contained
in a file `foo.py', then your setup script can be as simple as this:

    from distutils.core import setup
    setup(name='foo',
          version='1.0',
          py_modules=['foo'],
          )

Some observations:

   * most information that you supply to the Distutils is supplied as
     keyword arguments to the `setup()' function

   * those keyword arguments fall into two categories: package metadata
     (name, version number) and information about what's in the package
     (a list of pure Python modules, in this case)

   * modules are specified by module name, not filename (the same will
     hold true for packages and extensions)

   * it's recommended that you supply a little more metadata, in
     particular your name, email address and a URL for the project (see
     section *note Writing the Setup Script: 2e5d.  for an example)

  To create a source distribution for this module, you would create a
setup script, `setup.py', containing the above code, and run this
command from a terminal:

    python setup.py sdist

For Windows, open a command prompt windows (_Start ‣ Accessories_) and
change the command to:

    setup.py sdist

*sdist* will create an archive file (e.g., tarball on Unix, ZIP file on
Windows) containing your setup script `setup.py', and your module
`foo.py'.  The archive file will be named `foo-1.0.tar.gz' (or `.zip'),
and will unpack into a directory `foo-1.0'.

  If an end-user wishes to install your `foo' module, all she has to do
is download `foo-1.0.tar.gz' (or `.zip'), unpack it, and--from the
`foo-1.0' directory--run

    python setup.py install

which will ultimately copy `foo.py' to the appropriate directory for
third-party modules in their Python installation.

  This simple example demonstrates some fundamental concepts of the
Distutils.  First, both developers and installers have the same basic
user interface, i.e.  the setup script.  The difference is which
Distutils _commands_ they use: the *sdist* command is almost
exclusively for module developers, while *install* is more often for
installers (although most developers will want to install their own
code occasionally).

  If you want to make things really easy for your users, you can create
one or more built distributions for them.  For instance, if you are
running on a Windows machine, and want to make things easy for other
Windows users, you can create an executable installer (the most
appropriate type of built distribution for this platform) with the
*bdist_wininst* command.  For example:

    python setup.py bdist_wininst

will create an executable installer, `foo-1.0.win32.exe', in the current
directory.

  Other useful built distribution formats are RPM, implemented by the
*bdist_rpm* command, Solaris *pkgtool* (*bdist_pkgtool*), and HP-UX
*swinstall* (*bdist_sdux*).  For example, the following command will
create an RPM file called `foo-1.0.noarch.rpm':

    python setup.py bdist_rpm

(The *bdist_rpm* command uses the *rpm* executable, therefore this has
to be run on an RPM-based system such as Red Hat Linux, SuSE Linux, or
Mandrake Linux.)

  You can find out what distribution formats are available at any time
by running

    python setup.py bdist --help-formats



File: python.info,  Node: General Python terminology,  Next: Distutils-specific terminology,  Prev: A Simple Example<2>,  Up: An Introduction to Distutils

8.1.3 General Python terminology
--------------------------------

If you're reading this document, you probably have a good idea of what
modules, extensions, and so forth are.  Nevertheless, just to be sure
that everyone is operating from a common starting point, we offer the
following glossary of common Python terms:

module
     the basic unit of code reusability in Python: a block of code
     imported by some other code.  Three types of modules concern us
     here: pure Python modules, extension modules, and packages.

pure Python module
     a module written in Python and contained in a single `.py' file
     (and possibly associated `.pyc' and/or `.pyo' files).  Sometimes
     referred to as a "pure module."

extension module
     a module written in the low-level language of the Python
     implementation: C/C++ for Python, Java for Jython. Typically
     contained in a single dynamically loadable pre-compiled file, e.g.
     a shared object (`.so') file for Python extensions on Unix, a DLL
     (given the `.pyd' extension) for Python extensions on Windows, or
     a Java class file for Jython extensions.  (Note that currently,
     the Distutils only handles C/C++ extensions for Python.)

package
     a module that contains other modules; typically contained in a
     directory in the filesystem and distinguished from other
     directories by the presence of a file `__init__.py'.

root package
     the root of the hierarchy of packages.  (This isn't really a
     package, since it doesn't have an `__init__.py' file.  But we have
     to call it something.)  The vast majority of the standard library
     is in the root package, as are many small, standalone third-party
     modules that don't belong to a larger module collection. Unlike
     regular packages, modules in the root package can be found in many
     directories: in fact, every directory listed in `sys.path'
     contributes modules to the root package.


File: python.info,  Node: Distutils-specific terminology,  Prev: General Python terminology,  Up: An Introduction to Distutils

8.1.4 Distutils-specific terminology
------------------------------------

The following terms apply more specifically to the domain of
distributing Python modules using the Distutils:

module distribution
     a collection of Python modules distributed together as a single
     downloadable resource and meant to be installed _en masse_.
     Examples of some well-known module distributions are Numeric
     Python, PyXML, PIL (the Python Imaging Library), or mxBase.  (This
     would be called a _package_, except that term is already taken in
     the Python context: a single module distribution may contain zero,
     one, or many Python packages.)

pure module distribution
     a module distribution that contains only pure Python modules and
     packages.  Sometimes referred to as a "pure distribution."

non-pure module distribution
     a module distribution that contains at least one extension module.
     Sometimes referred to as a "non-pure distribution."

distribution root
     the top-level directory of your source tree (or  source
     distribution); the directory where `setup.py' exists.  Generally
     `setup.py' will be run from this directory.


File: python.info,  Node: Writing the Setup Script,  Next: Writing the Setup Configuration File,  Prev: An Introduction to Distutils,  Up: Distributing Python Modules

8.2 Writing the Setup Script
============================

The setup script is the centre of all activity in building,
distributing, and installing modules using the Distutils.  The main
purpose of the setup script is to describe your module distribution to
the Distutils, so that the various commands that operate on your
modules do the right thing.  As we saw in section *note A Simple
Example: 2e5b. above, the setup script consists mainly of a call to
`setup()', and most information supplied to the Distutils by the module
developer is supplied as keyword arguments to `setup()'.

  Here's a slightly more involved example, which we'll follow for the
next couple of sections: the Distutils' own setup script.  (Keep in
mind that although the Distutils are included with Python 1.6 and
later, they also have an independent existence so that Python 1.5.2
users can use them to install other module distributions.  The
Distutils' own setup script, shown here, is used to install the package
into Python 1.5.2.)

    #!/usr/bin/env python

    from distutils.core import setup

    setup(name='Distutils',
          version='1.0',
          description='Python Distribution Utilities',
          author='Greg Ward',
          author_email='gward@python.net',
          url='http://www.python.org/sigs/distutils-sig/',
          packages=['distutils', 'distutils.command'],
         )

There are only two differences between this and the trivial one-file
distribution presented in section *note A Simple Example: 2e5b.: more
metadata, and the specification of pure Python modules by package,
rather than by module.  This is important since the Distutils consist
of a couple of dozen modules split into (so far) two packages; an
explicit list of every module would be tedious to generate and
difficult to maintain.  For more information on the additional
meta-data, see section *note Additional meta-data: 2e64.

  Note that any pathnames (files or directories) supplied in the setup
script should be written using the Unix convention, i.e.
slash-separated.  The Distutils will take care of converting this
platform-neutral representation into whatever is appropriate on your
current platform before actually using the pathname.  This makes your
setup script portable across operating systems, which of course is one
of the major goals of the Distutils.  In this spirit, all pathnames in
this document are slash-separated.

  This, of course, only applies to pathnames given to Distutils
functions.  If you, for example, use standard Python functions such as
*note glob.glob(): 341. or *note os.listdir(): 2cf. to specify files,
you should be careful to write portable code instead of hardcoding path
separators:

    glob.glob(os.path.join('mydir', 'subdir', '*.html'))
    os.listdir(os.path.join('mydir', 'subdir'))


* Menu:

* Listing whole packages::
* Listing individual modules::
* Describing extension modules::
* Relationships between Distributions and Packages::
* Installing Scripts::
* Installing Package Data::
* Installing Additional Files::
* Additional meta-data::
* Debugging the setup script::


File: python.info,  Node: Listing whole packages,  Next: Listing individual modules,  Up: Writing the Setup Script

8.2.1 Listing whole packages
----------------------------

The `packages' option tells the Distutils to process (build, distribute,
install, etc.) all pure Python modules found in each package mentioned
in the `packages' list.  In order to do this, of course, there has to
be a correspondence between package names and directories in the
filesystem.  The default correspondence is the most obvious one, i.e.
package *note distutils: 85. is found in the directory `distutils'
relative to the distribution root.  Thus, when you say `packages =
['foo']' in your setup script, you are promising that the Distutils
will find a file `foo/__init__.py' (which might be spelled differently
on your system, but you get the idea) relative to the directory where
your setup script lives.  If you break this promise, the Distutils will
issue a warning but still process the broken package anyway.

  If you use a different convention to lay out your source directory,
that's no problem: you just have to supply the `package_dir' option to
tell the Distutils about your convention.  For example, say you keep
all Python source under `lib', so that modules in the "root package"
(i.e., not in any package at all) are in `lib', modules in the `foo'
package are in `lib/foo', and so forth.  Then you would put

    package_dir = {'': 'lib'}

in your setup script.  The keys to this dictionary are package names,
and an empty package name stands for the root package.  The values are
directory names relative to your distribution root.  In this case, when
you say `packages = ['foo']', you are promising that the file
`lib/foo/__init__.py' exists.

  Another possible convention is to put the `foo' package right in
`lib', the `foo.bar' package in `lib/bar', etc.  This would be written
in the setup script as

    package_dir = {'foo': 'lib'}

A `package: dir' entry in the `package_dir' dictionary implicitly
applies to all packages below _package_, so the `foo.bar' case is
automatically handled here.  In this example, having `packages = ['foo',
'foo.bar']' tells the Distutils to look for `lib/__init__.py' and
`lib/bar/__init__.py'.  (Keep in mind that although `package_dir'
applies recursively, you must explicitly list all packages in
`packages': the Distutils will _not_ recursively scan your source tree
looking for any directory with an `__init__.py' file.)


File: python.info,  Node: Listing individual modules,  Next: Describing extension modules,  Prev: Listing whole packages,  Up: Writing the Setup Script

8.2.2 Listing individual modules
--------------------------------

For a small module distribution, you might prefer to list all modules
rather than listing packages--especially the case of a single module
that goes in the "root package" (i.e., no package at all).  This
simplest case was shown in section *note A Simple Example: 2e5b.; here
is a slightly more involved example:

    py_modules = ['mod1', 'pkg.mod2']

This describes two modules, one of them in the "root" package, the
other in the `pkg' package.  Again, the default package/directory
layout implies that these two modules can be found in `mod1.py' and
`pkg/mod2.py', and that `pkg/__init__.py' exists as well. And again,
you can override the package/directory correspondence using the
`package_dir' option.


File: python.info,  Node: Describing extension modules,  Next: Relationships between Distributions and Packages,  Prev: Listing individual modules,  Up: Writing the Setup Script

8.2.3 Describing extension modules
----------------------------------

Just as writing Python extension modules is a bit more complicated than
writing pure Python modules, describing them to the Distutils is a bit
more complicated.  Unlike pure modules, it's not enough just to list
modules or packages and expect the Distutils to go out and find the
right files; you have to specify the extension name, source file(s),
and any compile/link requirements (include directories, libraries to
link with, etc.).

  All of this is done through another keyword argument to `setup()', the
`ext_modules' option.  `ext_modules' is just a list of `Extension'
instances, each of which describes a single extension module.  Suppose
your distribution includes a single extension, called `foo' and
implemented by `foo.c'.  If no additional instructions to the
compiler/linker are needed, describing this extension is quite simple:

    Extension('foo', ['foo.c'])

The `Extension' class can be imported from *note distutils.core: a0.
along with `setup()'.  Thus, the setup script for a module distribution
that contains only this one extension and nothing else might be:

    from distutils.core import setup, Extension
    setup(name='foo',
          version='1.0',
          ext_modules=[Extension('foo', ['foo.c'])],
          )

The `Extension' class (actually, the underlying extension-building
machinery implemented by the *build_ext* command) supports a great deal
of flexibility in describing Python extensions, which is explained in
the following sections.

* Menu:

* Extension names and packages::
* Extension source files::
* Preprocessor options::
* Library options::
* Other options::


File: python.info,  Node: Extension names and packages,  Next: Extension source files,  Up: Describing extension modules

8.2.3.1 Extension names and packages
....................................

The first argument to the `Extension' constructor is always the name of
the extension, including any package names.  For example,

    Extension('foo', ['src/foo1.c', 'src/foo2.c'])

describes an extension that lives in the root package, while

    Extension('pkg.foo', ['src/foo1.c', 'src/foo2.c'])

describes the same extension in the `pkg' package.  The source files and
resulting object code are identical in both cases; the only difference
is where in the filesystem (and therefore where in Python's namespace
hierarchy) the resulting extension lives.

  If you have a number of extensions all in the same package (or all
under the same base package), use the `ext_package' keyword argument to
`setup()'.  For example,

    setup(...,
          ext_package='pkg',
          ext_modules=[Extension('foo', ['foo.c']),
                       Extension('subpkg.bar', ['bar.c'])],
         )

will compile `foo.c' to the extension `pkg.foo', and `bar.c' to
`pkg.subpkg.bar'.


File: python.info,  Node: Extension source files,  Next: Preprocessor options,  Prev: Extension names and packages,  Up: Describing extension modules

8.2.3.2 Extension source files
..............................

The second argument to the `Extension' constructor is a list of source
files.  Since the Distutils currently only support C, C++, and
Objective-C extensions, these are normally C/C++/Objective-C source
files.  (Be sure to use appropriate extensions to distinguish C++source
files: `.cc' and `.cpp' seem to be recognized by both Unix and Windows
compilers.)

  However, you can also include SWIG interface (`.i') files in the
list; the *build_ext* command knows how to deal with SWIG extensions:
it will run SWIG on the interface file and compile the resulting C/C++
file into your extension.

  This warning notwithstanding, options to SWIG can be currently passed
like this:

    setup(...,
          ext_modules=[Extension('_foo', ['foo.i'],
                                 swig_opts=['-modern', '-I../include'])],
          py_modules=['foo'],
         )

Or on the commandline like this:

    > python setup.py build_ext --swig-opts="-modern -I../include"

On some platforms, you can include non-source files that are processed
by the compiler and included in your extension.  Currently, this just
means Windows message text (`.mc') files and resource definition
(`.rc') files for Visual C++. These will be compiled to binary resource
(`.res') files and linked into the executable.


File: python.info,  Node: Preprocessor options,  Next: Library options,  Prev: Extension source files,  Up: Describing extension modules

8.2.3.3 Preprocessor options
............................

Three optional arguments to `Extension' will help if you need to specify
include directories to search or preprocessor macros to define/undefine:
`include_dirs', `define_macros', and `undef_macros'.

  For example, if your extension requires header files in the `include'
directory under your distribution root, use the `include_dirs' option:

    Extension('foo', ['foo.c'], include_dirs=['include'])

You can specify absolute directories there; if you know that your
extension will only be built on Unix systems with X11R6 installed to
`/usr', you can get away with

    Extension('foo', ['foo.c'], include_dirs=['/usr/include/X11'])

You should avoid this sort of non-portable usage if you plan to
distribute your code: it's probably better to write C code like

    #include <X11/Xlib.h>

If you need to include header files from some other Python extension,
you can take advantage of the fact that header files are installed in a
consistent way by the Distutils *install_headers* command.  For
example, the Numerical Python header files are installed (on a standard
Unix installation) to `/usr/local/include/python1.5/Numerical'. (The
exact location will differ according to your platform and Python
installation.)  Since the Python include
directory--`/usr/local/include/python1.5' in this case--is always
included in the search path when building Python extensions, the best
approach is to write C code like

    #include <Numerical/arrayobject.h>

If you must put the `Numerical' include directory right into your header
search path, though, you can find that directory using the Distutils
*note distutils.sysconfig: af. module:

    from distutils.sysconfig import get_python_inc
    incdir = os.path.join(get_python_inc(plat_specific=1), 'Numerical')
    setup(...,
          Extension(..., include_dirs=[incdir]),
          )

Even though this is quite portable--it will work on any Python
installation, regardless of platform--it's probably easier to just
write your C code in the sensible way.

  You can define and undefine pre-processor macros with the
`define_macros' and `undef_macros' options. `define_macros' takes a
list of `(name, value)' tuples, where `name' is the name of the macro
to define (a string) and `value' is its value: either a string or
`None'.  (Defining a macro `FOO' to `None' is the equivalent of a bare
`#define FOO' in your C source: with most compilers, this sets `FOO' to
the string `1'.)  `undef_macros' is just a list of macros to undefine.

  For example:

    Extension(...,
              define_macros=[('NDEBUG', '1'),
                             ('HAVE_STRFTIME', None)],
              undef_macros=['HAVE_FOO', 'HAVE_BAR'])

is the equivalent of having this at the top of every C source file:

    #define NDEBUG 1
    #define HAVE_STRFTIME
    #undef HAVE_FOO
    #undef HAVE_BAR



File: python.info,  Node: Library options,  Next: Other options,  Prev: Preprocessor options,  Up: Describing extension modules

8.2.3.4 Library options
.......................

You can also specify the libraries to link against when building your
extension, and the directories to search for those libraries.  The
`libraries' option is a list of libraries to link against,
`library_dirs' is a list of directories to search for libraries at
link-time, and `runtime_library_dirs' is a list of directories to
search for shared (dynamically loaded) libraries at run-time.

  For example, if you need to link against libraries known to be in the
standard library search path on target systems

    Extension(...,
              libraries=['gdbm', 'readline'])

If you need to link with libraries in a non-standard location, you'll
have to include the location in `library_dirs':

    Extension(...,
              library_dirs=['/usr/X11R6/lib'],
              libraries=['X11', 'Xt'])

(Again, this sort of non-portable construct should be avoided if you
intend to distribute your code.)


File: python.info,  Node: Other options,  Prev: Library options,  Up: Describing extension modules

8.2.3.5 Other options
.....................

There are still some other options which can be used to handle special
cases.

  The `extra_objects' option is a list of object files to be passed to
the linker. These files must not have extensions, as the default
extension for the compiler is used.

  `extra_compile_args' and `extra_link_args' can be used to specify
additional command line options for the respective compiler and linker
command lines.

  `export_symbols' is only useful on Windows.  It can contain a list of
symbols (functions or variables) to be exported. This option is not
needed when building compiled extensions: Distutils  will automatically
add `initmodule' to the list of exported symbols.

  The `depends' option is a list of files that the extension depends on
(for example header files). The build command will call the compiler on
the sources to rebuild extension if any on this files has been modified
since the previous build.


File: python.info,  Node: Relationships between Distributions and Packages,  Next: Installing Scripts,  Prev: Describing extension modules,  Up: Writing the Setup Script

8.2.4 Relationships between Distributions and Packages
------------------------------------------------------

A distribution may relate to packages in three specific ways:

  1. It can require packages or modules.

  2. It can provide packages or modules.

  3. It can obsolete packages or modules.

  These relationships can be specified using keyword arguments to the
*note distutils.core.setup(): 2e71. function.

  Dependencies on other Python modules and packages can be specified by
supplying the _requires_ keyword argument to `setup()'. The value must
be a list of strings.  Each string specifies a package that is
required, and optionally what versions are sufficient.

  To specify that any version of a module or package is required, the
string should consist entirely of the module or package name. Examples
include `'mymodule'' and `'xml.parsers.expat''.

  If specific versions are required, a sequence of qualifiers can be
supplied in parentheses.  Each qualifier may consist of a comparison
operator and a version number.  The accepted comparison operators are:

    <    >    ==
    <=   >=   !=

These can be combined by using multiple qualifiers separated by commas
(and optional whitespace).  In this case, all of the qualifiers must be
matched; a logical AND is used to combine the evaluations.

  Let's look at a bunch of examples:

Requires Expression           Explanation
--------------------------------------------------------------------------------- 
`==1.0'                       Only version `1.0' is compatible
`>1.0, !=1.5.1, <2.0'         Any version after `1.0' and before `2.0' is
                              compatible, except `1.5.1'

  Now that we can specify dependencies, we also need to be able to
specify what we provide that other distributions can require.  This is
done using the _provides_ keyword argument to `setup()'. The value for
this keyword is a list of strings, each of which names a Python module
or package, and optionally identifies the version.  If the version is
not specified, it is assumed to match that of the distribution.

  Some examples:

Provides Expression       Explanation
----------------------------------------------------------------------------- 
`mypkg'                   Provide `mypkg', using the distribution version
`mypkg (1.1)'             Provide `mypkg' version 1.1, regardless of the
                          distribution version

  A package can declare that it obsoletes other packages using the
_obsoletes_ keyword argument.  The value for this is similar to that of
the _requires_ keyword: a list of strings giving module or package
specifiers.  Each specifier consists of a module or package name
optionally followed by one or more version qualifiers.  Version
qualifiers are given in parentheses after the module or package name.

  The versions identified by the qualifiers are those that are
obsoleted by the distribution being described.  If no qualifiers are
given, all versions of the named module or package are understood to be
obsoleted.


File: python.info,  Node: Installing Scripts,  Next: Installing Package Data,  Prev: Relationships between Distributions and Packages,  Up: Writing the Setup Script

8.2.5 Installing Scripts
------------------------

So far we have been dealing with pure and non-pure Python modules,
which are usually not run by themselves but imported by scripts.

  Scripts are files containing Python source code, intended to be
started from the command line.  Scripts don't require Distutils to do
anything very complicated.  The only clever feature is that if the
first line of the script starts with `#!' and contains the word
"python", the Distutils will adjust the first line to refer to the
current interpreter location. By default, it is replaced with the
current interpreter location.  The `--executable' (or `-e') option will
allow the interpreter path to be explicitly overridden.

  The `scripts' option simply is a list of files to be handled in this
way.  From the PyXML setup script:

    setup(...,
          scripts=['scripts/xmlproc_parse', 'scripts/xmlproc_val']
          )

Changed in version 2.7: All the scripts will also be added to the
`MANIFEST' file if no template is provided. See *note Specifying the
files to distribute: 2e74.


File: python.info,  Node: Installing Package Data,  Next: Installing Additional Files,  Prev: Installing Scripts,  Up: Writing the Setup Script

8.2.6 Installing Package Data
-----------------------------

Often, additional files need to be installed into a package.  These
files are often data that's closely related to the package's
implementation, or text files containing documentation that might be of
interest to programmers using the package.  These files are called
_package data_.

  Package data can be added to packages using the `package_data' keyword
argument to the `setup()' function.  The value must be a mapping from
package name to a list of relative path names that should be copied
into the package.  The paths are interpreted as relative to the
directory containing the package (information from the `package_dir'
mapping is used if appropriate); that is, the files are expected to be
part of the package in the source directories. They may contain glob
patterns as well.

  The path names may contain directory portions; any necessary
directories will be created in the installation.

  For example, if a package should contain a subdirectory with several
data files, the files can be arranged like this in the source tree:

    setup.py
    src/
        mypkg/
            __init__.py
            module.py
            data/
                tables.dat
                spoons.dat
                forks.dat

The corresponding call to `setup()' might be:

    setup(...,
          packages=['mypkg'],
          package_dir={'mypkg': 'src/mypkg'},
          package_data={'mypkg': ['data/*.dat']},
          )

New in version 2.4.

  Changed in version 2.7: All the files that match `package_data' will
be added to the `MANIFEST' file if no template is provided. See *note
Specifying the files to distribute: 2e74.


File: python.info,  Node: Installing Additional Files,  Next: Additional meta-data,  Prev: Installing Package Data,  Up: Writing the Setup Script

8.2.7 Installing Additional Files
---------------------------------

The `data_files' option can be used to specify additional files needed
by the module distribution: configuration files, message catalogs, data
files, anything which doesn't fit in the previous categories.

  `data_files' specifies a sequence of (_directory_, _files_) pairs in
the following way:

    setup(...,
          data_files=[('bitmaps', ['bm/b1.gif', 'bm/b2.gif']),
                      ('config', ['cfg/data.cfg']),
                      ('/etc/init.d', ['init-script'])]
         )

Note that you can specify the directory names where the data files will
be installed, but you cannot rename the data files themselves.

  Each (_directory_, _files_) pair in the sequence specifies the
installation directory and the files to install there.  If _directory_
is a relative path, it is interpreted relative to the installation
prefix (Python's `sys.prefix' for pure-Python packages,
`sys.exec_prefix' for packages that contain extension modules).  Each
file name in _files_ is interpreted relative to the `setup.py' script
at the top of the package source distribution.  No directory
information from _files_ is used to determine the final location of the
installed file; only the name of the file is used.

  You can specify the `data_files' options as a simple sequence of files
without specifying a target directory, but this is not recommended, and
the *install* command will print a warning in this case. To install data
files directly in the target directory, an empty string should be given
as the directory.

  Changed in version 2.7: All the files that match `data_files' will be
added to the `MANIFEST' file if no template is provided. See *note
Specifying the files to distribute: 2e74.


File: python.info,  Node: Additional meta-data,  Next: Debugging the setup script,  Prev: Installing Additional Files,  Up: Writing the Setup Script

8.2.8 Additional meta-data
--------------------------

The setup script may include additional meta-data beyond the name and
version.  This information includes:

Meta-Data                  Description                     Value                 Notes
---------------------------------------------------------------------------------------------- 
`name'                     name of the package             short string          (1)
`version'                  version of this release         short string          (1)(2)
`author'                   package author's name           short string          (3)
`author_email'             email address of the package    email address         (3)
                           author                                                
`maintainer'               package maintainer's name       short string          (3)
`maintainer_email'         email address of the package    email address         (3)
                           maintainer                                            
`url'                      home page for the package       URL                   (1)
`description'              short, summary description of   short string          
                           the package                                           
`long_description'         longer description of the       long string           (5)
                           package                                               
`download_url'             location where the package may  URL                   (4)
                           be downloaded                                         
`classifiers'              a list of classifiers           list of strings       (4)
`platforms'                a list of platforms             list of strings       
`license'                  license for the package         short string          (6)

  Notes:

  1. These fields are required.

  2. It is recommended that versions take the form
     _major.minor[.patch[.sub]]_.

  3. Either the author or the maintainer must be identified. If
     maintainer is provided, distutils lists it as the author in
     `PKG-INFO'.

  4. These fields should not be used if your package is to be
     compatible with Python versions prior to 2.2.3 or 2.3.  The list
     is available from the PyPI website(1).

  5. The `long_description' field is used by PyPI when you are *note
     registering: 2e7a. a package, to *note build its home page: 2e7b.

  6. The `license' field is a text indicating the license covering the
     package where the license is not a selection from the "License"
     Trove classifiers. See the `Classifier' field. Notice that there's
     a `licence' distribution option which is deprecated but still acts
     as an alias for `license'.

'short string'
     A single line of text, not more than 200 characters.

'long string'
     Multiple lines of plain text in reStructuredText format (see
     <http://docutils.sf.net/>).

'list of strings'
     See below.

  None of the string values may be Unicode.

  Encoding the version information is an art in itself. Python packages
generally adhere to the version format _major.minor[.patch][sub]_. The
major number is 0 for initial, experimental releases of software. It is
incremented for releases that represent major milestones in a package.
The minor number is incremented when important new features are added
to the package. The patch number increments when bug-fix releases are
made. Additional trailing version information is sometimes used to
indicate sub-releases.  These are "a1,a2,...,aN" (for alpha releases,
where functionality and API may change), "b1,b2,...,bN" (for beta
releases, which only fix bugs) and "pr1,pr2,...,prN" (for final
pre-release release testing). Some examples:

0.1.0
     the first, experimental release of a package

1.0.1a2
     the second alpha release of the first patch version of 1.0

  `classifiers' are specified in a Python list:

    setup(...,
          classifiers=[
              'Development Status :: 4 - Beta',
              'Environment :: Console',
              'Environment :: Web Environment',
              'Intended Audience :: End Users/Desktop',
              'Intended Audience :: Developers',
              'Intended Audience :: System Administrators',
              'License :: OSI Approved :: Python Software Foundation License',
              'Operating System :: MacOS :: MacOS X',
              'Operating System :: Microsoft :: Windows',
              'Operating System :: POSIX',
              'Programming Language :: Python',
              'Topic :: Communications :: Email',
              'Topic :: Office/Business',
              'Topic :: Software Development :: Bug Tracking',
              ],
          )

If you wish to include classifiers in your `setup.py' file and also wish
to remain backwards-compatible with Python releases prior to 2.2.3,
then you can include the following code fragment in your `setup.py'
before the `setup()' call.

    # patch distutils if it can't cope with the "classifiers" or
    # "download_url" keywords
    from sys import version
    if version < '2.2.3':
        from distutils.dist import DistributionMetadata
        DistributionMetadata.classifiers = None
        DistributionMetadata.download_url = None


  ---------- Footnotes ----------

  (1) http://pypi.python.org/pypi


File: python.info,  Node: Debugging the setup script,  Prev: Additional meta-data,  Up: Writing the Setup Script

8.2.9 Debugging the setup script
--------------------------------

Sometimes things go wrong, and the setup script doesn't do what the
developer wants.

  Distutils catches any exceptions when running the setup script, and
print a simple error message before the script is terminated.  The
motivation for this behaviour is to not confuse administrators who
don't know much about Python and are trying to install a package.  If
they get a big long traceback from deep inside the guts of Distutils,
they may think the package or the Python installation is broken because
they don't read all the way down to the bottom and see that it's a
permission problem.

  On the other hand, this doesn't help the developer to find the cause
of the failure. For this purpose, the DISTUTILS_DEBUG environment
variable can be set to anything except an empty string, and distutils
will now print detailed information what it is doing, and prints the
full traceback in case an exception occurs.


File: python.info,  Node: Writing the Setup Configuration File,  Next: Creating a Source Distribution,  Prev: Writing the Setup Script,  Up: Distributing Python Modules

8.3 Writing the Setup Configuration File
========================================

Often, it's not possible to write down everything needed to build a
distribution _a priori_: you may need to get some information from the
user, or from the user's system, in order to proceed.  As long as that
information is fairly simple--a list of directories to search for C
header files or libraries, for example--then providing a configuration
file, `setup.cfg', for users to edit is a cheap and easy way to solicit
it.  Configuration files also let you provide default values for any
command option, which the installer can then override either on the
command-line or by editing the config file.

  The setup configuration file is a useful middle-ground between the
setup script --which, ideally, would be opaque to installers (1)--and
the command-line to the setup script, which is outside of your control
and entirely up to the installer.  In fact, `setup.cfg' (and any other
Distutils configuration files present on the target system) are
processed after the contents of the setup script, but before the
command-line.  This has  several useful consequences:

   * installers can override some of what you put in `setup.py' by
     editing `setup.cfg'

   * you can provide non-standard defaults for options that are not
     easily set in `setup.py'

   * installers can override anything in `setup.cfg' using the
     command-line options to `setup.py'

  The basic syntax of the configuration file is simple:

    [command]
    option=value
    ...

where _command_ is one of the Distutils commands (e.g. *build_py*,
*install*), and _option_ is one of the options that command supports.
Any number of options can be supplied for each command, and any number
of command sections can be included in the file.  Blank lines are
ignored, as are comments, which run from a `'#'' character until the
end of the line.  Long option values can be split across multiple lines
simply by indenting the continuation lines.

  You can find out the list of options supported by a particular
command with the universal *note -help: 1d2. option, e.g.

    > python setup.py --help build_ext
    [...]
    Options for 'build_ext' command:
      --build-lib (-b)     directory for compiled extension modules
      --build-temp (-t)    directory for temporary files (build by-products)
      --inplace (-i)       ignore build-lib and put compiled extensions into the
                           source directory alongside your pure Python modules
      --include-dirs (-I)  list of directories to search for header files
      --define (-D)        C preprocessor macros to define
      --undef (-U)         C preprocessor macros to undefine
      --swig-opts          list of SWIG command line options
    [...]

Note that an option spelled `--foo-bar' on the command-line  is spelled
`foo_bar' in configuration files.

  For example, say you want your extensions to be built
"in-place"--that is, you have an extension `pkg.ext', and you want the
compiled extension file (`ext.so' on Unix, say) to be put in the same
source directory as your pure Python modules `pkg.mod1' and `pkg.mod2'.
You can always use the `--inplace' option on the command-line to ensure
this:

    python setup.py build_ext --inplace

But this requires that you always specify the *build_ext* command
explicitly, and remember to provide `--inplace'. An easier way is to
"set and forget" this option, by encoding it in `setup.cfg', the
configuration file for this distribution:

    [build_ext]
    inplace=1

This will affect all builds of this module distribution, whether or not
you explicitly specify *build_ext*.  If you include `setup.cfg' in your
source distribution, it will also affect end-user builds--which is
probably a bad idea for this option, since always building extensions
in-place would break installation of the module distribution.  In
certain peculiar cases, though, modules are built right in their
installation directory, so this is conceivably a useful ability.
(Distributing extensions that expect to be built in their installation
directory is almost always a bad idea, though.)

  Another example: certain commands take a lot of options that don't
change from run to run; for example, *bdist_rpm* needs to know
everything required to generate a "spec" file for creating an RPM
distribution.  Some of this information comes from the setup script,
and some is automatically generated by the Distutils (such as the list
of files installed).  But some of it has to be supplied as options to
*bdist_rpm*, which would be very tedious to do on the command-line for
every run.  Hence, here is a snippet from the Distutils' own
`setup.cfg':

    [bdist_rpm]
    release = 1
    packager = Greg Ward <gward@python.net>
    doc_files = CHANGES.txt
                README.txt
                USAGE.txt
                doc/
                examples/

Note that the `doc_files' option is simply a whitespace-separated string
split across multiple lines for readability.

See also
........

*note Syntax of config files: 2e80. in "Installing Python Modules"
     More information on the configuration files is available in the
     manual for system administrators.

  ---------- Footnotes ----------

  (1) This ideal probably won't be achieved until auto-configuration is
fully supported by the Distutils.


File: python.info,  Node: Creating a Source Distribution,  Next: Creating Built Distributions,  Prev: Writing the Setup Configuration File,  Up: Distributing Python Modules

8.4 Creating a Source Distribution
==================================

As shown in section *note A Simple Example: 2e5b, you use the *sdist*
command to create a source distribution.  In the simplest case,

    python setup.py sdist

(assuming you haven't specified any *sdist* options in the setup script
or config file), *sdist* creates the archive of the default format for
the current platform.  The default format is a gzip'ed tar file
(`.tar.gz') on Unix, and ZIP file on Windows.

  You can specify as many formats as you like using the `--formats'
option, for example:

    python setup.py sdist --formats=gztar,zip

to create a gzipped tarball and a zip file.  The available formats are:

Format          Description                   Notes
------------------------------------------------------------ 
`zip'           zip file (`.zip')             (1),(3)
`gztar'         gzip'ed tar file (`.tar.gz')  (2)
`bztar'         bzip2'ed tar file             
                (`.tar.bz2')                  
`ztar'          compressed tar file           (4)
                (`.tar.Z')                    
`tar'           tar file (`.tar')             

  Notes:

  1. default on Windows

  2. default on Unix

  3. requires either external *zip* utility or *note zipfile: 1ab.
     module (part of the standard Python library since Python 1.6)

  4. requires the *compress* program.

  When using any `tar' format (`gztar', `bztar', `ztar' or `tar') under
Unix, you can specify the `owner' and `group' names that will be set
for each member of the archive.

  For example, if you want all files of the archive to be owned by root:

    python setup.py sdist --owner=root --group=root


* Menu:

* Specifying the files to distribute::
* Manifest-related options::
* The MANIFEST.in template: The MANIFEST in template.


File: python.info,  Node: Specifying the files to distribute,  Next: Manifest-related options,  Up: Creating a Source Distribution

8.4.1 Specifying the files to distribute
----------------------------------------

If you don't supply an explicit list of files (or instructions on how to
generate one), the *sdist* command puts a minimal default set into the
source distribution:

   * all Python source files implied by the `py_modules' and `packages'
     options

   * all C source files mentioned in the `ext_modules' or `libraries'
     options

   * scripts identified by the `scripts' option See *note Installing
     Scripts: 2e73.

   * anything that looks like a test script: `test/test*.py'
     (currently, the Distutils don't do anything with test scripts
     except include them in source distributions, but in the future
     there will be a standard for testing Python module distributions)

   * `README.txt' (or `README'), `setup.py' (or whatever  you called
     your setup script), and `setup.cfg'

   * all files that matches the `package_data' metadata.  See *note
     Installing Package Data: 2e76.

   * all files that matches the `data_files' metadata.  See *note
     Installing Additional Files: 2e78.

  Sometimes this is enough, but usually you will want to specify
additional files to distribute.  The typical way to do this is to write
a _manifest template_, called `MANIFEST.in' by default.  The manifest
template is just a list of instructions for how to generate your
manifest file, `MANIFEST', which is the exact list of files to include
in your source distribution.  The *sdist* command processes this
template and generates a manifest based on its instructions and what it
finds in the filesystem.

  If you prefer to roll your own manifest file, the format is simple:
one filename per line, regular files (or symlinks to them) only.  If
you do supply your own `MANIFEST', you must specify everything: the
default set of files described above does not apply in this case.

  Changed in version 2.7: An existing generated `MANIFEST' will be
regenerated without *sdist* comparing its modification time to the one
of `MANIFEST.in' or `setup.py'.

  Changed in version 2.7.1: `MANIFEST' files start with a comment
indicating they are generated.  Files without this comment are not
overwritten or removed.

  Changed in version 2.7.3: *sdist* will read a `MANIFEST' file if no
`MANIFEST.in' exists, like it did before 2.7.

  See *note The MANIFEST.in template: 2e85. section for a syntax
reference.


File: python.info,  Node: Manifest-related options,  Next: The MANIFEST in template,  Prev: Specifying the files to distribute,  Up: Creating a Source Distribution

8.4.2 Manifest-related options
------------------------------

The normal course of operations for the *sdist* command is as follows:

   * if the manifest file (`MANIFEST' by default) exists and the first
     line does not have a comment indicating it is generated from
     `MANIFEST.in', then it is used as is, unaltered

   * if the manifest file doesn't exist or has been previously
     automatically generated, read `MANIFEST.in' and create the manifest

   * if neither `MANIFEST' nor `MANIFEST.in' exist, create a manifest
     with just the default file set

   * use the list of files now in `MANIFEST' (either just generated or
     read in) to create the source distribution archive(s)

  There are a couple of options that modify this behaviour.  First, use
the `--no-defaults' and `--no-prune' to disable the standard "include"
and "exclude" sets.

  Second, you might just want to (re)generate the manifest, but not
create a source distribution:

    python setup.py sdist --manifest-only

`-o' is a shortcut for `--manifest-only'.


File: python.info,  Node: The MANIFEST in template,  Prev: Manifest-related options,  Up: Creating a Source Distribution

8.4.3 The MANIFEST.in template
------------------------------

A `MANIFEST.in' file can be added in a project to define the list of
files to include in the distribution built by the *sdist* command.

  When *sdist* is run, it will look for the `MANIFEST.in' file and
interpret it to generate the `MANIFEST' file that contains the list of
files that will be included in the package.

  This mechanism can be used when the default list of files is not
enough.  (See *note Specifying the files to distribute: 2e74.).

* Menu:

* Principle::
* Commands::


File: python.info,  Node: Principle,  Next: Commands,  Up: The MANIFEST in template

8.4.3.1 Principle
.................

The manifest template has one command per line, where each command
specifies a set of files to include or exclude from the source
distribution.  For an example, let's look at the Distutils' own
manifest template:

    include *.txt
    recursive-include examples *.txt *.py
    prune examples/sample?/build

The meanings should be fairly clear: include all files in the
distribution root matching `*.txt', all files anywhere under the
`examples' directory matching `*.txt' or `*.py', and exclude all
directories matching `examples/sample?/build'.  All of this is done
_after_ the standard include set, so you can exclude files from the
standard set with explicit instructions in the manifest template.  (Or,
you can use the `--no-defaults' option to disable the standard set
entirely.)

  The order of commands in the manifest template matters: initially, we
have the list of default files as described above, and each command in
the template adds to or removes from that list of files.  Once we have
fully processed the manifest template, we remove files that should not
be included in the source distribution:

   * all files in the Distutils "build" tree (default `build/')

   * all files in directories named `RCS', `CVS', `.svn', `.hg',
     `.git', `.bzr' or `_darcs'

  Now we have our complete list of files, which is written to the
manifest for future reference, and then used to build the source
distribution archive(s).

  You can disable the default set of included files with the
`--no-defaults' option, and you can disable the standard exclude set
with `--no-prune'.

  Following the Distutils' own manifest template, let's trace how the
*sdist* command builds the list of files to include in the Distutils
source distribution:

  1. include all Python source files in the `distutils' and
     `distutils/command' subdirectories (because packages corresponding
     to those two directories were mentioned in the `packages' option
     in the setup script--see section *note Writing the Setup Script:
     2e5d.)

  2. include `README.txt', `setup.py', and `setup.cfg' (standard files)

  3. include `test/test*.py' (standard files)

  4. include `*.txt' in the distribution root (this will find
     `README.txt' a second time, but such redundancies are weeded out
     later)

  5. include anything matching `*.txt' or `*.py' in the sub-tree under
     `examples',

  6. exclude all files in the sub-trees starting at directories matching
     `examples/sample?/build'--this may exclude files included by the
     previous two steps, so it's important that the `prune' command in
     the manifest template comes after the `recursive-include' command

  7. exclude the entire `build' tree, and any `RCS', `CVS', `.svn',
     `.hg', `.git', `.bzr' and `_darcs' directories

  Just like in the setup script, file and directory names in the
manifest template should always be slash-separated; the Distutils will
take care of converting them to the standard representation on your
platform. That way, the manifest template is portable across operating
systems.


File: python.info,  Node: Commands,  Prev: Principle,  Up: The MANIFEST in template

8.4.3.2 Commands
................

The manifest template commands are:

Command                                         Description
---------------------------------------------------------------------------------------------------- 
*include pat1 pat2 ...*                         include all files matching any of the listed
                                                patterns
*exclude pat1 pat2 ...*                         exclude all files matching any of the listed
                                                patterns
*recursive-include dir pat1 pat2 ...*           include all files under _dir_ matching any of the
                                                listed patterns
*recursive-exclude dir pat1 pat2 ...*           exclude all files under _dir_ matching any of the
                                                listed patterns
*global-include pat1 pat2 ...*                  include all files anywhere in the source tree
                                                matching -- & any of the listed patterns
*global-exclude pat1 pat2 ...*                  exclude all files anywhere in the source tree
                                                matching -- & any of the listed patterns
*prune dir*                                     exclude all files under _dir_
*graft dir*                                     include all files under _dir_

  The patterns here are Unix-style "glob" patterns: `*' matches any
sequence of regular filename characters, `?' matches any single regular
filename character, and `[range]' matches any of the characters in
_range_ (e.g., `a-z', `a-zA-Z', `a-f0-9_.').  The definition of
"regular filename character" is platform-specific: on Unix it is
anything except slash; on Windows anything except backslash or colon.


File: python.info,  Node: Creating Built Distributions,  Next: The Python Package Index PyPI,  Prev: Creating a Source Distribution,  Up: Distributing Python Modules

8.5 Creating Built Distributions
================================

A "built distribution" is what you're probably used to thinking of
either as a "binary package" or an "installer" (depending on your
background).  It's not necessarily binary, though, because it might
contain only Python source code and/or byte-code; and we don't call it
a package, because that word is already spoken for in Python.  (And
"installer" is a term specific to the world of mainstream desktop
systems.)

  A built distribution is how you make life as easy as possible for
installers of your module distribution: for users of RPM-based Linux
systems, it's a binary RPM; for Windows users, it's an executable
installer; for Debian-based Linux users, it's a Debian package; and so
forth.  Obviously, no one person will be able to create built
distributions for every platform under the sun, so the Distutils are
designed to enable module developers to concentrate on their
specialty--writing code and creating source distributions--while an
intermediary species called _packagers_ springs up to turn source
distributions into built distributions for as many platforms as there
are packagers.

  Of course, the module developer could be his own packager; or the
packager could be a volunteer "out there" somewhere who has access to a
platform which the original developer does not; or it could be software
periodically grabbing new source distributions and turning them into
built distributions for as many platforms as the software has access
to.  Regardless of who they are, a packager uses the setup script and
the *bdist* command family to generate built distributions.

  As a simple example, if I run the following command in the Distutils
source tree:

    python setup.py bdist

then the Distutils builds my module distribution (the Distutils itself
in this case), does a "fake" installation (also in the `build'
directory), and creates the default type of built distribution for my
platform.  The default format for built distributions is a "dumb" tar
file on Unix, and a simple executable installer on Windows.  (That tar
file is considered "dumb" because it has to be unpacked in a specific
location to work.)

  Thus, the above command on a Unix system creates
`Distutils-1.0._plat_.tar.gz'; unpacking this tarball from the right
place installs the Distutils just as though you had downloaded the
source distribution and run `python setup.py install'.  (The "right
place" is either the root of the filesystem or  Python's `_prefix_'
directory, depending on the options given to the *bdist_dumb* command;
the default is to make dumb distributions relative to `_prefix_'.)

  Obviously, for pure Python distributions, this isn't any simpler than
just running `python setup.py install'--but for non-pure distributions,
which include extensions that would need to be compiled, it can mean
the difference between someone being able to use your extensions or
not.  And creating "smart" built distributions, such as an RPM package
or an executable installer for Windows, is far more convenient for
users even if your distribution doesn't include any extensions.

  The *bdist* command has a `--formats' option, similar to the *sdist*
command, which you can use to select the types of built distribution to
generate: for example,

    python setup.py bdist --format=zip

would, when run on a Unix system, create
`Distutils-1.0._plat_.zip'--again, this archive would be unpacked from
the root directory to install the Distutils.

  The available formats for built distributions are:

Format            Description                        Notes
------------------------------------------------------------------- 
`gztar'           gzipped tar file (`.tar.gz')       (1),(3)
`ztar'            compressed tar file (`.tar.Z')     (3)
`tar'             tar file (`.tar')                  (3)
`zip'             zip file (`.zip')                  (2),(4)
`rpm'             RPM                                (5)
`pkgtool'         Solaris *pkgtool*                  
`sdux'            HP-UX *swinstall*                  
`wininst'         self-extracting ZIP file for       (4)
                  Windows                            
`msi'             Microsoft Installer.               

  Notes:

  1. default on Unix

  2. default on Windows

  3. requires external utilities: *tar* and possibly one of *gzip*,
     *bzip2*, or *compress*

  4. requires either external *zip* utility or *note zipfile: 1ab.
     module (part of the standard Python library since Python 1.6)

  5. requires external *rpm* utility, version 3.0.4 or better (use `rpm
     --version' to find out which version you have)

  You don't have to use the *bdist* command with the `--formats'
option; you can also use the command that directly implements the
format you're interested in.  Some of these *bdist* "sub-commands"
actually generate several similar formats; for instance, the
*bdist_dumb* command generates all the "dumb" archive formats (`tar',
`ztar', `gztar', and `zip'), and *bdist_rpm* generates both binary and
source RPMs.  The *bdist* sub-commands, and the formats generated by
each, are:

Command                        Formats
----------------------------------------------------------- 
*bdist_dumb*                   tar, ztar, gztar, zip
*bdist_rpm*                    rpm, srpm
*bdist_wininst*                wininst
*bdist_msi*                    msi

  The following sections give details on the individual *bdist_**
commands.

* Menu:

* Creating dumb built distributions::
* Creating RPM packages::
* Creating Windows Installers::
* Cross-compiling on Windows::
* Vista User Access Control (UAC): Vista User Access Control UAC.


File: python.info,  Node: Creating dumb built distributions,  Next: Creating RPM packages,  Up: Creating Built Distributions

8.5.1 Creating dumb built distributions
---------------------------------------


File: python.info,  Node: Creating RPM packages,  Next: Creating Windows Installers,  Prev: Creating dumb built distributions,  Up: Creating Built Distributions

8.5.2 Creating RPM packages
---------------------------

The RPM format is used by many popular Linux distributions, including
Red Hat, SuSE, and Mandrake.  If one of these (or any of the other
RPM-based Linux distributions) is your usual environment, creating RPM
packages for other users of that same distribution is trivial.
Depending on the complexity of your module distribution and differences
between Linux distributions, you may also be able to create RPMs that
work on different RPM-based distributions.

  The usual way to create an RPM of your module distribution is to run
the *bdist_rpm* command:

    python setup.py bdist_rpm

or the *bdist* command with the `--format' option:

    python setup.py bdist --formats=rpm

The former allows you to specify RPM-specific options; the latter
allows  you to easily specify multiple formats in one run.  If you need
to do both, you can explicitly specify multiple *bdist_** commands and
their options:

    python setup.py bdist_rpm --packager="John Doe <jdoe@example.org>" \
                    bdist_wininst --target-version="2.0"

Creating RPM packages is driven by a `.spec' file, much as using the
Distutils is driven by the setup script.  To make your life easier, the
*bdist_rpm* command normally creates a `.spec' file based on the
information you supply in the setup script, on the command line, and in
any Distutils configuration files.  Various options and sections in the
`.spec' file are derived from options in the setup script as follows:

RPM `.spec' file option or section             Distutils setup script option
-------------------------------------------------------------------------------------------------- 
Name                                           `name'
Summary (in preamble)                          `description'
Version                                        `version'
Vendor                                         `author' and `author_email', or  -- &
                                               `maintainer' and `maintainer_email'
Copyright                                      `license'
Url                                            `url'
%description (section)                         `long_description'

  Additionally, there are many options in `.spec' files that don't have
corresponding options in the setup script.  Most of these are handled
through options to the *bdist_rpm* command as follows:

RPM `.spec' file option or section  *bdist_rpm* option                default value
---------------------------------------------------------------------------------------------------- 
Release                             `release'                         "1"
Group                               `group'                           "Development/Libraries"
Vendor                              `vendor'                          (see above)
Packager                            `packager'                        (none)
Provides                            `provides'                        (none)
Requires                            `requires'                        (none)
Conflicts                           `conflicts'                       (none)
Obsoletes                           `obsoletes'                       (none)
Distribution                        `distribution_name'               (none)
BuildRequires                       `build_requires'                  (none)
Icon                                `icon'                            (none)

  Obviously, supplying even a few of these options on the command-line
would be tedious and error-prone, so it's usually best to put them in
the setup configuration file, `setup.cfg'--see section *note Writing
the Setup Configuration File: 2e7f.  If you distribute or package many
Python module distributions, you might want to put options that apply
to all of them in your personal Distutils configuration file
(`~/.pydistutils.cfg').  If you want to temporarily disable this file,
you can pass the -no-user-cfg option to setup.py.

  There are three steps to building a binary RPM package, all of which
are handled automatically by the Distutils:

  1. create a `.spec' file, which describes the package (analogous  to
     the Distutils setup script; in fact, much of the information in
     the  setup script winds up in the `.spec' file)

  2. create the source RPM

  3. create the "binary" RPM (which may or may not contain binary code,
     depending on whether your module distribution contains Python
     extensions)

  Normally, RPM bundles the last two steps together; when you use the
Distutils, all three steps are typically bundled together.

  If you wish, you can separate these three steps.  You can use the
`--spec-only' option to make *bdist_rpm* just create the `.spec' file
and exit; in this case, the `.spec' file will be written to the
"distribution directory"--normally `dist/', but customizable with the
`--dist-dir' option.  (Normally, the `.spec' file winds up deep in the
"build tree," in a temporary directory created by *bdist_rpm*.)


File: python.info,  Node: Creating Windows Installers,  Next: Cross-compiling on Windows,  Prev: Creating RPM packages,  Up: Creating Built Distributions

8.5.3 Creating Windows Installers
---------------------------------

Executable installers are the natural format for binary distributions on
Windows.  They display a nice graphical user interface, display some
information about the module distribution to be installed taken from
the metadata in the setup script, let the user select a few options,
and start or cancel the installation.

  Since the metadata is taken from the setup script, creating Windows
installers is usually as easy as running:

    python setup.py bdist_wininst

or the *bdist* command with the `--formats' option:

    python setup.py bdist --formats=wininst

If you have a pure module distribution (only containing pure Python
modules and packages), the resulting installer will be version
independent and have a name like `foo-1.0.win32.exe'.  These installers
can even be created on Unix platforms or Mac OS X.

  If you have a non-pure distribution, the extensions can only be
created on a Windows platform, and will be Python version dependent.
The installer filename will reflect this and now has the form
`foo-1.0.win32-py2.0.exe'.  You have to create a separate installer for
every Python version you want to support.

  The installer will try to compile pure modules into *note bytecode:
57a. after installation on the target system in normal and optimizing
mode.  If you don't want this to happen for some reason, you can run
the *bdist_wininst* command with the `--no-target-compile' and/or the
`--no-target-optimize' option.

  By default the installer will display the cool "Python Powered" logo
when it is run, but you can also supply your own 152x261 bitmap which
must be a Windows `.bmp' file with the `--bitmap' option.

  The installer will also display a large title on the desktop
background window when it is run, which is constructed from the name of
your distribution and the version number.  This can be changed to
another text by using the `--title' option.

  The installer file will be written to the "distribution directory" --
normally `dist/', but customizable with the `--dist-dir' option.


File: python.info,  Node: Cross-compiling on Windows,  Next: Vista User Access Control UAC,  Prev: Creating Windows Installers,  Up: Creating Built Distributions

8.5.4 Cross-compiling on Windows
--------------------------------

Starting with Python 2.6, distutils is capable of cross-compiling
between Windows platforms.  In practice, this means that with the
correct tools installed, you can use a 32bit version of Windows to
create 64bit extensions and vice-versa.

  To build for an alternate platform, specify the `--plat-name' option
to the build command.  Valid values are currently 'win32', 'win-amd64'
and 'win-ia64'.  For example, on a 32bit version of Windows, you could
execute:

    python setup.py build --plat-name=win-amd64

to build a 64bit version of your extension.  The Windows Installers also
support this option, so the command:

    python setup.py build --plat-name=win-amd64 bdist_wininst

would create a 64bit installation executable on your 32bit version of
Windows.

  To cross-compile, you must download the Python source code and
cross-compile Python itself for the platform you are targetting - it is
not possible from a binary installation of Python (as the .lib etc file
for other platforms are not included.)  In practice, this means the
user of a 32 bit operating system will need to use Visual Studio 2008
to open the `PCBuild/PCbuild.sln' solution in the Python source tree
and build the "x64" configuration of the 'pythoncore' project before
cross-compiling extensions is possible.

  Note that by default, Visual Studio 2008 does not install 64bit
compilers or tools.  You may need to reexecute the Visual Studio setup
process and select these tools (using Control Panel->[Add/Remove]
Programs is a convenient way to check or modify your existing install.)

* Menu:

* The Postinstallation script::


File: python.info,  Node: The Postinstallation script,  Up: Cross-compiling on Windows

8.5.4.1 The Postinstallation script
...................................

Starting with Python 2.3, a postinstallation script can be specified
with the `--install-script' option.  The basename of the script must be
specified, and the script filename must also be listed in the scripts
argument to the setup function.

  This script will be run at installation time on the target system
after all the files have been copied, with `argv[1]' set to `-install',
and again at uninstallation time before the files are removed with
`argv[1]' set to `-remove'.

  The installation script runs embedded in the windows installer, every
output (`sys.stdout', `sys.stderr') is redirected into a buffer and
will be displayed in the GUI after the script has finished.

  Some functions especially useful in this context are available as
additional built-in functions in the installation script.

 -- Function: directory_created (path)
 -- Function: file_created (path)
     These functions should be called when a directory or file is
     created by the postinstall script at installation time.  It will
     register _path_ with the uninstaller, so that it will be removed
     when the distribution is uninstalled.  To be safe, directories are
     only removed if they are empty.

 -- Function: get_special_folder_path (csidl_string)
     This function can be used to retrieve special folder locations on
     Windows like the Start Menu or the Desktop.  It returns the full
     path to the folder.  _csidl_string_ must be one of the following
     strings:

         "CSIDL_APPDATA"

         "CSIDL_COMMON_STARTMENU"
         "CSIDL_STARTMENU"

         "CSIDL_COMMON_DESKTOPDIRECTORY"
         "CSIDL_DESKTOPDIRECTORY"

         "CSIDL_COMMON_STARTUP"
         "CSIDL_STARTUP"

         "CSIDL_COMMON_PROGRAMS"
         "CSIDL_PROGRAMS"

         "CSIDL_FONTS"

     If the folder cannot be retrieved, *note OSError: 22e. is raised.

     Which folders are available depends on the exact Windows version,
     and probably also the configuration.  For details refer to
     Microsoft's documentation of the `SHGetSpecialFolderPath()'
     function.

 -- Function: create_shortcut (target, description, filename[,
          arguments[, workdir[, iconpath[, iconindex]]]])
     This function creates a shortcut. _target_ is the path to the
     program to be started by the shortcut. _description_ is the
     description of the shortcut.  _filename_ is the title of the
     shortcut that the user will see. _arguments_ specifies the command
     line arguments, if any. _workdir_ is the working directory for the
     program. _iconpath_ is the file containing the icon for the
     shortcut, and _iconindex_ is the index of the icon in the file
     _iconpath_.  Again, for details consult the Microsoft
     documentation for the `IShellLink' interface.


File: python.info,  Node: Vista User Access Control UAC,  Prev: Cross-compiling on Windows,  Up: Creating Built Distributions

8.5.5 Vista User Access Control (UAC)
-------------------------------------

Starting with Python 2.6, bdist_wininst supports a
`--user-access-control' option.  The default is 'none' (meaning no UAC
handling is done), and other valid values are 'auto' (meaning prompt
for UAC elevation if Python was installed for all users) and 'force'
(meaning always prompt for elevation).


File: python.info,  Node: The Python Package Index PyPI,  Next: Examples<24>,  Prev: Creating Built Distributions,  Up: Distributing Python Modules

8.6 The Python Package Index (PyPI)
===================================

The Python Package Index (PyPI)(1) holds *note meta-data: 2e64.
describing distributions packaged with distutils, as well as package
data like distribution files if the package author wishes.

  Distutils exposes two commands for submitting package data to PyPI:
the *note register: 2e7a. command for submitting meta-data to PyPI and
the *note upload: 2ea0. command for submitting distribution files.
Both commands read configuration data from a special file called the
*note .pypirc file: 2ea1.  PyPI *note displays a home page: 2e7b. for
each package created from the `long_description' submitted by the
*register* command.

* Menu:

* Registering Packages::
* Uploading Packages::
* The .pypirc file: The pypirc file.
* PyPI package display::

  ---------- Footnotes ----------

  (1) http://pypi.python.org/


File: python.info,  Node: Registering Packages,  Next: Uploading Packages,  Up: The Python Package Index PyPI

8.6.1 Registering Packages
--------------------------

The distutils command *register* is used to submit your distribution's
meta-data to the index. It is invoked as follows:

    python setup.py register

Distutils will respond with the following prompt:

    running register
    We need to know who you are, so please choose either:
        1. use your existing login,
        2. register as a new user,
        3. have the server generate a new password for you (and email it to you), or
        4. quit
    Your selection [default 1]:

Note: if your username and password are saved locally, you will not see
this menu.

  If you have not registered with PyPI, then you will need to do so
now. You should choose option 2, and enter your details as required.
Soon after submitting your details, you will receive an email which
will be used to confirm your registration.

  Once you are registered, you may choose option 1 from the menu. You
will be prompted for your PyPI username and password, and *register*
will then submit your meta-data to the index.

  You may submit any number of versions of your distribution to the
index. If you alter the meta-data for a particular version, you may
submit it again and the index will be updated.

  PyPI holds a record for each (name, version) combination submitted.
The first user to submit information for a given name is designated the
Owner of that name. They may submit changes through the *register*
command or through the web interface. They may also designate other
users as Owners or Maintainers.  Maintainers may edit the package
information, but not designate other Owners or Maintainers.

  By default PyPI displays only the newest version of a given package.
The web interface lets one change this default behavior and manually
select which versions to display and hide.


File: python.info,  Node: Uploading Packages,  Next: The pypirc file,  Prev: Registering Packages,  Up: The Python Package Index PyPI

8.6.2 Uploading Packages
------------------------

New in version 2.5.

  The distutils command *upload* pushes the distribution files to PyPI.

  The command is invoked immediately after building one or more
distribution files.  For example, the command

    python setup.py sdist bdist_wininst upload

will cause the source distribution and the Windows installer to be
uploaded to PyPI.  Note that these will be uploaded even if they are
built using an earlier invocation of `setup.py', but that only
distributions named on the command line for the invocation including
the *upload* command are uploaded.

  The *upload* command uses the username, password, and repository URL
from the `$HOME/.pypirc' file (see section *note The .pypirc file:
2ea1. for more on this file). If a *register* command was previously
called in the same command, and if the password was entered in the
prompt, *upload* will reuse the entered password. This is useful if you
do not want to store a clear text password in the `$HOME/.pypirc' file.

  You can specify another PyPI server with the `--repository=url'
option:

    python setup.py sdist bdist_wininst upload -r http://example.com/pypi

See section *note The .pypirc file: 2ea1. for more on defining several
servers.

  You can use the `--sign' option to tell *upload* to sign each
uploaded file using GPG (GNU Privacy Guard).  The  *gpg* program must
be available for execution on the system `PATH'.  You can also specify
which key to use for signing using the `--identity=name' option.

  Other *upload* options include `--repository=url' or
`--repository=section' where _url_ is the url of the server and
_section_ the name of the section in `$HOME/.pypirc', and
`--show-response' (which displays the full response text from the PyPI
server for help in debugging upload problems).


File: python.info,  Node: The pypirc file,  Next: PyPI package display,  Prev: Uploading Packages,  Up: The Python Package Index PyPI

8.6.3 The .pypirc file
----------------------

The format of the `.pypirc' file is as follows:

    [distutils]
    index-servers =
        pypi

    [pypi]
    repository: <repository-url>
    username: <username>
    password: <password>

The _distutils_ section defines a _index-servers_ variable that lists
the name of all sections describing a repository.

  Each section describing a repository defines three variables:

   -
    _repository_, that defines the url of the PyPI server. Defaults to
          `http://www.python.org/pypi'.

   - _username_, which is the registered username on the PyPI server.

   -
    _password_, that will be used to authenticate. If omitted the user
          will be prompt to type it when needed.

  If you want to define another server a new section can be created and
listed in the _index-servers_ variable:

    [distutils]
    index-servers =
        pypi
        other

    [pypi]
    repository: <repository-url>
    username: <username>
    password: <password>

    [other]
    repository: http://example.com/pypi
    username: <username>
    password: <password>

*register* can then be called with the -r option to point the
repository to work with:

    python setup.py register -r http://example.com/pypi

For convenience, the name of the section that describes the repository
may also be used:

    python setup.py register -r other



File: python.info,  Node: PyPI package display,  Prev: The pypirc file,  Up: The Python Package Index PyPI

8.6.4 PyPI package display
--------------------------

The `long_description' field plays a special role at PyPI. It is used by
the server to display a home page for the registered package.

  If you use the reStructuredText(1) syntax for this field, PyPI will
parse it and display an HTML output for the package home page.

  The `long_description' field can be attached to a text file located
in the package:

    from distutils.core import setup

    with open('README.txt') as file:
        long_description = file.read()

    setup(name='Distutils',
          long_description=long_description)

In that case, `README.txt' is a regular reStructuredText text file
located in the root of the package besides `setup.py'.

  To prevent registering broken reStructuredText content, you can use
the *rst2html* program that is provided by the `docutils' package and
check the `long_description' from the command line:

    $ python setup.py --long-description | rst2html.py > output.html

`docutils' will display a warning if there's something wrong with your
syntax.  Because PyPI applies additional checks (e.g. by passing
`--no-raw' to `rst2html.py' in the command above), being able to run
the command above without warnings does not guarantee that PyPI will
convert the content successfully.

  ---------- Footnotes ----------

  (1) http://docutils.sourceforge.net/rst.html


File: python.info,  Node: Examples<24>,  Next: Extending Distutils,  Prev: The Python Package Index PyPI,  Up: Distributing Python Modules

8.7 Examples
============

This chapter provides a number of basic examples to help get started
with distutils.  Additional information about using distutils can be
found in the Distutils Cookbook.

See also
........

Distutils Cookbook(1)
     Collection of recipes showing how to achieve more control over
     distutils.

* Menu:

* Pure Python distribution (by module): Pure Python distribution by module.
* Pure Python distribution (by package): Pure Python distribution by package.
* Single extension module::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/Distutils/Cookbook


File: python.info,  Node: Pure Python distribution by module,  Next: Pure Python distribution by package,  Up: Examples<24>

8.7.1 Pure Python distribution (by module)
------------------------------------------

If you're just distributing a couple of modules, especially if they
don't live in a particular package, you can specify them individually
using the `py_modules' option in the setup script.

  In the simplest case, you'll have two files to worry about: a setup
script and the single module you're distributing, `foo.py' in this
example:

    <root>/
            setup.py
            foo.py

(In all diagrams in this section, _<root>_ will refer to the
distribution root directory.)  A minimal setup script to describe this
situation would be:

    from distutils.core import setup
    setup(name='foo',
          version='1.0',
          py_modules=['foo'],
          )

Note that the name of the distribution is specified independently with
the `name' option, and there's no rule that says it has to be the same
as the name of the sole module in the distribution (although that's
probably a good convention to follow).  However, the distribution name
is used to generate filenames, so you should stick to letters, digits,
underscores, and hyphens.

  Since `py_modules' is a list, you can of course specify multiple
modules, eg. if you're distributing modules `foo' and `bar', your setup
might look like this:

    <root>/
            setup.py
            foo.py
            bar.py

and the setup script might be

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          py_modules=['foo', 'bar'],
          )

You can put module source files into another directory, but if you have
enough modules to do that, it's probably easier to specify modules by
package rather than listing them individually.


File: python.info,  Node: Pure Python distribution by package,  Next: Single extension module,  Prev: Pure Python distribution by module,  Up: Examples<24>

8.7.2 Pure Python distribution (by package)
-------------------------------------------

If you have more than a couple of modules to distribute, especially if
they are in multiple packages, it's probably easier to specify whole
packages rather than individual modules.  This works even if your
modules are not in a package; you can just tell the Distutils to
process modules from the root package, and that works the same as any
other package (except that you don't have to have an `__init__.py'
file).

  The setup script from the last example could also be written as

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          packages=[''],
          )

(The empty string stands for the root package.)

  If those two files are moved into a subdirectory, but remain in the
root package, e.g.:

    <root>/
            setup.py
            src/      foo.py
                      bar.py

then you would still specify the root package, but you have to tell the
Distutils where source files in the root package live:

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          package_dir={'': 'src'},
          packages=[''],
          )

More typically, though, you will want to distribute multiple modules in
the same package (or in sub-packages).  For example, if the `foo'  and
`bar' modules belong in package `foobar', one way to layout your source
tree is

    <root>/
            setup.py
            foobar/
                     __init__.py
                     foo.py
                     bar.py

This is in fact the default layout expected by the Distutils, and the
one that requires the least work to describe in your setup script:

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          packages=['foobar'],
          )

If you want to put modules in directories not named for their package,
then you need to use the `package_dir' option again.  For example, if
the `src' directory holds modules in the `foobar' package:

    <root>/
            setup.py
            src/
                     __init__.py
                     foo.py
                     bar.py

an appropriate setup script would be

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          package_dir={'foobar': 'src'},
          packages=['foobar'],
          )

Or, you might put modules from your main package right in the
distribution root:

    <root>/
            setup.py
            __init__.py
            foo.py
            bar.py

in which case your setup script would be

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          package_dir={'foobar': ''},
          packages=['foobar'],
          )

(The empty string also stands for the current directory.)

  If you have sub-packages, they must be explicitly listed in
`packages', but any entries in `package_dir' automatically extend to
sub-packages.  (In other words, the Distutils does _not_ scan your
source tree, trying to figure out which directories correspond to
Python packages by looking for `__init__.py' files.)  Thus, if the
default layout grows a sub-package:

    <root>/
            setup.py
            foobar/
                     __init__.py
                     foo.py
                     bar.py
                     subfoo/
                               __init__.py
                               blah.py

then the corresponding setup script would be

    from distutils.core import setup
    setup(name='foobar',
          version='1.0',
          packages=['foobar', 'foobar.subfoo'],
          )

(Again, the empty string in `package_dir' stands for the current
directory.)


File: python.info,  Node: Single extension module,  Prev: Pure Python distribution by package,  Up: Examples<24>

8.7.3 Single extension module
-----------------------------

Extension modules are specified using the `ext_modules' option.
`package_dir' has no effect on where extension source files are found;
it only affects the source for pure Python modules.  The simplest
case, a single extension module in a single C source file, is:

    <root>/
            setup.py
            foo.c

If the `foo' extension belongs in the root package, the setup script for
this could be

    from distutils.core import setup
    from distutils.extension import Extension
    setup(name='foobar',
          version='1.0',
          ext_modules=[Extension('foo', ['foo.c'])],
          )

If the extension actually belongs in a package, say `foopkg', then

  With exactly the same source tree layout, this extension can be put
in the `foopkg' package simply by changing the name of the extension:

    from distutils.core import setup
    from distutils.extension import Extension
    setup(name='foobar',
          version='1.0',
          ext_modules=[Extension('foopkg.foo', ['foo.c'])],
          )



File: python.info,  Node: Extending Distutils,  Next: Command Reference,  Prev: Examples<24>,  Up: Distributing Python Modules

8.8 Extending Distutils
=======================

Distutils can be extended in various ways.  Most extensions take the
form of new commands or replacements for existing commands.  New
commands may be written to support new types of platform-specific
packaging, for example, while replacements for existing commands may be
made to modify details of how the command operates on a package.

  Most extensions of the distutils are made within `setup.py' scripts
that want to modify existing commands; many simply add a few file
extensions that should be copied into packages in addition to `.py'
files as a convenience.

  Most distutils command implementations are subclasses of the *note
distutils.cmd.Command: 2eb2. class.  New commands may directly inherit
from `Command', while replacements often derive from `Command'
indirectly, directly subclassing the command they are replacing.
Commands are required to derive from `Command'.

* Menu:

* Integrating new commands::
* Adding new distribution types::


File: python.info,  Node: Integrating new commands,  Next: Adding new distribution types,  Up: Extending Distutils

8.8.1 Integrating new commands
------------------------------

There are different ways to integrate new command implementations into
distutils.  The most difficult is to lobby for the inclusion of the new
features in distutils itself, and wait for (and require) a version of
Python that provides that support.  This is really hard for many
reasons.

  The most common, and possibly the most reasonable for most needs, is
to include the new implementations with your `setup.py' script, and
cause the *note distutils.core.setup(): 2e71. function use them:

    from distutils.command.build_py import build_py as _build_py
    from distutils.core import setup

    class build_py(_build_py):
        """Specialized Python source builder."""

        # implement whatever needs to be different...

    setup(cmdclass={'build_py': build_py},
          ...)

This approach is most valuable if the new implementations must be used
to use a particular package, as everyone interested in the package will
need to have the new command implementation.

  Beginning with Python 2.4, a third option is available, intended to
allow new commands to be added which can support existing `setup.py'
scripts without requiring modifications to the Python installation.
This is expected to allow third-party extensions to provide support for
additional packaging systems, but the commands can be used for anything
distutils commands can be used for.  A new configuration option,
`command_packages' (command-line option `--command-packages'), can be
used to specify additional packages to be searched for modules
implementing commands.  Like all distutils options, this can be
specified on the command line or in a configuration file.  This option
can only be set in the `[global]' section of a configuration file, or
before any commands on the command line.  If set in a configuration
file, it can be overridden from the command line; setting it to an
empty string on the command line causes the default to be used.  This
should never be set in a configuration file provided with a package.

  This new option can be used to add any number of packages to the list
of packages searched for command implementations; multiple package
names should be separated by commas.  When not specified, the search is
only performed in the *note distutils.command: 8a. package.  When
`setup.py' is run with the option `--command-packages'
`distcmds,buildcmds', however, the packages *note distutils.command:
8a, `distcmds', and `buildcmds' will be searched in that order.  New
commands are expected to be implemented in modules of the same name as
the command by classes sharing the same name.  Given the example
command line option above, the command *bdist_openpkg* could be
implemented by the class `distcmds.bdist_openpkg.bdist_openpkg' or
`buildcmds.bdist_openpkg.bdist_openpkg'.


File: python.info,  Node: Adding new distribution types,  Prev: Integrating new commands,  Up: Extending Distutils

8.8.2 Adding new distribution types
-----------------------------------

Commands that create distributions (files in the `dist/' directory) need
to add `(command, filename)' pairs to `self.distribution.dist_files' so
that *upload* can upload it to PyPI.  The _filename_ in the pair
contains no path information, only the name of the file itself.  In
dry-run mode, pairs should still be added to represent what would have
been created.


File: python.info,  Node: Command Reference,  Next: API Reference,  Prev: Extending Distutils,  Up: Distributing Python Modules

8.9 Command Reference
=====================

* Menu:

* Installing modules; the install command family: Installing modules the install command family.

Installing modules: the install command family

* install_data::
* install_scripts::


File: python.info,  Node: Installing modules the install command family,  Up: Command Reference

8.9.1 Installing modules: the *install* command family
------------------------------------------------------

The install command ensures that the build commands have been run and
then runs the subcommands *install_lib*, *install_data* and
*install_scripts*.

* Menu:

* install_data::
* install_scripts::


File: python.info,  Node: install_data,  Next: install_scripts,  Up: Installing modules the install command family

8.9.1.1 *install_data*
......................

This command installs all data files provided with the distribution.


File: python.info,  Node: install_scripts,  Prev: install_data,  Up: Installing modules the install command family

8.9.1.2 *install_scripts*
.........................

This command installs all (Python) scripts in the distribution.


File: python.info,  Node: API Reference,  Prev: Command Reference,  Up: Distributing Python Modules

8.10 API Reference
==================

* Menu:

* distutils.core: distutils core --- Core Distutils functionality. Core Distutils functionality
* distutils.ccompiler: distutils ccompiler --- CCompiler base class. CCompiler base class
* distutils.unixccompiler: distutils unixccompiler --- Unix C Compiler. Unix C Compiler
* distutils.msvccompiler: distutils msvccompiler --- Microsoft Compiler. Microsoft Compiler
* distutils.bcppcompiler: distutils bcppcompiler --- Borland Compiler. Borland Compiler
* distutils.cygwincompiler: distutils cygwincompiler --- Cygwin Compiler. Cygwin Compiler
* distutils.emxccompiler: distutils emxccompiler --- OS/2 EMX Compiler. OS/2 EMX Compiler
* distutils.archive_util: distutils archive_util --- Archiving utilities. Archiving utilities
* distutils.dep_util: distutils dep_util --- Dependency checking. Dependency checking
* distutils.dir_util: distutils dir_util --- Directory tree operations. Directory tree operations
* distutils.file_util: distutils file_util --- Single file operations. Single file operations
* distutils.util: distutils util --- Miscellaneous other utility functions. Miscellaneous other utility functions
* distutils.dist: distutils dist --- The Distribution class. The Distribution class
* distutils.extension: distutils extension --- The Extension class. The Extension class
* distutils.debug: distutils debug --- Distutils debug mode. Distutils debug mode
* distutils.errors: distutils errors --- Distutils exceptions. Distutils exceptions
* distutils.fancy_getopt: distutils fancy_getopt --- Wrapper around the standard getopt module. Wrapper around the standard getopt module
* distutils.filelist: distutils filelist --- The FileList class. The FileList class
* distutils.log: distutils log --- Simple PEP 282-style logging. Simple PEP 282-style logging
* distutils.spawn: distutils spawn --- Spawn a sub-process. Spawn a sub-process
* distutils.sysconfig: distutils sysconfig --- System configuration information. System configuration information
* distutils.text_file: distutils text_file --- The TextFile class. The TextFile class
* distutils.version: distutils version --- Version number classes. Version number classes
* distutils.cmd: distutils cmd --- Abstract base class for Distutils commands. Abstract base class for Distutils commands
* Creating a new Distutils command::
* distutils.command: distutils command --- Individual Distutils commands. Individual Distutils commands
* distutils.command.bdist: distutils command bdist --- Build a binary installer. Build a binary installer
* distutils.command.bdist_packager: distutils command bdist_packager --- Abstract base class for packagers. Abstract base class for packagers
* distutils.command.bdist_dumb: distutils command bdist_dumb --- Build a "dumb" installer. Build a "dumb" installer
* distutils.command.bdist_msi: distutils command bdist_msi --- Build a Microsoft Installer binary package. Build a Microsoft Installer binary package
* distutils.command.bdist_rpm: distutils command bdist_rpm --- Build a binary distribution as a Redhat RPM and SRPM. Build a binary distribution as a Redhat RPM and
                               SRPM
* distutils.command.bdist_wininst: distutils command bdist_wininst --- Build a Windows installer. Build a Windows installer
* distutils.command.sdist: distutils command sdist --- Build a source distribution. Build a source distribution
* distutils.command.build: distutils command build --- Build all files of a package. Build all files of a package
* distutils.command.build_clib: distutils command build_clib --- Build any C libraries in a package. Build any C libraries in a package
* distutils.command.build_ext: distutils command build_ext --- Build any extensions in a package. Build any extensions in a package
* distutils.command.build_py: distutils command build_py --- Build the py/ pyc files of a package. Build the .py/.pyc files of a package
* distutils.command.build_scripts: distutils command build_scripts --- Build the scripts of a package. Build the scripts of a package
* distutils.command.clean: distutils command clean --- Clean a package build area. Clean a package build area
* distutils.command.config: distutils command config --- Perform package configuration. Perform package configuration
* distutils.command.install: distutils command install --- Install a package. Install a package
* distutils.command.install_data: distutils command install_data --- Install data files from a package. Install data files from a package
* distutils.command.install_headers: distutils command install_headers --- Install C/C++ header files from a package. Install C/C++ header files from a package
* distutils.command.install_lib: distutils command install_lib --- Install library files from a package. Install library files from a package
* distutils.command.install_scripts: distutils command install_scripts --- Install script files from a package. Install script files from a package
* distutils.command.register: distutils command register --- Register a module with the Python Package Index. Register a module with the Python Package Index
* distutils.command.check: distutils command check --- Check the meta-data of a package. Check the meta-data of a package


File: python.info,  Node: distutils core --- Core Distutils functionality,  Next: distutils ccompiler --- CCompiler base class,  Up: API Reference

8.10.1 `distutils.core' -- Core Distutils functionality
-------------------------------------------------------

The *note distutils.core: a0. module is the only module that needs to
be installed to use the Distutils. It provides the *note setup(): 2e71.
(which is called from the setup script). Indirectly provides the
`distutils.dist.Distribution' and *note distutils.cmd.Command: 2eb2.
class.

 -- Function: distutils.core.setup (arguments)
     The basic do-everything function that does most everything you
     could ever ask for from a Distutils method.

     The setup function takes a large number of arguments. These are
     laid out in the following table.

     argument name            value                                type
     -------------------------------------------------------------------------------------------------------------------------------- 
     _name_                   The name of the package              a string
     _version_                The version number of the package;   a string
                              see *note distutils.version: b3.     
     _description_            A single line describing the package a string
     _long_description_       Longer description of the package    a string
     _author_                 The name of the package author       a string
     _author_email_           The email address of the package     a string
                              author                               
     _maintainer_             The name of the current maintainer,  a string
                              if different from the author. Note   
                              that if the maintainer is provided,  
                              distutils will use it as the author  
                              in `PKG-INFO'                        
     _maintainer_email_       The email address of the current     a string
                              maintainer, if different from the    
                              author                               
     _url_                    A URL for the package (homepage)     a string
     _download_url_           A URL to download the package        a string
     _packages_               A list of Python packages that       a list of strings
                              distutils will manipulate            
     _py_modules_             A list of Python modules that        a list of strings
                              distutils will manipulate            
     _scripts_                A list of standalone script files    a list of strings
                              to be built and installed            
     _ext_modules_            A list of Python extensions to be    a list of instances of *note distutils.core.Extension: 2ec2.
                              built                                
     _classifiers_            A list of categories for the package a list of strings; valid classifiers are listed on PyPI(1).
     _distclass_              the *note Distribution: 2ec3.        a subclass of *note distutils.core.Distribution: 2ec3.
                              class to use                         
     _script_name_            The name of the setup.py script -    a string
                              defaults to `sys.argv[0]'            
     _script_args_            Arguments to supply to the setup     a list of strings
                              script                               
     _options_                default options for the setup script a dictionary
     _license_                The license for the package          a string
     _keywords_               Descriptive meta-data, see PEP       a list of strings or a comma-separated string
                              314(2)                               
     _platforms_                                                   a list of strings or a comma-separated string
     _cmdclass_               A mapping of command names to *note  a dictionary
                              Command: 2ec4. subclasses            
     _data_files_             A list of data files to install      a list
     _package_dir_            A mapping of package to directory    a dictionary
                              names                                


 -- Function: distutils.core.run_setup (script_name[, script_args=None,
          stop_after='run'])
     Run a setup script in a somewhat controlled environment, and
     return  the `distutils.dist.Distribution' instance that drives
     things.   This is useful if you need to find out the distribution
     meta-data  (passed as keyword args from _script_ to *note setup():
     2e71.), or  the contents of the config files or command-line.

     _script_name_ is a file that will be run with *note execfile():
     42f. `sys.argv[0]' will be replaced with _script_ for the duration
     of the call.  _script_args_ is a list of strings; if supplied,
     `sys.argv[1:]' will be replaced by _script_args_ for the duration
     of the call.

     _stop_after_ tells *note setup(): 2e71. when to stop processing;
     possible  values:

     value               description
     ---------------------------------------------------------------------- 
     _init_              Stop after the *note Distribution: 2ec3.
                         instance has been created  and populated with
                         the keyword arguments to *note setup(): 2e71.
     _config_            Stop after config files have been parsed (and
                         their data stored in the *note Distribution:
                         2ec3. instance)
     _commandline_       Stop after the command-line (`sys.argv[1:]' or
                         _script_args_) have been parsed (and the data
                         stored in the *note Distribution: 2ec3.
                         instance.)
     _run_               Stop after all commands have been run (the same
                         as  if *note setup(): 2e71. had been called in
                         the usual way). This is the default value.


  In addition, the *note distutils.core: a0. module exposed a number of
classes that live elsewhere.

   * `Extension' from *note distutils.extension: a8.

   * *note Command: 2eb2. from *note distutils.cmd: 89.

   * `Distribution' from *note distutils.dist: a5.

  A short description of each of these follows, but see the relevant
module for the full reference.

 -- Class: distutils.core.Extension
     The Extension class describes a single C or C++extension module in
     a setup script. It accepts the following keyword arguments in its
     constructor

     argument name                value                                type
     -------------------------------------------------------------------------------------------------- 
     _name_                       the full name of the extension,      a string
                                  including any packages -- ie. _not_  
                                  a filename or pathname, but Python   
                                  dotted name                          
     _sources_                    list of source filenames, relative   a list of strings
                                  to the distribution root (where the  
                                  setup script lives), in Unix form    
                                  (slash- separated) for portability.  
                                  Source files may be C, C++, SWIG     
                                  (.i), platform-specific resource     
                                  files, or whatever else is           
                                  recognized by the *build_ext*        
                                  command as source for a Python       
                                  extension.                           
     _include_dirs_               list of directories to search for    a list of strings
                                  C/C++ header files (in Unix form     
                                  for portability)                     
     _define_macros_              list of macros to define; each       a list of tuples
                                  macro is defined using a 2-tuple     
                                  `(name, value)', where _value_ is    
                                  either the string to define it to    
                                  or `None' to define it without a     
                                  particular value (equivalent of      
                                  `#define FOO' in source or `-DFOO'   
                                  on Unix C compiler command line)     
     _undef_macros_               list of macros to undefine           a list of strings
                                  explicitly                           
     _library_dirs_               list of directories to search for    a list of strings
                                  C/C++ libraries at link time         
     _libraries_                  list of library names (not           a list of strings
                                  filenames or paths) to link against  
     _runtime_library_dirs_       list of directories to search for    a list of strings
                                  C/C++ libraries at run time (for     
                                  shared extensions, this is when the  
                                  extension is loaded)                 
     _extra_objects_              list of extra files to link with     a list of strings
                                  (eg. object files not implied by     
                                  'sources', static library that must  
                                  be explicitly specified, binary      
                                  resource files, etc.)                
     _extra_compile_args_         any extra platform- and              a list of strings
                                  compiler-specific information to     
                                  use when compiling the source files  
                                  in 'sources'. For platforms and      
                                  compilers where a command line       
                                  makes sense, this is typically a     
                                  list of command-line arguments, but  
                                  for other platforms it could be      
                                  anything.                            
     _extra_link_args_            any extra platform- and              a list of strings
                                  compiler-specific information to     
                                  use when linking object files        
                                  together to create the extension     
                                  (or to create a new static Python    
                                  interpreter).  Similar               
                                  interpretation as for                
                                  'extra_compile_args'.                
     _export_symbols_             list of symbols to be exported from  a list of strings
                                  a shared extension. Not used on all  
                                  platforms, and not generally         
                                  necessary for Python extensions,     
                                  which typically export exactly one   
                                  symbol: `init' + extension_name.     
     _depends_                    list of files that the extension     a list of strings
                                  depends on                           
     _language_                   extension language (i.e.  `'c'',     a string
                                  `'c++'', `'objc''). Will be detected 
                                  from the source extensions if not    
                                  provided.                            


 -- Class: distutils.core.Distribution
     A *note Distribution: 2ec3. describes how to build, install and
     package up a Python software package.

     See the *note setup(): 2e71. function for a list of keyword
     arguments accepted  by the Distribution constructor. *note
     setup(): 2e71. creates a Distribution instance.

 -- Class: distutils.core.Command
     A *note Command: 2ec4. class (or rather, an instance of one of its
     subclasses) implement a single distutils command.

  ---------- Footnotes ----------

  (1) http://pypi.python.org/pypi?:action=list_classifiers

  (2) http://www.python.org/dev/peps/pep-0314


File: python.info,  Node: distutils ccompiler --- CCompiler base class,  Next: distutils unixccompiler --- Unix C Compiler,  Prev: distutils core --- Core Distutils functionality,  Up: API Reference

8.10.2 `distutils.ccompiler' -- CCompiler base class
----------------------------------------------------

This module provides the abstract base class for the *note CCompiler:
2ec7.  classes.  A *note CCompiler: 2ec7. instance can be used for all
the compile  and link steps needed to build a single project. Methods
are provided to  set options for the compiler -- macro definitions,
include directories,  link path, libraries and the like.

  This module provides the following functions.

 -- Function: distutils.ccompiler.gen_lib_options (compiler,
          library_dirs, runtime_library_dirs, libraries)
     Generate linker options for searching library directories and
     linking with specific libraries.  _libraries_ and _library_dirs_
     are, respectively, lists of library names (not filenames!) and
     search directories.  Returns a list of command-line options
     suitable for use with some compiler (depending on the two format
     strings passed in).

 -- Function: distutils.ccompiler.gen_preprocess_options (macros,
          include_dirs)
     Generate C pre-processor options (`-D', *note -U: 63b, `-I') as
     used by at least two types of compilers: the typical Unix compiler
     and Visual C++. _macros_ is the usual thing, a list of 1- or
     2-tuples, where `(name,)' means undefine (*note -U: 63b.) macro
     _name_, and `(name, value)' means define (`-D') macro _name_ to
     _value_.  _include_dirs_ is just a list of directory names to be
     added to the header file search path (`-I').  Returns a list of
     command-line options suitable for either Unix compilers or Visual
     C++.

 -- Function: distutils.ccompiler.get_default_compiler (osname,
          platform)
     Determine the default compiler to use for the given platform.

     _osname_ should be one of the standard Python OS names (i.e. the
     ones returned by `os.name') and _platform_ the common value
     returned by `sys.platform' for the platform in question.

     The default values are `os.name' and `sys.platform' in case the
     parameters are not given.

 -- Function: distutils.ccompiler.new_compiler (plat=None,
          compiler=None, verbose=0, dry_run=0, force=0)
     Factory function to generate an instance of some CCompiler
     subclass for the supplied platform/compiler combination. _plat_
     defaults to `os.name' (eg.  `'posix'', `'nt''), and _compiler_
     defaults to the default compiler for that platform. Currently only
     `'posix'' and `'nt'' are supported, and the default compilers are
     "traditional Unix interface" (`UnixCCompiler' class) and Visual
     C++ (`MSVCCompiler' class).  Note that it's perfectly possible to
     ask for a Unix compiler object under Windows, and a Microsoft
     compiler object under Unix--if you supply a value for _compiler_,
     _plat_ is ignored.


 -- Function: distutils.ccompiler.show_compilers ()
     Print list of available compilers (used by the `--help-compiler'
     options to *build*, *build_ext*, *build_clib*).

 -- Class: distutils.ccompiler.CCompiler ([verbose=0, dry_run=0,
          force=0])
     The abstract base class *note CCompiler: 2ec7. defines the
     interface that  must be implemented by real compiler classes.  The
     class also has  some utility methods used by several compiler
     classes.

     The basic idea behind a compiler abstraction class is that each
     instance can be used for all the compile/link steps in building a
     single project.  Thus, attributes common to all of those compile
     and link steps -- include directories, macros to define, libraries
     to link against, etc. -- are attributes of the compiler instance.
     To allow for variability in how individual files are treated, most
     of those attributes may be varied on a per-compilation or per-link
     basis.

     The constructor for each subclass creates an instance of the
     Compiler object.  Flags are _verbose_ (show verbose output),
     _dry_run_ (don't actually execute the steps) and _force_ (rebuild
     everything, regardless of dependencies). All of these flags
     default to `0' (off). Note that you probably don't want to
     instantiate *note CCompiler: 2ec7. or one of its subclasses
     directly - use the `distutils.CCompiler.new_compiler()' factory
     function instead.

     The following methods allow you to manually alter compiler options
     for  the instance of the Compiler class.

      -- Method: add_include_dir (dir)
          Add _dir_ to the list of directories that will be searched
          for header files.  The compiler is instructed to search
          directories in the order in which they are supplied by
          successive calls to *note add_include_dir(): 2ecd.

      -- Method: set_include_dirs (dirs)
          Set the list of directories that will be searched to _dirs_
          (a list of strings).  Overrides any preceding calls to *note
          add_include_dir(): 2ecd.; subsequent calls to *note
          add_include_dir(): 2ecd. add to the list passed to *note
          set_include_dirs(): 2ece.  This does not affect any list of
          standard include directories that the compiler may search by
          default.

      -- Method: add_library (libname)
          Add _libname_ to the list of libraries that will be included
          in all links driven by this compiler object.  Note that
          _libname_ should *not* be the name of a file containing a
          library, but the name of the library itself: the actual
          filename will be inferred by the linker, the compiler, or the
          compiler class (depending on the platform).

          The linker will be instructed to link against libraries in
          the order they were supplied to *note add_library(): 2ecf.
          and/or *note set_libraries(): 2ed0.  It is perfectly valid to
          duplicate library names; the linker will be instructed to
          link against libraries as many times as they are mentioned.

      -- Method: set_libraries (libnames)
          Set the list of libraries to be included in all links driven
          by this compiler object to _libnames_ (a list of strings).
          This does not affect any standard system libraries that the
          linker may include by default.

      -- Method: add_library_dir (dir)
          Add _dir_ to the list of directories that will be searched
          for libraries specified to *note add_library(): 2ecf. and
          *note set_libraries(): 2ed0.  The linker will be instructed
          to search for libraries in the order they are supplied to
          *note add_library_dir(): 2ed1. and/or *note
          set_library_dirs(): 2ed2.

      -- Method: set_library_dirs (dirs)
          Set the list of library search directories to _dirs_ (a list
          of strings).  This does not affect any standard library
          search path that the linker may search by default.

      -- Method: add_runtime_library_dir (dir)
          Add _dir_ to the list of directories that will be searched
          for shared libraries at runtime.

      -- Method: set_runtime_library_dirs (dirs)
          Set the list of directories to search for shared libraries at
          runtime to _dirs_ (a list of strings).  This does not affect
          any standard search path that the runtime linker may search
          by default.

      -- Method: define_macro (name[, value=None])
          Define a preprocessor macro for all compilations driven by
          this compiler object.  The optional parameter _value_ should
          be a string; if it is not supplied, then the macro will be
          defined without an explicit value and the exact outcome
          depends on the compiler used.


      -- Method: undefine_macro (name)
          Undefine a preprocessor macro for all compilations driven by
          this compiler object.  If the same macro is defined by *note
          define_macro(): 2ed5. and undefined by *note
          undefine_macro(): 2ed6. the last call takes precedence
          (including multiple redefinitions or undefinitions).  If the
          macro is redefined/undefined on a per-compilation basis (ie.
          in the call to *note compile(): 1f8.), then that takes
          precedence.

      -- Method: add_link_object (object)
          Add _object_ to the list of object files (or analogues, such
          as explicitly named library files or the output of "resource
          compilers") to be included in every link driven by this
          compiler object.

      -- Method: set_link_objects (objects)
          Set the list of object files (or analogues) to be included in
          every link to _objects_.  This does not affect any standard
          object files that the linker may include by default (such as
          system libraries).

     The following methods implement methods for autodetection of
     compiler  options, providing some functionality similar to GNU
     *autoconf*.

      -- Method: detect_language (sources)
          Detect the language of a given file, or list of files. Uses
          the  instance attributes `language_map' (a dictionary), and
          `language_order' (a list) to do the job.

      -- Method: find_library_file (dirs, lib[, debug=0])
          Search the specified list of directories for a static or
          shared library file _lib_ and return the full path to that
          file.  If _debug_ is true, look for a debugging version (if
          that makes sense on the current platform).  Return `None' if
          _lib_ wasn't found in any of the specified directories.

      -- Method: has_function (funcname[, includes=None,
               include_dirs=None, libraries=None, library_dirs=None])
          Return a boolean indicating whether _funcname_ is supported
          on the current platform.  The optional arguments can be used
          to augment the compilation environment by providing
          additional include files and paths and libraries and paths.

      -- Method: library_dir_option (dir)
          Return the compiler option to add _dir_ to the list of
          directories searched for libraries.

      -- Method: library_option (lib)
          Return the compiler option to add _dir_ to the list of
          libraries linked into the shared library or executable.

      -- Method: runtime_library_dir_option (dir)
          Return the compiler option to add _dir_ to the list of
          directories searched for runtime libraries.

      -- Method: set_executables (**args)
          Define the executables (and options for them) that will be
          run to perform the various stages of compilation.  The exact
          set of executables that may be specified here depends on the
          compiler class (via the 'executables' class attribute), but
          most will have:

          attribute          description
          ------------------------------------------------------------------ 
          _compiler_         the C/C++ compiler
          _linker_so_        linker used to create shared objects and
                             libraries
          _linker_exe_       linker used to create binary executables
          _archiver_         static library creator

          On platforms with a command-line (Unix, DOS/Windows), each of
          these is a string that will be split into executable name and
          (optional) list of arguments.  (Splitting the string is done
          similarly to how Unix shells operate: words are delimited by
          spaces, but quotes and backslashes can override this.  See
          *note distutils.util.split_quoted(): 2ee0.)

     The following methods invoke stages in the build process.

      -- Method: compile (sources[, output_dir=None, macros=None,
               include_dirs=None, debug=0, extra_preargs=None,
               extra_postargs=None, depends=None])
          Compile one or more source files. Generates object files
          (e.g.  transforms a `.c' file to a `.o' file.)

          _sources_ must be a list of filenames, most likely C/C++
          files, but in reality anything that can be handled by a
          particular compiler and compiler class (eg.  `MSVCCompiler'
          can handle resource files in _sources_).  Return a list of
          object filenames, one per source filename in _sources_.
          Depending on the implementation, not all source files will
          necessarily be compiled, but all corresponding object
          filenames will be returned.

          If _output_dir_ is given, object files will be put under it,
          while retaining their original path component.  That is,
          `foo/bar.c' normally compiles to `foo/bar.o' (for a Unix
          implementation); if _output_dir_ is _build_, then it would
          compile to `build/foo/bar.o'.

          _macros_, if given, must be a list of macro definitions.  A
          macro definition is either a `(name, value)' 2-tuple or a
          `(name,)' 1-tuple. The former defines a macro; if the value
          is `None', the macro is defined without an explicit value.
          The 1-tuple case undefines a macro.  Later
          definitions/redefinitions/undefinitions take precedence.

          _include_dirs_, if given, must be a list of strings, the
          directories to add to the default include file search path
          for this compilation only.

          _debug_ is a boolean; if true, the compiler will be
          instructed to output debug symbols in (or alongside) the
          object file(s).

          _extra_preargs_ and _extra_postargs_ are
          implementation-dependent. On platforms that have the notion
          of a command-line (e.g. Unix, DOS/Windows), they are most
          likely lists of strings: extra command-line arguments to
          prepend/append to the compiler command line.  On other
          platforms, consult the implementation class documentation.
          In any event, they are intended as an escape hatch for those
          occasions when the abstract compiler framework doesn't cut
          the mustard.

          _depends_, if given, is a list of filenames that all targets
          depend on.  If a source file is older than any file in
          depends, then the source file will be recompiled.  This
          supports dependency tracking, but only at a coarse
          granularity.

          Raises `CompileError' on failure.

      -- Method: create_static_lib (objects, output_libname[,
               output_dir=None, debug=0, target_lang=None])
          Link a bunch of stuff together to create a static library
          file. The "bunch of stuff" consists of the list of object
          files supplied as _objects_, the extra object files supplied
          to *note add_link_object(): 2ed7. and/or *note
          set_link_objects(): 2ed8, the libraries supplied to *note
          add_library(): 2ecf. and/or *note set_libraries(): 2ed0, and
          the libraries supplied as _libraries_ (if any).

          _output_libname_ should be a library name, not a filename;
          the filename will be inferred from the library name.
          _output_dir_ is the directory where the library file will be
          put.

          _debug_ is a boolean; if true, debugging information will be
          included in the library (note that on most platforms, it is
          the compile step where this matters: the _debug_ flag is
          included here just for consistency).

          _target_lang_ is the target language for which the given
          objects are being compiled. This allows specific linkage time
          treatment of certain languages.

          Raises `LibError' on failure.

      -- Method: link (target_desc, objects, output_filename[,
               output_dir=None, libraries=None, library_dirs=None,
               runtime_library_dirs=None, export_symbols=None, debug=0,
               extra_preargs=None, extra_postargs=None,
               build_temp=None, target_lang=None])
          Link a bunch of stuff together to create an executable or
          shared library file.

          The "bunch of stuff" consists of the list of object files
          supplied as _objects_.  _output_filename_ should be a
          filename.  If _output_dir_ is supplied, _output_filename_ is
          relative to it (i.e. _output_filename_ can provide directory
          components if needed).

          _libraries_ is a list of libraries to link against.  These
          are library names, not filenames, since they're translated
          into filenames in a platform-specific way (eg. _foo_ becomes
          `libfoo.a' on Unix and `foo.lib' on DOS/Windows).  However,
          they can include a directory component, which means the
          linker will look in that specific directory rather than
          searching all the normal locations.

          _library_dirs_, if supplied, should be a list of directories
          to search for libraries that were specified as bare library
          names (ie. no directory component).  These are on top of the
          system default and those supplied to *note add_library_dir():
          2ed1. and/or *note set_library_dirs(): 2ed2.
          _runtime_library_dirs_ is a list of directories that will be
          embedded into the shared library and used to search for other
          shared libraries that *it* depends on at run-time.  (This may
          only be relevant on Unix.)

          _export_symbols_ is a list of symbols that the shared library
          will export.  (This appears to be relevant only on Windows.)

          _debug_ is as for *note compile(): 1f8. and *note
          create_static_lib(): 2ee2,  with the slight distinction that
          it actually matters on most platforms (as opposed to *note
          create_static_lib(): 2ee2, which includes a _debug_ flag
          mostly for form's sake).

          _extra_preargs_ and _extra_postargs_ are as for *note
          compile(): 1f8.  (except of course that they supply
          command-line arguments for the particular linker being used).

          _target_lang_ is the target language for which the given
          objects are being compiled. This allows specific linkage time
          treatment of certain languages.

          Raises `LinkError' on failure.

      -- Method: link_executable (objects, output_progname[,
               output_dir=None, libraries=None, library_dirs=None,
               runtime_library_dirs=None, debug=0, extra_preargs=None,
               extra_postargs=None, target_lang=None])
          Link an executable.  _output_progname_ is the name of the
          file executable, while _objects_ are a list of object
          filenames to link in. Other arguments  are as for the *note
          link(): 2ee3. method.

      -- Method: link_shared_lib (objects, output_libname[,
               output_dir=None, libraries=None, library_dirs=None,
               runtime_library_dirs=None, export_symbols=None, debug=0,
               extra_preargs=None, extra_postargs=None,
               build_temp=None, target_lang=None])
          Link a shared library. _output_libname_ is the name of the
          output  library, while _objects_ is a list of object
          filenames to link in.  Other arguments are as for the *note
          link(): 2ee3. method.

      -- Method: link_shared_object (objects, output_filename[,
               output_dir=None, libraries=None, library_dirs=None,
               runtime_library_dirs=None, export_symbols=None, debug=0,
               extra_preargs=None, extra_postargs=None,
               build_temp=None, target_lang=None])
          Link a shared object. _output_filename_ is the name of the
          shared object that will be created, while _objects_ is a list
          of object filenames  to link in.  Other arguments are as for
          the *note link(): 2ee3. method.

      -- Method: preprocess (source[, output_file=None, macros=None,
               include_dirs=None, extra_preargs=None,
               extra_postargs=None])
          Preprocess a single C/C++ source file, named in _source_.
          Output will be written to file named _output_file_, or
          _stdout_ if _output_file_ not supplied.  _macros_ is a list
          of macro definitions as for *note compile(): 1f8, which will
          augment the macros set with *note define_macro(): 2ed5. and
          *note undefine_macro(): 2ed6.  _include_dirs_ is a list of
          directory names that will be added to the  default list, in
          the same way as *note add_include_dir(): 2ecd.

          Raises `PreprocessError' on failure.

     The following utility methods are defined by the *note CCompiler:
     2ec7. class, for use by the various concrete subclasses.

      -- Method: executable_filename (basename[, strip_dir=0,
               output_dir=''])
          Returns the filename of the executable for the given
          _basename_.  Typically for non-Windows platforms this is the
          same as the basename,  while Windows will get a `.exe' added.

      -- Method: library_filename (libname[, lib_type='static',
               strip_dir=0, output_dir=''])
          Returns the filename for the given library name on the
          current platform. On Unix a library with _lib_type_ of
          `'static'' will typically  be of the form `liblibname.a',
          while a _lib_type_ of `'dynamic''  will be of the form
          `liblibname.so'.

      -- Method: object_filenames (source_filenames[, strip_dir=0,
               output_dir=''])
          Returns the name of the object files for the given source
          files.  _source_filenames_ should be a list of filenames.

      -- Method: shared_object_filename (basename[, strip_dir=0,
               output_dir=''])
          Returns the name of a shared object file for the given file
          name _basename_.

      -- Method: execute (func, args[, msg=None, level=1])
          Invokes *note distutils.util.execute(): 2eed. This method
          invokes a  Python function _func_ with the given arguments
          _args_, after  logging and taking into account the _dry_run_
          flag.

      -- Method: spawn (cmd)
          Invokes `distutils.util.spawn()'. This invokes an external
          process to run the given command.

      -- Method: mkpath (name[, mode=511])
          Invokes *note distutils.dir_util.mkpath(): 2ef0. This creates
          a directory  and any missing ancestor directories.

      -- Method: move_file (src, dst)
          Invokes *note distutils.file_util.move_file(): 2ef2. Renames
          _src_ to  _dst_.

      -- Method: announce (msg[, level=1])
          Write a message using `distutils.log.debug()'.

      -- Method: warn (msg)
          Write a warning message _msg_ to standard error.

      -- Method: debug_print (msg)
          If the _debug_ flag is set on this *note CCompiler: 2ec7.
          instance, print  _msg_ to standard output, otherwise do
          nothing.



Local Variables:
coding: utf-8
End:
