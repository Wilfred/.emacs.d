This is
/home/melpa/melpa/working/python-info-20130916.1420/python.info,
produced by makeinfo version 4.13 from
/home/melpa/melpa/working/python-info/python.texi.

Generated by Sphinx 1.1.3.
INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY

     Python 2.7.5, September 16, 2013

     Georg Brandl

     Copyright (C) 1990-2013, Python Software Foundation


File: python.info,  Node: What happens if no configuration is provided,  Next: Configuring Logging for a Library,  Prev: Configuring Logging,  Up: Advanced Logging Tutorial

10.7.2.6 What happens if no configuration is provided
.....................................................

If no logging configuration is provided, it is possible to have a
situation where a logging event needs to be output, but no handlers can
be found to output the event. The behaviour of the logging package in
these circumstances is dependent on the Python version.

  For Python 2.x, the behaviour is as follows:

   * If _logging.raiseExceptions_ is _False_ (production mode), the
     event is silently dropped.

   * If _logging.raiseExceptions_ is _True_ (development mode), a
     message 'No handlers could be found for logger X.Y.Z' is printed
     once.


File: python.info,  Node: Configuring Logging for a Library,  Prev: What happens if no configuration is provided,  Up: Advanced Logging Tutorial

10.7.2.7 Configuring Logging for a Library
..........................................

When developing a library which uses logging, you should take care to
document how the library uses logging - for example, the names of
loggers used. Some consideration also needs to be given to its logging
configuration.  If the using application does not configure logging,
and library code makes logging calls, then (as described in the
previous section) an error message will be printed to `sys.stderr'.

  If for some reason you _don't_ want this message printed in the
absence of any logging configuration, you can attach a do-nothing
handler to the top-level logger for your library. This avoids the
message being printed, since a handler will be always be found for the
library's events: it just doesn't produce any output. If the library
user configures logging for application use, presumably that
configuration will add some handlers, and if levels are suitably
configured then logging calls made in library code will send output to
those handlers, as normal.

  A do-nothing handler is included in the logging package: *note
NullHandler: 130c. (since Python 2.7). An instance of this handler
could be added to the top-level logger of the logging namespace used by
the library (_if_ you want to prevent an error message being output to
`sys.stderr' in the absence of logging configuration). If all logging
by a library _foo_ is done using loggers with names matching 'foo.x',
'foo.x.y', etc. then the code:

    import logging
    logging.getLogger('foo').addHandler(logging.NullHandler())

should have the desired effect. If an organisation produces a number of
libraries, then the logger name specified can be 'orgname.foo' rather
than just 'foo'.

     Note: It is strongly advised that you _do not add any handlers
     other than_ *note NullHandler: 130c. _to your library's loggers_.
     This is because the configuration of handlers is the prerogative
     of the application developer who uses your library. The
     application developer knows their target audience and what
     handlers are most appropriate for their application: if you add
     handlers 'under the hood', you might well interfere with their
     ability to carry out unit tests and deliver logs which suit their
     requirements.


File: python.info,  Node: Logging Levels,  Next: Useful Handlers,  Prev: Advanced Logging Tutorial,  Up: Logging HOWTO

10.7.3 Logging Levels
---------------------

The numeric values of logging levels are given in the following table.
These are primarily of interest if you want to define your own levels,
and need them to have specific values relative to the predefined
levels. If you define a level with the same numeric value, it
overwrites the predefined value; the predefined name is lost.

Level              Numeric value
--------------------------------------- 
`CRITICAL'         50
`ERROR'            40
`WARNING'          30
`INFO'             20
`DEBUG'            10
`NOTSET'           0

  Levels can also be associated with loggers, being set either by the
developer or through loading a saved logging configuration. When a
logging method is called on a logger, the logger compares its own level
with the level associated with the method call. If the logger's level
is higher than the method call's, no logging message is actually
generated. This is the basic mechanism controlling the verbosity of
logging output.

  Logging messages are encoded as instances of the *note LogRecord:
12b3.  class. When a logger decides to actually log an event, a *note
LogRecord: 12b3. instance is created from the logging message.

  Logging messages are subjected to a dispatch mechanism through the
use of _handlers_, which are instances of subclasses of the `Handler'
class. Handlers are responsible for ensuring that a logged message (in
the form of a *note LogRecord: 12b3.) ends up in a particular location
(or set of locations) which is useful for the target audience for that
message (such as end users, support desk staff, system administrators,
developers). Handlers are passed *note LogRecord: 12b3. instances
intended for particular destinations. Each logger can have zero, one or
more handlers associated with it (via the *note addHandler(): 12ae.
method of *note Logger: 1da.). In addition to any handlers directly
associated with a logger, _all handlers associated with all ancestors
of the logger_ are called to dispatch the message (unless the
_propagate_ flag for a logger is set to a false value, at which point
the passing to ancestor handlers stops).

  Just as for loggers, handlers can have levels associated with them. A
handler's level acts as a filter in the same way as a logger's level
does. If a handler decides to actually dispatch an event, the *note
emit(): 12c4. method is used to send the message to its destination.
Most user-defined subclasses of `Handler' will need to override this
*note emit(): 12c4.

* Menu:

* Custom Levels::


File: python.info,  Node: Custom Levels,  Up: Logging Levels

10.7.3.1 Custom Levels
......................

Defining your own levels is possible, but should not be necessary, as
the existing levels have been chosen on the basis of practical
experience.  However, if you are convinced that you need custom levels,
great care should be exercised when doing this, and it is possibly _a
very bad idea to define custom levels if you are developing a library_.
That's because if multiple library authors all define their own custom
levels, there is a chance that the logging output from such multiple
libraries used together will be difficult for the using developer to
control and/or interpret, because a given numeric value might mean
different things for different libraries.


File: python.info,  Node: Useful Handlers,  Next: Exceptions raised during logging,  Prev: Logging Levels,  Up: Logging HOWTO

10.7.4 Useful Handlers
----------------------

In addition to the base `Handler' class, many useful subclasses are
provided:

  1. *note StreamHandler: 12eb. instances send messages to streams
     (file-like objects).

  2. *note FileHandler: 130b. instances send messages to disk files.

  3. `BaseRotatingHandler' is the base class for handlers that rotate
     log files at a certain point. It is not meant to be  instantiated
     directly. Instead, use *note RotatingFileHandler: 12fb. or *note
     TimedRotatingFileHandler: 1325.

  4. *note RotatingFileHandler: 12fb. instances send messages to disk
     files, with support for maximum log file sizes and log file
     rotation.

  5. *note TimedRotatingFileHandler: 1325. instances send messages to
     disk files, rotating the log file at certain timed intervals.

  6. *note SocketHandler: 132a. instances send messages to TCP/IP
     sockets.

  7. *note DatagramHandler: 1334. instances send messages to UDP
     sockets.

  8. *note SMTPHandler: 1348. instances send messages to a designated
     email address.

  9. *note SysLogHandler: 1d7. instances send messages to a Unix syslog
     daemon, possibly on a remote machine.

 10. *note NTEventLogHandler: 1340. instances send messages to a
     Windows NT/2000/XP event log.

 11. *note MemoryHandler: 1304. instances send messages to a buffer in
     memory, which is flushed whenever specific criteria are met.

 12. *note HTTPHandler: 1358. instances send messages to an HTTP server
     using either `GET' or `POST' semantics.

 13. *note WatchedFileHandler: 131d. instances watch the file they are
     logging to. If the file changes, it is closed and reopened using
     the file name. This handler is only useful on Unix-like systems;
     Windows does not support the underlying mechanism used.

 14. *note NullHandler: 130c. instances do nothing with error messages.
     They are used by library developers who want to use logging, but
     want to avoid the 'No handlers could be found for logger XXX'
     message which can be displayed if the library user has not
     configured logging. See *note Configuring Logging for a Library:
     131a. for more information.

  New in version 2.7: The *note NullHandler: 130c. class.

  The *note NullHandler: 130c, *note StreamHandler: 12eb. and *note
FileHandler: 130b.  classes are defined in the core logging package.
The other handlers are defined in a sub- module, *note
logging.handlers: 103. (There is also another sub-module, *note
logging.config: 102, for configuration functionality.)

  Logged messages are formatted for presentation through instances of
the *note Formatter: 12a3. class. They are initialized with a format
string suitable for use with the % operator and a dictionary.

  For formatting multiple messages in a batch, instances of
`BufferingFormatter' can be used. In addition to the format string
(which is applied to each message in the batch), there is provision for
header and trailer format strings.

  When filtering based on logger level and/or handler level is not
enough, instances of *note Filter: 12cf. can be added to both *note
Logger: 1da. and `Handler' instances (through their `addFilter()'
method). Before deciding to process a message further, both loggers and
handlers consult all their filters for permission. If any filter
returns a false value, the message is not processed further.

  The basic *note Filter: 12cf. functionality allows filtering by
specific logger name. If this feature is used, messages sent to the
named logger and its children are allowed through the filter, and all
others dropped.


File: python.info,  Node: Exceptions raised during logging,  Next: Using arbitrary objects as messages,  Prev: Useful Handlers,  Up: Logging HOWTO

10.7.5 Exceptions raised during logging
---------------------------------------

The logging package is designed to swallow exceptions which occur while
logging in production. This is so that errors which occur while
handling logging events - such as logging misconfiguration, network or
other similar errors - do not cause the application using logging to
terminate prematurely.

  `SystemExit' and `KeyboardInterrupt' exceptions are never swallowed.
Other exceptions which occur during the `emit()' method of a `Handler'
subclass are passed to its `handleError()' method.

  The default implementation of `handleError()' in `Handler' checks to
see if a module-level variable, `raiseExceptions', is set. If set, a
traceback is printed to *note sys.stderr: 634. If not set, the
exception is swallowed.

     Note: The default value of `raiseExceptions' is `True'. This is
     because during development, you typically want to be notified of
     any exceptions that occur. It's advised that you set
     `raiseExceptions' to `False' for production usage.


File: python.info,  Node: Using arbitrary objects as messages,  Next: Optimization,  Prev: Exceptions raised during logging,  Up: Logging HOWTO

10.7.6 Using arbitrary objects as messages
------------------------------------------

In the preceding sections and examples, it has been assumed that the
message passed when logging the event is a string. However, this is not
the only possibility. You can pass an arbitrary object as a message,
and its *note __str__(): 48d. method will be called when the logging
system needs to convert it to a string representation. In fact, if you
want to, you can avoid computing a string representation altogether -
for example, the `SocketHandler' emits an event by pickling it and
sending it over the wire.


File: python.info,  Node: Optimization,  Prev: Using arbitrary objects as messages,  Up: Logging HOWTO

10.7.7 Optimization
-------------------

Formatting of message arguments is deferred until it cannot be avoided.
However, computing the arguments passed to the logging method can also
be expensive, and you may want to avoid doing it if the logger will
just throw away your event. To decide what to do, you can call the
`isEnabledFor()' method which takes a level argument and returns true
if the event would be created by the Logger for that level of call. You
can write code like this:

    if logger.isEnabledFor(logging.DEBUG):
        logger.debug('Message with %s, %s', expensive_func1(),
                                            expensive_func2())

so that if the logger's threshold is set above `DEBUG', the calls to
`expensive_func1()' and `expensive_func2()' are never made.

  There are other optimizations which can be made for specific
applications which need more precise control over what logging
information is collected. Here's a list of things you can do to avoid
processing during logging which you don't need:

What you don't want to collect                      How to avoid collecting it
------------------------------------------------------------------------------------------------- 
Information about where calls were made from.       Set `logging._srcfile' to `None'.
Threading information.                              Set `logging.logThreads' to `0'.
Process information.                                Set `logging.logProcesses' to `0'.

  Also note that the core logging module only includes the basic
handlers. If you don't import *note logging.handlers: 103. and *note
logging.config: 102, they won't take up any memory.

See also
........

Module *note logging: 101.
     API reference for the logging module.

Module *note logging.config: 102.
     Configuration API for the logging module.

Module *note logging.handlers: 103.
     Useful handlers included with the logging module.

  *note A logging cookbook: 129a.


File: python.info,  Node: Logging Cookbook,  Next: Regular Expression HOWTO,  Prev: Logging HOWTO,  Up: Python HOWTOs

10.8 Logging Cookbook
=====================

     Author: Vinay Sajip <vinay_sajip at red-dove dot com>

  This page contains a number of recipes related to logging, which have
been found useful in the past.

* Menu:

* Using logging in multiple modules::
* Multiple handlers and formatters::
* Logging to multiple destinations::
* Configuration server example::
* Sending and receiving logging events across a network::
* Adding contextual information to your logging output::
* Logging to a single file from multiple processes::
* Using file rotation::
* An example dictionary-based configuration::
* Inserting a BOM into messages sent to a SysLogHandler::
* Implementing structured logging::


File: python.info,  Node: Using logging in multiple modules,  Next: Multiple handlers and formatters,  Up: Logging Cookbook

10.8.1 Using logging in multiple modules
----------------------------------------

Multiple calls to `logging.getLogger('someLogger')' return a reference
to the same logger object.  This is true not only within the same
module, but also across modules as long as it is in the same Python
interpreter process.  It is true for references to the same object;
additionally, application code can define and configure a parent logger
in one module and create (but not configure) a child logger in a
separate module, and all logger calls to the child will pass up to the
parent.  Here is a main module:

    import logging
    import auxiliary_module

    # create logger with 'spam_application'
    logger = logging.getLogger('spam_application')
    logger.setLevel(logging.DEBUG)
    # create file handler which logs even debug messages
    fh = logging.FileHandler('spam.log')
    fh.setLevel(logging.DEBUG)
    # create console handler with a higher log level
    ch = logging.StreamHandler()
    ch.setLevel(logging.ERROR)
    # create formatter and add it to the handlers
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    fh.setFormatter(formatter)
    ch.setFormatter(formatter)
    # add the handlers to the logger
    logger.addHandler(fh)
    logger.addHandler(ch)

    logger.info('creating an instance of auxiliary_module.Auxiliary')
    a = auxiliary_module.Auxiliary()
    logger.info('created an instance of auxiliary_module.Auxiliary')
    logger.info('calling auxiliary_module.Auxiliary.do_something')
    a.do_something()
    logger.info('finished auxiliary_module.Auxiliary.do_something')
    logger.info('calling auxiliary_module.some_function()')
    auxiliary_module.some_function()
    logger.info('done with auxiliary_module.some_function()')

Here is the auxiliary module:

    import logging

    # create logger
    module_logger = logging.getLogger('spam_application.auxiliary')

    class Auxiliary:
        def __init__(self):
            self.logger = logging.getLogger('spam_application.auxiliary.Auxiliary')
            self.logger.info('creating an instance of Auxiliary')
        def do_something(self):
            self.logger.info('doing something')
            a = 1 + 1
            self.logger.info('done doing something')

    def some_function():
        module_logger.info('received a call to "some_function"')

The output looks like this:

    2005-03-23 23:47:11,663 - spam_application - INFO -
       creating an instance of auxiliary_module.Auxiliary
    2005-03-23 23:47:11,665 - spam_application.auxiliary.Auxiliary - INFO -
       creating an instance of Auxiliary
    2005-03-23 23:47:11,665 - spam_application - INFO -
       created an instance of auxiliary_module.Auxiliary
    2005-03-23 23:47:11,668 - spam_application - INFO -
       calling auxiliary_module.Auxiliary.do_something
    2005-03-23 23:47:11,668 - spam_application.auxiliary.Auxiliary - INFO -
       doing something
    2005-03-23 23:47:11,669 - spam_application.auxiliary.Auxiliary - INFO -
       done doing something
    2005-03-23 23:47:11,670 - spam_application - INFO -
       finished auxiliary_module.Auxiliary.do_something
    2005-03-23 23:47:11,671 - spam_application - INFO -
       calling auxiliary_module.some_function()
    2005-03-23 23:47:11,672 - spam_application.auxiliary - INFO -
       received a call to 'some_function'
    2005-03-23 23:47:11,673 - spam_application - INFO -
       done with auxiliary_module.some_function()



File: python.info,  Node: Multiple handlers and formatters,  Next: Logging to multiple destinations,  Prev: Using logging in multiple modules,  Up: Logging Cookbook

10.8.2 Multiple handlers and formatters
---------------------------------------

Loggers are plain Python objects.  The `addHandler()' method has no
minimum or maximum quota for the number of handlers you may add.
Sometimes it will be beneficial for an application to log all messages
of all severities to a text file while simultaneously logging errors or
above to the console.  To set this up, simply configure the appropriate
handlers.  The logging calls in the application code will remain
unchanged.  Here is a slight modification to the previous simple
module-based configuration example:

    import logging

    logger = logging.getLogger('simple_example')
    logger.setLevel(logging.DEBUG)
    # create file handler which logs even debug messages
    fh = logging.FileHandler('spam.log')
    fh.setLevel(logging.DEBUG)
    # create console handler with a higher log level
    ch = logging.StreamHandler()
    ch.setLevel(logging.ERROR)
    # create formatter and add it to the handlers
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    ch.setFormatter(formatter)
    fh.setFormatter(formatter)
    # add the handlers to logger
    logger.addHandler(ch)
    logger.addHandler(fh)

    # 'application' code
    logger.debug('debug message')
    logger.info('info message')
    logger.warn('warn message')
    logger.error('error message')
    logger.critical('critical message')

Notice that the 'application' code does not care about multiple
handlers.  All that changed was the addition and configuration of a new
handler named _fh_.

  The ability to create new handlers with higher- or lower-severity
filters can be very helpful when writing and testing an application.
Instead of using many `print' statements for debugging, use
`logger.debug': Unlike the print statements, which you will have to
delete or comment out later, the logger.debug statements can remain
intact in the source code and remain dormant until you need them again.
At that time, the only change that needs to happen is to modify the
severity level of the logger and/or handler to debug.


File: python.info,  Node: Logging to multiple destinations,  Next: Configuration server example,  Prev: Multiple handlers and formatters,  Up: Logging Cookbook

10.8.3 Logging to multiple destinations
---------------------------------------

Let's say you want to log to console and file with different message
formats and in differing circumstances. Say you want to log messages
with levels of DEBUG and higher to file, and those messages at level
INFO and higher to the console.  Let's also assume that the file should
contain timestamps, but the console messages should not. Here's how you
can achieve this:

    import logging

    # set up logging to file - see previous section for more details
    logging.basicConfig(level=logging.DEBUG,
                        format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',
                        datefmt='%m-%d %H:%M',
                        filename='/temp/myapp.log',
                        filemode='w')
    # define a Handler which writes INFO messages or higher to the sys.stderr
    console = logging.StreamHandler()
    console.setLevel(logging.INFO)
    # set a format which is simpler for console use
    formatter = logging.Formatter('%(name)-12s: %(levelname)-8s %(message)s')
    # tell the handler to use this format
    console.setFormatter(formatter)
    # add the handler to the root logger
    logging.getLogger('').addHandler(console)

    # Now, we can log to the root logger, or any other logger. First the root...
    logging.info('Jackdaws love my big sphinx of quartz.')

    # Now, define a couple of other loggers which might represent areas in your
    # application:

    logger1 = logging.getLogger('myapp.area1')
    logger2 = logging.getLogger('myapp.area2')

    logger1.debug('Quick zephyrs blow, vexing daft Jim.')
    logger1.info('How quickly daft jumping zebras vex.')
    logger2.warning('Jail zesty vixen who grabbed pay from quack.')
    logger2.error('The five boxing wizards jump quickly.')

When you run this, on the console you will see

    root        : INFO     Jackdaws love my big sphinx of quartz.
    myapp.area1 : INFO     How quickly daft jumping zebras vex.
    myapp.area2 : WARNING  Jail zesty vixen who grabbed pay from quack.
    myapp.area2 : ERROR    The five boxing wizards jump quickly.

and in the file you will see something like

    10-22 22:19 root         INFO     Jackdaws love my big sphinx of quartz.
    10-22 22:19 myapp.area1  DEBUG    Quick zephyrs blow, vexing daft Jim.
    10-22 22:19 myapp.area1  INFO     How quickly daft jumping zebras vex.
    10-22 22:19 myapp.area2  WARNING  Jail zesty vixen who grabbed pay from quack.
    10-22 22:19 myapp.area2  ERROR    The five boxing wizards jump quickly.

As you can see, the DEBUG message only shows up in the file. The other
messages are sent to both destinations.

  This example uses console and file handlers, but you can use any
number and combination of handlers you choose.


File: python.info,  Node: Configuration server example,  Next: Sending and receiving logging events across a network,  Prev: Logging to multiple destinations,  Up: Logging Cookbook

10.8.4 Configuration server example
-----------------------------------

Here is an example of a module using the logging configuration server:

    import logging
    import logging.config
    import time
    import os

    # read initial config file
    logging.config.fileConfig('logging.conf')

    # create and start listener on port 9999
    t = logging.config.listen(9999)
    t.start()

    logger = logging.getLogger('simpleExample')

    try:
        # loop through logging calls to see the difference
        # new configurations make, until Ctrl+C is pressed
        while True:
            logger.debug('debug message')
            logger.info('info message')
            logger.warn('warn message')
            logger.error('error message')
            logger.critical('critical message')
            time.sleep(5)
    except KeyboardInterrupt:
        # cleanup
        logging.config.stopListening()
        t.join()

And here is a script that takes a filename and sends that file to the
server, properly preceded with the binary-encoded length, as the new
logging configuration:

    #!/usr/bin/env python
    import socket, sys, struct

    with open(sys.argv[1], 'rb') as f:
        data_to_send = f.read()

    HOST = 'localhost'
    PORT = 9999
    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    print('connecting...')
    s.connect((HOST, PORT))
    print('sending config...')
    s.send(struct.pack('>L', len(data_to_send)))
    s.send(data_to_send)
    s.close()
    print('complete')



File: python.info,  Node: Sending and receiving logging events across a network,  Next: Adding contextual information to your logging output,  Prev: Configuration server example,  Up: Logging Cookbook

10.8.5 Sending and receiving logging events across a network
------------------------------------------------------------

Let's say you want to send logging events across a network, and handle
them at the receiving end. A simple way of doing this is attaching a
`SocketHandler' instance to the root logger at the sending end:

    import logging, logging.handlers

    rootLogger = logging.getLogger('')
    rootLogger.setLevel(logging.DEBUG)
    socketHandler = logging.handlers.SocketHandler('localhost',
                        logging.handlers.DEFAULT_TCP_LOGGING_PORT)
    # don't bother with a formatter, since a socket handler sends the event as
    # an unformatted pickle
    rootLogger.addHandler(socketHandler)

    # Now, we can log to the root logger, or any other logger. First the root...
    logging.info('Jackdaws love my big sphinx of quartz.')

    # Now, define a couple of other loggers which might represent areas in your
    # application:

    logger1 = logging.getLogger('myapp.area1')
    logger2 = logging.getLogger('myapp.area2')

    logger1.debug('Quick zephyrs blow, vexing daft Jim.')
    logger1.info('How quickly daft jumping zebras vex.')
    logger2.warning('Jail zesty vixen who grabbed pay from quack.')
    logger2.error('The five boxing wizards jump quickly.')

At the receiving end, you can set up a receiver using the *note
SocketServer: 15d.  module. Here is a basic working example:

    import pickle
    import logging
    import logging.handlers
    import SocketServer
    import struct


    class LogRecordStreamHandler(SocketServer.StreamRequestHandler):
        """Handler for a streaming logging request.

        This basically logs the record using whatever logging policy is
        configured locally.
        """

        def handle(self):
            """
            Handle multiple requests - each expected to be a 4-byte length,
            followed by the LogRecord in pickle format. Logs the record
            according to whatever policy is configured locally.
            """
            while True:
                chunk = self.connection.recv(4)
                if len(chunk) < 4:
                    break
                slen = struct.unpack('>L', chunk)[0]
                chunk = self.connection.recv(slen)
                while len(chunk) < slen:
                    chunk = chunk + self.connection.recv(slen - len(chunk))
                obj = self.unPickle(chunk)
                record = logging.makeLogRecord(obj)
                self.handleLogRecord(record)

        def unPickle(self, data):
            return pickle.loads(data)

        def handleLogRecord(self, record):
            # if a name is specified, we use the named logger rather than the one
            # implied by the record.
            if self.server.logname is not None:
                name = self.server.logname
            else:
                name = record.name
            logger = logging.getLogger(name)
            # N.B. EVERY record gets logged. This is because Logger.handle
            # is normally called AFTER logger-level filtering. If you want
            # to do filtering, do it at the client end to save wasting
            # cycles and network bandwidth!
            logger.handle(record)

    class LogRecordSocketReceiver(SocketServer.ThreadingTCPServer):
        """
        Simple TCP socket-based logging receiver suitable for testing.
        """

        allow_reuse_address = 1

        def __init__(self, host='localhost',
                     port=logging.handlers.DEFAULT_TCP_LOGGING_PORT,
                     handler=LogRecordStreamHandler):
            SocketServer.ThreadingTCPServer.__init__(self, (host, port), handler)
            self.abort = 0
            self.timeout = 1
            self.logname = None

        def serve_until_stopped(self):
            import select
            abort = 0
            while not abort:
                rd, wr, ex = select.select([self.socket.fileno()],
                                           [], [],
                                           self.timeout)
                if rd:
                    self.handle_request()
                abort = self.abort

    def main():
        logging.basicConfig(
            format='%(relativeCreated)5d %(name)-15s %(levelname)-8s %(message)s')
        tcpserver = LogRecordSocketReceiver()
        print('About to start TCP server...')
        tcpserver.serve_until_stopped()

    if __name__ == '__main__':
        main()

First run the server, and then the client. On the client side, nothing
is printed on the console; on the server side, you should see something
like:

    About to start TCP server...
       59 root            INFO     Jackdaws love my big sphinx of quartz.
       59 myapp.area1     DEBUG    Quick zephyrs blow, vexing daft Jim.
       69 myapp.area1     INFO     How quickly daft jumping zebras vex.
       69 myapp.area2     WARNING  Jail zesty vixen who grabbed pay from quack.
       69 myapp.area2     ERROR    The five boxing wizards jump quickly.

Note that there are some security issues with pickle in some scenarios.
If these affect you, you can use an alternative serialization scheme by
overriding the `makePickle()' method and implementing your alternative
there, as well as adapting the above script to use your alternative
serialization.


File: python.info,  Node: Adding contextual information to your logging output,  Next: Logging to a single file from multiple processes,  Prev: Sending and receiving logging events across a network,  Up: Logging Cookbook

10.8.6 Adding contextual information to your logging output
-----------------------------------------------------------

Sometimes you want logging output to contain contextual information in
addition to the parameters passed to the logging call. For example, in a
networked application, it may be desirable to log client-specific
information in the log (e.g. remote client's username, or IP address).
Although you could use the _extra_ parameter to achieve this, it's not
always convenient to pass the information in this way. While it might
be tempting to create *note Logger: 1da. instances on a per-connection
basis, this is not a good idea because these instances are not garbage
collected. While this is not a problem in practice, when the number of
*note Logger: 1da. instances is dependent on the level of granularity
you want to use in logging an application, it could be hard to manage
if the number of *note Logger: 1da. instances becomes effectively
unbounded.

* Menu:

* Using LoggerAdapters to impart contextual information::
* Using Filters to impart contextual information::


File: python.info,  Node: Using LoggerAdapters to impart contextual information,  Next: Using Filters to impart contextual information,  Up: Adding contextual information to your logging output

10.8.6.1 Using LoggerAdapters to impart contextual information
..............................................................

An easy way in which you can pass contextual information to be output
along with logging event information is to use the *note LoggerAdapter:
1dc. class.  This class is designed to look like a *note Logger: 1da,
so that you can call *note debug(): 12a5, *note info(): 12d1, *note
warning(): 12dd, *note error(): 12de, *note exception(): 12df, *note
critical(): 12e0. and *note log(): 12e1. These methods have the same
signatures as their counterparts in *note Logger: 1da, so you can use
the two types of instances interchangeably.

  When you create an instance of *note LoggerAdapter: 1dc, you pass it a
*note Logger: 1da. instance and a dict-like object which contains your
contextual information. When you call one of the logging methods on an
instance of *note LoggerAdapter: 1dc, it delegates the call to the
underlying instance of *note Logger: 1da. passed to its constructor,
and arranges to pass the contextual information in the delegated call.
Here's a snippet from the code of *note LoggerAdapter: 1dc.:

    def debug(self, msg, *args, **kwargs):
        """
        Delegate a debug call to the underlying logger, after adding
        contextual information from this adapter instance.
        """
        msg, kwargs = self.process(msg, kwargs)
        self.logger.debug(msg, *args, **kwargs)

The `process()' method of *note LoggerAdapter: 1dc. is where the
contextual information is added to the logging output. It's passed the
message and keyword arguments of the logging call, and it passes back
(potentially) modified versions of these to use in the call to the
underlying logger. The default implementation of this method leaves the
message alone, but inserts an 'extra' key in the keyword argument whose
value is the dict-like object passed to the constructor. Of course, if
you had passed an 'extra' keyword argument in the call to the adapter,
it will be silently overwritten.

  The advantage of using 'extra' is that the values in the dict-like
object are merged into the *note LogRecord: 12b3. instance's __dict__,
allowing you to use customized strings with your *note Formatter: 12a3.
instances which know about the keys of the dict-like object. If you
need a different method, e.g. if you want to prepend or append the
contextual information to the message string, you just need to subclass
*note LoggerAdapter: 1dc. and override `process()' to do what you need.
Here's an example script which uses this class, which also illustrates
what dict-like behaviour is needed from an arbitrary 'dict-like' object
for use in the constructor:

    import logging

    class ConnInfo:
        """
        An example class which shows how an arbitrary class can be used as
        the 'extra' context information repository passed to a LoggerAdapter.
        """

        def __getitem__(self, name):
            """
            To allow this instance to look like a dict.
            """
            from random import choice
            if name == 'ip':
                result = choice(['127.0.0.1', '192.168.0.1'])
            elif name == 'user':
                result = choice(['jim', 'fred', 'sheila'])
            else:
                result = self.__dict__.get(name, '?')
            return result

        def __iter__(self):
            """
            To allow iteration over keys, which will be merged into
            the LogRecord dict before formatting and output.
            """
            keys = ['ip', 'user']
            keys.extend(self.__dict__.keys())
            return keys.__iter__()

    if __name__ == '__main__':
        from random import choice
        levels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL)
        a1 = logging.LoggerAdapter(logging.getLogger('a.b.c'),
                                   { 'ip' : '123.231.231.123', 'user' : 'sheila' })
        logging.basicConfig(level=logging.DEBUG,
                            format='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip)-15s User: %(user)-8s %(message)s')
        a1.debug('A debug message')
        a1.info('An info message with %s', 'some parameters')
        a2 = logging.LoggerAdapter(logging.getLogger('d.e.f'), ConnInfo())
        for x in range(10):
            lvl = choice(levels)
            lvlname = logging.getLevelName(lvl)
            a2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')

When this script is run, the output should look something like this:

    2008-01-18 14:49:54,023 a.b.c DEBUG    IP: 123.231.231.123 User: sheila   A debug message
    2008-01-18 14:49:54,023 a.b.c INFO     IP: 123.231.231.123 User: sheila   An info message with some parameters
    2008-01-18 14:49:54,023 d.e.f CRITICAL IP: 192.168.0.1     User: jim      A message at CRITICAL level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f INFO     IP: 192.168.0.1     User: jim      A message at INFO level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: sheila   A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f ERROR    IP: 127.0.0.1       User: fred     A message at ERROR level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f ERROR    IP: 127.0.0.1       User: sheila   A message at ERROR level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: sheila   A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: jim      A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f INFO     IP: 192.168.0.1     User: fred     A message at INFO level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 192.168.0.1     User: sheila   A message at WARNING level with 2 parameters
    2008-01-18 14:49:54,033 d.e.f WARNING  IP: 127.0.0.1       User: jim      A message at WARNING level with 2 parameters



File: python.info,  Node: Using Filters to impart contextual information,  Prev: Using LoggerAdapters to impart contextual information,  Up: Adding contextual information to your logging output

10.8.6.2 Using Filters to impart contextual information
.......................................................

You can also add contextual information to log output using a
user-defined *note Filter: 12cf. `Filter' instances are allowed to
modify the `LogRecords' passed to them, including adding additional
attributes which can then be output using a suitable format string, or
if needed a custom *note Formatter: 12a3.

  For example in a web application, the request being processed (or at
least, the interesting parts of it) can be stored in a threadlocal
(*note threading.local: 15a0.) variable, and then accessed from a
`Filter' to add, say, information from the request - say, the remote IP
address and remote user's username - to the `LogRecord', using the
attribute names 'ip' and 'user' as in the `LoggerAdapter' example
above. In that case, the same format string can be used to get similar
output to that shown above. Here's an example script:

    import logging
    from random import choice

    class ContextFilter(logging.Filter):
        """
        This is a filter which injects contextual information into the log.

        Rather than use actual contextual information, we just use random
        data in this demo.
        """

        USERS = ['jim', 'fred', 'sheila']
        IPS = ['123.231.231.123', '127.0.0.1', '192.168.0.1']

        def filter(self, record):

            record.ip = choice(ContextFilter.IPS)
            record.user = choice(ContextFilter.USERS)
            return True

    if __name__ == '__main__':
       levels = (logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR, logging.CRITICAL)
       logging.basicConfig(level=logging.DEBUG,
                           format='%(asctime)-15s %(name)-5s %(levelname)-8s IP: %(ip)-15s User: %(user)-8s %(message)s')
       a1 = logging.getLogger('a.b.c')
       a2 = logging.getLogger('d.e.f')

       f = ContextFilter()
       a1.addFilter(f)
       a2.addFilter(f)
       a1.debug('A debug message')
       a1.info('An info message with %s', 'some parameters')
       for x in range(10):
           lvl = choice(levels)
           lvlname = logging.getLevelName(lvl)
           a2.log(lvl, 'A message at %s level with %d %s', lvlname, 2, 'parameters')

which, when run, produces something like:

    2010-09-06 22:38:15,292 a.b.c DEBUG    IP: 123.231.231.123 User: fred     A debug message
    2010-09-06 22:38:15,300 a.b.c INFO     IP: 192.168.0.1     User: sheila   An info message with some parameters
    2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1       User: sheila   A message at CRITICAL level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f ERROR    IP: 127.0.0.1       User: jim      A message at ERROR level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f DEBUG    IP: 127.0.0.1       User: sheila   A message at DEBUG level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f ERROR    IP: 123.231.231.123 User: fred     A message at ERROR level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 192.168.0.1     User: jim      A message at CRITICAL level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f CRITICAL IP: 127.0.0.1       User: sheila   A message at CRITICAL level with 2 parameters
    2010-09-06 22:38:15,300 d.e.f DEBUG    IP: 192.168.0.1     User: jim      A message at DEBUG level with 2 parameters
    2010-09-06 22:38:15,301 d.e.f ERROR    IP: 127.0.0.1       User: sheila   A message at ERROR level with 2 parameters
    2010-09-06 22:38:15,301 d.e.f DEBUG    IP: 123.231.231.123 User: fred     A message at DEBUG level with 2 parameters
    2010-09-06 22:38:15,301 d.e.f INFO     IP: 123.231.231.123 User: fred     A message at INFO level with 2 parameters



File: python.info,  Node: Logging to a single file from multiple processes,  Next: Using file rotation,  Prev: Adding contextual information to your logging output,  Up: Logging Cookbook

10.8.7 Logging to a single file from multiple processes
-------------------------------------------------------

Although logging is thread-safe, and logging to a single file from
multiple threads in a single process _is_ supported, logging to a
single file from _multiple processes_ is _not_ supported, because there
is no standard way to serialize access to a single file across multiple
processes in Python. If you need to log to a single file from multiple
processes, one way of doing this is to have all the processes log to a
`SocketHandler', and have a separate process which implements a socket
server which reads from the socket and logs to file. (If you prefer,
you can dedicate one thread in one of the existing processes to perform
this function.) *note This section: 3018.  documents this approach in
more detail and includes a working socket receiver which can be used as
a starting point for you to adapt in your own applications.

  If you are using a recent version of Python which includes the *note
multiprocessing: 119. module, you could write your own handler which
uses the `Lock' class from this module to serialize access to the file
from your processes. The existing *note FileHandler: 130b. and
subclasses do not make use of *note multiprocessing: 119. at present,
though they may do so in the future.  Note that at present, the *note
multiprocessing: 119. module does not provide working lock
functionality on all platforms (see <http://bugs.python.org/issue3770>).


File: python.info,  Node: Using file rotation,  Next: An example dictionary-based configuration,  Prev: Logging to a single file from multiple processes,  Up: Logging Cookbook

10.8.8 Using file rotation
--------------------------

Sometimes you want to let a log file grow to a certain size, then open
a new file and log to that. You may want to keep a certain number of
these files, and when that many files have been created, rotate the
files so that the number of files and the size of the files both remain
bounded. For this usage pattern, the logging package provides a *note
RotatingFileHandler: 12fb.:

    import glob
    import logging
    import logging.handlers

    LOG_FILENAME = 'logging_rotatingfile_example.out'

    # Set up a specific logger with our desired output level
    my_logger = logging.getLogger('MyLogger')
    my_logger.setLevel(logging.DEBUG)

    # Add the log message handler to the logger
    handler = logging.handlers.RotatingFileHandler(
                  LOG_FILENAME, maxBytes=20, backupCount=5)

    my_logger.addHandler(handler)

    # Log some messages
    for i in range(20):
        my_logger.debug('i = %d' % i)

    # See what files are created
    logfiles = glob.glob('%s*' % LOG_FILENAME)

    for filename in logfiles:
        print(filename)

The result should be 6 separate files, each with part of the log
history for the application:

    logging_rotatingfile_example.out
    logging_rotatingfile_example.out.1
    logging_rotatingfile_example.out.2
    logging_rotatingfile_example.out.3
    logging_rotatingfile_example.out.4
    logging_rotatingfile_example.out.5

The most current file is always `logging_rotatingfile_example.out', and
each time it reaches the size limit it is renamed with the suffix `.1'.
Each of the existing backup files is renamed to increment the suffix
(`.1' becomes `.2', etc.)  and the `.6' file is erased.

  Obviously this example sets the log length much too small as an
extreme example.  You would want to set _maxBytes_ to an appropriate
value.


File: python.info,  Node: An example dictionary-based configuration,  Next: Inserting a BOM into messages sent to a SysLogHandler,  Prev: Using file rotation,  Up: Logging Cookbook

10.8.9 An example dictionary-based configuration
------------------------------------------------

Below is an example of a logging configuration dictionary - it's taken
from the documentation on the Django project(1).  This dictionary is
passed to *note dictConfig(): 12f2. to put the configuration into
effect:

    LOGGING = {
        'version': 1,
        'disable_existing_loggers': True,
        'formatters': {
            'verbose': {
                'format': '%(levelname)s %(asctime)s %(module)s %(process)d %(thread)d %(message)s'
            },
            'simple': {
                'format': '%(levelname)s %(message)s'
            },
        },
        'filters': {
            'special': {
                '()': 'project.logging.SpecialFilter',
                'foo': 'bar',
            }
        },
        'handlers': {
            'null': {
                'level':'DEBUG',
                'class':'django.utils.log.NullHandler',
            },
            'console':{
                'level':'DEBUG',
                'class':'logging.StreamHandler',
                'formatter': 'simple'
            },
            'mail_admins': {
                'level': 'ERROR',
                'class': 'django.utils.log.AdminEmailHandler',
                'filters': ['special']
            }
        },
        'loggers': {
            'django': {
                'handlers':['null'],
                'propagate': True,
                'level':'INFO',
            },
            'django.request': {
                'handlers': ['mail_admins'],
                'level': 'ERROR',
                'propagate': False,
            },
            'myproject.custom': {
                'handlers': ['console', 'mail_admins'],
                'level': 'INFO',
                'filters': ['special']
            }
        }
    }

For more information about this configuration, you can see the relevant
section(2) of the Django documentation.

  ---------- Footnotes ----------

  (1)
https://docs.djangoproject.com/en/1.3/topics/logging/#configuring-logging

  (2)
https://docs.djangoproject.com/en/1.3/topics/logging/#configuring-logging


File: python.info,  Node: Inserting a BOM into messages sent to a SysLogHandler,  Next: Implementing structured logging,  Prev: An example dictionary-based configuration,  Up: Logging Cookbook

10.8.10 Inserting a BOM into messages sent to a SysLogHandler
-------------------------------------------------------------

RFC 5424(1) requires that a Unicode message be sent to a syslog daemon
as a set of bytes which have the following structure: an optional
pure-ASCII component, followed by a UTF-8 Byte Order Mark (BOM),
followed by Unicode encoded using UTF-8. (See the relevant section of
the specification(2).)

  In Python 2.6 and 2.7, code was added to *note SysLogHandler: 1d7. to
insert a BOM into the message, but unfortunately, it was implemented
incorrectly, with the BOM appearing at the beginning of the message and
hence not allowing any pure-ASCII component to appear before it.

  As this behaviour is broken, the incorrect BOM insertion code is
being removed from Python 2.7.4 and later. However, it is not being
replaced, and if you want to produce RFC 5424-compliant messages which
include a BOM, an optional pure-ASCII sequence before it and arbitrary
Unicode after it, encoded using UTF-8, then you need to do the
following:

  1. Attach a *note Formatter: 12a3. instance to your *note
     SysLogHandler: 1d7. instance, with a format string such as:

         u'ASCII section\ufeffUnicode section'

     The Unicode code point `u'\ufeff'', when encoded using UTF-8, will
     be encoded as a UTF-8 BOM - the byte-string `'\xef\xbb\xbf''.

  2. Replace the ASCII section with whatever placeholders you like, but
     make sure that the data that appears in there after substitution
     is always ASCII (that way, it will remain unchanged after UTF-8
     encoding).

  3. Replace the Unicode section with whatever placeholders you like;
     if the data which appears there after substitution contains
     characters outside the ASCII range, that's fine - it will be
     encoded using UTF-8.

  If the formatted message is Unicode, it _will_ be encoded using UTF-8
encoding by `SysLogHandler'. If you follow the above rules, you should
be able to produce RFC 5424-compliant messages. If you don't, logging
may not complain, but your messages will not be RFC 5424-compliant, and
your syslog daemon may complain.

  ---------- Footnotes ----------

  (1) http://tools.ietf.org/html/rfc5424

  (2) http://tools.ietf.org/html/rfc5424#section-6


File: python.info,  Node: Implementing structured logging,  Prev: Inserting a BOM into messages sent to a SysLogHandler,  Up: Logging Cookbook

10.8.11 Implementing structured logging
---------------------------------------

Although most logging messages are intended for reading by humans, and
thus not readily machine-parseable, there might be cirumstances where
you want to output messages in a structured format which _is_ capable
of being parsed by a program (without needing complex regular
expressions to parse the log message). This is straightforward to
achieve using the logging package. There are a number of ways in which
this could be achieved, but the following is a simple approach which
uses JSON to serialise the event in a machine-parseable manner:

    import json
    import logging

    class StructuredMessage(object):
        def __init__(self, message, **kwargs):
            self.message = message
            self.kwargs = kwargs

        def __str__(self):
            return '%s >>> %s' % (self.message, json.dumps(self.kwargs))

    _ = StructuredMessage   # optional, to improve readability

    logging.basicConfig(level=logging.INFO, format='%(message)s')
    logging.info(_('message 1', foo='bar', bar='baz', num=123, fnum=123.456))

If the above script is run, it prints:

    message 1 >>> {"fnum": 123.456, "num": 123, "bar": "baz", "foo": "bar"}

Note that the order of items might be different according to the
version of Python used.

  If you need more specialised processing, you can use a custom JSON
encoder, as in the following complete example:

    from __future__ import unicode_literals

    import json
    import logging

    # This next bit is to ensure the script runs unchanged on 2.x and 3.x
    try:
        unicode
    except NameError:
        unicode = str

    class Encoder(json.JSONEncoder):
        def default(self, o):
            if isinstance(o, set):
                return tuple(o)
            elif isinstance(o, unicode):
                return o.encode('unicode_escape').decode('ascii')
            return super(Encoder, self).default(o)

    class StructuredMessage(object):
        def __init__(self, message, **kwargs):
            self.message = message
            self.kwargs = kwargs

        def __str__(self):
            s = Encoder().encode(self.kwargs)
            return '%s >>> %s' % (self.message, s)

    _ = StructuredMessage   # optional, to improve readability

    def main():
        logging.basicConfig(level=logging.INFO, format='%(message)s')
        logging.info(_('message 1', set_value=set([1, 2, 3]), snowman='\u2603'))

    if __name__ == '__main__':
        main()

When the above script is run, it prints:

    message 1 >>> {"snowman": "\u2603", "set_value": [1, 2, 3]}

Note that the order of items might be different according to the
version of Python used.


File: python.info,  Node: Regular Expression HOWTO,  Next: Socket Programming HOWTO,  Prev: Logging Cookbook,  Up: Python HOWTOs

10.9 Regular Expression HOWTO
=============================

     Author: A.M. Kuchling <<amk@amk.ca>>

Abstract
........

This document is an introductory tutorial to using regular expressions
in Python with the *note re: 143. module.  It provides a gentler
introduction than the corresponding section in the Library Reference.

* Menu:

* Introduction: Introduction<13>.
* Simple Patterns::
* Using Regular Expressions::
* More Pattern Power::
* Modifying Strings::
* Common Problems::
* Feedback::


File: python.info,  Node: Introduction<13>,  Next: Simple Patterns,  Up: Regular Expression HOWTO

10.9.1 Introduction
-------------------

The *note re: 143. module was added in Python 1.5, and provides
Perl-style regular expression patterns.  Earlier versions of Python
came with the `regex' module, which provided Emacs-style patterns.  The
`regex' module was removed completely in Python 2.5.

  Regular expressions (called REs, or regexes, or regex patterns) are
essentially a tiny, highly specialized programming language embedded
inside Python and made available through the *note re: 143. module.
Using this little language, you specify the rules for the set of
possible strings that you want to match; this set might contain English
sentences, or e-mail addresses, or TeX commands, or anything you like.
You can then ask questions such as "Does this string match the
pattern?", or "Is there a match for the pattern anywhere in this
string?".  You can also use REs to modify a string or to split it apart
in various ways.

  Regular expression patterns are compiled into a series of bytecodes
which are then executed by a matching engine written in C.  For
advanced use, it may be necessary to pay careful attention to how the
engine will execute a given RE, and write the RE in a certain way in
order to produce bytecode that runs faster.  Optimization isn't covered
in this document, because it requires that you have a good
understanding of the matching engine's internals.

  The regular expression language is relatively small and restricted,
so not all possible string processing tasks can be done using regular
expressions.  There are also tasks that _can_ be done with regular
expressions, but the expressions turn out to be very complicated.  In
these cases, you may be better off writing Python code to do the
processing; while Python code will be slower than an elaborate regular
expression, it will also probably be more understandable.


File: python.info,  Node: Simple Patterns,  Next: Using Regular Expressions,  Prev: Introduction<13>,  Up: Regular Expression HOWTO

10.9.2 Simple Patterns
----------------------

We'll start by learning about the simplest possible regular
expressions.  Since regular expressions are used to operate on strings,
we'll begin with the most common task: matching characters.

  For a detailed explanation of the computer science underlying regular
expressions (deterministic and non-deterministic finite automata), you
can refer to almost any textbook on writing compilers.

* Menu:

* Matching Characters::
* Repeating Things::


File: python.info,  Node: Matching Characters,  Next: Repeating Things,  Up: Simple Patterns

10.9.2.1 Matching Characters
............................

Most letters and characters will simply match themselves.  For example,
the regular expression `test' will match the string `test' exactly.
(You can enable a case-insensitive mode that would let this RE match
`Test' or `TEST' as well; more about this later.)

  There are exceptions to this rule; some characters are special
_metacharacters_, and don't match themselves.  Instead, they signal that
some out-of-the-ordinary thing should be matched, or they affect other
portions of the RE by repeating them or changing their meaning.  Much
of this document is devoted to discussing various metacharacters and
what they do.

  Here's a complete list of the metacharacters; their meanings will be
discussed in the rest of this HOWTO.

    . ^ $ * + ? { } [ ] \ | ( )

The first metacharacters we'll look at are `[' and `]'. They're used for
specifying a character class, which is a set of characters that you
wish to match.  Characters can be listed individually, or a range of
characters can be indicated by giving two characters and separating
them by a `'-''.  For example, `[abc]' will match any of the characters
`a', `b', or `c'; this is the same as `[a-c]', which uses a range to
express the same set of characters.  If you wanted to match only
lowercase letters, your RE would be `[a-z]'.

  Metacharacters are not active inside classes.  For example, `[akm$]'
will match any of the characters `'a'', `'k'', `'m'', or `'$''; `'$'' is
usually a metacharacter, but inside a character class it's stripped of
its special nature.

  You can match the characters not listed within the class by
_complementing_ the set.  This is indicated by including a `'^'' as the
first character of the class; `'^'' outside a character class will
simply match the `'^'' character.  For example, `[^5]' will match any
character except `'5''.

  Perhaps the most important metacharacter is the backslash, `\'.   As
in Python string literals, the backslash can be followed by various
characters to signal various special sequences.  It's also used to
escape all the metacharacters so you can still match them in patterns;
for example, if you need to match a `[' or  `\', you can precede them
with a backslash to remove their special meaning: `\[' or `\\'.

  Some of the special sequences beginning with `'\'' represent
predefined sets of characters that are often useful, such as the set of
digits, the set of letters, or the set of anything that isn't
whitespace.  The following predefined special sequences are a subset of
those available. The equivalent classes are for byte string patterns.
For a complete list of sequences and expanded class definitions for
Unicode string patterns, see the last part of *note Regular Expression
Syntax: 9a1.

`\d'
     Matches any decimal digit; this is equivalent to the class `[0-9]'.

`\D'
     Matches any non-digit character; this is equivalent to the class
     `[^0-9]'.

`\s'
     Matches any whitespace character; this is equivalent to the class
     `[ \t\n\r\f\v]'.

`\S'
     Matches any non-whitespace character; this is equivalent to the
     class `[^ \t\n\r\f\v]'.

`\w'
     Matches any alphanumeric character; this is equivalent to the class
     `[a-zA-Z0-9_]'.

`\W'
     Matches any non-alphanumeric character; this is equivalent to the
     class `[^a-zA-Z0-9_]'.

  These sequences can be included inside a character class.  For
example, `[\s,.]' is a character class that will match any whitespace
character, or `','' or `'.''.

  The final metacharacter in this section is `.'.  It matches anything
except a newline character, and there's an alternate mode (`re.DOTALL')
where it will match even a newline.  `'.'' is often used where you want
to match "any character".


File: python.info,  Node: Repeating Things,  Prev: Matching Characters,  Up: Simple Patterns

10.9.2.2 Repeating Things
.........................

Being able to match varying sets of characters is the first thing
regular expressions can do that isn't already possible with the methods
available on strings.  However, if that was the only additional
capability of regexes, they wouldn't be much of an advance. Another
capability is that you can specify that portions of the RE must be
repeated a certain number of times.

  The first metacharacter for repeating things that we'll look at is
`*'.  `*' doesn't match the literal character `*'; instead, it
specifies that the previous character can be matched zero or more
times, instead of exactly once.

  For example, `ca*t' will match `ct' (0 `a' characters), `cat' (1 `a'),
`caaat' (3 `a' characters), and so forth.  The RE engine has various
internal limitations stemming from the size of C's `int' type that will
prevent it from matching over 2 billion `a' characters; you probably
don't have enough memory to construct a string that large, so you
shouldn't run into that limit.

  Repetitions such as `*' are _greedy_; when repeating a RE, the
matching engine will try to repeat it as many times as possible. If
later portions of the pattern don't match, the matching engine will
then back up and try again with few repetitions.

  A step-by-step example will make this more obvious.  Let's consider
the expression `a[bcd]*b'.  This matches the letter `'a'', zero or more
letters from the class `[bcd]', and finally ends with a `'b''.  Now
imagine matching this RE against the string `abcbd'.

Step       Matched         Explanation
----------------------------------------------------------------- 
1          `a'             The `a' in the RE matches.
2          `abcbd'         The engine matches `[bcd]*', going
                           as far as it can, which is to the
                           end of the string.
3          _Failure_       The engine tries to match `b', but
                           the current position is at the end
                           of the string, so it fails.
4          `abcb'          Back up, so that  `[bcd]*' matches
                           one less character.
5          _Failure_       Try `b' again, but the current
                           position is at the last character,
                           which is a `'d''.
6          `abc'           Back up again, so that `[bcd]*' is
                           only matching `bc'.
6          `abcb'          Try `b' again.  This time the
                           character at the current position is
                           `'b'', so it succeeds.

  The end of the RE has now been reached, and it has matched `abcb'.
This demonstrates how the matching engine goes as far as it can at
first, and if no match is found it will then progressively back up and
retry the rest of the RE again and again.  It will back up until it has
tried zero matches for `[bcd]*', and if that subsequently fails, the
engine will conclude that the string doesn't match the RE at all.

  Another repeating metacharacter is `+', which matches one or more
times.  Pay careful attention to the difference between `*' and `+';
`*' matches _zero_ or more times, so whatever's being repeated may not
be present at all, while `+' requires at least _one_ occurrence.  To
use a similar example, `ca+t' will match `cat' (1 `a'), `caaat' (3
`a''s), but won't match `ct'.

  There are two more repeating qualifiers.  The question mark
character, `?', matches either once or zero times; you can think of it
as marking something as being optional.  For example, `home-?brew'
matches either `homebrew' or `home-brew'.

  The most complicated repeated qualifier is `{m,n}', where _m_ and _n_
are decimal integers.  This qualifier means there must be at least _m_
repetitions, and at most _n_.  For example, `a/{1,3}b' will match
`a/b', `a//b', and `a///b'.  It won't match `ab', which has no slashes,
or `a////b', which has four.

  You can omit either _m_ or _n_; in that case, a reasonable value is
assumed for the missing value.  Omitting _m_ is interpreted as a lower
limit of 0, while omitting _n_ results in an upper bound of infinity --
actually, the upper bound is the 2-billion limit mentioned earlier, but
that might as well be infinity.

  Readers of a reductionist bent may notice that the three other
qualifiers can all be expressed using this notation.  `{0,}' is the
same as `*', `{1,}' is equivalent to `+', and `{0,1}' is the same as
`?'.  It's better to use `*', `+', or `?' when you can, simply because
they're shorter and easier to read.


File: python.info,  Node: Using Regular Expressions,  Next: More Pattern Power,  Prev: Simple Patterns,  Up: Regular Expression HOWTO

10.9.3 Using Regular Expressions
--------------------------------

Now that we've looked at some simple regular expressions, how do we
actually use them in Python?  The *note re: 143. module provides an
interface to the regular expression engine, allowing you to compile REs
into objects and then perform matches with them.

* Menu:

* Compiling Regular Expressions::
* The Backslash Plague::
* Performing Matches::
* Module-Level Functions: Module-Level Functions<2>.
* Compilation Flags::


File: python.info,  Node: Compiling Regular Expressions,  Next: The Backslash Plague,  Up: Using Regular Expressions

10.9.3.1 Compiling Regular Expressions
......................................

Regular expressions are compiled into pattern objects, which have
methods for various operations such as searching for pattern matches or
performing string substitutions.

    >>> import re
    >>> p = re.compile('ab*')
    >>> p  #doctest: +ELLIPSIS
    <_sre.SRE_Pattern object at 0x...>

*note re.compile(): 9ae. also accepts an optional _flags_ argument,
used to enable various special features and syntax variations.  We'll
go over the available settings later, but for now a single example will
do:

    >>> p = re.compile('ab*', re.IGNORECASE)

The RE is passed to *note re.compile(): 9ae. as a string.  REs are
handled as strings because regular expressions aren't part of the core
Python language, and no special syntax was created for expressing them.
(There are applications that don't need REs at all, so there's no need
to bloat the language specification by including them.) Instead, the
*note re: 143. module is simply a C extension module included with
Python, just like the *note socket: 15c. or *note zlib: 1ad. modules.

  Putting REs in strings keeps the Python language simpler, but has one
disadvantage which is the topic of the next section.


File: python.info,  Node: The Backslash Plague,  Next: Performing Matches,  Prev: Compiling Regular Expressions,  Up: Using Regular Expressions

10.9.3.2 The Backslash Plague
.............................

As stated earlier, regular expressions use the backslash character
(`'\'') to indicate special forms or to allow special characters to be
used without invoking their special meaning. This conflicts with
Python's usage of the same character for the same purpose in string
literals.

  Let's say you want to write a RE that matches the string `\section',
which might be found in a LaTeX file.  To figure out what to write in
the program code, start with the desired string to be matched.  Next,
you must escape any backslashes and other metacharacters by preceding
them with a backslash, resulting in the string `\\section'.  The
resulting string that must be passed to *note re.compile(): 9ae. must
be `\\section'.  However, to express this as a Python string literal,
both backslashes must be escaped _again_.

Characters              Stage
----------------------------------------------------------------------- 
`\section'              Text string to be matched
`\\section'             Escaped backslash for *note re.compile(): 9ae.
`"\\\\section"'         Escaped backslashes for a string literal

  In short, to match a literal backslash, one has to write `'\\\\'' as
the RE string, because the regular expression must be `\\', and each
backslash must be expressed as `\\' inside a regular Python string
literal.  In REs that feature backslashes repeatedly, this leads to
lots of repeated backslashes and makes the resulting strings difficult
to understand.

  The solution is to use Python's raw string notation for regular
expressions; backslashes are not handled in any special way in a string
literal prefixed with `'r'', so `r"\n"' is a two-character string
containing `'\'' and `'n'', while `"\n"' is a one-character string
containing a newline. Regular expressions will often be written in
Python code using this raw string notation.

Regular String          Raw string
----------------------------------------------- 
`"ab*"'                 `r"ab*"'
`"\\\\section"'         `r"\\section"'
`"\\w+\\s+\\1"'         `r"\w+\s+\1"'


File: python.info,  Node: Performing Matches,  Next: Module-Level Functions<2>,  Prev: The Backslash Plague,  Up: Using Regular Expressions

10.9.3.3 Performing Matches
...........................

Once you have an object representing a compiled regular expression,
what do you do with it?  Pattern objects have several methods and
attributes.  Only the most significant ones will be covered here;
consult the *note re: 143. docs for a complete listing.

Method/Attribute       Purpose
--------------------------------------------------------------------------- 
`match()'              Determine if the RE matches at the beginning of
                       the string.
`search()'             Scan through a string, looking for any location
                       where this RE matches.
`findall()'            Find all substrings where the RE matches, and
                       returns them as a list.
`finditer()'           Find all substrings where the RE matches, and
                       returns them as an *note iterator: 869.

  `match()' and `search()' return `None' if no match can be found.  If
they're successful, a *note match object: 9c8. instance is returned,
containing information about the match: where it starts and ends, the
substring it matched, and more.

  You can learn about this by interactively experimenting with the
*note re: 143.  module.  If you have Tkinter available, you may also
want to look at Tools/scripts/redemo.py(1), a demonstration program
included with the Python distribution.  It allows you to enter REs and
strings, and displays whether the RE matches or fails. `redemo.py' can
be quite useful when trying to debug a complicated RE.  Phil Schwartz's
Kodos(2) is also an interactive tool for developing and testing RE
patterns.

  This HOWTO uses the standard Python interpreter for its examples.
First, run the Python interpreter, import the *note re: 143. module,
and compile a RE:

    Python 2.2.2 (#1, Feb 10 2003, 12:57:01)
    >>> import re
    >>> p = re.compile('[a-z]+')
    >>> p  #doctest: +ELLIPSIS
    <_sre.SRE_Pattern object at 0x...>

Now, you can try matching various strings against the RE `[a-z]+'.  An
empty string shouldn't match at all, since `+' means 'one or more
repetitions'.  `match()' should return `None' in this case, which will
cause the interpreter to print no output.  You can explicitly print the
result of `match()' to make this clear.

    >>> p.match("")
    >>> print p.match("")
    None

Now, let's try it on a string that it should match, such as `tempo'.
In this case, `match()' will return a *note match object: 9c8, so you
should store the result in a variable for later use.

    >>> m = p.match('tempo')
    >>> m  #doctest: +ELLIPSIS
    <_sre.SRE_Match object at 0x...>

Now you can query the *note match object: 9c8. for information about
the matching string.  *note match object: 9c8. instances also have
several methods and attributes; the most important ones are:

Method/Attribute       Purpose
------------------------------------------------------------------------ 
`group()'              Return the string matched by the RE
`start()'              Return the starting position of the match
`end()'                Return the ending position of the match
`span()'               Return a tuple containing the (start, end)
                       positions  of the match

  Trying these methods will soon clarify their meaning:

    >>> m.group()
    'tempo'
    >>> m.start(), m.end()
    (0, 5)
    >>> m.span()
    (0, 5)

`group()' returns the substring that was matched by the RE.  `start()'
and `end()' return the starting and ending index of the match. `span()'
returns both start and end indexes in a single tuple.  Since the
`match()' method only checks if the RE matches at the start of a
string, `start()' will always be zero.  However, the `search()' method
of patterns scans through the string, so  the match may not start at
zero in that case.

    >>> print p.match('::: message')
    None
    >>> m = p.search('::: message'); print m  #doctest: +ELLIPSIS
    <_sre.SRE_Match object at 0x...>
    >>> m.group()
    'message'
    >>> m.span()
    (4, 11)

In actual programs, the most common style is to store the *note match
object: 9c8. in a variable, and then check if it was `None'.  This
usually looks like:

    p = re.compile( ... )
    m = p.match( 'string goes here' )
    if m:
        print 'Match found: ', m.group()
    else:
        print 'No match'

Two pattern methods return all of the matches for a pattern.
`findall()' returns a list of matching strings:

    >>> p = re.compile('\d+')
    >>> p.findall('12 drummers drumming, 11 pipers piping, 10 lords a-leaping')
    ['12', '11', '10']

`findall()' has to create the entire list before it can be returned as
the result.  The `finditer()' method returns a sequence of *note match
object: 9c8. instances as an *note iterator: 869. (3)

    >>> iterator = p.finditer('12 drummers drumming, 11 ... 10 ...')
    >>> iterator  #doctest: +ELLIPSIS
    <callable-iterator object at 0x...>
    >>> for match in iterator:
    ...     print match.span()
    ...
    (0, 2)
    (22, 24)
    (29, 31)


  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Tools/scripts/redemo.py

  (2) http://kodos.sourceforge.net/

  (3) Introduced in Python 2.2.2.


File: python.info,  Node: Module-Level Functions<2>,  Next: Compilation Flags,  Prev: Performing Matches,  Up: Using Regular Expressions

10.9.3.4 Module-Level Functions
...............................

You don't have to create a pattern object and call its methods; the
*note re: 143. module also provides top-level functions called
`match()', `search()', `findall()', `sub()', and so forth.  These
functions take the same arguments as the corresponding pattern method,
with the RE string added as the first argument, and still return either
`None' or a *note match object: 9c8. instance.

    >>> print re.match(r'From\s+', 'Fromage amk')
    None
    >>> re.match(r'From\s+', 'From amk Thu May 14 19:12:10 1998')  #doctest: +ELLIPSIS
    <_sre.SRE_Match object at 0x...>

Under the hood, these functions simply create a pattern object for you
and call the appropriate method on it.  They also store the compiled
object in a cache, so future calls using the same RE are faster.

  Should you use these module-level functions, or should you get the
pattern and call its methods yourself?  That choice depends on how
frequently the RE will be used, and on your personal coding style.  If
the RE is being used at only one point in the code, then the module
functions are probably more convenient.  If a program contains a lot of
regular expressions, or re-uses the same ones in several locations,
then it might be worthwhile to collect all the definitions in one
place, in a section of code that compiles all the REs ahead of time.
To take an example from the standard library, here's an extract from
the deprecated `xmllib' module:

    ref = re.compile( ... )
    entityref = re.compile( ... )
    charref = re.compile( ... )
    starttagopen = re.compile( ... )

I generally prefer to work with the compiled object, even for one-time
uses, but few people will be as much of a purist about this as I am.


File: python.info,  Node: Compilation Flags,  Prev: Module-Level Functions<2>,  Up: Using Regular Expressions

10.9.3.5 Compilation Flags
..........................

Compilation flags let you modify some aspects of how regular
expressions work.  Flags are available in the *note re: 143. module
under two names, a long name such as `IGNORECASE' and a short,
one-letter form such as `I'.  (If you're familiar with Perl's pattern
modifiers, the one-letter forms use the same letters; the short form of
*note re.VERBOSE: 9b4. is *note re.X: 9ac, for example.)  Multiple
flags can be specified by bitwise OR-ing them; `re.I | re.M' sets both
the `I' and `M' flags, for example.

  Here's a table of the available flags, followed by a more detailed
explanation of each one.

Flag                                  Meaning
--------------------------------------------------------------------------------------- 
`DOTALL', `S'                         Make `.' match any character, including newlines
`IGNORECASE', `I'                     Do case-insensitive matches
`LOCALE', `L'                         Do a locale-aware match
`MULTILINE', `M'                      Multi-line matching, affecting `^' and `$'
`VERBOSE', `X'                        Enable verbose REs, which can be organized more
                                      cleanly and understandably.
`UNICODE', `U'                        Makes several escapes like `\w', `\b', `\s' and
                                      `\d' dependent on the Unicode character
                                      database.

 -- Data: I
 -- Data: IGNORECASE
     Perform case-insensitive matching; character class and literal
     strings will match letters by ignoring case.  For example, `[A-Z]'
     will match lowercase letters, too, and `Spam' will match `Spam',
     `spam', or `spAM'. This lowercasing doesn't take the current
     locale into account; it will if you also set the `LOCALE' flag.

 -- Data: L
 -- Data: LOCALE
     Make `\w', `\W', `\b', and `\B', dependent on the current locale.

     Locales are a feature of the C library intended to help in writing
     programs that take account of language differences.  For example,
     if you're processing French text, you'd want to be able to write
     `\w+' to match words, but `\w' only matches the character class
     `[A-Za-z]'; it won't match `''' or `'''.  If your system is
     configured properly and a French locale is selected, certain C
     functions will tell the program that `''' should also be
     considered a letter.  Setting the `LOCALE' flag when compiling a
     regular expression will cause the resulting compiled object to use
     these C functions for `\w'; this is slower, but also enables `\w+'
     to match French words as you'd expect.

 -- Data: M
 -- Data: MULTILINE
     (`^' and `$' haven't been explained yet;  they'll be introduced in
     section *note More Metacharacters: 302f.)

     Usually `^' matches only at the beginning of the string, and `$'
     matches only at the end of the string and immediately before the
     newline (if any) at the end of the string. When this flag is
     specified, `^' matches at the beginning of the string and at the
     beginning of each line within the string, immediately following
     each newline.  Similarly, the `$' metacharacter matches either at
     the end of the string and at the end of each line (immediately
     preceding each newline).

 -- Data: S
 -- Data: DOTALL
     Makes the `'.'' special character match any character at all,
     including a newline; without this flag, `'.'' will match anything
     _except_ a newline.

 -- Data: U
 -- Data: UNICODE
     Make `\w', `\W', `\b', `\B', `\d', `\D', `\s' and `\S' dependent
     on the Unicode character properties database.

 -- Data: X
 -- Data: VERBOSE
     This flag allows you to write regular expressions that are more
     readable by granting you more flexibility in how you can format
     them.  When this flag has been specified, whitespace within the RE
     string is ignored, except when the whitespace is in a character
     class or preceded by an unescaped backslash; this lets you
     organize and indent the RE more clearly.  This flag also lets you
     put comments within a RE that will be ignored by the engine;
     comments are marked by a `'#'' that's neither in a character class
     or preceded by an unescaped backslash.

     For example, here's a RE that uses *note re.VERBOSE: 9b4.; see how
     much easier it is to read?

         charref = re.compile(r"""
          &[#]                # Start of a numeric entity reference
          (
              0[0-7]+         # Octal form
            | [0-9]+          # Decimal form
            | x[0-9a-fA-F]+   # Hexadecimal form
          )
          ;                   # Trailing semicolon
         """, re.VERBOSE)

     Without the verbose setting, the RE would look like this:

         charref = re.compile("&#(0[0-7]+"
                              "|[0-9]+"
                              "|x[0-9a-fA-F]+);")

     In the above example, Python's automatic concatenation of string
     literals has been used to break up the RE into smaller pieces, but
     it's still more difficult to understand than the version using
     *note re.VERBOSE: 9b4.


File: python.info,  Node: More Pattern Power,  Next: Modifying Strings,  Prev: Using Regular Expressions,  Up: Regular Expression HOWTO

10.9.4 More Pattern Power
-------------------------

So far we've only covered a part of the features of regular
expressions.  In this section, we'll cover some new metacharacters, and
how to use groups to retrieve portions of the text that was matched.

* Menu:

* More Metacharacters::
* Grouping::
* Non-capturing and Named Groups::
* Lookahead Assertions::


File: python.info,  Node: More Metacharacters,  Next: Grouping,  Up: More Pattern Power

10.9.4.1 More Metacharacters
............................

There are some metacharacters that we haven't covered yet.  Most of
them will be covered in this section.

  Some of the remaining metacharacters to be discussed are _zero-width
assertions_.  They don't cause the engine to advance through the string;
instead, they consume no characters at all, and simply succeed or fail.
For example, `\b' is an assertion that the current position is located
at a word boundary; the position isn't changed by the `\b' at all.
This means that zero-width assertions should never be repeated, because
if they match once at a given location, they can obviously be matched
an infinite number of times.

`|'
     Alternation, or the "or" operator.   If A and B are regular
     expressions, `A|B' will match any string that matches either `A'
     or `B'. `|' has very low precedence in order to make it work
     reasonably when you're alternating multi-character strings.
     `Crow|Servo' will match either `Crow' or `Servo', not `Cro', a
     `'w'' or an `'S'', and `ervo'.

     To match a literal `'|'', use `\|', or enclose it inside a
     character class, as in `[|]'.

`^'
     Matches at the beginning of lines.  Unless the `MULTILINE' flag
     has been set, this will only match at the beginning of the string.
     In `MULTILINE' mode, this also matches immediately after each
     newline within the string.

     For example, if you wish to match the word `From' only at the
     beginning of a line, the RE to use is `^From'.

         >>> print re.search('^From', 'From Here to Eternity')  #doctest: +ELLIPSIS
         <_sre.SRE_Match object at 0x...>
         >>> print re.search('^From', 'Reciting From Memory')
         None


`$'
     Matches at the end of a line, which is defined as either the end
     of the string, or any location followed by a newline character.

         >>> print re.search('}$', '{block}')  #doctest: +ELLIPSIS
         <_sre.SRE_Match object at 0x...>
         >>> print re.search('}$', '{block} ')
         None
         >>> print re.search('}$', '{block}\n')  #doctest: +ELLIPSIS
         <_sre.SRE_Match object at 0x...>

     To match a literal `'$'', use `\$' or enclose it inside a
     character class, as in  `[$]'.

`\A'
     Matches only at the start of the string.  When not in `MULTILINE'
     mode, `\A' and `^' are effectively the same.  In `MULTILINE' mode,
     they're different: `\A' still matches only at the beginning of the
     string, but `^' may match at any location inside the string that
     follows a newline character.

`\Z'
     Matches only at the end of the string.

`\b'
     Word boundary.  This is a zero-width assertion that matches only
     at the beginning or end of a word.  A word is defined as a
     sequence of alphanumeric characters, so the end of a word is
     indicated by whitespace or a non-alphanumeric character.

     The following example matches `class' only when it's a complete
     word; it won't match when it's contained inside another word.

         >>> p = re.compile(r'\bclass\b')
         >>> print p.search('no class at all')  #doctest: +ELLIPSIS
         <_sre.SRE_Match object at 0x...>
         >>> print p.search('the declassified algorithm')
         None
         >>> print p.search('one subclass is')
         None

     There are two subtleties you should remember when using this
     special sequence.  First, this is the worst collision between
     Python's string literals and regular expression sequences.  In
     Python's string literals, `\b' is the backspace character, ASCII
     value 8.  If you're not using raw strings, then Python will
     convert the `\b' to a backspace, and your RE won't match as you
     expect it to.  The following example looks the same as our
     previous RE, but omits the `'r'' in front of the RE string.

         >>> p = re.compile('\bclass\b')
         >>> print p.search('no class at all')
         None
         >>> print p.search('\b' + 'class' + '\b')  #doctest: +ELLIPSIS
         <_sre.SRE_Match object at 0x...>

     Second, inside a character class, where there's no use for this
     assertion, `\b' represents the backspace character, for
     compatibility with Python's string literals.

`\B'
     Another zero-width assertion, this is the opposite of `\b', only
     matching when the current position is not at a word boundary.


File: python.info,  Node: Grouping,  Next: Non-capturing and Named Groups,  Prev: More Metacharacters,  Up: More Pattern Power

10.9.4.2 Grouping
.................

Frequently you need to obtain more information than just whether the RE
matched or not.  Regular expressions are often used to dissect strings
by writing a RE divided into several subgroups which match different
components of interest.  For example, an RFC-822 header line is divided
into a header name and a value, separated by a `':'', like this:

    From: author@example.com
    User-Agent: Thunderbird 1.5.0.9 (X11/20061227)
    MIME-Version: 1.0
    To: editor@example.com

This can be handled by writing a regular expression which matches an
entire header line, and has one group which matches the header name,
and another group which matches the header's value.

  Groups are marked by the `'('', `')'' metacharacters. `'('' and `')''
have much the same meaning as they do in mathematical expressions; they
group together the expressions contained inside them, and you can
repeat the contents of a group with a repeating qualifier, such as `*',
`+', `?', or `{m,n}'.  For example, `(ab)*' will match zero or more
repetitions of `ab'.

    >>> p = re.compile('(ab)*')
    >>> print p.match('ababababab').span()
    (0, 10)

Groups indicated with `'('', `')'' also capture the starting and ending
index of the text that they match; this can be retrieved by passing an
argument to `group()', `start()', `end()', and `span()'.  Groups are
numbered starting with 0.  Group 0 is always present; it's the whole
RE, so *note match object: 9c8. methods all have group 0 as their
default argument.  Later we'll see how to express groups that don't
capture the span of text that they match.

    >>> p = re.compile('(a)b')
    >>> m = p.match('ab')
    >>> m.group()
    'ab'
    >>> m.group(0)
    'ab'

Subgroups are numbered from left to right, from 1 upward.  Groups can
be nested; to determine the number, just count the opening parenthesis
characters, going from left to right.

    >>> p = re.compile('(a(b)c)d')
    >>> m = p.match('abcd')
    >>> m.group(0)
    'abcd'
    >>> m.group(1)
    'abc'
    >>> m.group(2)
    'b'

`group()' can be passed multiple group numbers at a time, in which case
it will return a tuple containing the corresponding values for those
groups.

    >>> m.group(2,1,2)
    ('b', 'abc', 'b')

The `groups()' method returns a tuple containing the strings for all the
subgroups, from 1 up to however many there are.

    >>> m.groups()
    ('abc', 'b')

Backreferences in a pattern allow you to specify that the contents of
an earlier capturing group must also be found at the current location
in the string.  For example, `\1' will succeed if the exact contents of
group 1 can be found at the current position, and fails otherwise.
Remember that Python's string literals also use a backslash followed by
numbers to allow including arbitrary characters in a string, so be sure
to use a raw string when incorporating backreferences in a RE.

  For example, the following RE detects doubled words in a string.

    >>> p = re.compile(r'(\b\w+)\s+\1')
    >>> p.search('Paris in the the spring').group()
    'the the'

Backreferences like this aren't often useful for just searching through
a string -- there are few text formats which repeat data in this way --
but you'll soon find out that they're _very_ useful when performing
string substitutions.


File: python.info,  Node: Non-capturing and Named Groups,  Next: Lookahead Assertions,  Prev: Grouping,  Up: More Pattern Power

10.9.4.3 Non-capturing and Named Groups
.......................................

Elaborate REs may use many groups, both to capture substrings of
interest, and to group and structure the RE itself.  In complex REs, it
becomes difficult to keep track of the group numbers.  There are two
features which help with this problem.  Both of them use a common
syntax for regular expression extensions, so we'll look at that first.

  Perl 5 added several additional features to standard regular
expressions, and the Python *note re: 143. module supports most of
them.   It would have been difficult to choose new single-keystroke
metacharacters or new special sequences beginning with `\' to represent
the new features without making Perl's regular expressions confusingly
different from standard REs.  If you chose `&' as a new metacharacter,
for example, old expressions would be assuming that `&' was a regular
character and wouldn't have escaped it by writing `\&' or `[&]'.

  The solution chosen by the Perl developers was to use `(?...)' as the
extension syntax.  `?' immediately after a parenthesis was a syntax
error because the `?' would have nothing to repeat, so this didn't
introduce any compatibility problems.  The characters immediately after
the `?'  indicate what extension is being used, so `(?=foo)' is one
thing (a positive lookahead assertion) and `(?:foo)' is something else
(a non-capturing group containing the subexpression `foo').

  Python adds an extension syntax to Perl's extension syntax.  If the
first character after the question mark is a `P', you know that it's an
extension that's specific to Python.  Currently there are two such
extensions: `(?P<name>...)' defines a named group, and `(?P=name)' is a
backreference to a named group.  If future versions of Perl 5 add
similar features using a different syntax, the *note re: 143. module
will be changed to support the new syntax, while preserving the
Python-specific syntax for compatibility's sake.

  Now that we've looked at the general extension syntax, we can return
to the features that simplify working with groups in complex REs. Since
groups are numbered from left to right and a complex expression may use
many groups, it can become difficult to keep track of the correct
numbering.  Modifying such a complex RE is annoying, too: insert a new
group near the beginning and you change the numbers of everything that
follows it.

  Sometimes you'll want to use a group to collect a part of a regular
expression, but aren't interested in retrieving the group's contents.
You can make this fact explicit by using a non-capturing group:
`(?:...)', where you can replace the `...' with any other regular
expression.

    >>> m = re.match("([abc])+", "abc")
    >>> m.groups()
    ('c',)
    >>> m = re.match("(?:[abc])+", "abc")
    >>> m.groups()
    ()

Except for the fact that you can't retrieve the contents of what the
group matched, a non-capturing group behaves exactly the same as a
capturing group; you can put anything inside it, repeat it with a
repetition metacharacter such as `*', and nest it within other groups
(capturing or non-capturing).  `(?:...)' is particularly useful when
modifying an existing pattern, since you can add new groups without
changing how all the other groups are numbered.  It should be mentioned
that there's no performance difference in searching between capturing
and non-capturing groups; neither form is any faster than the other.

  A more significant feature is named groups: instead of referring to
them by numbers, groups can be referenced by a name.

  The syntax for a named group is one of the Python-specific extensions:
`(?P<name>...)'.  _name_ is, obviously, the name of the group.  Named
groups also behave exactly like capturing groups, and additionally
associate a name with a group.  The *note match object: 9c8. methods
that deal with capturing groups all accept either integers that refer
to the group by number or strings that contain the desired group's
name.  Named groups are still given numbers, so you can retrieve
information about a group in two ways:

    >>> p = re.compile(r'(?P<word>\b\w+\b)')
    >>> m = p.search( '(((( Lots of punctuation )))' )
    >>> m.group('word')
    'Lots'
    >>> m.group(1)
    'Lots'

Named groups are handy because they let you use easily-remembered
names, instead of having to remember numbers.  Here's an example RE
from the *note imaplib: f2.  module:

    InternalDate = re.compile(r'INTERNALDATE "'
            r'(?P<day>[ 123][0-9])-(?P<mon>[A-Z][a-z][a-z])-'
            r'(?P<year>[0-9][0-9][0-9][0-9])'
            r' (?P<hour>[0-9][0-9]):(?P<min>[0-9][0-9]):(?P<sec>[0-9][0-9])'
            r' (?P<zonen>[-+])(?P<zoneh>[0-9][0-9])(?P<zonem>[0-9][0-9])'
            r'"')

It's obviously much easier to retrieve `m.group('zonem')', instead of
having to remember to retrieve group 9.

  The syntax for backreferences in an expression such as `(...)\1'
refers to the number of the group.  There's naturally a variant that
uses the group name instead of the number. This is another Python
extension: `(?P=name)' indicates that the contents of the group called
_name_ should again be matched at the current point.  The regular
expression for finding doubled words, `(\b\w+)\s+\1' can also be
written as `(?P<word>\b\w+)\s+(?P=word)':

    >>> p = re.compile(r'(?P<word>\b\w+)\s+(?P=word)')
    >>> p.search('Paris in the the spring').group()
    'the the'



File: python.info,  Node: Lookahead Assertions,  Prev: Non-capturing and Named Groups,  Up: More Pattern Power

10.9.4.4 Lookahead Assertions
.............................

Another zero-width assertion is the lookahead assertion.  Lookahead
assertions are available in both positive and negative form, and  look
like this:

`(?=...)'
     Positive lookahead assertion.  This succeeds if the contained
     regular expression, represented here by `...', successfully
     matches at the current location, and fails otherwise. But, once
     the contained expression has been tried, the matching engine
     doesn't advance at all; the rest of the pattern is tried right
     where the assertion started.

`(?!...)'
     Negative lookahead assertion.  This is the opposite of the
     positive assertion; it succeeds if the contained expression
     _doesn't_ match at the current position in the string.

  To make this concrete, let's look at a case where a lookahead is
useful.  Consider a simple pattern to match a filename and split it
apart into a base name and an extension, separated by a `.'.  For
example, in `news.rc', `news' is the base name, and `rc' is the
filename's extension.

  The pattern to match this is quite simple:

  `.*[.].*$'

  Notice that the `.' needs to be treated specially because it's a
metacharacter; I've put it inside a character class.  Also notice the
trailing `$'; this is added to ensure that all the rest of the string
must be included in the extension.  This regular expression matches
`foo.bar' and `autoexec.bat' and `sendmail.cf' and `printers.conf'.

  Now, consider complicating the problem a bit; what if you want to
match filenames where the extension is not `bat'? Some incorrect
attempts:

  `.*[.][^b].*$'  The first attempt above tries to exclude `bat' by
requiring that the first character of the extension is not a `b'.  This
is wrong, because the pattern also doesn't match `foo.bar'.

  `.*[.]([^b]..|.[^a].|..[^t])$'

  The expression gets messier when you try to patch up the first
solution by requiring one of the following cases to match: the first
character of the extension isn't `b'; the second character isn't `a';
or the third character isn't `t'.  This accepts `foo.bar' and rejects
`autoexec.bat', but it requires a three-letter extension and won't
accept a filename with a two-letter extension such as `sendmail.cf'.
We'll complicate the pattern again in an effort to fix it.

  `.*[.]([^b].?.?|.[^a]?.?|..?[^t]?)$'

  In the third attempt, the second and third letters are all made
optional in order to allow matching extensions shorter than three
characters, such as `sendmail.cf'.

  The pattern's getting really complicated now, which makes it hard to
read and understand.  Worse, if the problem changes and you want to
exclude both `bat' and `exe' as extensions, the pattern would get even
more complicated and confusing.

  A negative lookahead cuts through all this confusion:

  `.*[.](?!bat$).*$'  The negative lookahead means: if the expression
`bat' doesn't match at this point, try the rest of the pattern; if
`bat$' does match, the whole pattern will fail.  The trailing `$' is
required to ensure that something like `sample.batch', where the
extension only starts with `bat', will be allowed.

  Excluding another filename extension is now easy; simply add it as an
alternative inside the assertion.  The following pattern excludes
filenames that end in either `bat' or `exe':

  `.*[.](?!bat$|exe$).*$'


File: python.info,  Node: Modifying Strings,  Next: Common Problems,  Prev: More Pattern Power,  Up: Regular Expression HOWTO

10.9.5 Modifying Strings
------------------------

Up to this point, we've simply performed searches against a static
string.  Regular expressions are also commonly used to modify strings
in various ways, using the following pattern methods:

Method/Attribute       Purpose
--------------------------------------------------------------------------- 
`split()'              Split the string into a list, splitting it
                       wherever the RE matches
`sub()'                Find all substrings where the RE matches, and
                       replace them with a different string
`subn()'               Does the same thing as `sub()',  but returns the
                       new string and the number of replacements

* Menu:

* Splitting Strings::
* Search and Replace::


File: python.info,  Node: Splitting Strings,  Next: Search and Replace,  Up: Modifying Strings

10.9.5.1 Splitting Strings
..........................

The `split()' method of a pattern splits a string apart wherever the RE
matches, returning a list of the pieces. It's similar to the `split()'
method of strings but provides much more generality in the delimiters
that you can split by; `split()' only supports splitting by whitespace
or by a fixed string.  As you'd expect, there's a module-level *note
re.split(): 244. function, too.

 -- Method: .split (string[, maxsplit=0])
     Split _string_ by the matches of the regular expression.  If
     capturing parentheses are used in the RE, then their contents will
     also be returned as part of the resulting list.  If _maxsplit_ is
     nonzero, at most _maxsplit_ splits are performed.

  You can limit the number of splits made, by passing a value for
_maxsplit_.  When _maxsplit_ is nonzero, at most _maxsplit_ splits will
be made, and the remainder of the string is returned as the final
element of the list.  In the following example, the delimiter is any
sequence of non-alphanumeric characters.

    >>> p = re.compile(r'\W+')
    >>> p.split('This is a test, short and sweet, of split().')
    ['This', 'is', 'a', 'test', 'short', 'and', 'sweet', 'of', 'split', '']
    >>> p.split('This is a test, short and sweet, of split().', 3)
    ['This', 'is', 'a', 'test, short and sweet, of split().']

Sometimes you're not only interested in what the text between
delimiters is, but also need to know what the delimiter was.  If
capturing parentheses are used in the RE, then their values are also
returned as part of the list.  Compare the following calls:

    >>> p = re.compile(r'\W+')
    >>> p2 = re.compile(r'(\W+)')
    >>> p.split('This... is a test.')
    ['This', 'is', 'a', 'test', '']
    >>> p2.split('This... is a test.')
    ['This', '... ', 'is', ' ', 'a', ' ', 'test', '.', '']

The module-level function *note re.split(): 244. adds the RE to be used
as the first argument, but is otherwise the same.

    >>> re.split('[\W]+', 'Words, words, words.')
    ['Words', 'words', 'words', '']
    >>> re.split('([\W]+)', 'Words, words, words.')
    ['Words', ', ', 'words', ', ', 'words', '.', '']
    >>> re.split('[\W]+', 'Words, words, words.', 1)
    ['Words', 'words, words.']



File: python.info,  Node: Search and Replace,  Prev: Splitting Strings,  Up: Modifying Strings

10.9.5.2 Search and Replace
...........................

Another common task is to find all the matches for a pattern, and
replace them with a different string.  The `sub()' method takes a
replacement value, which can be either a string or a function, and the
string to be processed.

 -- Method: .sub (replacement, string[, count=0])
     Returns the string obtained by replacing the leftmost
     non-overlapping occurrences of the RE in _string_ by the
     replacement _replacement_.  If the pattern isn't found, _string_
     is returned unchanged.

     The optional argument _count_ is the maximum number of pattern
     occurrences to be replaced; _count_ must be a non-negative
     integer.  The default value of 0 means to replace all occurrences.

  Here's a simple example of using the `sub()' method.  It replaces
colour names with the word `colour':

    >>> p = re.compile( '(blue|white|red)')
    >>> p.sub( 'colour', 'blue socks and red shoes')
    'colour socks and colour shoes'
    >>> p.sub( 'colour', 'blue socks and red shoes', count=1)
    'colour socks and red shoes'

The `subn()' method does the same work, but returns a 2-tuple
containing the new string value and the number of replacements  that
were performed:

    >>> p = re.compile( '(blue|white|red)')
    >>> p.subn( 'colour', 'blue socks and red shoes')
    ('colour socks and colour shoes', 2)
    >>> p.subn( 'colour', 'no colours at all')
    ('no colours at all', 0)

Empty matches are replaced only when they're not adjacent to a previous
match.

    >>> p = re.compile('x*')
    >>> p.sub('-', 'abxd')
    '-a-b-d-'

If _replacement_ is a string, any backslash escapes in it are
processed.  That is, `\n' is converted to a single newline character,
`\r' is converted to a carriage return, and so forth. Unknown escapes
such as `\j' are left alone.  Backreferences, such as `\6', are
replaced with the substring matched by the corresponding group in the
RE.  This lets you incorporate portions of the original text in the
resulting replacement string.

  This example matches the word `section' followed by a string enclosed
in `{', `}', and changes `section' to `subsection':

    >>> p = re.compile('section{ ( [^}]* ) }', re.VERBOSE)
    >>> p.sub(r'subsection{\1}','section{First} section{second}')
    'subsection{First} subsection{second}'

There's also a syntax for referring to named groups as defined by the
`(?P<name>...)' syntax.  `\g<name>' will use the substring matched by
the group named `name', and  `\g<number>'  uses the corresponding group
number.  `\g<2>' is therefore equivalent to `\2',  but isn't ambiguous
in a replacement string such as `\g<2>0'.  (`\20' would be interpreted
as a reference to group 20, not a reference to group 2 followed by the
literal character `'0''.)  The following substitutions are all
equivalent, but use all three variations of the replacement string.

    >>> p = re.compile('section{ (?P<name> [^}]* ) }', re.VERBOSE)
    >>> p.sub(r'subsection{\1}','section{First}')
    'subsection{First}'
    >>> p.sub(r'subsection{\g<1>}','section{First}')
    'subsection{First}'
    >>> p.sub(r'subsection{\g<name>}','section{First}')
    'subsection{First}'

_replacement_ can also be a function, which gives you even more
control.  If _replacement_ is a function, the function is called for
every non-overlapping occurrence of _pattern_.  On each call, the
function is passed a *note match object: 9c8. argument for the match
and can use this information to compute the desired replacement string
and return it.

  In the following example, the replacement function translates
decimals into hexadecimal:

    >>> def hexrepl(match):
    ...     "Return the hex string for a decimal number"
    ...     value = int(match.group())
    ...     return hex(value)
    ...
    >>> p = re.compile(r'\d+')
    >>> p.sub(hexrepl, 'Call 65490 for printing, 49152 for user code.')
    'Call 0xffd2 for printing, 0xc000 for user code.'

When using the module-level *note re.sub(): 245. function, the pattern
is passed as the first argument.  The pattern may be provided as an
object or as a string; if you need to specify regular expression flags,
you must either use a pattern object as the first parameter, or use
embedded modifiers in the pattern string, e.g. `sub("(?i)b+", "x",
"bbbb BBBB")' returns `'x x''.


File: python.info,  Node: Common Problems,  Next: Feedback,  Prev: Modifying Strings,  Up: Regular Expression HOWTO

10.9.6 Common Problems
----------------------

Regular expressions are a powerful tool for some applications, but in
some ways their behaviour isn't intuitive and at times they don't
behave the way you may expect them to.  This section will point out
some of the most common pitfalls.

* Menu:

* Use String Methods::
* match() versus search(): match versus search.
* Greedy versus Non-Greedy::
* Using re.VERBOSE: Using re VERBOSE.


File: python.info,  Node: Use String Methods,  Next: match versus search,  Up: Common Problems

10.9.6.1 Use String Methods
...........................

Sometimes using the *note re: 143. module is a mistake.  If you're
matching a fixed string, or a single character class, and you're not
using any *note re: 143. features such as the `IGNORECASE' flag, then
the full power of regular expressions may not be required. Strings have
several methods for performing operations with fixed strings and
they're usually much faster, because the implementation is a single
small C loop that's been optimized for the purpose, instead of the
large, more generalized regular expression engine.

  One example might be replacing a single fixed string with another
one; for example, you might replace `word' with `deed'.  `re.sub()'
seems like the function to use for this, but consider the `replace()'
method.  Note that `replace()' will also replace `word' inside words,
turning `swordfish' into `sdeedfish', but the  naive RE `word' would
have done that, too.  (To avoid performing the substitution on parts of
words, the pattern would have to be `\bword\b', in order to require
that `word' have a word boundary on either side.  This takes the job
beyond  `replace()''s abilities.)

  Another common task is deleting every occurrence of a single
character from a string or replacing it with another single character.
You might do this with something like `re.sub('\n', ' ', S)', but
`translate()' is capable of doing both tasks and will be faster than
any regular expression operation can be.

  In short, before turning to the *note re: 143. module, consider
whether your problem can be solved with a faster and simpler string
method.


File: python.info,  Node: match versus search,  Next: Greedy versus Non-Greedy,  Prev: Use String Methods,  Up: Common Problems

10.9.6.2 match() versus search()
................................

The `match()' function only checks if the RE matches at the beginning
of the string while `search()' will scan forward through the string for
a match.  It's important to keep this distinction in mind.  Remember,
`match()' will only report a successful match which will start at 0; if
the match wouldn't start at zero,  `match()' will _not_ report it.

    >>> print re.match('super', 'superstition').span()
    (0, 5)
    >>> print re.match('super', 'insuperable')
    None

On the other hand, `search()' will scan forward through the string,
reporting the first match it finds.

    >>> print re.search('super', 'superstition').span()
    (0, 5)
    >>> print re.search('super', 'insuperable').span()
    (2, 7)

Sometimes you'll be tempted to keep using *note re.match(): 9b0, and
just add `.*' to the front of your RE.  Resist this temptation and use
*note re.search(): 9af.  instead.  The regular expression compiler does
some analysis of REs in order to speed up the process of looking for a
match.  One such analysis figures out what the first character of a
match must be; for example, a pattern starting with `Crow' must match
starting with a `'C''.  The analysis lets the engine quickly scan
through the string looking for the starting character, only trying the
full match if a `'C'' is found.

  Adding `.*' defeats this optimization, requiring scanning to the end
of the string and then backtracking to find a match for the rest of the
RE.  Use *note re.search(): 9af. instead.


File: python.info,  Node: Greedy versus Non-Greedy,  Next: Using re VERBOSE,  Prev: match versus search,  Up: Common Problems

10.9.6.3 Greedy versus Non-Greedy
.................................

When repeating a regular expression, as in `a*', the resulting action
is to consume as much of the pattern as possible.  This fact often
bites you when you're trying to match a pair of balanced delimiters,
such as the angle brackets surrounding an HTML tag.  The naive pattern
for matching a single HTML tag doesn't work because of the greedy
nature of `.*'.

    >>> s = '<html><head><title>Title</title>'
    >>> len(s)
    32
    >>> print re.match('<.*>', s).span()
    (0, 32)
    >>> print re.match('<.*>', s).group()
    <html><head><title>Title</title>

The RE matches the `'<'' in `<html>', and the `.*' consumes the rest of
the string.  There's still more left in the RE, though, and the `>'
can't match at the end of the string, so the regular expression engine
has to backtrack character by character until it finds a match for the
`>'.   The final match extends from the `'<'' in `<html>' to the `'>''
in `</title>', which isn't what you want.

  In this case, the solution is to use the non-greedy qualifiers `*?',
`+?', `??', or `{m,n}?', which match as _little_ text as possible.  In
the above example, the `'>'' is tried immediately after the first `'<''
matches, and when it fails, the engine advances a character at a time,
retrying the `'>'' at every step.  This produces just the right result:

    >>> print re.match('<.*?>', s).group()
    <html>

(Note that parsing HTML or XML with regular expressions is painful.
Quick-and-dirty patterns will handle common cases, but HTML and XML
have special cases that will break the obvious regular expression; by
the time you've written a regular expression that handles all of the
possible cases, the patterns will be _very_ complicated.  Use an HTML
or XML parser module for such tasks.)


File: python.info,  Node: Using re VERBOSE,  Prev: Greedy versus Non-Greedy,  Up: Common Problems

10.9.6.4 Using re.VERBOSE
.........................

By now you've probably noticed that regular expressions are a very
compact notation, but they're not terribly readable.  REs of moderate
complexity can become lengthy collections of backslashes, parentheses,
and metacharacters, making them difficult to read and understand.

  For such REs, specifying the `re.VERBOSE' flag when compiling the
regular expression can be helpful, because it allows you to format the
regular expression more clearly.

  The `re.VERBOSE' flag has several effects.  Whitespace in the regular
expression that _isn't_ inside a character class is ignored.  This
means that an expression such as `dog | cat' is equivalent to the less
readable `dog|cat', but `[a b]' will still match the characters `'a'',
`'b'', or a space.  In addition, you can also put comments inside a RE;
comments extend from a `#' character to the next newline.  When used
with triple-quoted strings, this enables REs to be formatted more
neatly:

    pat = re.compile(r"""
     \s*                 # Skip leading whitespace
     (?P<header>[^:]+)   # Header name
     \s* :               # Whitespace, and a colon
     (?P<value>.*?)      # The header's value -- *? used to
                         # lose the following trailing whitespace
     \s*$                # Trailing whitespace to end-of-line
    """, re.VERBOSE)

This is far more readable than:

    pat = re.compile(r"\s*(?P<header>[^:]+)\s*:(?P<value>.*?)\s*$")



File: python.info,  Node: Feedback,  Prev: Common Problems,  Up: Regular Expression HOWTO

10.9.7 Feedback
---------------

Regular expressions are a complicated topic.  Did this document help you
understand them?  Were there parts that were unclear, or Problems you
encountered that weren't covered here?  If so, please send suggestions
for improvements to the author.

  The most complete book on regular expressions is almost certainly
Jeffrey Friedl's Mastering Regular Expressions, published by O'Reilly.
Unfortunately, it exclusively concentrates on Perl and Java's flavours
of regular expressions, and doesn't contain any Python material at all,
so it won't be useful as a reference for programming in Python.  (The
first edition covered Python's now-removed `regex' module, which won't
help you much.)  Consider checking it out from your library.


File: python.info,  Node: Socket Programming HOWTO,  Next: Sorting HOW TO,  Prev: Regular Expression HOWTO,  Up: Python HOWTOs

10.10 Socket Programming HOWTO
==============================

     Author: Gordon McMillan

Abstract
........

Sockets are used nearly everywhere, but are one of the most severely
misunderstood technologies around. This is a 10,000 foot overview of
sockets.  It's not really a tutorial - you'll still have work to do in
getting things operational. It doesn't cover the fine points (and there
are a lot of them), but I hope it will give you enough background to
begin using them decently.

* Menu:

* Sockets::
* Creating a Socket::
* Using a Socket::
* Disconnecting::
* Non-blocking Sockets::

Sockets

* History::

Creating a Socket

* IPC::

Using a Socket

* Binary Data::

Disconnecting

* When Sockets Die::

Non-blocking Sockets

* Performance: Performance<2>.


File: python.info,  Node: Sockets,  Next: Creating a Socket,  Up: Socket Programming HOWTO

10.10.1 Sockets
---------------

Sockets are used nearly everywhere, but are one of the most severely
misunderstood technologies around. This is a 10,000 foot overview of
sockets.  It's not really a tutorial - you'll still have work to do in
getting things working. It doesn't cover the fine points (and there are
a lot of them), but I hope it will give you enough background to begin
using them decently.

  I'm only going to talk about INET sockets, but they account for at
least 99% of the sockets in use. And I'll only talk about STREAM
sockets - unless you really know what you're doing (in which case this
HOWTO isn't for you!), you'll get better behavior and performance from
a STREAM socket than anything else. I will try to clear up the mystery
of what a socket is, as well as some hints on how to work with blocking
and non-blocking sockets. But I'll start by talking about blocking
sockets. You'll need to know how they work before dealing with
non-blocking sockets.

  Part of the trouble with understanding these things is that "socket"
can mean a number of subtly different things, depending on context. So
first, let's make a distinction between a "client" socket - an endpoint
of a conversation, and a "server" socket, which is more like a
switchboard operator. The client application (your browser, for
example) uses "client" sockets exclusively; the web server it's talking
to uses both "server" sockets and "client" sockets.

* Menu:

* History::


File: python.info,  Node: History,  Up: Sockets

10.10.1.1 History
.................

Of the various forms of IPC (Inter Process Communication), sockets are
by far the most popular.  On any given platform, there are likely to be
other forms of IPC that are faster, but for cross-platform
communication, sockets are about the only game in town.

  They were invented in Berkeley as part of the BSD flavor of Unix.
They spread like wildfire with the Internet. With good reason -- the
combination of sockets with INET makes talking to arbitrary machines
around the world unbelievably easy (at least compared to other schemes).


File: python.info,  Node: Creating a Socket,  Next: Using a Socket,  Prev: Sockets,  Up: Socket Programming HOWTO

10.10.2 Creating a Socket
-------------------------

Roughly speaking, when you clicked on the link that brought you to this
page, your browser did something like the following:

    #create an INET, STREAMing socket
    s = socket.socket(
        socket.AF_INET, socket.SOCK_STREAM)
    #now connect to the web server on port 80
    # - the normal http port
    s.connect(("www.mcmillan-inc.com", 80))

When the `connect' completes, the socket `s' can be used to send in a
request for the text of the page. The same socket will read the reply,
and then be destroyed. That's right, destroyed. Client sockets are
normally only used for one exchange (or a small set of sequential
exchanges).

  What happens in the web server is a bit more complex. First, the web
server creates a "server socket":

    #create an INET, STREAMing socket
    serversocket = socket.socket(
        socket.AF_INET, socket.SOCK_STREAM)
    #bind the socket to a public host,
    # and a well-known port
    serversocket.bind((socket.gethostname(), 80))
    #become a server socket
    serversocket.listen(5)

A couple things to notice: we used `socket.gethostname()' so that the
socket would be visible to the outside world.  If we had used
`s.bind(('localhost', 80))' or `s.bind(('127.0.0.1', 80))' we would
still have a "server" socket, but one that was only visible within the
same machine.  `s.bind(('', 80))' specifies that the socket is
reachable by any address the machine happens to have.

  A second thing to note: low number ports are usually reserved for
"well known" services (HTTP, SNMP etc). If you're playing around, use a
nice high number (4 digits).

  Finally, the argument to `listen' tells the socket library that we
want it to queue up as many as 5 connect requests (the normal max)
before refusing outside connections. If the rest of the code is written
properly, that should be plenty.

  Now that we have a "server" socket, listening on port 80, we can
enter the mainloop of the web server:

    while 1:
        #accept connections from outside
        (clientsocket, address) = serversocket.accept()
        #now do something with the clientsocket
        #in this case, we'll pretend this is a threaded server
        ct = client_thread(clientsocket)
        ct.run()

There's actually 3 general ways in which this loop could work -
dispatching a thread to handle `clientsocket', create a new process to
handle `clientsocket', or restructure this app to use non-blocking
sockets, and mulitplex between our "server" socket and any active
`clientsocket's using `select'. More about that later. The important
thing to understand now is this: this is _all_ a "server" socket does.
It doesn't send any data. It doesn't receive any data. It just produces
"client" sockets. Each `clientsocket' is created in response to some
_other_ "client" socket doing a `connect()' to the host and port we're
bound to. As soon as we've created that `clientsocket', we go back to
listening for more connections. The two "clients" are free to chat it
up - they are using some dynamically allocated port which will be
recycled when the conversation ends.

* Menu:

* IPC::


File: python.info,  Node: IPC,  Up: Creating a Socket

10.10.2.1 IPC
.............

If you need fast IPC between two processes on one machine, you should
look into whatever form of shared memory the platform offers. A simple
protocol based around shared memory and locks or semaphores is by far
the fastest technique.

  If you do decide to use sockets, bind the "server" socket to
`'localhost''. On most platforms, this will take a shortcut around a
couple of layers of network code and be quite a bit faster.


File: python.info,  Node: Using a Socket,  Next: Disconnecting,  Prev: Creating a Socket,  Up: Socket Programming HOWTO

10.10.3 Using a Socket
----------------------

The first thing to note, is that the web browser's "client" socket and
the web server's "client" socket are identical beasts. That is, this is
a "peer to peer" conversation. Or to put it another way, _as the
designer, you will have to decide what the rules of etiquette are for a
conversation_. Normally, the `connect'ing socket starts the
conversation, by sending in a request, or perhaps a signon. But that's
a design decision - it's not a rule of sockets.

  Now there are two sets of verbs to use for communication. You can use
`send' and `recv', or you can transform your client socket into a
file-like beast and use `read' and `write'. The latter is the way Java
presents its sockets.  I'm not going to talk about it here, except to
warn you that you need to use `flush' on sockets. These are buffered
"files", and a common mistake is to `write' something, and then `read'
for a reply. Without a `flush' in there, you may wait forever for the
reply, because the request may still be in your output buffer.

  Now we come to the major stumbling block of sockets - `send' and
`recv' operate on the network buffers. They do not necessarily handle
all the bytes you hand them (or expect from them), because their major
focus is handling the network buffers. In general, they return when the
associated network buffers have been filled (`send') or emptied
(`recv'). They then tell you how many bytes they handled. It is _your_
responsibility to call them again until your message has been
completely dealt with.

  When a `recv' returns 0 bytes, it means the other side has closed (or
is in the process of closing) the connection.  You will not receive any
more data on this connection. Ever.  You may be able to send data
successfully; I'll talk more about this later.

  A protocol like HTTP uses a socket for only one transfer. The client
sends a request, then reads a reply.  That's it. The socket is
discarded. This means that a client can detect the end of the reply by
receiving 0 bytes.

  But if you plan to reuse your socket for further transfers, you need
to realize that _there is no_ EOT (End of Transfer) _on a socket._ I
repeat: if a socket `send' or `recv' returns after handling 0 bytes,
the connection has been broken.  If the connection has _not_ been
broken, you may wait on a `recv' forever, because the socket will _not_
tell you that there's nothing more to read (for now).  Now if you think
about that a bit, you'll come to realize a fundamental truth of
sockets: _messages must either be fixed length_ (yuck), _or be
delimited_ (shrug), _or indicate how long they are_ (much better), _or
end by shutting down the connection_. The choice is entirely yours,
(but some ways are righter than others).

  Assuming you don't want to end the connection, the simplest solution
is a fixed length message:

    class mysocket:
        '''demonstration class only
          - coded for clarity, not efficiency
        '''

        def __init__(self, sock=None):
            if sock is None:
                self.sock = socket.socket(
                    socket.AF_INET, socket.SOCK_STREAM)
            else:
                self.sock = sock

        def connect(self, host, port):
            self.sock.connect((host, port))

        def mysend(self, msg):
            totalsent = 0
            while totalsent < MSGLEN:
                sent = self.sock.send(msg[totalsent:])
                if sent == 0:
                    raise RuntimeError("socket connection broken")
                totalsent = totalsent + sent

        def myreceive(self):
            msg = ''
            while len(msg) < MSGLEN:
                chunk = self.sock.recv(MSGLEN-len(msg))
                if chunk == '':
                    raise RuntimeError("socket connection broken")
                msg = msg + chunk
            return msg

The sending code here is usable for almost any messaging scheme - in
Python you send strings, and you can use `len()' to determine its
length (even if it has embedded `\0' characters). It's mostly the
receiving code that gets more complex. (And in C, it's not much worse,
except you can't use `strlen' if the message has embedded `\0's.)

  The easiest enhancement is to make the first character of the message
an indicator of message type, and have the type determine the length.
Now you have two `recv's - the first to get (at least) that first
character so you can look up the length, and the second in a loop to
get the rest. If you decide to go the delimited route, you'll be
receiving in some arbitrary chunk size, (4096 or 8192 is frequently a
good match for network buffer sizes), and scanning what you've received
for a delimiter.

  One complication to be aware of: if your conversational protocol
allows multiple messages to be sent back to back (without some kind of
reply), and you pass `recv' an arbitrary chunk size, you may end up
reading the start of a following message. You'll need to put that aside
and hold onto it, until it's needed.

  Prefixing the message with it's length (say, as 5 numeric characters)
gets more complex, because (believe it or not), you may not get all 5
characters in one `recv'. In playing around, you'll get away with it;
but in high network loads, your code will very quickly break unless you
use two `recv' loops - the first to determine the length, the second to
get the data part of the message. Nasty.  This is also when you'll
discover that `send' does not always manage to get rid of everything in
one pass. And despite having read this, you will eventually get bit by
it!

  In the interests of space, building your character, (and preserving my
competitive position), these enhancements are left as an exercise for
the reader. Lets move on to cleaning up.

* Menu:

* Binary Data::


File: python.info,  Node: Binary Data,  Up: Using a Socket

10.10.3.1 Binary Data
.....................

It is perfectly possible to send binary data over a socket. The major
problem is that not all machines use the same formats for binary data.
For example, a Motorola chip will represent a 16 bit integer with the
value 1 as the two hex bytes 00 01. Intel and DEC, however, are
byte-reversed - that same 1 is 01 00.  Socket libraries have calls for
converting 16 and 32 bit integers - `ntohl, htonl, ntohs, htons' where
"n" means _network_ and "h" means _host_, "s" means _short_ and "l"
means _long_. Where network order is host order, these do nothing, but
where the machine is byte-reversed, these swap the bytes around
appropriately.

  In these days of 32 bit machines, the ascii representation of binary
data is frequently smaller than the binary representation. That's
because a surprising amount of the time, all those longs have the value
0, or maybe 1. The string "0" would be two bytes, while binary is four.
Of course, this doesn't fit well with fixed-length messages. Decisions,
decisions.


File: python.info,  Node: Disconnecting,  Next: Non-blocking Sockets,  Prev: Using a Socket,  Up: Socket Programming HOWTO

10.10.4 Disconnecting
---------------------

Strictly speaking, you're supposed to use `shutdown' on a socket before
you `close' it.  The `shutdown' is an advisory to the socket at the
other end.  Depending on the argument you pass it, it can mean "I'm not
going to send anymore, but I'll still listen", or "I'm not listening,
good riddance!".  Most socket libraries, however, are so used to
programmers neglecting to use this piece of etiquette that normally a
`close' is the same as `shutdown(); close()'.  So in most situations,
an explicit `shutdown' is not needed.

  One way to use `shutdown' effectively is in an HTTP-like exchange.
The client sends a request and then does a `shutdown(1)'. This tells
the server "This client is done sending, but can still receive."  The
server can detect "EOF" by a receive of 0 bytes. It can assume it has
the complete request.  The server sends a reply. If the `send'
completes successfully then, indeed, the client was still receiving.

  Python takes the automatic shutdown a step further, and says that
when a socket is garbage collected, it will automatically do a `close'
if it's needed. But relying on this is a very bad habit. If your socket
just disappears without doing a `close', the socket at the other end
may hang indefinitely, thinking you're just being slow. _Please_
`close' your sockets when you're done.

* Menu:

* When Sockets Die::


File: python.info,  Node: When Sockets Die,  Up: Disconnecting

10.10.4.1 When Sockets Die
..........................

Probably the worst thing about using blocking sockets is what happens
when the other side comes down hard (without doing a `close'). Your
socket is likely to hang. SOCKSTREAM is a reliable protocol, and it
will wait a long, long time before giving up on a connection. If you're
using threads, the entire thread is essentially dead. There's not much
you can do about it. As long as you aren't doing something dumb, like
holding a lock while doing a blocking read, the thread isn't really
consuming much in the way of resources. Do _not_ try to kill the thread
- part of the reason that threads are more efficient than processes is
that they avoid the overhead associated with the automatic recycling of
resources. In other words, if you do manage to kill the thread, your
whole process is likely to be screwed up.


File: python.info,  Node: Non-blocking Sockets,  Prev: Disconnecting,  Up: Socket Programming HOWTO

10.10.5 Non-blocking Sockets
----------------------------

If you've understood the preceding, you already know most of what you
need to know about the mechanics of using sockets. You'll still use the
same calls, in much the same ways. It's just that, if you do it right,
your app will be almost inside-out.

  In Python, you use `socket.setblocking(0)' to make it non-blocking.
In C, it's more complex, (for one thing, you'll need to choose between
the BSD flavor `O_NONBLOCK' and the almost indistinguishable Posix
flavor `O_NDELAY', which is completely different from `TCP_NODELAY'),
but it's the exact same idea. You do this after creating the socket,
but before using it. (Actually, if you're nuts, you can switch back and
forth.)

  The major mechanical difference is that `send', `recv', `connect' and
`accept' can return without having done anything. You have (of course) a
number of choices. You can check return code and error codes and
generally drive yourself crazy. If you don't believe me, try it
sometime. Your app will grow large, buggy and suck CPU. So let's skip
the brain-dead solutions and do it right.

  Use `select'.

  In C, coding `select' is fairly complex. In Python, it's a piece of
cake, but it's close enough to the C version that if you understand
`select' in Python, you'll have little trouble with it in C:

    ready_to_read, ready_to_write, in_error = \
                   select.select(
                      potential_readers,
                      potential_writers,
                      potential_errs,
                      timeout)

You pass `select' three lists: the first contains all sockets that you
might want to try reading; the second all the sockets you might want to
try writing to, and the last (normally left empty) those that you want
to check for errors.  You should note that a socket can go into more
than one list. The `select' call is blocking, but you can give it a
timeout. This is generally a sensible thing to do - give it a nice long
timeout (say a minute) unless you have good reason to do otherwise.

  In return, you will get three lists. They contain the sockets that
are actually readable, writable and in error. Each of these lists is a
subset (possibly empty) of the corresponding list you passed in.

  If a socket is in the output readable list, you can be
as-close-to-certain-as-we-ever-get-in-this-business that a `recv' on
that socket will return _something_. Same idea for the writable list.
You'll be able to send _something_. Maybe not all you want to, but
_something_ is better than nothing.  (Actually, any reasonably healthy
socket will return as writable - it just means outbound network buffer
space is available.)

  If you have a "server" socket, put it in the potential_readers list.
If it comes out in the readable list, your `accept' will (almost
certainly) work. If you have created a new socket to `connect' to
someone else, put it in the potential_writers list. If it shows up in
the writable list, you have a decent chance that it has connected.

  One very nasty problem with `select': if somewhere in those input
lists of sockets is one which has died a nasty death, the `select' will
fail. You then need to loop through every single damn socket in all
those lists and do a `select([sock],[],[],0)' until you find the bad
one. That timeout of 0 means it won't take long, but it's ugly.

  Actually, `select' can be handy even with blocking sockets. It's one
way of determining whether you will block - the socket returns as
readable when there's something in the buffers.  However, this still
doesn't help with the problem of determining whether the other end is
done, or just busy with something else.

  *Portability alert*: On Unix, `select' works both with the sockets and
files. Don't try this on Windows. On Windows, `select' works with
sockets only. Also note that in C, many of the more advanced socket
options are done differently on Windows. In fact, on Windows I usually
use threads (which work very, very well) with my sockets. Face it, if
you want any kind of performance, your code will look very different on
Windows than on Unix.

* Menu:

* Performance: Performance<2>.


File: python.info,  Node: Performance<2>,  Up: Non-blocking Sockets

10.10.5.1 Performance
.....................

There's no question that the fastest sockets code uses non-blocking
sockets and select to multiplex them. You can put together something
that will saturate a LAN connection without putting any strain on the
CPU. The trouble is that an app written this way can't do much of
anything else - it needs to be ready to shuffle bytes around at all
times.

  Assuming that your app is actually supposed to do something more than
that, threading is the optimal solution, (and using non-blocking
sockets will be faster than using blocking sockets). Unfortunately,
threading support in Unixes varies both in API and quality. So the
normal Unix solution is to fork a subprocess to deal with each
connection. The overhead for this is significant (and don't do this on
Windows - the overhead of process creation is enormous there). It also
means that unless each subprocess is completely independent, you'll
need to use another form of IPC, say a pipe, or shared memory and
semaphores, to communicate between the parent and child processes.

  Finally, remember that even though blocking sockets are somewhat
slower than non-blocking, in many cases they are the "right" solution.
After all, if your app is driven by the data it receives over a socket,
there's not much sense in complicating the logic just so your app can
wait on `select' instead of `recv'.


File: python.info,  Node: Sorting HOW TO,  Next: Unicode HOWTO,  Prev: Socket Programming HOWTO,  Up: Python HOWTOs

10.11 Sorting HOW TO
====================

     Author: Andrew Dalke and Raymond Hettinger

     Release: 0.1

  Python lists have a built-in `list.sort()' method that modifies the
list in-place.  There is also a *note sorted(): 220. built-in function
that builds a new sorted list from an iterable.

  In this document, we explore the various techniques for sorting data
using Python.

* Menu:

* Sorting Basics::
* Key Functions::
* Operator Module Functions::
* Ascending and Descending::
* Sort Stability and Complex Sorts::
* The Old Way Using Decorate-Sort-Undecorate::
* The Old Way Using the cmp Parameter::
* Odd and Ends::


File: python.info,  Node: Sorting Basics,  Next: Key Functions,  Up: Sorting HOW TO

10.11.1 Sorting Basics
----------------------

A simple ascending sort is very easy: just call the *note sorted():
220. function. It returns a new sorted list:

    >>> sorted([5, 2, 3, 1, 4])
    [1, 2, 3, 4, 5]

You can also use the `list.sort()' method of a list. It modifies the
list in-place (and returns _None_ to avoid confusion). Usually it's
less convenient than *note sorted(): 220. - but if you don't need the
original list, it's slightly more efficient.

    >>> a = [5, 2, 3, 1, 4]
    >>> a.sort()
    >>> a
    [1, 2, 3, 4, 5]

Another difference is that the `list.sort()' method is only defined for
lists. In contrast, the *note sorted(): 220. function accepts any
iterable.

    >>> sorted({1: 'D', 2: 'B', 3: 'B', 4: 'E', 5: 'A'})
    [1, 2, 3, 4, 5]



File: python.info,  Node: Key Functions,  Next: Operator Module Functions,  Prev: Sorting Basics,  Up: Sorting HOW TO

10.11.2 Key Functions
---------------------

Starting with Python 2.4, both `list.sort()' and *note sorted(): 220.
added a _key_ parameter to specify a function to be called on each list
element prior to making comparisons.

  For example, here's a case-insensitive string comparison:

    >>> sorted("This is a test string from Andrew".split(), key=str.lower)
    ['a', 'Andrew', 'from', 'is', 'string', 'test', 'This']

The value of the _key_ parameter should be a function that takes a
single argument and returns a key to use for sorting purposes. This
technique is fast because the key function is called exactly once for
each input record.

  A common pattern is to sort complex objects using some of the
object's indices as keys. For example:

    >>> student_tuples = [
        ('john', 'A', 15),
        ('jane', 'B', 12),
        ('dave', 'B', 10),
    ]
    >>> sorted(student_tuples, key=lambda student: student[2])   # sort by age
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The same technique works for objects with named attributes. For example:

    >>> class Student:
            def __init__(self, name, grade, age):
                self.name = name
                self.grade = grade
                self.age = age
            def __repr__(self):
                return repr((self.name, self.grade, self.age))


    >>> student_objects = [
        Student('john', 'A', 15),
        Student('jane', 'B', 12),
        Student('dave', 'B', 10),
    ]
    >>> sorted(student_objects, key=lambda student: student.age)   # sort by age
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]



File: python.info,  Node: Operator Module Functions,  Next: Ascending and Descending,  Prev: Key Functions,  Up: Sorting HOW TO

10.11.3 Operator Module Functions
---------------------------------

The key-function patterns shown above are very common, so Python
provides convenience functions to make accessor functions easier and
faster. The operator module has *note operator.itemgetter(): dcf, *note
operator.attrgetter(): dce, and starting in Python 2.5 a *note
operator.methodcaller(): dd0. function.

  Using those functions, the above examples become simpler and faster:

    >>> from operator import itemgetter, attrgetter


    >>> sorted(student_tuples, key=itemgetter(2))
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]


    >>> sorted(student_objects, key=attrgetter('age'))
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The operator module functions allow multiple levels of sorting. For
example, to sort by _grade_ then by _age_:

    >>> sorted(student_tuples, key=itemgetter(1,2))
    [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]


    >>> sorted(student_objects, key=attrgetter('grade', 'age'))
    [('john', 'A', 15), ('dave', 'B', 10), ('jane', 'B', 12)]

The *note operator.methodcaller(): dd0. function makes method calls
with fixed parameters for each object being sorted.  For example, the
*note str.count(): 8a5.  method could be used to compute message
priority by counting the number of exclamation marks in a message:

    >>> messages = ['critical!!!', 'hurry!', 'standby', 'immediate!!']
    >>> sorted(messages, key=methodcaller('count', '!'))
    ['standby', 'hurry!', 'immediate!!', 'critical!!!']



File: python.info,  Node: Ascending and Descending,  Next: Sort Stability and Complex Sorts,  Prev: Operator Module Functions,  Up: Sorting HOW TO

10.11.4 Ascending and Descending
--------------------------------

Both `list.sort()' and *note sorted(): 220. accept a _reverse_
parameter with a boolean value. This is used to flag descending sorts.
For example, to get the student data in reverse _age_ order:

    >>> sorted(student_tuples, key=itemgetter(2), reverse=True)
    [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]


    >>> sorted(student_objects, key=attrgetter('age'), reverse=True)
    [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]



File: python.info,  Node: Sort Stability and Complex Sorts,  Next: The Old Way Using Decorate-Sort-Undecorate,  Prev: Ascending and Descending,  Up: Sorting HOW TO

10.11.5 Sort Stability and Complex Sorts
----------------------------------------

Starting with Python 2.2, sorts are guaranteed to be stable(1). That
means that when multiple records have the same key, their original
order is preserved.

    >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]
    >>> sorted(data, key=itemgetter(0))
    [('blue', 1), ('blue', 2), ('red', 1), ('red', 2)]

Notice how the two records for _blue_ retain their original order so
that `('blue', 1)' is guaranteed to precede `('blue', 2)'.

  This wonderful property lets you build complex sorts in a series of
sorting steps. For example, to sort the student data by descending
_grade_ and then ascending _age_, do the _age_ sort first and then sort
again using _grade_:

    >>> s = sorted(student_objects, key=attrgetter('age'))     # sort on secondary key
    >>> sorted(s, key=attrgetter('grade'), reverse=True)       # now sort on primary key, descending
    [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

The Timsort(2) algorithm used in Python does multiple sorts efficiently
because it can take advantage of any ordering already present in a
dataset.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Sorting_algorithm#Stability

  (2) http://en.wikipedia.org/wiki/Timsort


File: python.info,  Node: The Old Way Using Decorate-Sort-Undecorate,  Next: The Old Way Using the cmp Parameter,  Prev: Sort Stability and Complex Sorts,  Up: Sorting HOW TO

10.11.6 The Old Way Using Decorate-Sort-Undecorate
--------------------------------------------------

This idiom is called Decorate-Sort-Undecorate after its three steps:

   * First, the initial list is decorated with new values that control
     the sort order.

   * Second, the decorated list is sorted.

   * Finally, the decorations are removed, creating a list that
     contains only the initial values in the new order.

  For example, to sort the student data by _grade_ using the DSU
approach:

    >>> decorated = [(student.grade, i, student) for i, student in enumerate(student_objects)]
    >>> decorated.sort()
    >>> [student for grade, i, student in decorated]               # undecorate
    [('john', 'A', 15), ('jane', 'B', 12), ('dave', 'B', 10)]

This idiom works because tuples are compared lexicographically; the
first items are compared; if they are the same then the second items
are compared, and so on.

  It is not strictly necessary in all cases to include the index _i_ in
the decorated list, but including it gives two benefits:

   * The sort is stable - if two items have the same key, their order
     will be preserved in the sorted list.

   * The original items do not have to be comparable because the
     ordering of the decorated tuples will be determined by at most the
     first two items. So for example the original list could contain
     complex numbers which cannot be sorted directly.

  Another name for this idiom is Schwartzian transform(1), after Randal
L. Schwartz, who popularized it among Perl programmers.

  For large lists and lists where the comparison information is
expensive to calculate, and Python versions before 2.4, DSU is likely
to be the fastest way to sort the list. For 2.4 and later, key
functions provide the same functionality.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Schwartzian_transform


File: python.info,  Node: The Old Way Using the cmp Parameter,  Next: Odd and Ends,  Prev: The Old Way Using Decorate-Sort-Undecorate,  Up: Sorting HOW TO

10.11.7 The Old Way Using the _cmp_ Parameter
---------------------------------------------

Many constructs given in this HOWTO assume Python 2.4 or later. Before
that, there was no *note sorted(): 220. builtin and `list.sort()' took
no keyword arguments. Instead, all of the Py2.x versions supported a
_cmp_ parameter to handle user specified comparison functions.

  In Python 3, the _cmp_ parameter was removed entirely (as part of a
larger effort to simplify and unify the language, eliminating the
conflict between rich comparisons and the *note __cmp__(): 21e. magic
method).

  In Python 2, `sort()' allowed an optional function which can be
called for doing the comparisons. That function should take two
arguments to be compared and then return a negative value for
less-than, return zero if they are equal, or return a positive value
for greater-than. For example, we can do:

    >>> def numeric_compare(x, y):
            return x - y
    >>> sorted([5, 2, 4, 1, 3], cmp=numeric_compare)
    [1, 2, 3, 4, 5]

Or you can reverse the order of comparison with:

    >>> def reverse_numeric(x, y):
            return y - x
    >>> sorted([5, 2, 4, 1, 3], cmp=reverse_numeric)
    [5, 4, 3, 2, 1]

When porting code from Python 2.x to 3.x, the situation can arise when
you have the user supplying a comparison function and you need to
convert that to a key function. The following wrapper makes that easy
to do:

    def cmp_to_key(mycmp):
        'Convert a cmp= function into a key= function'
        class K(object):
            def __init__(self, obj, *args):
                self.obj = obj
            def __lt__(self, other):
                return mycmp(self.obj, other.obj) < 0
            def __gt__(self, other):
                return mycmp(self.obj, other.obj) > 0
            def __eq__(self, other):
                return mycmp(self.obj, other.obj) == 0
            def __le__(self, other):
                return mycmp(self.obj, other.obj) <= 0
            def __ge__(self, other):
                return mycmp(self.obj, other.obj) >= 0
            def __ne__(self, other):
                return mycmp(self.obj, other.obj) != 0
        return K

To convert to a key function, just wrap the old comparison function:

    >>> sorted([5, 2, 4, 1, 3], key=cmp_to_key(reverse_numeric))
    [5, 4, 3, 2, 1]

In Python 2.7, the *note functools.cmp_to_key(): 21f. function was
added to the functools module.


File: python.info,  Node: Odd and Ends,  Prev: The Old Way Using the cmp Parameter,  Up: Sorting HOW TO

10.11.8 Odd and Ends
--------------------

   * For locale aware sorting, use *note locale.strxfrm(): 200a. for a
     key function or *note locale.strcoll(): 2008. for a comparison
     function.

   * The _reverse_ parameter still maintains sort stability (so that
     records with equal keys retain their original order).
     Interestingly, that effect can be simulated without the parameter
     by using the builtin *note reversed(): 3f1. function twice:

         >>> data = [('red', 1), ('blue', 1), ('red', 2), ('blue', 2)]
         >>> assert sorted(data, reverse=True) == list(reversed(sorted(reversed(data))))


   * To create a standard sort order for a class, just add the
     appropriate rich comparison methods:

         >>> Student.__eq__ = lambda self, other: self.age == other.age
         >>> Student.__ne__ = lambda self, other: self.age != other.age
         >>> Student.__lt__ = lambda self, other: self.age < other.age
         >>> Student.__le__ = lambda self, other: self.age <= other.age
         >>> Student.__gt__ = lambda self, other: self.age > other.age
         >>> Student.__ge__ = lambda self, other: self.age >= other.age
         >>> sorted(student_objects)
         [('dave', 'B', 10), ('jane', 'B', 12), ('john', 'A', 15)]

     For general purpose comparisons, the recommended approach is to
     define all six rich comparison operators.  The *note
     functools.total_ordering(): 218. class decorator makes this easy
     to implement.

   * Key functions need not depend directly on the objects being
     sorted. A key function can also access external resources. For
     instance, if the student grades are stored in a dictionary, they
     can be used to sort a separate list of student names:

         >>> students = ['dave', 'john', 'jane']
         >>> grades = {'john': 'F', 'jane':'A', 'dave': 'C'}
         >>> sorted(students, key=grades.__getitem__)
         ['jane', 'dave', 'john']




File: python.info,  Node: Unicode HOWTO,  Next: HOWTO Fetch Internet Resources Using urllib2,  Prev: Sorting HOW TO,  Up: Python HOWTOs

10.12 Unicode HOWTO
===================

     Release: 1.03

  This HOWTO discusses Python 2.x's support for Unicode, and explains
various problems that people commonly encounter when trying to work
with Unicode.  For the Python 3 version, see
<<http://docs.python.org/py3k/howto/unicode.html>>.

* Menu:

* Introduction to Unicode::
* Python 2.x's Unicode Support: Python 2 x's Unicode Support.
* Reading and Writing Unicode Data::
* Revision History and Acknowledgements: Revision History and Acknowledgements<2>.

Introduction to Unicode

* History of Character Codes::
* Definitions::
* Encodings::
* References: References<2>.

Python 2.x's Unicode Support

* The Unicode Type::
* Unicode Literals in Python Source Code::
* Unicode Properties::
* References: References<3>.

Reading and Writing Unicode Data

* Unicode filenames::
* Tips for Writing Unicode-aware Programs::
* References: References<4>.


File: python.info,  Node: Introduction to Unicode,  Next: Python 2 x's Unicode Support,  Up: Unicode HOWTO

10.12.1 Introduction to Unicode
-------------------------------

* Menu:

* History of Character Codes::
* Definitions::
* Encodings::
* References: References<2>.


File: python.info,  Node: History of Character Codes,  Next: Definitions,  Up: Introduction to Unicode

10.12.1.1 History of Character Codes
....................................

In 1968, the American Standard Code for Information Interchange, better
known by its acronym ASCII, was standardized.  ASCII defined numeric
codes for various characters, with the numeric values running from 0 to
127.  For example, the lowercase letter 'a' is assigned 97 as its code
value.

  ASCII was an American-developed standard, so it only defined
unaccented characters.  There was an 'e', but no '' or ''.  This
meant that languages which required accented characters couldn't be
faithfully represented in ASCII.  (Actually the missing accents matter
for English, too, which contains words such as 'nave' and 'caf', and
some publications have house styles which require spellings such as
'coperate'.)

  For a while people just wrote programs that didn't display accents.
I remember looking at Apple ][ BASIC programs, published in
French-language publications in the mid-1980s, that had lines like
these:

    PRINT "FICHIER EST COMPLETE."
    PRINT "CARACTERE NON ACCEPTE."

Those messages should contain accents, and they just look wrong to
someone who can read French.

  In the 1980s, almost all personal computers were 8-bit, meaning that
bytes could hold values ranging from 0 to 255.  ASCII codes only went
up to 127, so some machines assigned values between 128 and 255 to
accented characters.  Different machines had different codes, however,
which led to problems exchanging files.  Eventually various commonly
used sets of values for the 128-255 range emerged.  Some were true
standards, defined by the International Standards Organization, and
some were *de facto* conventions that were invented by one company or
another and managed to catch on.

  255 characters aren't very many.  For example, you can't fit both the
accented characters used in Western Europe and the Cyrillic alphabet
used for Russian into the 128-255 range because there are more than 127
such characters.

  You could write files using different codes (all your Russian files
in a coding system called KOI8, all your French files in a different
coding system called Latin1), but what if you wanted to write a French
document that quotes some Russian text?  In the 1980s people began to
want to solve this problem, and the Unicode standardization effort
began.

  Unicode started out using 16-bit characters instead of 8-bit
characters.  16 bits means you have 2^16 = 65,536 distinct values
available, making it possible to represent many different characters
from many different alphabets; an initial goal was to have Unicode
contain the alphabets for every single human language.  It turns out
that even 16 bits isn't enough to meet that goal, and the modern
Unicode specification uses a wider range of codes, 0-1,114,111
(0x10ffff in base-16).

  There's a related ISO standard, ISO 10646.  Unicode and ISO 10646 were
originally separate efforts, but the specifications were merged with
the 1.1 revision of Unicode.

  (This discussion of Unicode's history is highly simplified.  I don't
think the average Python programmer needs to worry about the historical
details; consult the Unicode consortium site listed in the References
for more information.)


File: python.info,  Node: Definitions,  Next: Encodings,  Prev: History of Character Codes,  Up: Introduction to Unicode

10.12.1.2 Definitions
.....................

A *character* is the smallest possible component of a text.  'A', 'B',
'C', etc., are all different characters.  So are '' and ''.
Characters are abstractions, and vary depending on the language or
context you're talking about.  For example, the symbol for ohms () is
usually drawn much like the capital letter omega () in the Greek
alphabet (they may even be the same in some fonts), but these are two
different characters that have different meanings.

  The Unicode standard describes how characters are represented by *code
points*.  A code point is an integer value, usually denoted in base 16.
In the standard, a code point is written using the notation U+12ca to
mean the character with value 0x12ca (4810 decimal).  The Unicode
standard contains a lot of tables listing characters and their
corresponding code points:

    0061    'a'; LATIN SMALL LETTER A
    0062    'b'; LATIN SMALL LETTER B
    0063    'c'; LATIN SMALL LETTER C
    ...
    007B    '{'; LEFT CURLY BRACKET

Strictly, these definitions imply that it's meaningless to say 'this is
character U+12ca'.  U+12ca is a code point, which represents some
particular character; in this case, it represents the character
'ETHIOPIC SYLLABLE WI'.  In informal contexts, this distinction between
code points and characters will sometimes be forgotten.

  A character is represented on a screen or on paper by a set of
graphical elements that's called a *glyph*.  The glyph for an uppercase
A, for example, is two diagonal strokes and a horizontal stroke, though
the exact details will depend on the font being used.  Most Python code
doesn't need to worry about glyphs; figuring out the correct glyph to
display is generally the job of a GUI toolkit or a terminal's font
renderer.


File: python.info,  Node: Encodings,  Next: References<2>,  Prev: Definitions,  Up: Introduction to Unicode

10.12.1.3 Encodings
...................

To summarize the previous section: a Unicode string is a sequence of
code points, which are numbers from 0 to 0x10ffff.  This sequence needs
to be represented as a set of bytes (meaning, values from 0-255) in
memory.  The rules for translating a Unicode string into a sequence of
bytes are called an *encoding*.

  The first encoding you might think of is an array of 32-bit integers.
In this representation, the string "Python" would look like this:

       P           y           t           h           o           n
    0x50 00 00 00 79 00 00 00 74 00 00 00 68 00 00 00 6f 00 00 00 6e 00 00 00
       0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23

This representation is straightforward but using it presents a number of
problems.

  1. It's not portable; different processors order the bytes
     differently.

  2. It's very wasteful of space.  In most texts, the majority of the
     code points are less than 127, or less than 255, so a lot of space
     is occupied by zero bytes.  The above string takes 24 bytes
     compared to the 6 bytes needed for an ASCII representation.
     Increased RAM usage doesn't matter too much (desktop computers
     have megabytes of RAM, and strings aren't usually that large), but
     expanding our usage of disk and network bandwidth by a factor of 4
     is intolerable.

  3. It's not compatible with existing C functions such as `strlen()',
     so a new family of wide string functions would need to be used.

  4. Many Internet standards are defined in terms of textual data, and
     can't handle content with embedded zero bytes.

  Generally people don't use this encoding, instead choosing other
encodings that are more efficient and convenient.  UTF-8 is probably
the most commonly supported encoding; it will be discussed below.

  Encodings don't have to handle every possible Unicode character, and
most encodings don't.  For example, Python's default encoding is the
'ascii' encoding.  The rules for converting a Unicode string into the
ASCII encoding are simple; for each code point:

  1. If the code point is < 128, each byte is the same as the value of
     the code point.

  2. If the code point is 128 or greater, the Unicode string can't be
     represented in this encoding.  (Python raises a *note
     UnicodeEncodeError: 944. exception in this case.)

  Latin-1, also known as ISO-8859-1, is a similar encoding.  Unicode
code points 0-255 are identical to the Latin-1 values, so converting to
this encoding simply requires converting code points to byte values; if
a code point larger than 255 is encountered, the string can't be
encoded into Latin-1.

  Encodings don't have to be simple one-to-one mappings like Latin-1.
Consider IBM's EBCDIC, which was used on IBM mainframes.  Letter values
weren't in one block: 'a' through 'i' had values from 129 to 137, but
'j' through 'r' were 145 through 153.  If you wanted to use EBCDIC as
an encoding, you'd probably use some sort of lookup table to perform
the conversion, but this is largely an internal detail.

  UTF-8 is one of the most commonly used encodings.  UTF stands for
"Unicode Transformation Format", and the '8' means that 8-bit numbers
are used in the encoding.  (There's also a UTF-16 encoding, but it's
less frequently used than UTF-8.)  UTF-8 uses the following rules:

  1. If the code point is <128, it's represented by the corresponding
     byte value.

  2. If the code point is between 128 and 0x7ff, it's turned into two
     byte values between 128 and 255.

  3. Code points >0x7ff are turned into three- or four-byte sequences,
     where each byte of the sequence is between 128 and 255.

  UTF-8 has several convenient properties:

  1. It can handle any Unicode code point.

  2. A Unicode string is turned into a string of bytes containing no
     embedded zero bytes.  This avoids byte-ordering issues, and means
     UTF-8 strings can be processed by C functions such as `strcpy()'
     and sent through protocols that can't handle zero bytes.

  3. A string of ASCII text is also valid UTF-8 text.

  4. UTF-8 is fairly compact; the majority of code points are turned
     into two bytes, and values less than 128 occupy only a single byte.

  5. If bytes are corrupted or lost, it's possible to determine the
     start of the next UTF-8-encoded code point and resynchronize.
     It's also unlikely that random 8-bit data will look like valid
     UTF-8.


File: python.info,  Node: References<2>,  Prev: Encodings,  Up: Introduction to Unicode

10.12.1.4 References
....................

The Unicode Consortium site at <<http://www.unicode.org>> has character
charts, a glossary, and PDF versions of the Unicode specification.  Be
prepared for some difficult reading.
<<http://www.unicode.org/history/>> is a chronology of the origin and
development of Unicode.

  To help understand the standard, Jukka Korpela has written an
introductory guide to reading the Unicode character tables, available at
<<http://www.cs.tut.fi/~jkorpela/unicode/guide.html>>.

  Another good introductory article was written by Joel Spolsky
<<http://www.joelonsoftware.com/articles/Unicode.html>>.  If this
introduction didn't make things clear to you, you should try reading
this alternate article before continuing.

  Wikipedia entries are often helpful; see the entries for "character
encoding" <<http://en.wikipedia.org/wiki/Character_encoding>> and UTF-8
<<http://en.wikipedia.org/wiki/UTF-8>>, for example.


File: python.info,  Node: Python 2 x's Unicode Support,  Next: Reading and Writing Unicode Data,  Prev: Introduction to Unicode,  Up: Unicode HOWTO

10.12.2 Python 2.x's Unicode Support
------------------------------------

Now that you've learned the rudiments of Unicode, we can look at
Python's Unicode features.

* Menu:

* The Unicode Type::
* Unicode Literals in Python Source Code::
* Unicode Properties::
* References: References<3>.


File: python.info,  Node: The Unicode Type,  Next: Unicode Literals in Python Source Code,  Up: Python 2 x's Unicode Support

10.12.2.1 The Unicode Type
..........................

Unicode strings are expressed as instances of the *note unicode: 1f2.
type, one of Python's repertoire of built-in types.  It derives from an
abstract type called *note basestring: 451, which is also an ancestor
of the *note str: 1e7. type; you can therefore check if a value is a
string type with `isinstance(value, basestring)'.  Under the hood,
Python represents Unicode strings as either 16- or 32-bit integers,
depending on how the Python interpreter was compiled.

  The *note unicode(): 1f2. constructor has the signature
`unicode(string[, encoding, errors])'.  All of its arguments should be
8-bit strings.  The first argument is converted to Unicode using the
specified encoding; if you leave off the `encoding' argument, the ASCII
encoding is used for the conversion, so characters greater than 127
will be treated as errors:

    >>> unicode('abcdef')
    u'abcdef'
    >>> s = unicode('abcdef')
    >>> type(s)
    <type 'unicode'>
    >>> unicode('abcdef' + chr(255))    #doctest: +NORMALIZE_WHITESPACE
    Traceback (most recent call last):
    ...
    UnicodeDecodeError: 'ascii' codec can't decode byte 0xff in position 6:
    ordinal not in range(128)

The `errors' argument specifies the response when the input string
can't be converted according to the encoding's rules.  Legal values for
this argument are 'strict' (raise a `UnicodeDecodeError' exception),
'replace' (add U+FFFD, 'REPLACEMENT CHARACTER'), or 'ignore' (just
leave the character out of the Unicode result).  The following examples
show the differences:

    >>> unicode('\x80abc', errors='strict')     #doctest: +NORMALIZE_WHITESPACE
    Traceback (most recent call last):
        ...
    UnicodeDecodeError: 'ascii' codec can't decode byte 0x80 in position 0:
    ordinal not in range(128)
    >>> unicode('\x80abc', errors='replace')
    u'\ufffdabc'
    >>> unicode('\x80abc', errors='ignore')
    u'abc'

Encodings are specified as strings containing the encoding's name.
Python 2.7 comes with roughly 100 different encodings; see the Python
Library Reference at *note Standard Encodings: 8a8. for a list.  Some
encodings have multiple names; for example, 'latin-1', 'iso_8859_1' and
'8859' are all synonyms for the same encoding.

  One-character Unicode strings can also be created with the *note
unichr(): 48c.  built-in function, which takes integers and returns a
Unicode string of length 1 that contains the corresponding code point.
The reverse operation is the built-in *note ord(): 6e4. function that
takes a one-character Unicode string and returns the code point value:

    >>> unichr(40960)
    u'\ua000'
    >>> ord(u'\ua000')
    40960

Instances of the *note unicode: 1f2. type have many of the same methods
as the 8-bit string type for operations such as searching and
formatting:

    >>> s = u'Was ever feather so lightly blown to and fro as this multitude?'
    >>> s.count('e')
    5
    >>> s.find('feather')
    9
    >>> s.find('bird')
    -1
    >>> s.replace('feather', 'sand')
    u'Was ever sand so lightly blown to and fro as this multitude?'
    >>> s.upper()
    u'WAS EVER FEATHER SO LIGHTLY BLOWN TO AND FRO AS THIS MULTITUDE?'

Note that the arguments to these methods can be Unicode strings or 8-bit
strings.  8-bit strings will be converted to Unicode before carrying
out the operation; Python's default ASCII encoding will be used, so
characters greater than 127 will cause an exception:

    >>> s.find('Was\x9f')                   #doctest: +NORMALIZE_WHITESPACE
    Traceback (most recent call last):
        ...
    UnicodeDecodeError: 'ascii' codec can't decode byte 0x9f in position 3:
    ordinal not in range(128)
    >>> s.find(u'Was\x9f')
    -1

Much Python code that operates on strings will therefore work with
Unicode strings without requiring any changes to the code.  (Input and
output code needs more updating for Unicode; more on this later.)

  Another important method is `.encode([encoding], [errors='strict'])',
which returns an 8-bit string version of the Unicode string, encoded in
the requested encoding.  The `errors' parameter is the same as the
parameter of the `unicode()' constructor, with one additional
possibility; as well as 'strict', 'ignore', and 'replace', you can also
pass 'xmlcharrefreplace' which uses XML's character references.  The
following example shows the different results:

    >>> u = unichr(40960) + u'abcd' + unichr(1972)
    >>> u.encode('utf-8')
    '\xea\x80\x80abcd\xde\xb4'
    >>> u.encode('ascii')                       #doctest: +NORMALIZE_WHITESPACE
    Traceback (most recent call last):
        ...
    UnicodeEncodeError: 'ascii' codec can't encode character u'\ua000' in
    position 0: ordinal not in range(128)
    >>> u.encode('ascii', 'ignore')
    'abcd'
    >>> u.encode('ascii', 'replace')
    '?abcd?'
    >>> u.encode('ascii', 'xmlcharrefreplace')
    '&#40960;abcd&#1972;'

Python's 8-bit strings have a `.decode([encoding], [errors])' method
that interprets the string using the given encoding:

    >>> u = unichr(40960) + u'abcd' + unichr(1972)   # Assemble a string
    >>> utf8_version = u.encode('utf-8')             # Encode as UTF-8
    >>> type(utf8_version), utf8_version
    (<type 'str'>, '\xea\x80\x80abcd\xde\xb4')
    >>> u2 = utf8_version.decode('utf-8')            # Decode using UTF-8
    >>> u == u2                                      # The two strings match
    True

The low-level routines for registering and accessing the available
encodings are found in the *note codecs: 63. module.  However, the
encoding and decoding functions returned by this module are usually
more low-level than is comfortable, so I'm not going to describe the
*note codecs: 63. module here.  If you need to implement a completely
new encoding, you'll need to learn about the *note codecs: 63. module
interfaces, but implementing encodings is a specialized task that also
won't be covered here.  Consult the Python documentation to learn more
about this module.

  The most commonly used part of the *note codecs: 63. module is the
*note codecs.open(): a48. function which will be discussed in the
section on input and output.


File: python.info,  Node: Unicode Literals in Python Source Code,  Next: Unicode Properties,  Prev: The Unicode Type,  Up: Python 2 x's Unicode Support

10.12.2.2 Unicode Literals in Python Source Code
................................................

In Python source code, Unicode literals are written as strings prefixed
with the 'u' or 'U' character: `u'abcdefghijk''.  Specific code points
can be written using the `\u' escape sequence, which is followed by
four hex digits giving the code point.  The `\U' escape sequence is
similar, but expects 8 hex digits, not 4.

  Unicode literals can also use the same escape sequences as 8-bit
strings, including `\x', but `\x' only takes two hex digits so it can't
express an arbitrary code point.  Octal escapes can go up to U+01ff,
which is octal 777.

    >>> s = u"a\xac\u1234\u20ac\U00008000"
    ... #      ^^^^ two-digit hex escape
    ... #          ^^^^^^ four-digit Unicode escape
    ... #                      ^^^^^^^^^^ eight-digit Unicode escape
    >>> for c in s:  print ord(c),
    ...
    97 172 4660 8364 32768

Using escape sequences for code points greater than 127 is fine in
small doses, but becomes an annoyance if you're using many accented
characters, as you would in a program with messages in French or some
other accent-using language.  You can also assemble strings using the
*note unichr(): 48c. built-in function, but this is even more tedious.

  Ideally, you'd want to be able to write literals in your language's
natural encoding.  You could then edit Python source code with your
favorite editor which would display the accented characters naturally,
and have the right characters used at runtime.

  Python supports writing Unicode literals in any encoding, but you
have to declare the encoding being used.  This is done by including a
special comment as either the first or second line of the source file:

    #!/usr/bin/env python
    # -*- coding: latin-1 -*-

    u = u'abcd'
    print ord(u[-1])

The syntax is inspired by Emacs's notation for specifying variables
local to a file.  Emacs supports many different variables, but Python
only supports 'coding'.  The `-*-' symbols indicate to Emacs that the
comment is special; they have no significance to Python but are a
convention.  Python looks for `coding: name' or `coding=name' in the
comment.

  If you don't include such a comment, the default encoding used will
be ASCII.  Versions of Python before 2.4 were Euro-centric and assumed
Latin-1 as a default encoding for string literals; in Python 2.4,
characters greater than 127 still work but result in a warning.  For
example, the following program has no encoding declaration:

    #!/usr/bin/env python
    u = u'abcd'
    print ord(u[-1])

When you run it with Python 2.4, it will output the following warning:

    amk:~$ python2.4 p263.py
    sys:1: DeprecationWarning: Non-ASCII character '\xe9'
         in file p263.py on line 2, but no encoding declared;
         see http://www.python.org/peps/pep-0263.html for details

Python 2.5 and higher are stricter and will produce a syntax error:

    amk:~$ python2.5 p263.py
    File "/tmp/p263.py", line 2
    SyntaxError: Non-ASCII character '\xc3' in file /tmp/p263.py
      on line 2, but no encoding declared; see
      http://www.python.org/peps/pep-0263.html for details



File: python.info,  Node: Unicode Properties,  Next: References<3>,  Prev: Unicode Literals in Python Source Code,  Up: Python 2 x's Unicode Support

10.12.2.3 Unicode Properties
............................

The Unicode specification includes a database of information about code
points.  For each code point that's defined, the information includes
the character's name, its category, the numeric value if applicable
(Unicode has characters representing the Roman numerals and fractions
such as one-third and four-fifths).  There are also properties related
to the code point's use in bidirectional text and other display-related
properties.

  The following program displays some information about several
characters, and prints the numeric value of one particular character:

    import unicodedata

    u = unichr(233) + unichr(0x0bf2) + unichr(3972) + unichr(6000) + unichr(13231)

    for i, c in enumerate(u):
        print i, '%04x' % ord(c), unicodedata.category(c),
        print unicodedata.name(c)

    # Get numeric value of second character
    print unicodedata.numeric(u[1])

When run, this prints:

    0 00e9 Ll LATIN SMALL LETTER E WITH ACUTE
    1 0bf2 No TAMIL NUMBER ONE THOUSAND
    2 0f84 Mn TIBETAN MARK HALANTA
    3 1770 Lo TAGBANWA LETTER SA
    4 33af So SQUARE RAD OVER S SQUARED
    1000.0

The category codes are abbreviations describing the nature of the
character.  These are grouped into categories such as "Letter",
"Number", "Punctuation", or "Symbol", which in turn are broken up into
subcategories.  To take the codes from the above output, `'Ll'' means
'Letter, lowercase', `'No'' means "Number, other", `'Mn'' is "Mark,
nonspacing", and `'So'' is "Symbol, other".  See
<<http://www.unicode.org/reports/tr44/#General_Category_Values>> for a
list of category codes.


File: python.info,  Node: References<3>,  Prev: Unicode Properties,  Up: Python 2 x's Unicode Support

10.12.2.4 References
....................

The Unicode and 8-bit string types are described in the Python library
reference at *note Sequence Types -- str, unicode, list, tuple,
bytearray, buffer, xrange: 518.

  The documentation for the *note unicodedata: 186. module.

  The documentation for the *note codecs: 63. module.

  Marc-Andr Lemburg gave a presentation at EuroPython 2002 titled
"Python and Unicode".  A PDF version of his slides is available at
<<http://downloads.egenix.com/python/Unicode-EPC2002-Talk.pdf>>, and is
an excellent overview of the design of Python's Unicode features.


File: python.info,  Node: Reading and Writing Unicode Data,  Next: Revision History and Acknowledgements<2>,  Prev: Python 2 x's Unicode Support,  Up: Unicode HOWTO

10.12.3 Reading and Writing Unicode Data
----------------------------------------

Once you've written some code that works with Unicode data, the next
problem is input/output.  How do you get Unicode strings into your
program, and how do you convert Unicode into a form suitable for
storage or transmission?

  It's possible that you may not need to do anything depending on your
input sources and output destinations; you should check whether the
libraries used in your application support Unicode natively.  XML
parsers often return Unicode data, for example.  Many relational
databases also support Unicode-valued columns and can return Unicode
values from an SQL query.

  Unicode data is usually converted to a particular encoding before it
gets written to disk or sent over a socket.  It's possible to do all
the work yourself: open a file, read an 8-bit string from it, and
convert the string with `unicode(str, encoding)'.  However, the manual
approach is not recommended.

  One problem is the multi-byte nature of encodings; one Unicode
character can be represented by several bytes.  If you want to read the
file in arbitrary-sized chunks (say, 1K or 4K), you need to write
error-handling code to catch the case where only part of the bytes
encoding a single Unicode character are read at the end of a chunk.
One solution would be to read the entire file into memory and then
perform the decoding, but that prevents you from working with files that
are extremely large; if you need to read a 2Gb file, you need 2Gb of
RAM.  (More, really, since for at least a moment you'd need to have
both the encoded string and its Unicode version in memory.)

  The solution would be to use the low-level decoding interface to
catch the case of partial coding sequences.  The work of implementing
this has already been done for you: the *note codecs: 63. module
includes a version of the *note open(): 2d3.  function that returns a
file-like object that assumes the file's contents are in a specified
encoding and accepts Unicode parameters for methods such as `.read()'
and `.write()'.

  The function's parameters are `open(filename, mode='rb',
encoding=None, errors='strict', buffering=1)'.  `mode' can be `'r'',
`'w'', or `'a'', just like the corresponding parameter to the regular
built-in `open()' function; add a `'+'' to update the file.
`buffering' is similarly parallel to the standard function's parameter.
`encoding' is a string giving the encoding to use; if it's left as
`None', a regular Python file object that accepts 8-bit strings is
returned.  Otherwise, a wrapper object is returned, and data written to
or read from the wrapper object will be converted as needed.  `errors'
specifies the action for encoding errors and can be one of the usual
values of 'strict', 'ignore', and 'replace'.

  Reading Unicode from a file is therefore simple:

    import codecs
    f = codecs.open('unicode.rst', encoding='utf-8')
    for line in f:
        print repr(line)

It's also possible to open files in update mode, allowing both reading
and writing:

    f = codecs.open('test', encoding='utf-8', mode='w+')
    f.write(u'\u4500 blah blah blah\n')
    f.seek(0)
    print repr(f.readline()[:1])
    f.close()

Unicode character U+FEFF is used as a byte-order mark (BOM), and is
often written as the first character of a file in order to assist with
autodetection of the file's byte ordering.  Some encodings, such as
UTF-16, expect a BOM to be present at the start of a file; when such an
encoding is used, the BOM will be automatically written as the first
character and will be silently dropped when the file is read.  There
are variants of these encodings, such as 'utf-16-le' and 'utf-16-be'
for little-endian and big-endian encodings, that specify one particular
byte ordering and don't skip the BOM.

* Menu:

* Unicode filenames::
* Tips for Writing Unicode-aware Programs::
* References: References<4>.


File: python.info,  Node: Unicode filenames,  Next: Tips for Writing Unicode-aware Programs,  Up: Reading and Writing Unicode Data

10.12.3.1 Unicode filenames
...........................

Most of the operating systems in common use today support filenames
that contain arbitrary Unicode characters.  Usually this is implemented
by converting the Unicode string into some encoding that varies
depending on the system.  For example, Mac OS X uses UTF-8 while
Windows uses a configurable encoding; on Windows, Python uses the name
"mbcs" to refer to whatever the currently configured encoding is.  On
Unix systems, there will only be a filesystem encoding if you've set
the `LANG' or `LC_CTYPE' environment variables; if you haven't, the
default encoding is ASCII.

  The *note sys.getfilesystemencoding(): fc7. function returns the
encoding to use on your current system, in case you want to do the
encoding manually, but there's not much reason to bother.  When opening
a file for reading or writing, you can usually just provide the Unicode
string as the filename, and it will be automatically converted to the
right encoding for you:

    filename = u'filename\u4500abc'
    f = open(filename, 'w')
    f.write('blah\n')
    f.close()

Functions in the *note os: 128. module such as *note os.stat(): 3bd.
will also accept Unicode filenames.

  *note os.listdir(): 2cf, which returns filenames, raises an issue:
should it return the Unicode version of filenames, or should it return
8-bit strings containing the encoded versions?  *note os.listdir():
2cf. will do both, depending on whether you provided the directory path
as an 8-bit string or a Unicode string.  If you pass a Unicode string
as the path, filenames will be decoded using the filesystem's encoding
and a list of Unicode strings will be returned, while passing an 8-bit
path will return the 8-bit versions of the filenames.  For example,
assuming the default filesystem encoding is UTF-8, running the
following program:

    fn = u'filename\u4500abc'
    f = open(fn, 'w')
    f.close()

    import os
    print os.listdir('.')
    print os.listdir(u'.')

will produce the following output:

    amk:~$ python t.py
    ['.svn', 'filename\xe4\x94\x80abc', ...]
    [u'.svn', u'filename\u4500abc', ...]

The first list contains UTF-8-encoded filenames, and the second list
contains the Unicode versions.


File: python.info,  Node: Tips for Writing Unicode-aware Programs,  Next: References<4>,  Prev: Unicode filenames,  Up: Reading and Writing Unicode Data

10.12.3.2 Tips for Writing Unicode-aware Programs
.................................................

This section provides some suggestions on writing software that deals
with Unicode.

  The most important tip is:

     Software should only work with Unicode strings internally,
     converting to a particular encoding on output.

  If you attempt to write processing functions that accept both Unicode
and 8-bit strings, you will find your program vulnerable to bugs
wherever you combine the two different kinds of strings.  Python's
default encoding is ASCII, so whenever a character with an ASCII value
> 127 is in the input data, you'll get a *note UnicodeDecodeError: 945.
because that character can't be handled by the ASCII encoding.

  It's easy to miss such problems if you only test your software with
data that doesn't contain any accents; everything will seem to work,
but there's actually a bug in your program waiting for the first user
who attempts to use characters > 127.  A second tip, therefore, is:

     Include characters > 127 and, even better, characters > 255 in
     your test data.

  When using data coming from a web browser or some other untrusted
source, a common technique is to check for illegal characters in a
string before using the string in a generated command line or storing
it in a database.  If you're doing this, be careful to check the string
once it's in the form that will be used or stored; it's possible for
encodings to be used to disguise characters.  This is especially true
if the input data also specifies the encoding; many encodings leave the
commonly checked-for characters alone, but Python includes some
encodings such as `'base64'' that modify every single character.

  For example, let's say you have a content management system that
takes a Unicode filename, and you want to disallow paths with a '/'
character.  You might write this code:

    def read_file (filename, encoding):
        if '/' in filename:
            raise ValueError("'/' not allowed in filenames")
        unicode_name = filename.decode(encoding)
        f = open(unicode_name, 'r')
        # ... return contents of file ...

However, if an attacker could specify the `'base64'' encoding, they
could pass `'L2V0Yy9wYXNzd2Q='', which is the base-64 encoded form of
the string `'/etc/passwd'', to read a system file.  The above code
looks for `'/'' characters in the encoded form and misses the dangerous
character in the resulting decoded form.


File: python.info,  Node: References<4>,  Prev: Tips for Writing Unicode-aware Programs,  Up: Reading and Writing Unicode Data

10.12.3.3 References
....................

The PDF slides for Marc-Andr Lemburg's presentation "Writing
Unicode-aware Applications in Python" are available at
<<http://downloads.egenix.com/python/LSM2005-Developing-Unicode-aware-applications-in-Python.pdf>>
and discuss questions of character encodings as well as how to
internationalize and localize an application.


File: python.info,  Node: Revision History and Acknowledgements<2>,  Prev: Reading and Writing Unicode Data,  Up: Unicode HOWTO

10.12.4 Revision History and Acknowledgements
---------------------------------------------

Thanks to the following people who have noted errors or offered
suggestions on this article: Nicholas Bastin, Marius Gedminas, Kent
Johnson, Ken Krugler, Marc-Andr Lemburg, Martin von Lwis, Chad
Whitacre.

  Version 1.0: posted August 5 2005.

  Version 1.01: posted August 7 2005.  Corrects factual and markup
errors; adds several links.

  Version 1.02: posted August 16 2005.  Corrects factual errors.

  Version 1.03: posted June 20 2010.  Notes that Python 3.x is not
covered, and that the HOWTO only covers 2.x.


File: python.info,  Node: HOWTO Fetch Internet Resources Using urllib2,  Next: HOWTO Use Python in the web,  Prev: Unicode HOWTO,  Up: Python HOWTOs

10.13 HOWTO Fetch Internet Resources Using urllib2
==================================================

     Author: Michael Foord(1)

     Note: There is an French translation of an earlier revision of this
     HOWTO, available at urllib2 - Le Manuel manquant(2).

* Menu:

* Introduction: Introduction<14>.
* Fetching URLs::
* Handling Exceptions: Handling Exceptions<2>.
* info and geturl::
* Openers and Handlers::
* Basic Authentication::
* Proxies::
* Sockets and Layers::
* Footnotes::

  ---------- Footnotes ----------

  (1) http://www.voidspace.org.uk/python/index.shtml

  (2) http://www.voidspace.org.uk/python/articles/urllib2_francais.shtml


File: python.info,  Node: Introduction<14>,  Next: Fetching URLs,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.1 Introduction
--------------------

Related Articles
................

You may also find useful the following article on fetching web resources
with Python :

   * Basic Authentication(1)

          A tutorial on _Basic Authentication_, with examples in Python.

  *urllib2* is a Python(2) module for fetching URLs (Uniform Resource
Locators). It offers a very simple interface, in the form of the
_urlopen_ function. This is capable of fetching URLs using a variety of
different protocols. It also offers a slightly more complex interface
for handling common situations - like basic authentication, cookies,
proxies and so on. These are provided by objects called handlers and
openers.

  urllib2 supports fetching URLs for many "URL schemes" (identified by
the string before the ":" in URL - for example "ftp" is the URL scheme
of "<ftp://python.org/>") using their associated network protocols
(e.g. FTP, HTTP).  This tutorial focuses on the most common case, HTTP.

  For straightforward situations _urlopen_ is very easy to use. But as
soon as you encounter errors or non-trivial cases when opening HTTP
URLs, you will need some understanding of the HyperText Transfer
Protocol. The most comprehensive and authoritative reference to HTTP is RFC
2616(3). This is a technical document and not intended to be easy to
read. This HOWTO aims to illustrate using _urllib2_, with enough detail
about HTTP to help you through. It is not intended to replace the *note
urllib2: 189. docs, but is supplementary to them.

  ---------- Footnotes ----------

  (1) http://www.voidspace.org.uk/python/articles/authentication.shtml

  (2) http://www.python.org

  (3) http://tools.ietf.org/html/rfc2616.html


File: python.info,  Node: Fetching URLs,  Next: Handling Exceptions<2>,  Prev: Introduction<14>,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.2 Fetching URLs
---------------------

The simplest way to use urllib2 is as follows:

    import urllib2
    response = urllib2.urlopen('http://python.org/')
    html = response.read()

Many uses of urllib2 will be that simple (note that instead of an
'http:' URL we could have used an URL starting with 'ftp:', 'file:',
etc.).  However, it's the purpose of this tutorial to explain the more
complicated cases, concentrating on HTTP.

  HTTP is based on requests and responses - the client makes requests
and servers send responses. urllib2 mirrors this with a `Request'
object which represents the HTTP request you are making. In its
simplest form you create a Request object that specifies the URL you
want to fetch. Calling `urlopen' with this Request object returns a
response object for the URL requested. This response is a file-like
object, which means you can for example call `.read()' on the response:

    import urllib2

    req = urllib2.Request('http://www.voidspace.org.uk')
    response = urllib2.urlopen(req)
    the_page = response.read()

Note that urllib2 makes use of the same Request interface to handle all
URL schemes.  For example, you can make an FTP request like so:

    req = urllib2.Request('ftp://example.com/')

In the case of HTTP, there are two extra things that Request objects
allow you to do: First, you can pass data to be sent to the server.
Second, you can pass extra information ("metadata") _about_ the data or
the about request itself, to the server - this information is sent as
HTTP "headers".  Let's look at each of these in turn.

* Menu:

* Data::
* Headers::


File: python.info,  Node: Data,  Next: Headers,  Up: Fetching URLs

10.13.2.1 Data
..............

Sometimes you want to send data to a URL (often the URL will refer to a
CGI (Common Gateway Interface) script (1) or other web application).
With HTTP, this is often done using what's known as a *POST* request.
This is often what your browser does when you submit a HTML form that
you filled in on the web. Not all POSTs have to come from forms: you
can use a POST to transmit arbitrary data to your own application. In
the common case of HTML forms, the data needs to be encoded in a
standard way, and then passed to the Request object as the `data'
argument. The encoding is done using a function from the `urllib'
library _not_ from `urllib2'.

    import urllib
    import urllib2

    url = 'http://www.someserver.com/cgi-bin/register.cgi'
    values = {'name' : 'Michael Foord',
              'location' : 'Northampton',
              'language' : 'Python' }

    data = urllib.urlencode(values)
    req = urllib2.Request(url, data)
    response = urllib2.urlopen(req)
    the_page = response.read()

Note that other encodings are sometimes required (e.g. for file upload
from HTML forms - see HTML Specification, Form Submission(2) for more
details).

  If you do not pass the `data' argument, urllib2 uses a *GET* request.
One way in which GET and POST requests differ is that POST requests
often have "side-effects": they change the state of the system in some
way (for example by placing an order with the website for a
hundredweight of tinned spam to be delivered to your door).  Though the
HTTP standard makes it clear that POSTs are intended to _always_ cause
side-effects, and GET requests _never_ to cause side-effects, nothing
prevents a GET request from having side-effects, nor a POST requests
from having no side-effects. Data can also be passed in an HTTP GET
request by encoding it in the URL itself.

  This is done as follows:

    >>> import urllib2
    >>> import urllib
    >>> data = {}
    >>> data['name'] = 'Somebody Here'
    >>> data['location'] = 'Northampton'
    >>> data['language'] = 'Python'
    >>> url_values = urllib.urlencode(data)
    >>> print url_values  # The order may differ. #doctest: +SKIP
    name=Somebody+Here&language=Python&location=Northampton
    >>> url = 'http://www.example.com/example.cgi'
    >>> full_url = url + '?' + url_values
    >>> data = urllib2.urlopen(full_url)

Notice that the full URL is created by adding a `?' to the URL,
followed by the encoded values.

  ---------- Footnotes ----------

  (1) For an introduction to the CGI protocol see Writing Web
Applications in Python
(http://www.pyzine.com/Issue008/Section_Articles/article_CGIOne.html).

  (2) http://www.w3.org/TR/REC-html40/interact/forms.html#h-17.13


File: python.info,  Node: Headers,  Prev: Data,  Up: Fetching URLs

10.13.2.2 Headers
.................

We'll discuss here one particular HTTP header, to illustrate how to add
headers to your HTTP request.

  Some websites (1) dislike being browsed by programs, or send
different versions to different browsers (2) . By default urllib2
identifies itself as `Python-urllib/x.y' (where `x' and `y' are the
major and minor version numbers of the Python release, e.g.
`Python-urllib/2.5'), which may confuse the site, or just plain not
work. The way a browser identifies itself is through the `User-Agent'
header (3). When you create a Request object you can pass a dictionary
of headers in. The following example makes the same request as above,
but identifies itself as a version of Internet Explorer (4).

    import urllib
    import urllib2

    url = 'http://www.someserver.com/cgi-bin/register.cgi'
    user_agent = 'Mozilla/4.0 (compatible; MSIE 5.5; Windows NT)'
    values = {'name' : 'Michael Foord',
              'location' : 'Northampton',
              'language' : 'Python' }
    headers = { 'User-Agent' : user_agent }

    data = urllib.urlencode(values)
    req = urllib2.Request(url, data, headers)
    response = urllib2.urlopen(req)
    the_page = response.read()

The response also has two useful methods. See the section on *note info
and geturl: 306c.  which comes after we have a look at what happens
when things go wrong.

  ---------- Footnotes ----------

  (1) Like Google for example. The _proper_ way to use google from a
program is to use PyGoogle (http://pygoogle.sourceforge.net) of course.
See Voidspace Google
(http://www.voidspace.org.uk/python/recipebook.shtml#google) for some
examples of using the Google API.

  (2) Browser sniffing is a very bad practise for website design -
building sites using web standards is much more sensible. Unfortunately
a lot of sites still send different versions to different browsers.

  (3) The user agent for MSIE 6 is _'Mozilla/4.0 (compatible; MSIE 6.0;
Windows NT 5.1; SV1; .NET CLR 1.1.4322)'_

  (4) For details of more HTTP request headers, see Quick Reference to
HTTP Headers (http://www.cs.tut.fi/~jkorpela/http.html).


File: python.info,  Node: Handling Exceptions<2>,  Next: info and geturl,  Prev: Fetching URLs,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.3 Handling Exceptions
---------------------------

_urlopen_ raises `URLError' when it cannot handle a response (though as
usual with Python APIs, built-in exceptions such as *note ValueError:
233, *note TypeError: 215. etc. may also be raised).

  `HTTPError' is the subclass of `URLError' raised in the specific case
of HTTP URLs.

* Menu:

* URLError::
* HTTPError::
* Wrapping it Up::


File: python.info,  Node: URLError,  Next: HTTPError,  Up: Handling Exceptions<2>

10.13.3.1 URLError
..................

Often, URLError is raised because there is no network connection (no
route to the specified server), or the specified server doesn't exist.
In this case, the exception raised will have a 'reason' attribute,
which is a tuple containing an error code and a text error message.

  e.g.

    >>> req = urllib2.Request('http://www.pretend_server.org')
    >>> try: urllib2.urlopen(req)
    ... except URLError as e:
    ...    print e.reason   #doctest: +SKIP
    ...
    (4, 'getaddrinfo failed')



File: python.info,  Node: HTTPError,  Next: Wrapping it Up,  Prev: URLError,  Up: Handling Exceptions<2>

10.13.3.2 HTTPError
...................

Every HTTP response from the server contains a numeric "status code".
Sometimes the status code indicates that the server is unable to fulfil
the request. The default handlers will handle some of these responses
for you (for example, if the response is a "redirection" that requests
the client fetch the document from a different URL, urllib2 will handle
that for you). For those it can't handle, urlopen will raise an
`HTTPError'. Typical errors include '404' (page not found), '403'
(request forbidden), and '401' (authentication required).

  See section 10 of RFC 2616 for a reference on all the HTTP error
codes.

  The `HTTPError' instance raised will have an integer 'code'
attribute, which corresponds to the error sent by the server.

* Menu:

* Error Codes::


File: python.info,  Node: Error Codes,  Up: HTTPError

10.13.3.3 Error Codes
.....................

Because the default handlers handle redirects (codes in the 300 range),
and codes in the 100-299 range indicate success, you will usually only
see error codes in the 400-599 range.

  `BaseHTTPServer.BaseHTTPRequestHandler.responses' is a useful
dictionary of response codes in that shows all the response codes used
by RFC 2616. The dictionary is reproduced here for convenience

    # Table mapping response codes to messages; entries have the
    # form {code: (shortmessage, longmessage)}.
    responses = {
        100: ('Continue', 'Request received, please continue'),
        101: ('Switching Protocols',
              'Switching to new protocol; obey Upgrade header'),

        200: ('OK', 'Request fulfilled, document follows'),
        201: ('Created', 'Document created, URL follows'),
        202: ('Accepted',
              'Request accepted, processing continues off-line'),
        203: ('Non-Authoritative Information', 'Request fulfilled from cache'),
        204: ('No Content', 'Request fulfilled, nothing follows'),
        205: ('Reset Content', 'Clear input form for further input.'),
        206: ('Partial Content', 'Partial content follows.'),

        300: ('Multiple Choices',
              'Object has several resources -- see URI list'),
        301: ('Moved Permanently', 'Object moved permanently -- see URI list'),
        302: ('Found', 'Object moved temporarily -- see URI list'),
        303: ('See Other', 'Object moved -- see Method and URL list'),
        304: ('Not Modified',
              'Document has not changed since given time'),
        305: ('Use Proxy',
              'You must use proxy specified in Location to access this '
              'resource.'),
        307: ('Temporary Redirect',
              'Object moved temporarily -- see URI list'),

        400: ('Bad Request',
              'Bad request syntax or unsupported method'),
        401: ('Unauthorized',
              'No permission -- see authorization schemes'),
        402: ('Payment Required',
              'No payment -- see charging schemes'),
        403: ('Forbidden',
              'Request forbidden -- authorization will not help'),
        404: ('Not Found', 'Nothing matches the given URI'),
        405: ('Method Not Allowed',
              'Specified method is invalid for this server.'),
        406: ('Not Acceptable', 'URI not available in preferred format.'),
        407: ('Proxy Authentication Required', 'You must authenticate with '
              'this proxy before proceeding.'),
        408: ('Request Timeout', 'Request timed out; try again later.'),
        409: ('Conflict', 'Request conflict.'),
        410: ('Gone',
              'URI no longer exists and has been permanently removed.'),
        411: ('Length Required', 'Client must specify Content-Length.'),
        412: ('Precondition Failed', 'Precondition in headers is false.'),
        413: ('Request Entity Too Large', 'Entity is too large.'),
        414: ('Request-URI Too Long', 'URI is too long.'),
        415: ('Unsupported Media Type', 'Entity body in unsupported format.'),
        416: ('Requested Range Not Satisfiable',
              'Cannot satisfy request range.'),
        417: ('Expectation Failed',
              'Expect condition could not be satisfied.'),

        500: ('Internal Server Error', 'Server got itself in trouble'),
        501: ('Not Implemented',
              'Server does not support this operation'),
        502: ('Bad Gateway', 'Invalid responses from another server/proxy.'),
        503: ('Service Unavailable',
              'The server cannot process the request due to a high load'),
        504: ('Gateway Timeout',
              'The gateway server did not receive a timely response'),
        505: ('HTTP Version Not Supported', 'Cannot fulfill request.'),
        }

When an error is raised the server responds by returning an HTTP error
code _and_ an error page. You can use the `HTTPError' instance as a
response on the page returned. This means that as well as the code
attribute, it also has read, geturl, and info, methods.

    >>> req = urllib2.Request('http://www.python.org/fish.html')
    >>> try:
    ...     urllib2.urlopen(req)
    ... except urllib2.HTTPError as e:
    ...     print e.code
    ...     print e.read() #doctest: +ELLIPSIS, +NORMALIZE_WHITESPACE
    ...
    404
    <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
    ...
    <title>Page Not Found</title>
    ...



File: python.info,  Node: Wrapping it Up,  Prev: HTTPError,  Up: Handling Exceptions<2>

10.13.3.4 Wrapping it Up
........................

So if you want to be prepared for `HTTPError' _or_ `URLError' there are
two basic approaches. I prefer the second approach.

* Menu:

* Number 1::
* Number 2::


File: python.info,  Node: Number 1,  Next: Number 2,  Up: Wrapping it Up

10.13.3.5 Number 1
..................

    from urllib2 import Request, urlopen, URLError, HTTPError
    req = Request(someurl)
    try:
        response = urlopen(req)
    except HTTPError as e:
        print 'The server couldn\'t fulfill the request.'
        print 'Error code: ', e.code
    except URLError as e:
        print 'We failed to reach a server.'
        print 'Reason: ', e.reason
    else:
        # everything is fine


     Note: The `except HTTPError' _must_ come first, otherwise `except
     URLError' will _also_ catch an `HTTPError'.


File: python.info,  Node: Number 2,  Prev: Number 1,  Up: Wrapping it Up

10.13.3.6 Number 2
..................

    from urllib2 import Request, urlopen, URLError
    req = Request(someurl)
    try:
        response = urlopen(req)
    except URLError as e:
        if hasattr(e, 'reason'):
            print 'We failed to reach a server.'
            print 'Reason: ', e.reason
        elif hasattr(e, 'code'):
            print 'The server couldn\'t fulfill the request.'
            print 'Error code: ', e.code
    else:
        # everything is fine



File: python.info,  Node: info and geturl,  Next: Openers and Handlers,  Prev: Handling Exceptions<2>,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.4 info and geturl
-----------------------

The response returned by urlopen (or the `HTTPError' instance) has two
useful methods `info()' and `geturl()'.

  *geturl* - this returns the real URL of the page fetched. This is
useful because `urlopen' (or the opener object used) may have followed a
redirect. The URL of the page fetched may not be the same as the URL
requested.

  *info* - this returns a dictionary-like object that describes the page
fetched, particularly the headers sent by the server. It is currently an
`httplib.HTTPMessage' instance.

  Typical headers include 'Content-length', 'Content-type', and so on.
See the Quick Reference to HTTP Headers(1) for a useful listing of HTTP
headers with brief explanations of their meaning and use.

  ---------- Footnotes ----------

  (1) http://www.cs.tut.fi/~jkorpela/http.html


File: python.info,  Node: Openers and Handlers,  Next: Basic Authentication,  Prev: info and geturl,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.5 Openers and Handlers
----------------------------

When you fetch a URL you use an opener (an instance of the perhaps
confusingly-named *note urllib2.OpenerDirector: 1c38.). Normally we
have been using the default opener - via `urlopen' - but you can create
custom openers. Openers use handlers. All the "heavy lifting" is done
by the handlers. Each handler knows how to open URLs for a particular
URL scheme (http, ftp, etc.), or how to handle an aspect of URL
opening, for example HTTP redirections or HTTP cookies.

  You will want to create openers if you want to fetch URLs with
specific handlers installed, for example to get an opener that handles
cookies, or to get an opener that does not handle redirections.

  To create an opener, instantiate an `OpenerDirector', and then call
`.add_handler(some_handler_instance)' repeatedly.

  Alternatively, you can use `build_opener', which is a convenience
function for creating opener objects with a single function call.
`build_opener' adds several handlers by default, but provides a quick
way to add more and/or override the default handlers.

  Other sorts of handlers you might want to can handle proxies,
authentication, and other common but slightly specialised situations.

  `install_opener' can be used to make an `opener' object the (global)
default opener. This means that calls to `urlopen' will use the opener
you have installed.

  Opener objects have an `open' method, which can be called directly to
fetch urls in the same way as the `urlopen' function: there's no need
to call `install_opener', except as a convenience.


File: python.info,  Node: Basic Authentication,  Next: Proxies,  Prev: Openers and Handlers,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.6 Basic Authentication
----------------------------

To illustrate creating and installing a handler we will use the
`HTTPBasicAuthHandler'. For a more detailed discussion of this subject -
including an explanation of how Basic Authentication works - see the
Basic Authentication Tutorial(1).

  When authentication is required, the server sends a header (as well
as the 401 error code) requesting authentication.  This specifies the
authentication scheme and a 'realm'. The header looks like :
`WWW-Authenticate: SCHEME realm="REALM"'.

  e.g.

    WWW-Authenticate: Basic realm="cPanel Users"

The client should then retry the request with the appropriate name and
password for the realm included as a header in the request. This is
'basic authentication'. In order to simplify this process we can create
an instance of `HTTPBasicAuthHandler' and an opener to use this handler.

  The `HTTPBasicAuthHandler' uses an object called a password manager
to handle the mapping of URLs and realms to passwords and usernames. If
you know what the realm is (from the authentication header sent by the
server), then you can use a `HTTPPasswordMgr'. Frequently one doesn't
care what the realm is. In that case, it is convenient to use
`HTTPPasswordMgrWithDefaultRealm'. This allows you to specify a default
username and password for a URL. This will be supplied in the absence
of you providing an alternative combination for a specific realm. We
indicate this by providing `None' as the realm argument to the
`add_password' method.

  The top-level URL is the first URL that requires authentication. URLs
"deeper" than the URL you pass to .add_password() will also match.

    # create a password manager
    password_mgr = urllib2.HTTPPasswordMgrWithDefaultRealm()

    # Add the username and password.
    # If we knew the realm, we could use it instead of None.
    top_level_url = "http://example.com/foo/"
    password_mgr.add_password(None, top_level_url, username, password)

    handler = urllib2.HTTPBasicAuthHandler(password_mgr)

    # create "opener" (OpenerDirector instance)
    opener = urllib2.build_opener(handler)

    # use the opener to fetch a URL
    opener.open(a_url)

    # Install the opener.
    # Now all calls to urllib2.urlopen use our opener.
    urllib2.install_opener(opener)


     Note: In the above example we only supplied our
     `HTTPBasicAuthHandler' to `build_opener'. By default openers have
     the handlers for normal situations - `ProxyHandler' (if a proxy
     setting such as an `http_proxy' environment variable is set),
     `UnknownHandler', `HTTPHandler', `HTTPDefaultErrorHandler',
     `HTTPRedirectHandler', `FTPHandler', `FileHandler',
     `HTTPErrorProcessor'.

  `top_level_url' is in fact _either_ a full URL (including the 'http:'
scheme component and the hostname and optionally the port number) e.g.
"<http://example.com/>" _or_ an "authority" (i.e. the hostname,
optionally including the port number) e.g. "example.com" or
"example.com:8080" (the latter example includes a port number).  The
authority, if present, must NOT contain the "userinfo" component - for
example "joe@password:example.com" is not correct.

  ---------- Footnotes ----------

  (1) http://www.voidspace.org.uk/python/articles/authentication.shtml


File: python.info,  Node: Proxies,  Next: Sockets and Layers,  Prev: Basic Authentication,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.7 Proxies
---------------

*urllib2* will auto-detect your proxy settings and use those. This is
through the `ProxyHandler', which is part of the normal handler chain
when a proxy setting is detected.  Normally that's a good thing, but
there are occasions when it may not be helpful (1). One way to do this
is to setup our own `ProxyHandler', with no proxies defined. This is
done using similar steps to setting up a Basic Authentication(2)
handler :

    >>> proxy_support = urllib2.ProxyHandler({})
    >>> opener = urllib2.build_opener(proxy_support)
    >>> urllib2.install_opener(opener)


     Note: Currently `urllib2' _does not_ support fetching of `https'
     locations through a proxy.  However, this can be enabled by
     extending urllib2 as shown in the recipe (3).

  ---------- Footnotes ----------

  (1) In my case I have to use a proxy to access the internet at work.
If you attempt to fetch _localhost_ URLs through this proxy it blocks
them. IE is set to use the proxy, which urllib2 picks up on. In order
to test scripts with a localhost server, I have to prevent urllib2 from
using the proxy.

  (2) http://www.voidspace.org.uk/python/articles/authentication.shtml

  (3) urllib2 opener for SSL proxy (CONNECT method): ASPN Cookbook
Recipe (http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/456195).


File: python.info,  Node: Sockets and Layers,  Next: Footnotes,  Prev: Proxies,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.8 Sockets and Layers
--------------------------

The Python support for fetching resources from the web is layered.
urllib2 uses the httplib library, which in turn uses the socket library.

  As of Python 2.3 you can specify how long a socket should wait for a
response before timing out. This can be useful in applications which
have to fetch web pages. By default the socket module has _no timeout_
and can hang. Currently, the socket timeout is not exposed at the
httplib or urllib2 levels.  However, you can set the default timeout
globally for all sockets using

    import socket
    import urllib2

    # timeout in seconds
    timeout = 10
    socket.setdefaulttimeout(timeout)

    # this call to urllib2.urlopen now uses the default timeout
    # we have set in the socket module
    req = urllib2.Request('http://www.voidspace.org.uk')
    response = urllib2.urlopen(req)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 



File: python.info,  Node: Footnotes,  Prev: Sockets and Layers,  Up: HOWTO Fetch Internet Resources Using urllib2

10.13.9 Footnotes
-----------------

This document was reviewed and revised by John Lee.


File: python.info,  Node: HOWTO Use Python in the web,  Next: Argparse Tutorial,  Prev: HOWTO Fetch Internet Resources Using urllib2,  Up: Python HOWTOs

10.14 HOWTO Use Python in the web
=================================

     Author: Marek Kubica

Abstract
........

This document shows how Python fits into the web.  It presents some ways
to integrate Python with a web server, and general practices useful for
developing web sites.

  Programming for the Web has become a hot topic since the rise of "Web
2.0", which focuses on user-generated content on web sites.  It has
always been possible to use Python for creating web sites, but it was a
rather tedious task.  Therefore, many frameworks and helper tools have
been created to assist developers in creating faster and more robust
sites.  This HOWTO describes some of the methods used to combine Python
with a web server to create dynamic content.  It is not meant as a
complete introduction, as this topic is far too broad to be covered in
one single document.  However, a short overview of the most popular
libraries is provided.

See also
........

While this HOWTO tries to give an overview of Python in the web, it
cannot always be as up to date as desired.  Web development in Python
is rapidly moving forward, so the wiki page on Web Programming(1) may
be more in sync with recent development.

* Menu:

* The Low-Level View::
* Step back; WSGI: Step back WSGI.
* Model-View-Controller::
* Ingredients for Websites::
* Frameworks::

The Low-Level View

* Common Gateway Interface::
* mod_python::
* FastCGI and SCGI::
* mod_wsgi::

Common Gateway Interface

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

FastCGI and SCGI

* Setting up FastCGI::

Step back: WSGI

* WSGI Servers::
* Case study; MoinMoin: Case study MoinMoin.

Ingredients for Websites

* Templates::
* Data persistence::

Frameworks

* Some notable frameworks::

Some notable frameworks

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/WebProgramming


File: python.info,  Node: The Low-Level View,  Next: Step back WSGI,  Up: HOWTO Use Python in the web

10.14.1 The Low-Level View
--------------------------

When a user enters a web site, their browser makes a connection to the
site's web server (this is called the _request_).  The server looks up
the file in the file system and sends it back to the user's browser,
which displays it (this is the _response_).  This is roughly how the
underlying protocol, HTTP, works.

  Dynamic web sites are not based on files in the file system, but
rather on programs which are run by the web server when a request comes
in, and which _generate_ the content that is returned to the user.
They can do all sorts of useful things, like display the postings of a
bulletin board, show your email, configure software, or just display
the current time.  These programs can be written in any programming
language the server supports.  Since most servers support Python, it is
easy to use Python to create dynamic web sites.

  Most HTTP servers are written in C or C++, so they cannot execute
Python code directly - a bridge is needed between the server and the
program.  These bridges, or rather interfaces, define how programs
interact with the server.  There have been numerous attempts to create
the best possible interface, but there are only a few worth mentioning.

  Not every web server supports every interface.  Many web servers only
support old, now-obsolete interfaces; however, they can often be
extended using third-party modules to support newer ones.

* Menu:

* Common Gateway Interface::
* mod_python::
* FastCGI and SCGI::
* mod_wsgi::

Common Gateway Interface

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

FastCGI and SCGI

* Setting up FastCGI::


File: python.info,  Node: Common Gateway Interface,  Next: mod_python,  Up: The Low-Level View

10.14.1.1 Common Gateway Interface
..................................

This interface, most commonly referred to as "CGI", is the oldest, and
is supported by nearly every web server out of the box.  Programs using
CGI to communicate with their web server need to be started by the
server for every request.  So, every request starts a new Python
interpreter - which takes some time to start up - thus making the whole
interface only usable for low load situations.

  The upside of CGI is that it is simple - writing a Python program
which uses CGI is a matter of about three lines of code.  This
simplicity comes at a price: it does very few things to help the
developer.

  Writing CGI programs, while still possible, is no longer recommended.
With *note WSGI: 307d, a topic covered later in this document, it is
possible to write programs that emulate CGI, so they can be run as CGI
if no better option is available.

See also
........

The Python standard library includes some modules that are helpful for
creating plain CGI programs:

   * *note cgi: 5c. - Handling of user input in CGI scripts

   * *note cgitb: 5e. - Displays nice tracebacks when errors happen in
     CGI applications, instead of presenting a "500 Internal Server
     Error" message

  The Python wiki features a page on CGI scripts(1) with some
additional information about CGI in Python.

* Menu:

* Simple script for testing CGI::
* Setting up CGI on your own server::
* Common problems with CGI scripts::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/CgiScripts


File: python.info,  Node: Simple script for testing CGI,  Next: Setting up CGI on your own server,  Up: Common Gateway Interface

10.14.1.2 Simple script for testing CGI
.......................................

To test whether your web server works with CGI, you can use this short
and simple CGI program:

    #!/usr/bin/env python
    # -*- coding: UTF-8 -*-

    # enable debugging
    import cgitb
    cgitb.enable()

    print "Content-Type: text/plain;charset=utf-8"
    print

    print "Hello World!"

Depending on your web server configuration, you may need to save this
code with a `.py' or `.cgi' extension.  Additionally, this file may
also need to be in a `cgi-bin' folder, for security reasons.

  You might wonder what the `cgitb' line is about.  This line makes it
possible to display a nice traceback instead of just crashing and
displaying an "Internal Server Error" in the user's browser.  This is
useful for debugging, but it might risk exposing some confidential data
to the user.  You should not use `cgitb' in production code for this
reason.  You should _always_ catch exceptions, and display proper error
pages - end-users don't like to see nondescript "Internal Server
Errors" in their browsers.


File: python.info,  Node: Setting up CGI on your own server,  Next: Common problems with CGI scripts,  Prev: Simple script for testing CGI,  Up: Common Gateway Interface

10.14.1.3 Setting up CGI on your own server
...........................................

If you don't have your own web server, this does not apply to you.  You
can check whether it works as-is, and if not you will need to talk to
the administrator of your web server. If it is a big host, you can try
filing a ticket asking for Python support.

  If you are your own administrator or want to set up CGI for testing
purposes on your own computers, you have to configure it by yourself.
There is no single way to configure CGI, as there are many web servers
with different configuration options.  Currently the most widely used
free web server is Apache HTTPd(1), or Apache for short. Apache can be
easily installed on nearly every system using the system's package
management tool.  lighttpd(2) is another alternative and is said to
have better performance.  On many systems this server can also be
installed using the package management tool, so manually compiling the
web server may not be needed.

   * On Apache you can take a look at the Dynamic Content with CGI(3)
     tutorial, where everything is described.  Most of the time it is
     enough just to set `+ExecCGI'.  The tutorial also describes the
     most common gotchas that might arise.

   * On lighttpd you need to use the CGI module(4), which can be
     configured in a straightforward way.  It boils down to setting
     `cgi.assign' properly.

  ---------- Footnotes ----------

  (1) http://httpd.apache.org/

  (2) http://www.lighttpd.net

  (3) http://httpd.apache.org/docs/2.2/howto/cgi.html

  (4) http://redmine.lighttpd.net/wiki/lighttpd/Docs:ModCGI


File: python.info,  Node: Common problems with CGI scripts,  Prev: Setting up CGI on your own server,  Up: Common Gateway Interface

10.14.1.4 Common problems with CGI scripts
..........................................

Using CGI sometimes leads to small annoyances while trying to get these
scripts to run.  Sometimes a seemingly correct script does not work as
expected, the cause being some small hidden problem that's difficult to
spot.

  Some of these potential problems are:

   * The Python script is not marked as executable.  When CGI scripts
     are not executable most web servers will let the user download it,
     instead of running it and sending the output to the user.  For CGI
     scripts to run properly on Unix-like operating systems, the `+x'
     bit needs to be set.  Using `chmod a+x your_script.py' may solve
     this problem.

   * On a Unix-like system, The line endings in the program file must
     be Unix style line endings.  This is important because the web
     server checks the first line of the script (called shebang) and
     tries to run the program specified there.  It gets easily confused
     by Windows line endings (Carriage Return & Line Feed, also called
     CRLF), so you have to convert the file to Unix line endings (only
     Line Feed, LF).  This can be done automatically by uploading the
     file via FTP in text mode instead of binary mode, but the
     preferred way is just telling your editor to save the files with
     Unix line endings.  Most editors support this.

   * Your web server must be able to read the file, and you need to
     make sure the permissions are correct.  On unix-like systems, the
     server often runs as user and group `www-data', so it might be
     worth a try to change the file ownership, or making the file world
     readable by using `chmod a+r your_script.py'.

   * The web server must know that the file you're trying to access is
     a CGI script.  Check the configuration of your web server, as it
     may be configured to expect a specific file extension for CGI
     scripts.

   * On Unix-like systems, the path to the interpreter in the shebang
     (`#!/usr/bin/env python') must be correct.  This line calls
     `/usr/bin/env' to find Python, but it will fail if there is no
     `/usr/bin/env', or if Python is not in the web server's path.  If
     you know where your Python is installed, you can also use that
     full path.  The commands `whereis python' and `type -p python'
     could help you find where it is installed.  Once you know the
     path, you can change the shebang accordingly: `#!/usr/bin/python'.

   * The file must not contain a BOM (Byte Order Mark). The BOM is
     meant for determining the byte order of UTF-16 and UTF-32
     encodings, but some editors write this also into UTF-8 files.  The
     BOM interferes with the shebang line, so be sure to tell your
     editor not to write the BOM.

   * If the web server is using *note mod_python: 3081, `mod_python'
     may be having problems.  `mod_python' is able to handle CGI
     scripts by itself, but it can also be a source of issues.


File: python.info,  Node: mod_python,  Next: FastCGI and SCGI,  Prev: Common Gateway Interface,  Up: The Low-Level View

10.14.1.5 mod_python
....................

People coming from PHP often find it hard to grasp how to use Python in
the web.  Their first thought is mostly mod_python(1), because they
think that this is the equivalent to `mod_php'.  Actually, there are
many differences.  What `mod_python' does is embed the interpreter into
the Apache process, thus speeding up requests by not having to start a
Python interpreter for each request.  On the other hand, it is not
"Python intermixed with HTML" in the way that PHP is often intermixed
with HTML. The Python equivalent of that is a template engine.
`mod_python' itself is much more powerful and provides more access to
Apache internals.  It can emulate CGI, work in a "Python Server Pages"
mode (similar to JSP) which is "HTML intermingled with Python", and it
has a "Publisher" which designates one file to accept all requests and
decide what to do with them.

  `mod_python' does have some problems.  Unlike the PHP interpreter,
the Python interpreter uses caching when executing files, so changes to
a file will require the web server to be restarted.  Another problem is
the basic concept - Apache starts child processes to handle the
requests, and unfortunately every child process needs to load the whole
Python interpreter even if it does not use it.  This makes the whole
web server slower.  Another problem is that, because `mod_python' is
linked against a specific version of `libpython', it is not possible to
switch from an older version to a newer (e.g. 2.4 to 2.5) without
recompiling `mod_python'.  `mod_python' is also bound to the Apache web
server, so programs written for `mod_python' cannot easily run on other
web servers.

  These are the reasons why `mod_python' should be avoided when writing
new programs.  In some circumstances it still might be a good idea to
use `mod_python' for deployment, but WSGI makes it possible to run WSGI
programs under `mod_python' as well.

  ---------- Footnotes ----------

  (1) http://www.modpython.org/


File: python.info,  Node: FastCGI and SCGI,  Next: mod_wsgi,  Prev: mod_python,  Up: The Low-Level View

10.14.1.6 FastCGI and SCGI
..........................

FastCGI and SCGI try to solve the performance problem of CGI in another
way.  Instead of embedding the interpreter into the web server, they
create long-running background processes. There is still a module in
the web server which makes it possible for the web server to "speak"
with the background process.  As the background process is independent
of the server, it can be written in any language, including Python.
The language just needs to have a library which handles the
communication with the webserver.

  The difference between FastCGI and SCGI is very small, as SCGI is
essentially just a "simpler FastCGI".  As the web server support for
SCGI is limited, most people use FastCGI instead, which works the same
way.  Almost everything that applies to SCGI also applies to FastCGI as
well, so we'll only cover the latter.

  These days, FastCGI is never used directly.  Just like `mod_python',
it is only used for the deployment of WSGI applications.

See also
........

   * FastCGI, SCGI, and Apache: Background and Future(1) is a
     discussion on why the concept of FastCGI and SCGI is better than
     that of mod_python.

* Menu:

* Setting up FastCGI::

  ---------- Footnotes ----------

  (1)
http://www.vmunix.com/mark/blog/archives/2006/01/02/fastcgi-scgi-and-apache-background-and-future/


File: python.info,  Node: Setting up FastCGI,  Up: FastCGI and SCGI

10.14.1.7 Setting up FastCGI
............................

Each web server requires a specific module.

   * Apache has both mod_fastcgi(1) and mod_fcgid(2).  `mod_fastcgi' is
     the original one, but it has some licensing issues, which is why
     it is sometimes considered non-free.  `mod_fcgid' is a smaller,
     compatible alternative.  One of these modules needs to be loaded
     by Apache.

   * lighttpd ships its own FastCGI module(3) as well as an SCGI
     module(4).

   * nginx(5) also supports FastCGI(6).

  Once you have installed and configured the module, you can test it
with the following WSGI-application:

    #!/usr/bin/env python
    # -*- coding: UTF-8 -*-

    from cgi import escape
    import sys, os
    from flup.server.fcgi import WSGIServer

    def app(environ, start_response):
        start_response('200 OK', [('Content-Type', 'text/html')])

        yield '<h1>FastCGI Environment</h1>'
        yield '<table>'
        for k, v in sorted(environ.items()):
             yield '<tr><th>%s</th><td>%s</td></tr>' % (escape(k), escape(v))
        yield '</table>'

    WSGIServer(app).run()

This is a simple WSGI application, but you need to install flup(7)
first, as flup handles the low level FastCGI access.

See also
........

There is some documentation on setting up Django with FastCGI(8), most
of which can be reused for other WSGI-compliant frameworks and
libraries.  Only the `manage.py' part has to be changed, the example
used here can be used instead.  Django does more or less the exact same
thing.

  ---------- Footnotes ----------

  (1) http://www.fastcgi.com/drupal/

  (2) http://httpd.apache.org/mod_fcgid/

  (3) http://redmine.lighttpd.net/wiki/lighttpd/Docs:ModFastCGI

  (4) http://redmine.lighttpd.net/wiki/lighttpd/Docs:ModSCGI

  (5) http://nginx.org/

  (6) http://wiki.nginx.org/NginxSimplePythonFCGI

  (7) http://pypi.python.org/pypi/flup/1.0

  (8) http://docs.djangoproject.com/en/dev/howto/deployment/fastcgi/


File: python.info,  Node: mod_wsgi,  Prev: FastCGI and SCGI,  Up: The Low-Level View

10.14.1.8 mod_wsgi
..................

mod_wsgi(1) is an attempt to get rid of the low level gateways.  Given
that FastCGI, SCGI, and mod_python are mostly used to deploy WSGI
applications, mod_wsgi was started to directly embed WSGI applications
into the Apache web server. mod_wsgi is specifically designed to host
WSGI applications.  It makes the deployment of WSGI applications much
easier than deployment using other low level methods, which need glue
code.  The downside is that mod_wsgi is limited to the Apache web
server; other servers would need their own implementations of mod_wsgi.

  mod_wsgi supports two modes: embedded mode, in which it integrates
with the Apache process, and daemon mode, which is more FastCGI-like.
Unlike FastCGI, mod_wsgi handles the worker-processes by itself, which
makes administration easier.

  ---------- Footnotes ----------

  (1) http://code.google.com/p/modwsgi/


File: python.info,  Node: Step back WSGI,  Next: Model-View-Controller,  Prev: The Low-Level View,  Up: HOWTO Use Python in the web

10.14.2 Step back: WSGI
-----------------------

WSGI has already been mentioned several times, so it has to be something
important.  In fact it really is, and now it is time to explain it.

  The _Web Server Gateway Interface_,  or WSGI for short, is defined in PEP
333(1) and is currently the best way to do Python web programming.
While it is great for programmers writing frameworks, a normal web
developer does not need to get in direct contact with it.  When
choosing a framework for web development it is a good idea to choose
one which supports WSGI.

  The big benefit of WSGI is the unification of the application
programming interface.  When your program is compatible with WSGI -
which at the outer level means that the framework you are using has
support for WSGI - your program can be deployed via any web server
interface for which there are WSGI wrappers.  You do not need to care
about whether the application user uses mod_python or FastCGI or
mod_wsgi - with WSGI your application will work on any gateway
interface.  The Python standard library contains its own WSGI server,
*note wsgiref: 199, which is a small web server that can be used for
testing.

  A really great WSGI feature is middleware.  Middleware is a layer
around your program which can add various functionality to it.  There
is quite a bit of middleware(2) already available.  For example,
instead of writing your own session management (HTTP is a stateless
protocol, so to associate multiple HTTP requests with a single user
your application must create and manage such state via a session), you
can just download middleware which does that, plug it in, and get on
with coding the unique parts of your application.  The same thing with
compression - there is existing middleware which handles compressing
your HTML using gzip to save on your server's bandwidth.
Authentication is another a problem easily solved using existing
middleware.

  Although WSGI may seem complex, the initial phase of learning can be
very rewarding because WSGI and the associated middleware already have
solutions to many problems that might arise while developing web sites.

* Menu:

* WSGI Servers::
* Case study; MoinMoin: Case study MoinMoin.

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0333

  (2) http://www.wsgi.org/en/latest/libraries.html


File: python.info,  Node: WSGI Servers,  Next: Case study MoinMoin,  Up: Step back WSGI

10.14.2.1 WSGI Servers
......................

The code that is used to connect to various low level gateways like CGI
or mod_python is called a _WSGI server_.  One of these servers is
`flup', which supports FastCGI and SCGI, as well as AJP(1).  Some of
these servers are written in Python, as `flup' is, but there also exist
others which are written in C and can be used as drop-in replacements.

  There are many servers already available, so a Python web application
can be deployed nearly anywhere.  This is one big advantage that Python
has compared with other web technologies.

See also
........

A good overview of WSGI-related code can be found in the WSGI
homepage(2), which contains an extensive list of WSGI servers(3) which
can be used by _any_ application supporting WSGI.

  You might be interested in some WSGI-supporting modules already
contained in the standard library, namely:

   * *note wsgiref: 199. - some tiny utilities and servers for WSGI

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Apache_JServ_Protocol

  (2) http://www.wsgi.org/en/latest/index.html

  (3) http://www.wsgi.org/en/latest/servers.html


File: python.info,  Node: Case study MoinMoin,  Prev: WSGI Servers,  Up: Step back WSGI

10.14.2.2 Case study: MoinMoin
..............................

What does WSGI give the web application developer?  Let's take a look at
an application that's been around for a while, which was written in
Python without using WSGI.

  One of the most widely used wiki software packages is MoinMoin(1).
It was created in 2000, so it predates WSGI by about three years.
Older versions needed separate code to run on CGI, mod_python, FastCGI
and standalone.

  It now includes support for WSGI.  Using WSGI, it is possible to
deploy MoinMoin on any WSGI compliant server, with no additional glue
code.  Unlike the pre-WSGI versions, this could include WSGI servers
that the authors of MoinMoin know nothing about.

  ---------- Footnotes ----------

  (1) http://moinmo.in/


File: python.info,  Node: Model-View-Controller,  Next: Ingredients for Websites,  Prev: Step back WSGI,  Up: HOWTO Use Python in the web

10.14.3 Model-View-Controller
-----------------------------

The term _MVC_ is often encountered in statements such as "framework
_foo_ supports MVC".  MVC is more about the overall organization of
code, rather than any particular API.  Many web frameworks use this
model to help the developer bring structure to their program.  Bigger
web applications can have lots of code, so it is a good idea to have an
effective structure right from the beginning.  That way, even users of
other frameworks (or even other languages, since MVC is not
Python-specific) can easily understand the code, given that they are
already familiar with the MVC structure.

  MVC stands for three components:

   * The _model_.  This is the data that will be displayed and
     modified.  In Python frameworks, this component is often
     represented by the classes used by an object-relational mapper.

   * The _view_.  This component's job is to display the data of the
     model to the user.  Typically this component is implemented via
     templates.

   * The _controller_.  This is the layer between the user and the
     model.  The controller reacts to user actions (like opening some
     specific URL), tells the model to modify the data if necessary,
     and tells the view code what to display,

  While one might think that MVC is a complex design pattern, in fact
it is not.  It is used in Python because it has turned out to be useful
for creating clean, maintainable web sites.

     Note: While not all Python frameworks explicitly support MVC, it
     is often trivial to create a web site which uses the MVC pattern
     by separating the data logic (the model) from the user interaction
     logic (the controller) and the templates (the view).  That's why
     it is important not to write unnecessary Python code in the
     templates - it works against the MVC model and creates chaos in
     the code base, making it harder to understand and modify.

See also
........

The English Wikipedia has an article about the Model-View-Controller
pattern(1).  It includes a long list of web frameworks for various
programming languages.

  ---------- Footnotes ----------

  (1) http://en.wikipedia.org/wiki/Model-view-controller


File: python.info,  Node: Ingredients for Websites,  Next: Frameworks,  Prev: Model-View-Controller,  Up: HOWTO Use Python in the web

10.14.4 Ingredients for Websites
--------------------------------

Websites are complex constructs, so tools have been created to help web
developers make their code easier to write and more maintainable.
Tools like these exist for all web frameworks in all languages.
Developers are not forced to use these tools, and often there is no
"best" tool.  It is worth learning about the available tools because
they can greatly simplify the process of developing a web site.

See also
........

There are far more components than can be presented here.  The Python
wiki has a page about these components, called Web Components(1).

* Menu:

* Templates::
* Data persistence::

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/WebComponents


File: python.info,  Node: Templates,  Next: Data persistence,  Up: Ingredients for Websites

10.14.4.1 Templates
...................

Mixing of HTML and Python code is made possible by a few libraries.
While convenient at first, it leads to horribly unmaintainable code.
That's why templates exist.  Templates are, in the simplest case, just
HTML files with placeholders.  The HTML is sent to the user's browser
after filling in the placeholders.

  Python already includes two ways to build simple templates:

    >>> template = "<html><body><h1>Hello %s!</h1></body></html>"
    >>> print template % "Reader"
    <html><body><h1>Hello Reader!</h1></body></html>

    >>> from string import Template
    >>> template = Template("<html><body><h1>Hello ${name}</h1></body></html>")
    >>> print template.substitute(dict(name='Dinsdale'))
    <html><body><h1>Hello Dinsdale!</h1></body></html>

To generate complex HTML based on non-trivial model data, conditional
and looping constructs like Python's _for_ and _if_ are generally
needed.  _Template engines_ support templates of this complexity.

  There are a lot of template engines available for Python which can be
used with or without a *note framework: 308c.  Some of these define a
plain-text programming language which is easy to learn, partly because
it is limited in scope.  Others use XML, and the template output is
guaranteed to be always be valid XML.  There are many other variations.

  Some *note frameworks: 308d. ship their own template engine or
recommend one in particular.  In the absence of a reason to use a
different template engine, using the one provided by or recommended by
the framework is a good idea.

  Popular template engines include:

        * Mako(1)

        * Genshi(2)

        * Jinja(3)

See also
........

There are many template engines competing for attention, because it is
pretty easy to create them in Python.  The page Templating(4) in the
wiki lists a big, ever-growing number of these.  The three listed above
are considered "second generation" template engines and are a good
place to start.

  ---------- Footnotes ----------

  (1) http://www.makotemplates.org/

  (2) http://genshi.edgewall.org/

  (3) http://jinja.pocoo.org/2/

  (4) http://wiki.python.org/moin/Templating


File: python.info,  Node: Data persistence,  Prev: Templates,  Up: Ingredients for Websites

10.14.4.2 Data persistence
..........................

_Data persistence_, while sounding very complicated, is just about
storing data.  This data might be the text of blog entries, the
postings on a bulletin board or the text of a wiki page.  There are, of
course, a number of different ways to store information on a web server.

  Often, relational database engines like MySQL(1) or PostgreSQL(2) are
used because of their good performance when handling very large
databases consisting of millions of entries.  There is also a small
database engine called SQLite(3), which is bundled with Python in the
*note sqlite3: 15f.  module, and which uses only one file.  It has no
other dependencies.  For smaller sites SQLite is just enough.

  Relational databases are _queried_ using a language called SQL(4).
Python programmers in general do not like SQL too much, as they prefer
to work with objects.  It is possible to save Python objects into a
database using a technology called ORM(5) (Object Relational Mapping).
ORM translates all object-oriented access into SQL code under the hood,
so the developer does not need to think about it.  Most *note
frameworks: 308d. use ORMs, and it works quite well.

  A second possibility is storing data in normal, plain text files (some
times called "flat files").  This is very easy for simple sites, but
can be difficult to get right if the web site is performing many
updates to the stored data.

  A third possibility are object oriented databases (also called "object
databases").  These databases store the object data in a form that
closely parallels the way the objects are structured in memory during
program execution.  (By contrast, ORMs store the object data as rows of
data in tables and relations between those rows.)  Storing the objects
directly has the advantage that nearly all objects can be saved in a
straightforward way, unlike in relational databases where some objects
are very hard to represent.

  *note Frameworks: 308d. often give hints on which data storage method
to choose.  It is usually a good idea to stick to the data store
recommended by the framework unless the application has special
requirements better satisfied by an alternate storage mechanism.

See also
........

   * Persistence Tools(6) lists possibilities on how to save data in
     the file system.  Some of these modules are part of the standard
     library

   * Database Programming(7) helps with choosing a method for saving
     data

   * SQLAlchemy(8), the most powerful OR-Mapper for Python, and
     Elixir(9), which makes SQLAlchemy easier to use

   * SQLObject(10), another popular OR-Mapper

   * ZODB(11) and Durus(12), two object oriented databases

  ---------- Footnotes ----------

  (1) http://www.mysql.com/

  (2) http://www.postgresql.org/

  (3) http://www.sqlite.org/

  (4) http://en.wikipedia.org/wiki/SQL

  (5) http://en.wikipedia.org/wiki/Object-relational_mapping

  (6) http://wiki.python.org/moin/PersistenceTools

  (7) http://wiki.python.org/moin/DatabaseProgramming

  (8) http://www.sqlalchemy.org/

  (9) http://elixir.ematia.de/

  (10) http://www.sqlobject.org/

  (11) https://launchpad.net/zodb

  (12) http://www.mems-exchange.org/software/durus/


File: python.info,  Node: Frameworks,  Prev: Ingredients for Websites,  Up: HOWTO Use Python in the web

10.14.5 Frameworks
------------------

The process of creating code to run web sites involves writing code to
provide various services.  The code to provide a particular service
often works the same way regardless of the complexity or purpose of the
web site in question.  Abstracting these common solutions into reusable
code produces what are called "frameworks" for web development.
Perhaps the most well-known framework for web development is Ruby on
Rails, but Python has its own frameworks.  Some of these were partly
inspired by Rails, or borrowed ideas from Rails, but many existed a
long time before Rails.

  Originally Python web frameworks tended to incorporate all of the
services needed to develop web sites as a giant, integrated set of
tools.  No two web frameworks were interoperable:  a program developed
for one could not be deployed on a different one without considerable
re-engineering work.  This led to the development of "minimalist" web
frameworks that provided just the tools to communicate between the
Python code and the http protocol, with all other services to be added
on top via separate components.  Some ad hoc standards were developed
that allowed for limited interoperability between frameworks, such as a
standard that allowed different template engines to be used
interchangeably.

  Since the advent of WSGI, the Python web framework world has been
evolving toward interoperability based on the WSGI standard.  Now many
web frameworks, whether "full stack" (providing all the tools one needs
to deploy the most complex web sites) or minimalist, or anything in
between, are built from collections of reusable components that can be
used with more than one framework.

  The majority of users will probably want to select a "full stack"
framework that has an active community.  These frameworks tend to be
well documented, and provide the easiest path to producing a fully
functional web site in minimal time.

* Menu:

* Some notable frameworks::

Some notable frameworks

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::


File: python.info,  Node: Some notable frameworks,  Up: Frameworks

10.14.5.1 Some notable frameworks
.................................

There are an incredible number of frameworks, so they cannot all be
covered here.  Instead we will briefly touch on some of the most
popular.

* Menu:

* Django::
* TurboGears::
* Zope::
* Other notable frameworks::


File: python.info,  Node: Django,  Next: TurboGears,  Up: Some notable frameworks

10.14.5.2 Django
................

Django(1) is a framework consisting of several tightly coupled elements
which were written from scratch and work together very well.  It
includes an ORM which is quite powerful while being simple to use, and
has a great online administration interface which makes it possible to
edit the data in the database with a browser.  The template engine is
text-based and is designed to be usable for page designers who cannot
write Python.  It supports template inheritance and filters (which work
like Unix pipes).  Django has many handy features bundled, such as
creation of RSS feeds or generic views, which make it possible to
create web sites almost without writing any Python code.

  It has a big, international community, the members of which have
created many web sites.  There are also a lot of add-on projects which
extend Django's normal functionality.  This is partly due to Django's
well written online documentation(2) and the Django book(3).

     Note: Although Django is an MVC-style framework, it names the
     elements differently, which is described in the Django FAQ(4).

  ---------- Footnotes ----------

  (1) http://www.djangoproject.com/

  (2) http://docs.djangoproject.com/

  (3) http://www.djangobook.com/

  (4)
http://docs.djangoproject.com/en/dev/faq/general/#django-appears-to-be-a-mvc-framework-but-you-call-the-controller-the-view-and-the-view-the-template-how-come-you-don-t-use-the-standard-names


File: python.info,  Node: TurboGears,  Next: Zope,  Prev: Django,  Up: Some notable frameworks

10.14.5.3 TurboGears
....................

Another popular web framework for Python is TurboGears(1).  TurboGears
takes the approach of using already existing components and combining
them with glue code to create a seamless experience.  TurboGears gives
the user flexibility in choosing components. For example the ORM and
template engine can be changed to use packages different from those
used by default.

  The documentation can be found in the TurboGears wiki(2), where links
to screencasts can be found.  TurboGears has also an active user
community which can respond to most related questions.  There is also a
TurboGears book(3) published, which is a good starting point.

  The newest version of TurboGears, version 2.0, moves even further in
direction of WSGI support and a component-based architecture.
TurboGears 2 is based on the WSGI stack of another popular
component-based web framework, Pylons(4).

  ---------- Footnotes ----------

  (1) http://www.turbogears.org/

  (2) http://docs.turbogears.org/

  (3) http://turbogearsbook.com/

  (4) http://pylonshq.com/


File: python.info,  Node: Zope,  Next: Other notable frameworks,  Prev: TurboGears,  Up: Some notable frameworks

10.14.5.4 Zope
..............

The Zope framework is one of the "old original" frameworks.  Its current
incarnation in Zope2 is a tightly integrated full-stack framework.  One
of its most interesting feature is its tight integration with a
powerful object database called the ZODB(1) (Zope Object Database).
Because of its highly integrated nature, Zope wound up in a somewhat
isolated ecosystem:  code written for Zope wasn't very usable outside
of Zope, and vice-versa.  To solve this problem the Zope 3 effort was
started.  Zope 3 re-engineers Zope as a set of more cleanly isolated
components.  This effort was started before the advent of the WSGI
standard, but there is WSGI support for Zope 3 from the Repoze(2)
project.  Zope components have many years of production use behind
them, and the Zope 3 project gives access to these components to the
wider Python community.  There is even a separate framework based on
the Zope components: Grok(3).

  Zope is also the infrastructure used by the Plone(4) content
management system, one of the most powerful and popular content
management systems available.

  ---------- Footnotes ----------

  (1) https://launchpad.net/zodb

  (2) http://repoze.org/

  (3) http://grok.zope.org/

  (4) http://plone.org/


File: python.info,  Node: Other notable frameworks,  Prev: Zope,  Up: Some notable frameworks

10.14.5.5 Other notable frameworks
..................................

Of course these are not the only frameworks that are available.  There
are many other frameworks worth mentioning.

  Another framework that's already been mentioned is Pylons(1).  Pylons
is much like TurboGears, but with an even stronger emphasis on
flexibility, which comes at the cost of being more difficult to use.
Nearly every component can be exchanged, which makes it necessary to
use the documentation of every single component, of which there are
many.  Pylons builds upon Paste(2), an extensive set of tools which are
handy for WSGI.

  And that's still not everything.  The most up-to-date information can
always be found in the Python wiki.

See also
........

The Python wiki contains an extensive list of web frameworks(3).

  Most frameworks also have their own mailing lists and IRC channels,
look out for these on the projects' web sites.  There is also a general
"Python in the Web" IRC channel on freenode called #python.web(4).

  ---------- Footnotes ----------

  (1) http://pylonshq.com/

  (2) http://pythonpaste.org/

  (3) http://wiki.python.org/moin/WebFrameworks

  (4) http://wiki.python.org/moin/PoundPythonWeb


File: python.info,  Node: Argparse Tutorial,  Prev: HOWTO Use Python in the web,  Up: Python HOWTOs

10.15 Argparse Tutorial
=======================

     author: Tshepang Lekhonkhobe
This tutorial is intended to be a gentle introduction to *note
argparse: d, the recommended command-line parsing module in the Python
standard library.

     Note: There are two other modules that fulfill the same task,
     namely *note getopt: de. (an equivalent for `getopt()' from the C
     language) and the deprecated *note optparse: 127.  Note also that
     *note argparse: d. is based on *note optparse: 127, and therefore
     very similar in terms of usage.

* Menu:

* Concepts::
* The basics::
* Introducing Positional arguments::
* Introducing Optional arguments::
* Combining Positional and Optional arguments::
* Getting a little more advanced::
* Conclusion::


File: python.info,  Node: Concepts,  Next: The basics,  Up: Argparse Tutorial

10.15.1 Concepts
----------------

Let's show the sort of functionality that we are going to explore in
this introductory tutorial by making use of the *ls* command:

    $ ls
    cpython  devguide  prog.py  pypy  rm-unused-function.patch
    $ ls pypy
    ctypes_configure  demo  dotviewer  include  lib_pypy  lib-python ...
    $ ls -l
    total 20
    drwxr-xr-x 19 wena wena 4096 Feb 18 18:51 cpython
    drwxr-xr-x  4 wena wena 4096 Feb  8 12:04 devguide
    -rwxr-xr-x  1 wena wena  535 Feb 19 00:05 prog.py
    drwxr-xr-x 14 wena wena 4096 Feb  7 00:59 pypy
    -rw-r--r--  1 wena wena  741 Feb 18 01:01 rm-unused-function.patch
    $ ls --help
    Usage: ls [OPTION]... [FILE]...
    List information about the FILEs (the current directory by default).
    Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.
    ...

A few concepts we can learn from the four commands:

   * The *ls* command is useful when run without any options at all. It
     defaults to displaying the contents of the current directory.

   * If we want beyond what it provides by default, we tell it a bit
     more. In this case, we want it to display a different directory,
     `pypy'.  What we did is specify what is known as a positional
     argument. It's named so because the program should know what to do
     with the value, solely based on where it appears on the command
     line. This concept is more relevant to a command like *cp*, whose
     most basic usage is `cp SRC DEST'.  The first position is _what
     you want copied,_ and the second position is _where you want it
     copied to_.

   * Now, say we want to change behaviour of the program. In our
     example, we display more info for each file instead of just
     showing the file names.  The `-l' in that case is known as an
     optional argument.

   * That's a snippet of the help text. It's very useful in that you can
     come across a program you have never used before, and can figure
     out how it works simply by reading it's help text.


File: python.info,  Node: The basics,  Next: Introducing Positional arguments,  Prev: Concepts,  Up: Argparse Tutorial

10.15.2 The basics
------------------

Let us start with a very simple example which does (almost) nothing:

    import argparse
    parser = argparse.ArgumentParser()
    parser.parse_args()

Following is a result of running the code:

    $ python prog.py
    $ python prog.py --help
    usage: prog.py [-h]

    optional arguments:
      -h, --help  show this help message and exit
    $ python prog.py --verbose
    usage: prog.py [-h]
    prog.py: error: unrecognized arguments: --verbose
    $ python prog.py foo
    usage: prog.py [-h]
    prog.py: error: unrecognized arguments: foo

Here is what is happening:

   * Running the script without any options results in nothing
     displayed to stdout. Not so useful.

   * The second one starts to display the usefulness of the *note
     argparse: d.  module. We have done almost nothing, but already we
     get a nice help message.

   * The `--help' option, which can also be shortened to `-h', is the
     only option we get for free (i.e. no need to specify it).
     Specifying anything else results in an error. But even then, we do
     get a useful usage message, also for free.


File: python.info,  Node: Introducing Positional arguments,  Next: Introducing Optional arguments,  Prev: The basics,  Up: Argparse Tutorial

10.15.3 Introducing Positional arguments
----------------------------------------

An example:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("echo")
    args = parser.parse_args()
    print args.echo

And running the code:

    $ python prog.py
    usage: prog.py [-h] echo
    prog.py: error: the following arguments are required: echo
    $ python prog.py --help
    usage: prog.py [-h] echo

    positional arguments:
      echo

    optional arguments:
      -h, --help  show this help message and exit
    $ python prog.py foo
    foo

Here is what's happening:

   * We've added the `add_argument()' method, which is what we use to
     specify which command-line options the program is willing to
     accept. In this case, I've named it `echo' so that it's in line
     with its function.

   * Calling our program now requires us to specify an option.

   * The `parse_args()' method actually returns some data from the
     options specified, in this case, `echo'.

   * The variable is some form of 'magic' that *note argparse: d.
     performs for free (i.e. no need to specify which variable that
     value is stored in).  You will also notice that its name matches
     the string argument given to the method, `echo'.

  Note however that, although the help display looks nice and all, it
currently is not as helpful as it can be. For example we see that we
got `echo' as a positional argument, but we don't know what it does,
other than by guessing or by reading the source code. So, let's make it
a bit more useful:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("echo", help="echo the string you use here")
    args = parser.parse_args()
    print args.echo

And we get:

    $ python prog.py -h
    usage: prog.py [-h] echo

    positional arguments:
      echo        echo the string you use here

    optional arguments:
      -h, --help  show this help message and exit

Now, how about doing something even more useful:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", help="display a square of a given number")
    args = parser.parse_args()
    print args.square**2

Following is a result of running the code:

    $ python prog.py 4
    Traceback (most recent call last):
      File "prog.py", line 5, in <module>
        print args.square**2
    TypeError: unsupported operand type(s) for ** or pow(): 'str' and 'int'

That didn't go so well. That's because *note argparse: d. treats the
options we give it as strings, unless we tell it otherwise. So, let's
tell *note argparse: d. to treat that input as an integer:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", help="display a square of a given number",
                        type=int)
    args = parser.parse_args()
    print args.square**2

Following is a result of running the code:

    $ python prog.py 4
    16
    $ python prog.py four
    usage: prog.py [-h] square
    prog.py: error: argument square: invalid int value: 'four'

That went well. The program now even helpfully quits on bad illegal
input before proceeding.


File: python.info,  Node: Introducing Optional arguments,  Next: Combining Positional and Optional arguments,  Prev: Introducing Positional arguments,  Up: Argparse Tutorial

10.15.4 Introducing Optional arguments
--------------------------------------

So far we, have been playing with positional arguments. Let us have a
look on how to add optional ones:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--verbosity", help="increase output verbosity")
    args = parser.parse_args()
    if args.verbosity:
        print "verbosity turned on"

And the output:

    $ python prog.py --verbosity 1
    verbosity turned on
    $ python prog.py
    $ python prog.py --help
    usage: prog.py [-h] [--verbosity VERBOSITY]

    optional arguments:
      -h, --help            show this help message and exit
      --verbosity VERBOSITY
                            increase output verbosity
    $ python prog.py --verbosity
    usage: prog.py [-h] [--verbosity VERBOSITY]
    prog.py: error: argument --verbosity: expected one argument

Here is what is happening:

   * The program is written so as to display something when
     `--verbosity' is specified and display nothing when not.

   * To show that the option is actually optional, there is no error
     when running the program without it. Note that by default, if an
     optional argument isn't used, the relevant variable, in this case
     `args.verbosity', is given `None' as a value, which is the reason
     it fails the truth test of the *note if: 425. statement.

   * The help message is a bit different.

   * When using the `--verbosity' option, one must also specify some
     value, any value.

  The above example accepts arbitrary integer values for `--verbosity',
but for our simple program, only two values are actually useful, `True'
or `False'.  Let's modify the code accordingly:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--verbose", help="increase output verbosity",
                        action="store_true")
    args = parser.parse_args()
    if args.verbose:
       print "verbosity turned on"

And the output:

    $ python prog.py --verbose
    verbosity turned on
    $ python prog.py --verbose 1
    usage: prog.py [-h] [--verbose]
    prog.py: error: unrecognized arguments: 1
    $ python prog.py --help
    usage: prog.py [-h] [--verbose]

    optional arguments:
      -h, --help  show this help message and exit
      --verbose   increase output verbosity

Here is what is happening:

   * The option is now more of a flag than something that requires a
     value.  We even changed the name of the option to match that idea.
     Note that we now specify a new keyword, `action', and give it the
     value `"store_true"'. This means that, if the option is specified,
     assign the value `True' to `args.verbose'.  Not specifying it
     implies `False'.

   * It complains when you specify a value, in true spirit of what flags
     actually are.

   * Notice the different help text.

* Menu:

* Short options::


File: python.info,  Node: Short options,  Up: Introducing Optional arguments

10.15.4.1 Short options
.......................

If you are familiar with command line usage, you will notice that I
haven't yet touched on the topic of short versions of the options. It's
quite simple:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("-v", "--verbose", help="increase output verbosity",
                        action="store_true")
    args = parser.parse_args()
    if args.verbose:
        print "verbosity turned on"

And here goes:

    $ python prog.py -v
    verbosity turned on
    $ python prog.py --help
    usage: prog.py [-h] [-v]

    optional arguments:
      -h, --help     show this help message and exit
      -v, --verbose  increase output verbosity

Note that the new ability is also reflected in the help text.


File: python.info,  Node: Combining Positional and Optional arguments,  Next: Getting a little more advanced,  Prev: Introducing Optional arguments,  Up: Argparse Tutorial

10.15.5 Combining Positional and Optional arguments
---------------------------------------------------

Our program keeps growing in complexity:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", type=int,
                        help="display a square of a given number")
    parser.add_argument("-v", "--verbose", action="store_true",
                        help="increase output verbosity")
    args = parser.parse_args()
    answer = args.square**2
    if args.verbose:
        print "the square of {} equals {}".format(args.square, answer)
    else:
        print answer

And now the output:

    $ python prog.py
    usage: prog.py [-h] [-v] square
    prog.py: error: the following arguments are required: square
    $ python prog.py 4
    16
    $ python prog.py 4 --verbose
    the square of 4 equals 16
    $ python prog.py --verbose 4
    the square of 4 equals 16


   * We've brought back a positional argument, hence the complaint.

   * Note that the order does not matter.

  How about we give this program of ours back the ability to have
multiple verbosity values, and actually get to use them:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", type=int,
                        help="display a square of a given number")
    parser.add_argument("-v", "--verbosity", type=int,
                        help="increase output verbosity")
    args = parser.parse_args()
    answer = args.square**2
    if args.verbosity == 2:
        print "the square of {} equals {}".format(args.square, answer)
    elif args.verbosity == 1:
        print "{}^2 == {}".format(args.square, answer)
    else:
        print answer

And the output:

    $ python prog.py 4
    16
    $ python prog.py 4 -v
    usage: prog.py [-h] [-v VERBOSITY] square
    prog.py: error: argument -v/--verbosity: expected one argument
    $ python prog.py 4 -v 1
    4^2 == 16
    $ python prog.py 4 -v 2
    the square of 4 equals 16
    $ python prog.py 4 -v 3
    16

These all look good except the last one, which exposes a bug in our
program.  Let's fix it by restricting the values the `--verbosity'
option can accept:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", type=int,
                        help="display a square of a given number")
    parser.add_argument("-v", "--verbosity", type=int, choices=[0, 1, 2],
                        help="increase output verbosity")
    args = parser.parse_args()
    answer = args.square**2
    if args.verbosity == 2:
        print "the square of {} equals {}".format(args.square, answer)
    elif args.verbosity == 1:
        print "{}^2 == {}".format(args.square, answer)
    else:
        print answer

And the output:

    $ python prog.py 4 -v 3
    usage: prog.py [-h] [-v {0,1,2}] square
    prog.py: error: argument -v/--verbosity: invalid choice: 3 (choose from 0, 1, 2)
    $ python prog.py 4 -h
    usage: prog.py [-h] [-v {0,1,2}] square

    positional arguments:
      square                display a square of a given number

    optional arguments:
      -h, --help            show this help message and exit
      -v {0,1,2}, --verbosity {0,1,2}
                            increase output verbosity

Note that the change also reflects both in the error message as well as
the help string.

  Now, let's use a different approach of playing with verbosity, which
is pretty common. It also matches the way the CPython executable
handles its own verbosity argument (check the output of `python
--help'):

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", type=int,
                        help="display the square of a given number")
    parser.add_argument("-v", "--verbosity", action="count",
                        help="increase output verbosity")
    args = parser.parse_args()
    answer = args.square**2
    if args.verbosity == 2:
        print "the square of {} equals {}".format(args.square, answer)
    elif args.verbosity == 1:
        print "{}^2 == {}".format(args.square, answer)
    else:
        print answer

We have introduced another action, "count", to count the number of
occurences of a specific optional arguments:

    $ python prog.py 4
    16
    $ python prog.py 4 -v
    4^2 == 16
    $ python prog.py 4 -vv
    the square of 4 equals 16
    $ python prog.py 4 --verbosity --verbosity
    the square of 4 equals 16
    $ python prog.py 4 -v 1
    usage: prog.py [-h] [-v] square
    prog.py: error: unrecognized arguments: 1
    $ python prog.py 4 -h
    usage: prog.py [-h] [-v] square

    positional arguments:
      square           display a square of a given number

    optional arguments:
      -h, --help       show this help message and exit
      -v, --verbosity  increase output verbosity
    $ python prog.py 4 -vvv
    16


   * Yes, it's now more of a flag (similar to `action="store_true"') in
     the previous version of our script. That should explain the
     complaint.

   * It also behaves similar to "store_true" action.

   * Now here's a demonstration of what the "count" action gives.
     You've probably seen this sort of usage before.

   * And, just like the "store_true" action, if you don't specify the
     `-v' flag, that flag is considered to have `None' value.

   * As should be expected, specifying the long form of the flag, we
     should get the same output.

   * Sadly, our help output isn't very informative on the new ability
     our script has acquired, but that can always be fixed by improving
     the documentation for out script (e.g. via the `help' keyword
     argument).

   * That last output exposes a bug in our program.

  Let's fix:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", type=int,
                        help="display a square of a given number")
    parser.add_argument("-v", "--verbosity", action="count",
                        help="increase output verbosity")
    args = parser.parse_args()
    answer = args.square**2

    # bugfix: replace == with >=
    if args.verbosity >= 2:
        print "the square of {} equals {}".format(args.square, answer)
    elif args.verbosity >= 1:
        print "{}^2 == {}".format(args.square, answer)
    else:
        print answer

And this is what it gives:

    $ python prog.py 4 -vvv
    the square of 4 equals 16
    $ python prog.py 4 -vvvv
    the square of 4 equals 16
    $ python prog.py 4
    Traceback (most recent call last):
      File "prog.py", line 11, in <module>
        if args.verbosity >= 2:
    TypeError: unorderable types: NoneType() >= int()


   * First output went well, and fixes the bug we had before.  That is,
     we want any value >= 2 to be as verbose as possible.

   * Third output not so good.

  Let's fix that bug:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("square", type=int,
                        help="display a square of a given number")
    parser.add_argument("-v", "--verbosity", action="count", default=0,
                        help="increase output verbosity")
    args = parser.parse_args()
    answer = args.square**2
    if args.verbosity >= 2:
        print "the square of {} equals {}".format(args.square, answer)
    elif args.verbosity >= 1:
        print "{}^2 == {}".format(args.square, answer)
    else:
        print answer

We've just introduced yet another keyword, `default'.  We've set it to
`0' in order to make it comparable to the other int values.  Remember
that by default, if an optional argument isn't specified, it gets the
`None' value, and that cannot be compared to an int value (hence the
*note TypeError: 215. exception).

  And:

    $ python prog.py 4
    16

You can go quite far just with what we've learned so far, and we have
only scratched the surface.  The *note argparse: d. module is very
powerful, and we'll explore a bit more of it before we end this
tutorial.


File: python.info,  Node: Getting a little more advanced,  Next: Conclusion,  Prev: Combining Positional and Optional arguments,  Up: Argparse Tutorial

10.15.6 Getting a little more advanced
--------------------------------------

What if we wanted to expand our tiny program to perform other powers,
not just squares:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("x", type=int, help="the base")
    parser.add_argument("y", type=int, help="the exponent")
    parser.add_argument("-v", "--verbosity", action="count", default=0)
    args = parser.parse_args()
    answer = args.x**args.y
    if args.verbosity >= 2:
        print "{} to the power {} equals {}".format(args.x, args.y, answer)
    elif args.verbosity >= 1:
        print "{}^{} == {}".format(args.x, args.y, answer)
    else:
        print answer

Output:

    $ python prog.py
    usage: prog.py [-h] [-v] x y
    prog.py: error: the following arguments are required: x, y
    $ python prog.py -h
    usage: prog.py [-h] [-v] x y

    positional arguments:
      x                the base
      y                the exponent

    optional arguments:
      -h, --help       show this help message and exit
      -v, --verbosity
    $ python prog.py 4 2 -v
    4^2 == 16

Notice that so far we've been using verbosity level to _change_ the text
that gets displayed. The following example instead uses verbosity level
to display _more_ text instead:

    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("x", type=int, help="the base")
    parser.add_argument("y", type=int, help="the exponent")
    parser.add_argument("-v", "--verbosity", action="count", default=0)
    args = parser.parse_args()
    answer = args.x**args.y
    if args.verbosity >= 2:
        print "Running '{}'".format(__file__)
    if args.verbosity >= 1:
        print "{}^{} ==".format(args.x, args.y),
    print answer

Output:

    $ python prog.py 4 2
    16
    $ python prog.py 4 2 -v
    4^2 == 16
    $ python prog.py 4 2 -vv
    Running 'prog.py'
    4^2 == 16


* Menu:

* Conflicting options::


File: python.info,  Node: Conflicting options,  Up: Getting a little more advanced

10.15.6.1 Conflicting options
.............................

So far, we have been working with two methods of an *note
argparse.ArgumentParser: 11de. instance. Let's introduce a third one,
`add_mutually_exclusive_group()'. It allows for us to specify options
that conflict with each other. Let's also change the rest of the
program so that the new functionality makes more sense: we'll introduce
the `--quiet' option, which will be the opposite of the `--verbose' one:

    import argparse

    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group()
    group.add_argument("-v", "--verbose", action="store_true")
    group.add_argument("-q", "--quiet", action="store_true")
    parser.add_argument("x", type=int, help="the base")
    parser.add_argument("y", type=int, help="the exponent")
    args = parser.parse_args()
    answer = args.x**args.y

    if args.quiet:
        print answer
    elif args.verbose:
        print "{} to the power {} equals {}".format(args.x, args.y, answer)
    else:
        print "{}^{} == {}".format(args.x, args.y, answer)

Our program is now simpler, and we've lost some functionality for the
sake of demonstration. Anyways, here's the output:

    $ python prog.py 4 2
    4^2 == 16
    $ python prog.py 4 2 -q
    16
    $ python prog.py 4 2 -v
    4 to the power 2 equals 16
    $ python prog.py 4 2 -vq
    usage: prog.py [-h] [-v | -q] x y
    prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose
    $ python prog.py 4 2 -v --quiet
    usage: prog.py [-h] [-v | -q] x y
    prog.py: error: argument -q/--quiet: not allowed with argument -v/--verbose

That should be easy to follow. I've added that last output so you can
see the sort of flexibility you get, i.e. mixing long form options with
short form ones.

  Before we conclude, you probably want to tell your users the main
purpose of your program, just in case they don't know:

    import argparse

    parser = argparse.ArgumentParser(description="calculate X to the power of Y")
    group = parser.add_mutually_exclusive_group()
    group.add_argument("-v", "--verbose", action="store_true")
    group.add_argument("-q", "--quiet", action="store_true")
    parser.add_argument("x", type=int, help="the base")
    parser.add_argument("y", type=int, help="the exponent")
    args = parser.parse_args()
    answer = args.x**args.y

    if args.quiet:
        print answer
    elif args.verbose:
        print "{} to the power {} equals {}".format(args.x, args.y, answer)
    else:
        print "{}^{} == {}".format(args.x, args.y, answer)

Note that slight difference in the usage text. Note the `[-v | -q]',
which tells us that we can either use `-v' or `-q', but not both at the
same time:

    $ python prog.py --help
    usage: prog.py [-h] [-v | -q] x y

    calculate X to the power of Y

    positional arguments:
      x              the base
      y              the exponent

    optional arguments:
      -h, --help     show this help message and exit
      -v, --verbose
      -q, --quiet



File: python.info,  Node: Conclusion,  Prev: Getting a little more advanced,  Up: Argparse Tutorial

10.15.7 Conclusion
------------------

The *note argparse: d. module offers a lot more than shown here.  Its
docs are quite detailed and thorough, and full of examples.  Having
gone through this tutorial, you should easily digest them without
feeling overwhelmed.


File: python.info,  Node: Python Frequently Asked Questions,  Next: Glossary,  Prev: Python HOWTOs,  Up: Top

11 Python Frequently Asked Questions
************************************

* Menu:

* General Python FAQ::
* Programming FAQ::
* Design and History FAQ::
* Library and Extension FAQ::
* Extending/Embedding FAQ::
* Python on Windows FAQ::
* Graphic User Interface FAQ::
* "Why is Python Installed on my Computer?" FAQ::

General Python FAQ

* General Information::
* Python in the real world::
* Upgrading Python::

General Information

* What is Python?::
* What is the Python Software Foundation?::
* Are there copyright restrictions on the use of Python?::
* Why was Python created in the first place?::
* What is Python good for?::
* How does the Python version numbering scheme work?::
* How do I obtain a copy of the Python source?::
* How do I get documentation on Python?::
* I've never programmed before. Is there a Python tutorial?: I've never programmed before Is there a Python tutorial?.
* Is there a newsgroup or mailing list devoted to Python?::
* How do I get a beta test version of Python?::
* How do I submit bug reports and patches for Python?::
* Are there any published articles about Python that I can reference?::
* Are there any books on Python?::
* Where in the world is www.python.org located?: Where in the world is www python org located?.
* Why is it called Python?::
* Do I have to like "Monty Python's Flying Circus"?::

Python in the real world

* How stable is Python?::
* How many people are using Python?::
* Have any significant projects been done in Python?::
* What new developments are expected for Python in the future?::
* Is it reasonable to propose incompatible changes to Python?::
* Is Python Y2K (Year 2000) Compliant?: Is Python Y2K Year 2000 Compliant?.
* Is Python a good language for beginning programmers?::

Upgrading Python

* What is this bsddb185 module my application keeps complaining about?::

Programming FAQ

* General Questions::
* Core Language::
* Numbers and strings::
* Sequences (Tuples/Lists): Sequences Tuples/Lists.
* Dictionaries: Dictionaries<2>.
* Objects::
* Modules: Modules<3>.

General Questions

* Is there a source code level debugger with breakpoints, single-stepping, etc.?: Is there a source code level debugger with breakpoints single-stepping etc ?.
* Is there a tool to help find bugs or perform static analysis?::
* How can I create a stand-alone binary from a Python script?::
* Are there coding standards or a style guide for Python programs?::
* My program is too slow. How do I speed it up?: My program is too slow How do I speed it up?.

Core Language

* Why am I getting an UnboundLocalError when the variable has a value?::
* What are the rules for local and global variables in Python?::
* Why do lambdas defined in a loop with different values all return the same result?::
* How do I share global variables across modules?::
* What are the "best practices" for using import in a module?::
* How can I pass optional or keyword parameters from one function to another?::
* What is the difference between arguments and parameters?::
* How do I write a function with output parameters (call by reference)?: How do I write a function with output parameters call by reference ?.
* How do you make a higher order function in Python?::
* How do I copy an object in Python?::
* How can I find the methods or attributes of an object?::
* How can my code discover the name of an object?::
* What's up with the comma operator's precedence?::
* Is there an equivalent of C's "?;" ternary operator?: Is there an equivalent of C's "? " ternary operator?.
* Is it possible to write obfuscated one-liners in Python?::

Numbers and strings

* How do I specify hexadecimal and octal integers?::
* Why does -22 // 10 return -3?::
* How do I convert a string to a number?::
* How do I convert a number to a string?::
* How do I modify a string in place?::
* How do I use strings to call functions/methods?::
* Is there an equivalent to Perl's chomp() for removing trailing newlines from strings?: Is there an equivalent to Perl's chomp for removing trailing newlines from strings?.
* Is there a scanf() or sscanf() equivalent?: Is there a scanf or sscanf equivalent?.
* What does 'UnicodeError; ASCII [decoding,encoding] error; ordinal not in range(128)' mean?: What does 'UnicodeError ASCII [decoding encoding] error ordinal not in range 128 ' mean?.

Sequences (Tuples/Lists)

* How do I convert between tuples and lists?::
* What's a negative index?::
* How do I iterate over a sequence in reverse order?::
* How do you remove duplicates from a list?::
* How do you make an array in Python?::
* How do I create a multidimensional list?::
* How do I apply a method to a sequence of objects?::

Dictionaries

* How can I get a dictionary to display its keys in a consistent order?::
* I want to do a complicated sort; can you do a Schwartzian Transform in Python?: I want to do a complicated sort can you do a Schwartzian Transform in Python?.
* How can I sort one list by values from another list?::

Objects

* What is a class?::
* What is a method?::
* What is self?::
* How do I check if an object is an instance of a given class or of a subclass of it?::
* What is delegation?::
* How do I call a method defined in a base class from a derived class that overrides it?::
* How can I organize my code to make it easier to change the base class?::
* How do I create static class data and static class methods?::
* How can I overload constructors (or methods) in Python?: How can I overload constructors or methods in Python?.
* I try to use __spam and I get an error about _SomeClassName__spam.: I try to use __spam and I get an error about _SomeClassName__spam.
* My class defines __del__ but it is not called when I delete the object.: My class defines __del__ but it is not called when I delete the object.
* How do I get a list of all instances of a given class?::

Modules

* How do I create a .pyc file?: How do I create a pyc file?.
* How do I find the current module name?::
* How can I have modules that mutually import each other?::
* __import__('x.y.z') returns <module 'x'>; how do I get z?: __import__ 'x y z' returns <module 'x'>; how do I get z?.
* When I edit an imported module and reimport it, the changes don't show up. Why does this happen?: When I edit an imported module and reimport it the changes don't show up Why does this happen?.

Design and History FAQ

* Why does Python use indentation for grouping of statements?::
* Why am I getting strange results with simple arithmetic operations?::
* Why are floating point calculations so inaccurate?::
* Why are Python strings immutable?::
* Why must 'self' be used explicitly in method definitions and calls?::
* Why can't I use an assignment in an expression?::
* Why does Python use methods for some functionality (e.g. list.index()) but functions for other (e.g. len(list))?: Why does Python use methods for some functionality e g list index but functions for other e g len list ?.
* Why is join() a string method instead of a list or tuple method?: Why is join a string method instead of a list or tuple method?.
* How fast are exceptions?::
* Why isn't there a switch or case statement in Python?::
* Can't you emulate threads in the interpreter instead of relying on an OS-specific thread implementation?::
* Why can't lambda forms contain statements?::
* Can Python be compiled to machine code, C or some other language?: Can Python be compiled to machine code C or some other language?.
* How does Python manage memory?::
* Why isn't all memory freed when Python exits?::
* Why are there separate tuple and list data types?::
* How are lists implemented?::
* How are dictionaries implemented?::
* Why must dictionary keys be immutable?::
* Why doesn't list.sort() return the sorted list?: Why doesn't list sort return the sorted list?.
* How do you specify and enforce an interface spec in Python?::
* Why are default values shared between objects?::
* Why is there no goto?::
* Why can't raw strings (r-strings) end with a backslash?: Why can't raw strings r-strings end with a backslash?.
* Why doesn't Python have a "with" statement for attribute assignments?::
* Why are colons required for the if/while/def/class statements?::
* Why does Python allow commas at the end of lists and tuples?::

Library and Extension FAQ

* General Library Questions::
* Common tasks::
* Threads::
* Input and Output: Input and Output<2>.
* Network/Internet Programming::
* Databases::
* Mathematics and Numerics::

General Library Questions

* How do I find a module or application to perform task X?::
* Where is the math.py (socket.py, regex.py, etc.) source file?: Where is the math py socket py regex py etc source file?.
* How do I make a Python script executable on Unix?::
* Is there a curses/termcap package for Python?::
* Is there an equivalent to C's onexit() in Python?: Is there an equivalent to C's onexit in Python?.
* Why don't my signal handlers work?::

Common tasks

* How do I test a Python program or component?::
* How do I create documentation from doc strings?::
* How do I get a single keypress at a time?::

Threads

* How do I program using threads?::
* None of my threads seem to run; why?: None of my threads seem to run why?.
* How do I parcel out work among a bunch of worker threads?::
* What kinds of global value mutation are thread-safe?::
* Can't we get rid of the Global Interpreter Lock?::

Input and Output

* How do I delete a file? (And other file questions...): How do I delete a file? And other file questions.
* How do I copy a file?::
* How do I read (or write) binary data?: How do I read or write binary data?.
* I can't seem to use os.read() on a pipe created with os.popen(); why?: I can't seem to use os read on a pipe created with os popen ; why?.
* How do I run a subprocess with pipes connected to both input and output?::
* How do I access the serial (RS232) port?: How do I access the serial RS232 port?.
* Why doesn't closing sys.stdout (stdin, stderr) really close it?: Why doesn't closing sys stdout stdin stderr really close it?.

Network/Internet Programming

* What WWW tools are there for Python?::
* How can I mimic CGI form submission (METHOD=POST)?: How can I mimic CGI form submission METHOD=POST ?.
* What module should I use to help with generating HTML?::
* How do I send mail from a Python script?::
* How do I avoid blocking in the connect() method of a socket?: How do I avoid blocking in the connect method of a socket?.

Databases

* Are there any interfaces to database packages in Python?::
* How do you implement persistent objects in Python?::
* Why is cPickle so slow?::
* If my program crashes with a bsddb (or anydbm) database open, it gets corrupted. How come?: If my program crashes with a bsddb or anydbm database open it gets corrupted How come?.
* I tried to open Berkeley DB file, but bsddb produces bsddb.error; (22, 'Invalid argument'). Help! How can I restore my data?: I tried to open Berkeley DB file but bsddb produces bsddb error 22 'Invalid argument' Help! How can I restore my data?.

Mathematics and Numerics

* How do I generate random numbers in Python?::

Extending/Embedding FAQ

* Can I create my own functions in C?::
* Can I create my own functions in C++?::
* Writing C is hard; are there any alternatives?::
* How can I execute arbitrary Python statements from C?::
* How can I evaluate an arbitrary Python expression from C?::
* How do I extract C values from a Python object?::
* How do I use Py_BuildValue() to create a tuple of arbitrary length?: How do I use Py_BuildValue to create a tuple of arbitrary length?.
* How do I call an object's method from C?::
* How do I catch the output from PyErr_Print() (or anything that prints to stdout/stderr)?: How do I catch the output from PyErr_Print or anything that prints to stdout/stderr ?.
* How do I access a module written in Python from C?::
* How do I interface to C++ objects from Python?::
* I added a module using the Setup file and the make fails; why?::
* How do I debug an extension?::
* I want to compile a Python module on my Linux system, but some files are missing. Why?: I want to compile a Python module on my Linux system but some files are missing Why?.
* What does "SystemError; _PyImport_FixupExtension; module yourmodule not loaded" mean?: What does "SystemError _PyImport_FixupExtension module yourmodule not loaded" mean?.
* How do I tell "incomplete input" from "invalid input"?::
* How do I find undefined g++ symbols __builtin_new or __pure_virtual?::
* Can I create an object class with some methods implemented in C and others in Python (e.g. through inheritance)?: Can I create an object class with some methods implemented in C and others in Python e g through inheritance ?.
* When importing module X, why do I get "undefined symbol; PyUnicodeUCS2*"?: When importing module X why do I get "undefined symbol PyUnicodeUCS2*"?.

Python on Windows FAQ

* How do I run a Python program under Windows?::
* How do I make Python scripts executable?::
* Why does Python sometimes take so long to start?::
* How do I make an executable from a Python script?::
* Is a *.pyd file the same as a DLL?: Is a * pyd file the same as a DLL?.
* How can I embed Python into a Windows application?::
* How do I keep editors from inserting tabs into my Python source?::
* How do I check for a keypress without blocking?::
* How do I emulate os.kill() in Windows?: How do I emulate os kill in Windows?.
* How do I extract the downloaded documentation on Windows?::

Graphic User Interface FAQ

* What platform-independent GUI toolkits exist for Python?::
* What platform-specific GUI toolkits exist for Python?::
* Tkinter questions::

What platform-independent GUI toolkits exist for Python?

* Tkinter::
* wxWidgets::
* Qt::
* Gtk+::
* FLTK::
* FOX::
* OpenGL::

Tkinter questions

* How do I freeze Tkinter applications?::
* Can I have Tk events handled while waiting for I/O?::
* I can't get key bindings to work in Tkinter; why?: I can't get key bindings to work in Tkinter why?.

"Why is Python Installed on my Computer?" FAQ

* What is Python?: What is Python?<2>.
* Why is Python installed on my machine?::
* Can I delete Python?::


File: python.info,  Node: General Python FAQ,  Next: Programming FAQ,  Up: Python Frequently Asked Questions

11.1 General Python FAQ
=======================

* Menu:

* General Information::
* Python in the real world::
* Upgrading Python::

General Information

* What is Python?::
* What is the Python Software Foundation?::
* Are there copyright restrictions on the use of Python?::
* Why was Python created in the first place?::
* What is Python good for?::
* How does the Python version numbering scheme work?::
* How do I obtain a copy of the Python source?::
* How do I get documentation on Python?::
* I've never programmed before. Is there a Python tutorial?: I've never programmed before Is there a Python tutorial?.
* Is there a newsgroup or mailing list devoted to Python?::
* How do I get a beta test version of Python?::
* How do I submit bug reports and patches for Python?::
* Are there any published articles about Python that I can reference?::
* Are there any books on Python?::
* Where in the world is www.python.org located?: Where in the world is www python org located?.
* Why is it called Python?::
* Do I have to like "Monty Python's Flying Circus"?::

Python in the real world

* How stable is Python?::
* How many people are using Python?::
* Have any significant projects been done in Python?::
* What new developments are expected for Python in the future?::
* Is it reasonable to propose incompatible changes to Python?::
* Is Python Y2K (Year 2000) Compliant?: Is Python Y2K Year 2000 Compliant?.
* Is Python a good language for beginning programmers?::

Upgrading Python

* What is this bsddb185 module my application keeps complaining about?::


File: python.info,  Node: General Information,  Next: Python in the real world,  Up: General Python FAQ

11.1.1 General Information
--------------------------

* Menu:

* What is Python?::
* What is the Python Software Foundation?::
* Are there copyright restrictions on the use of Python?::
* Why was Python created in the first place?::
* What is Python good for?::
* How does the Python version numbering scheme work?::
* How do I obtain a copy of the Python source?::
* How do I get documentation on Python?::
* I've never programmed before. Is there a Python tutorial?: I've never programmed before Is there a Python tutorial?.
* Is there a newsgroup or mailing list devoted to Python?::
* How do I get a beta test version of Python?::
* How do I submit bug reports and patches for Python?::
* Are there any published articles about Python that I can reference?::
* Are there any books on Python?::
* Where in the world is www.python.org located?: Where in the world is www python org located?.
* Why is it called Python?::
* Do I have to like "Monty Python's Flying Circus"?::


File: python.info,  Node: What is Python?,  Next: What is the Python Software Foundation?,  Up: General Information

11.1.1.1 What is Python?
........................

Python is an interpreted, interactive, object-oriented programming
language.  It incorporates modules, exceptions, dynamic typing, very
high level dynamic data types, and classes.  Python combines remarkable
power with very clear syntax.  It has interfaces to many system calls
and libraries, as well as to various window systems, and is extensible
in C or C++.  It is also usable as an extension language for
applications that need a programmable interface.  Finally, Python is
portable: it runs on many Unix variants, on the Mac, and on PCs under
MS-DOS, Windows, Windows NT, and OS/2.

  To find out more, start with *note The Python Tutorial: 4ee.  The
Beginner's Guide to Python(1) links to other introductory tutorials and
resources for learning Python.

  ---------- Footnotes ----------

  (1) http://wiki.python.org/moin/BeginnersGuide


File: python.info,  Node: What is the Python Software Foundation?,  Next: Are there copyright restrictions on the use of Python?,  Prev: What is Python?,  Up: General Information

11.1.1.2 What is the Python Software Foundation?
................................................

The Python Software Foundation is an independent non-profit
organization that holds the copyright on Python versions 2.1 and newer.
The PSF's mission is to advance open source technology related to the
Python programming language and to publicize the use of Python.  The
PSF's home page is at <http://www.python.org/psf/>.

  Donations to the PSF are tax-exempt in the US.  If you use Python and
find it helpful, please contribute via the PSF donation page(1).

  ---------- Footnotes ----------

  (1) http://www.python.org/psf/donations/


File: python.info,  Node: Are there copyright restrictions on the use of Python?,  Next: Why was Python created in the first place?,  Prev: What is the Python Software Foundation?,  Up: General Information

11.1.1.3 Are there copyright restrictions on the use of Python?
...............................................................

You can do anything you want with the source, as long as you leave the
copyrights in and display those copyrights in any documentation about
Python that you produce.  If you honor the copyright rules, it's OK to
use Python for commercial use, to sell copies of Python in source or
binary form (modified or unmodified), or to sell products that
incorporate Python in some form.  We would still like to know about all
commercial use of Python, of course.

  See the PSF license page(1) to find further explanations and a link
to the full text of the license.

  The Python logo is trademarked, and in certain cases permission is
required to use it.  Consult the Trademark Usage Policy(2) for more
information.

  ---------- Footnotes ----------

  (1) http://python.org/psf/license/

  (2) http://www.python.org/psf/trademarks/


File: python.info,  Node: Why was Python created in the first place?,  Next: What is Python good for?,  Prev: Are there copyright restrictions on the use of Python?,  Up: General Information

11.1.1.4 Why was Python created in the first place?
...................................................

Here's a _very_ brief summary of what started it all, written by Guido
van Rossum:

     I had extensive experience with implementing an interpreted
     language in the ABC group at CWI, and from working with this group
     I had learned a lot about language design.  This is the origin of
     many Python features, including the use of indentation for
     statement grouping and the inclusion of very-high-level data types
     (although the details are all different in Python).

     I had a number of gripes about the ABC language, but also liked
     many of its features.  It was impossible to extend the ABC
     language (or its implementation) to remedy my complaints - in fact
     its lack of extensibility was one of its biggest problems.  I had
     some experience with using Modula-2+ and talked with the designers
     of Modula-3 and read the Modula-3 report.  Modula-3 is the origin
     of the syntax and semantics used for exceptions, and some other
     Python features.

     I was working in the Amoeba distributed operating system group at
     CWI.  We needed a better way to do system administration than by
     writing either C programs or Bourne shell scripts, since Amoeba
     had its own system call interface which wasn't easily accessible
     from the Bourne shell.  My experience with error handling in
     Amoeba made me acutely aware of the importance of exceptions as a
     programming language feature.

     It occurred to me that a scripting language with a syntax like ABC
     but with access to the Amoeba system calls would fill the need.  I
     realized that it would be foolish to write an Amoeba-specific
     language, so I decided that I needed a language that was generally
     extensible.

     During the 1989 Christmas holidays, I had a lot of time on my
     hand, so I decided to give it a try.  During the next year, while
     still mostly working on it in my own time, Python was used in the
     Amoeba project with increasing success, and the feedback from
     colleagues made me add many early improvements.

     In February 1991, after just over a year of development, I decided
     to post to USENET.  The rest is in the `Misc/HISTORY' file.



Local Variables:
coding: utf-8
End:
