This is
/home/melpa/melpa/working/python-info-20130916.1420/python.info,
produced by makeinfo version 4.13 from
/home/melpa/melpa/working/python-info/python.texi.

Generated by Sphinx 1.1.3.
INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY

     Python 2.7.5, September 16, 2013

     Georg Brandl

     Copyright (C) 1990-2013, Python Software Foundation


File: python.info,  Node: The numeric tower,  Next: Notes for type implementors,  Up: numbers --- Numeric abstract base classes

5.9.1.1 The numeric tower
.........................

 -- Class: numbers.Complex
     Subclasses of this type describe complex numbers and include the
     operations that work on the built-in *note complex: 1e9. type.
     These are: conversions to *note complex: 1e9. and *note bool: 435,
     *note real: c4a, *note imag: c4b, `+', `-', `*', `/', *note abs():
     5b3, *note conjugate(): c4c, `==', and `!='. All except `-' and
     `!=' are abstract.

      -- Attribute: real
          Abstract. Retrieves the real component of this number.

      -- Attribute: imag
          Abstract. Retrieves the imaginary component of this number.

      -- Method: conjugate ()
          Abstract. Returns the complex conjugate. For example,
          `(1+3j).conjugate() == (1-3j)'.

 -- Class: numbers.Real
     To *note Complex: 6e2, *note Real: 6e1. adds the operations that
     work on real numbers.

     In short, those are: a conversion to *note float: 1e8, *note
     math.trunc(): 326, *note round(): 1c2, *note math.floor(): 324,
     *note math.ceil(): 325, *note divmod(): 72a, `//', `%', `<', `<=',
     `>', and `>='.

     Real also provides defaults for *note complex(): 1e9, *note real:
     c4a, *note imag: c4b, and *note conjugate(): c4c.

 -- Class: numbers.Rational
     Subtypes *note Real: 6e1. and adds *note numerator: c4d. and *note
     denominator: c4e. properties, which should be in lowest terms.
     With these, it provides a default for *note float(): 1e8.

      -- Attribute: numerator
          Abstract.

      -- Attribute: denominator
          Abstract.

 -- Class: numbers.Integral
     Subtypes *note Rational: 323. and adds a conversion to *note int:
     1ef.  Provides defaults for *note float(): 1e8, *note numerator:
     c4d, and *note denominator: c4e.  Adds abstract methods for `**'
     and bit-string operations: `<<', `>>', `&', `^', `|', `~'.


File: python.info,  Node: Notes for type implementors,  Prev: The numeric tower,  Up: numbers --- Numeric abstract base classes

5.9.1.2 Notes for type implementors
...................................

Implementors should be careful to make equal numbers equal and hash
them to the same values. This may be subtle if there are two different
extensions of the real numbers. For example, *note fractions.Fraction:
214.  implements *note hash(): 6f8. as follows:

    def __hash__(self):
        if self.denominator == 1:
            # Get integers right.
            return hash(self.numerator)
        # Expensive check, but definitely correct.
        if self == float(self):
            return hash(float(self))
        else:
            # Use tuple's hash to avoid a high collision rate on
            # simple fractions.
            return hash((self.numerator, self.denominator))


* Menu:

* Adding More Numeric ABCs::
* Implementing the arithmetic operations::


File: python.info,  Node: Adding More Numeric ABCs,  Next: Implementing the arithmetic operations,  Up: Notes for type implementors

5.9.1.3 Adding More Numeric ABCs
................................

There are, of course, more possible ABCs for numbers, and this would be
a poor hierarchy if it precluded the possibility of adding those. You
can add `MyFoo' between *note Complex: 6e2. and *note Real: 6e1. with:

    class MyFoo(Complex): ...
    MyFoo.register(Real)



File: python.info,  Node: Implementing the arithmetic operations,  Prev: Adding More Numeric ABCs,  Up: Notes for type implementors

5.9.1.4 Implementing the arithmetic operations
..............................................

We want to implement the arithmetic operations so that mixed-mode
operations either call an implementation whose author knew about the
types of both arguments, or convert both to the nearest built in type
and do the operation there. For subtypes of *note Integral: 6e0, this
means that *note __add__(): 712. and *note __radd__(): 713. should be
defined as:

    class MyIntegral(Integral):

        def __add__(self, other):
            if isinstance(other, MyIntegral):
                return do_my_adding_stuff(self, other)
            elif isinstance(other, OtherTypeIKnowAbout):
                return do_my_other_adding_stuff(self, other)
            else:
                return NotImplemented

        def __radd__(self, other):
            if isinstance(other, MyIntegral):
                return do_my_adding_stuff(other, self)
            elif isinstance(other, OtherTypeIKnowAbout):
                return do_my_other_adding_stuff(other, self)
            elif isinstance(other, Integral):
                return int(other) + int(self)
            elif isinstance(other, Real):
                return float(other) + float(self)
            elif isinstance(other, Complex):
                return complex(other) + complex(self)
            else:
                return NotImplemented

There are 5 different cases for a mixed-type operation on subclasses of
*note Complex: 6e2. I'll refer to all of the above code that doesn't
refer to `MyIntegral' and `OtherTypeIKnowAbout' as "boilerplate". `a'
will be an instance of `A', which is a subtype of *note Complex: 6e2.
(`a : A <: Complex'), and `b : B <: Complex'. I'll consider `a + b':

       1. If `A' defines an *note __add__(): 712. which accepts `b',
          all is well.

       2. If `A' falls back to the boilerplate code, and it were to
          return a value from *note __add__(): 712, we'd miss the
          possibility that `B' defines a more intelligent *note
          __radd__(): 713, so the boilerplate should return *note
          NotImplemented: 20b. from *note __add__(): 712. (Or `A' may
          not implement *note __add__(): 712. at all.)

       3. Then `B''s *note __radd__(): 713. gets a chance. If it accepts
          `a', all is well.

       4. If it falls back to the boilerplate, there are no more
          possible methods to try, so this is where the default
          implementation should live.

       5. If `B <: A', Python tries `B.__radd__' before `A.__add__'.
          This is ok, because it was implemented with knowledge of `A',
          so it can handle those instances before delegating to *note
          Complex: 6e2.

  If `A <: Complex' and `B <: Real' without sharing any other knowledge,
then the appropriate shared operation is the one involving the built in
*note complex: 1e9, and both *note __radd__(): 713. s land there, so
`a+b == b+a'.

  Because most of the operations on any given type will be very similar,
it can be useful to define a helper function which generates the
forward and reverse instances of any given operator. For example, *note
fractions.Fraction: 214. uses:

    def _operator_fallbacks(monomorphic_operator, fallback_operator):
        def forward(a, b):
            if isinstance(b, (int, long, Fraction)):
                return monomorphic_operator(a, b)
            elif isinstance(b, float):
                return fallback_operator(float(a), b)
            elif isinstance(b, complex):
                return fallback_operator(complex(a), b)
            else:
                return NotImplemented
        forward.__name__ = '__' + fallback_operator.__name__ + '__'
        forward.__doc__ = monomorphic_operator.__doc__

        def reverse(b, a):
            if isinstance(a, Rational):
                # Includes ints.
                return monomorphic_operator(a, b)
            elif isinstance(a, numbers.Real):
                return fallback_operator(float(a), float(b))
            elif isinstance(a, numbers.Complex):
                return fallback_operator(complex(a), complex(b))
            else:
                return NotImplemented
        reverse.__name__ = '__r' + fallback_operator.__name__ + '__'
        reverse.__doc__ = monomorphic_operator.__doc__

        return forward, reverse

    def _add(a, b):
        """a + b"""
        return Fraction(a.numerator * b.denominator +
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __add__, __radd__ = _operator_fallbacks(_add, operator.add)

    # ...



File: python.info,  Node: math --- Mathematical functions,  Next: cmath --- Mathematical functions for complex numbers,  Prev: numbers --- Numeric abstract base classes,  Up: Numeric and Mathematical Modules

5.9.2 `math' -- Mathematical functions
--------------------------------------

This module is always available.  It provides access to the mathematical
functions defined by the C standard.

  These functions cannot be used with complex numbers; use the
functions of the same name from the *note cmath: 60. module if you
require support for complex numbers.  The distinction between functions
which support complex numbers and those which don't is made since most
users do not want to learn quite as much mathematics as required to
understand complex numbers.  Receiving an exception instead of a
complex result allows earlier detection of the unexpected complex
number used as a parameter, so that the programmer can determine how
and why it was generated in the first place.

  The following functions are provided by this module.  Except when
explicitly noted otherwise, all return values are floats.

* Menu:

* Number-theoretic and representation functions::
* Power and logarithmic functions::
* Trigonometric functions::
* Angular conversion::
* Hyperbolic functions::
* Special functions::
* Constants::


File: python.info,  Node: Number-theoretic and representation functions,  Next: Power and logarithmic functions,  Up: math --- Mathematical functions

5.9.2.1 Number-theoretic and representation functions
.....................................................

 -- Function: math.ceil (x)
     Return the ceiling of _x_ as a float, the smallest integer value
     greater than or equal to _x_.

 -- Function: math.copysign (x, y)
     Return _x_ with the sign of _y_.  On a platform that supports
     signed zeros, `copysign(1.0, -0.0)' returns _-1.0_.

     New in version 2.6.

 -- Function: math.fabs (x)
     Return the absolute value of _x_.

 -- Function: math.factorial (x)
     Return _x_ factorial.  Raises *note ValueError: 233. if _x_ is not
     integral or is negative.

     New in version 2.6.

 -- Function: math.floor (x)
     Return the floor of _x_ as a float, the largest integer value less
     than or equal to _x_.

 -- Function: math.fmod (x, y)
     Return `fmod(x, y)', as defined by the platform C library. Note
     that the Python expression `x % y' may not return the same result.
     The intent of the C standard is that `fmod(x, y)' be exactly
     (mathematically; to infinite precision) equal to `x - n*y' for
     some integer _n_ such that the result has the same sign as _x_ and
     magnitude less than `abs(y)'.  Python's `x % y' returns a result
     with the sign of _y_ instead, and may not be exactly computable
     for float arguments. For example, `fmod(-1e-100, 1e100)' is
     `-1e-100', but the result of Python's `-1e-100 % 1e100' is
     `1e100-1e-100', which cannot be represented exactly as a float,
     and rounds to the surprising `1e100'.  For this reason, function
     *note fmod(): 7bd. is generally preferred when working with
     floats, while Python's `x % y' is preferred when working with
     integers.

 -- Function: math.frexp (x)
     Return the mantissa and exponent of _x_ as the pair `(m, e)'.  _m_
     is a float and _e_ is an integer such that `x == m * 2**e'
     exactly. If _x_ is zero, returns `(0.0, 0)', otherwise `0.5 <=
     abs(m) < 1'.  This is used to "pick apart" the internal
     representation of a float in a portable way.

 -- Function: math.fsum (iterable)
     Return an accurate floating point sum of values in the iterable.
     Avoids loss of precision by tracking multiple intermediate partial
     sums:

         >>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
         0.9999999999999999
         >>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
         1.0

     The algorithm's accuracy depends on IEEE-754 arithmetic guarantees
     and the typical case where the rounding mode is half-even.  On
     some non-Windows builds, the underlying C library uses extended
     precision addition and may occasionally double-round an
     intermediate sum causing it to be off in its least significant bit.

     For further discussion and two alternative approaches, see the
     ASPN cookbook recipes for accurate floating point summation(1).

     New in version 2.6.

 -- Function: math.isinf (x)
     Check if the float _x_ is positive or negative infinity.

     New in version 2.6.

 -- Function: math.isnan (x)
     Check if the float _x_ is a NaN (not a number).  For more
     information on NaNs, see the IEEE 754 standards.

     New in version 2.6.

 -- Function: math.ldexp (x, i)
     Return `x * (2**i)'.  This is essentially the inverse of function
     *note frexp(): c56.

 -- Function: math.modf (x)
     Return the fractional and integer parts of _x_.  Both results
     carry the sign of _x_ and are floats.

 -- Function: math.trunc (x)
     Return the `Real' value _x_ truncated to an `Integral' (usually a
     long integer).  Uses the `__trunc__' method.

     New in version 2.6.

  Note that *note frexp(): c56. and *note modf(): c58. have a different
call/return pattern than their C equivalents: they take a single
argument and return a pair of values, rather than returning their
second return value through an 'output parameter' (there is no such
thing in Python).

  For the *note ceil(): 325, *note floor(): 324, and *note modf(): c58.
functions, note that _all_ floating-point numbers of sufficiently large
magnitude are exact integers.  Python floats typically carry no more
than 53 bits of precision (the same as the platform C double type), in
which case any float _x_ with `abs(x) >= 2**52' necessarily has no
fractional bits.

  ---------- Footnotes ----------

  (1) http://code.activestate.com/recipes/393090/


File: python.info,  Node: Power and logarithmic functions,  Next: Trigonometric functions,  Prev: Number-theoretic and representation functions,  Up: math --- Mathematical functions

5.9.2.2 Power and logarithmic functions
.......................................

 -- Function: math.exp (x)
     Return `e**x'.

 -- Function: math.expm1 (x)
     Return `e**x - 1'.  For small floats _x_, the subtraction in
     `exp(x) - 1' can result in a significant loss of precision; the
     *note expm1(): 238. function provides a way to compute this
     quantity to full precision:

         >>> from math import exp, expm1
         >>> exp(1e-5) - 1  # gives result accurate to 11 places
         1.0000050000069649e-05
         >>> expm1(1e-5)    # result accurate to full precision
         1.0000050000166668e-05

     New in version 2.7.

 -- Function: math.log (x[, base])
     With one argument, return the natural logarithm of _x_ (to base
     _e_).

     With two arguments, return the logarithm of _x_ to the given
     _base_, calculated as `log(x)/log(base)'.

     Changed in version 2.3: _base_ argument added.

 -- Function: math.log1p (x)
     Return the natural logarithm of _1+x_ (base _e_). The result is
     calculated in a way which is accurate for _x_ near zero.

     New in version 2.6.

 -- Function: math.log10 (x)
     Return the base-10 logarithm of _x_.  This is usually more accurate
     than `log(x, 10)'.

 -- Function: math.pow (x, y)
     Return `x' raised to the power `y'.  Exceptional cases follow
     Annex 'F' of the C99 standard as far as possible.  In particular,
     `pow(1.0, x)' and `pow(x, 0.0)' always return `1.0', even when `x'
     is a zero or a NaN.  If both `x' and `y' are finite, `x' is
     negative, and `y' is not an integer then `pow(x, y)' is undefined,
     and raises *note ValueError: 233.

     Unlike the built-in `**' operator, *note math.pow(): c5b. converts
     both its arguments to type *note float: 1e8.  Use `**' or the
     built-in *note pow(): 4ac. function for computing exact integer
     powers.

     Changed in version 2.6: The outcome of `1**nan' and `nan**0' was
     undefined.

 -- Function: math.sqrt (x)
     Return the square root of _x_.


File: python.info,  Node: Trigonometric functions,  Next: Angular conversion,  Prev: Power and logarithmic functions,  Up: math --- Mathematical functions

5.9.2.3 Trigonometric functions
...............................

 -- Function: math.acos (x)
     Return the arc cosine of _x_, in radians.

 -- Function: math.asin (x)
     Return the arc sine of _x_, in radians.

 -- Function: math.atan (x)
     Return the arc tangent of _x_, in radians.

 -- Function: math.atan2 (y, x)
     Return `atan(y / x)', in radians. The result is between `-pi' and
     `pi'.  The vector in the plane from the origin to point `(x, y)'
     makes this angle with the positive X axis. The point of *note
     atan2(): c61. is that the signs of both inputs are known to it, so
     it can compute the correct quadrant for the angle.  For example,
     `atan(1)' and `atan2(1, 1)' are both `pi/4', but `atan2(-1, -1)'
     is `-3*pi/4'.

 -- Function: math.cos (x)
     Return the cosine of _x_ radians.

 -- Function: math.hypot (x, y)
     Return the Euclidean norm, `sqrt(x*x + y*y)'. This is the length
     of the vector from the origin to point `(x, y)'.

 -- Function: math.sin (x)
     Return the sine of _x_ radians.

 -- Function: math.tan (x)
     Return the tangent of _x_ radians.


File: python.info,  Node: Angular conversion,  Next: Hyperbolic functions,  Prev: Trigonometric functions,  Up: math --- Mathematical functions

5.9.2.4 Angular conversion
..........................

 -- Function: math.degrees (x)
     Converts angle _x_ from radians to degrees.

 -- Function: math.radians (x)
     Converts angle _x_ from degrees to radians.


File: python.info,  Node: Hyperbolic functions,  Next: Special functions,  Prev: Angular conversion,  Up: math --- Mathematical functions

5.9.2.5 Hyperbolic functions
............................

 -- Function: math.acosh (x)
     Return the inverse hyperbolic cosine of _x_.

     New in version 2.6.

 -- Function: math.asinh (x)
     Return the inverse hyperbolic sine of _x_.

     New in version 2.6.

 -- Function: math.atanh (x)
     Return the inverse hyperbolic tangent of _x_.

     New in version 2.6.

 -- Function: math.cosh (x)
     Return the hyperbolic cosine of _x_.

 -- Function: math.sinh (x)
     Return the hyperbolic sine of _x_.

 -- Function: math.tanh (x)
     Return the hyperbolic tangent of _x_.


File: python.info,  Node: Special functions,  Next: Constants,  Prev: Hyperbolic functions,  Up: math --- Mathematical functions

5.9.2.6 Special functions
.........................

 -- Function: math.erf (x)
     Return the error function at _x_.

     New in version 2.7.

 -- Function: math.erfc (x)
     Return the complementary error function at _x_.

     New in version 2.7.

 -- Function: math.gamma (x)
     Return the Gamma function at _x_.

     New in version 2.7.

 -- Function: math.lgamma (x)
     Return the natural logarithm of the absolute value of the Gamma
     function at _x_.

     New in version 2.7.


File: python.info,  Node: Constants,  Prev: Special functions,  Up: math --- Mathematical functions

5.9.2.7 Constants
.................

 -- Data: math.pi
     The mathematical constant π = 3.141592..., to available precision.

 -- Data: math.e
     The mathematical constant e = 2.718281..., to available precision.

*CPython implementation detail:* The *note math: 10c. module consists
mostly of thin wrappers around the platform C math library functions.
Behavior in exceptional cases follows Annex F of the C99 standard where
appropriate.  The current implementation will raise *note ValueError:
233. for invalid operations like `sqrt(-1.0)' or `log(0.0)' (where C99
Annex F recommends signaling invalid operation or divide-by-zero), and
*note OverflowError: 2d8. for results that overflow (for example,
`exp(1000.0)').  A NaN will not be returned from any of the functions
above unless one or more of the input arguments was a NaN; in that case,
most functions will return a NaN, but (again following C99 Annex F)
there are some exceptions to this rule, for example `pow(float('nan'),
0.0)' or `hypot(float('nan'), float('inf'))'.

Note that Python makes no effort to distinguish signaling NaNs from
quiet NaNs, and behavior for signaling NaNs remains unspecified.
Typical behavior is to treat all NaNs as though they were quiet.

  Changed in version 2.6: Behavior in special cases now aims to follow
C99 Annex F.  In earlier versions of Python the behavior in special
cases was loosely specified.

See also
........

Module *note cmath: 60.
     Complex number versions of many of these functions.


File: python.info,  Node: cmath --- Mathematical functions for complex numbers,  Next: decimal --- Decimal fixed point and floating point arithmetic,  Prev: math --- Mathematical functions,  Up: Numeric and Mathematical Modules

5.9.3 `cmath' -- Mathematical functions for complex numbers
-----------------------------------------------------------

This module is always available.  It provides access to mathematical
functions for complex numbers.  The functions in this module accept
integers, floating-point numbers or complex numbers as arguments. They
will also accept any Python object that has either a *note
__complex__(): 2e0. or a *note __float__(): 747.  method: these methods
are used to convert the object to a complex or floating-point number,
respectively, and the function is then applied to the result of the
conversion.

     Note: On platforms with hardware and system-level support for
     signed zeros, functions involving branch cuts are continuous on
     _both_ sides of the branch cut: the sign of the zero distinguishes
     one side of the branch cut from the other.  On platforms that do
     not support signed zeros the continuity is as specified below.

* Menu:

* Conversions to and from polar coordinates::
* Power and logarithmic functions: Power and logarithmic functions<2>.
* Trigonometric functions: Trigonometric functions<2>.
* Hyperbolic functions: Hyperbolic functions<2>.
* Classification functions::
* Constants: Constants<2>.


File: python.info,  Node: Conversions to and from polar coordinates,  Next: Power and logarithmic functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.1 Conversions to and from polar coordinates
.................................................

A Python complex number `z' is stored internally using _rectangular_ or
_Cartesian_ coordinates.  It is completely determined by its _real
part_ `z.real' and its _imaginary part_ `z.imag'.  In other words:

    z == z.real + z.imag*1j

_Polar coordinates_ give an alternative way to represent a complex
number.  In polar coordinates, a complex number _z_ is defined by the
modulus _r_ and the phase angle _phi_. The modulus _r_ is the distance
from _z_ to the origin, while the phase _phi_ is the counterclockwise
angle, measured in radians, from the positive x-axis to the line
segment that joins the origin to _z_.

  The following functions can be used to convert from the native
rectangular coordinates to polar coordinates and back.

 -- Function: cmath.phase (x)
     Return the phase of _x_ (also known as the _argument_ of _x_), as a
     float.  `phase(x)' is equivalent to `math.atan2(x.imag, x.real)'.
     The result lies in the range [-π, π], and the branch cut for this
     operation lies along the negative real axis, continuous from
     above.  On systems with support for signed zeros (which includes
     most systems in current use), this means that the sign of the
     result is the same as the sign of `x.imag', even when `x.imag' is
     zero:

         >>> phase(complex(-1.0, 0.0))
         3.1415926535897931
         >>> phase(complex(-1.0, -0.0))
         -3.1415926535897931

     New in version 2.6.

     Note: The modulus (absolute value) of a complex number _x_ can be
     computed using the built-in *note abs(): 5b3. function.  There is
     no separate *note cmath: 60. module function for this operation.

 -- Function: cmath.polar (x)
     Return the representation of _x_ in polar coordinates.  Returns a
     pair `(r, phi)' where _r_ is the modulus of _x_ and phi is the
     phase of _x_.  `polar(x)' is equivalent to `(abs(x), phase(x))'.

     New in version 2.6.

 -- Function: cmath.rect (r, phi)
     Return the complex number _x_ with polar coordinates _r_ and _phi_.
     Equivalent to `r * (math.cos(phi) + math.sin(phi)*1j)'.

     New in version 2.6.


File: python.info,  Node: Power and logarithmic functions<2>,  Next: Trigonometric functions<2>,  Prev: Conversions to and from polar coordinates,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.2 Power and logarithmic functions
.......................................

 -- Function: cmath.exp (x)
     Return the exponential value `e**x'.

 -- Function: cmath.log (x[, base])
     Returns the logarithm of _x_ to the given _base_. If the _base_ is
     not specified, returns the natural logarithm of _x_. There is one
     branch cut, from 0 along the negative real axis to -∞, continuous
     from above.

     Changed in version 2.4: _base_ argument added.

 -- Function: cmath.log10 (x)
     Return the base-10 logarithm of _x_. This has the same branch cut
     as *note log(): c77.

 -- Function: cmath.sqrt (x)
     Return the square root of _x_. This has the same branch cut as
     *note log(): c77.


File: python.info,  Node: Trigonometric functions<2>,  Next: Hyperbolic functions<2>,  Prev: Power and logarithmic functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.3 Trigonometric functions
...............................

 -- Function: cmath.acos (x)
     Return the arc cosine of _x_. There are two branch cuts: One
     extends right from 1 along the real axis to ∞, continuous from
     below. The other extends left from -1 along the real axis to -∞,
     continuous from above.

 -- Function: cmath.asin (x)
     Return the arc sine of _x_. This has the same branch cuts as *note
     acos(): c7b.

 -- Function: cmath.atan (x)
     Return the arc tangent of _x_. There are two branch cuts: One
     extends from `1j' along the imaginary axis to `∞j', continuous
     from the right. The other extends from `-1j' along the imaginary
     axis to `-∞j', continuous from the left.

     Changed in version 2.6: direction of continuity of upper cut
     reversed

 -- Function: cmath.cos (x)
     Return the cosine of _x_.

 -- Function: cmath.sin (x)
     Return the sine of _x_.

 -- Function: cmath.tan (x)
     Return the tangent of _x_.


File: python.info,  Node: Hyperbolic functions<2>,  Next: Classification functions,  Prev: Trigonometric functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.4 Hyperbolic functions
............................

 -- Function: cmath.acosh (x)
     Return the hyperbolic arc cosine of _x_. There is one branch cut,
     extending left from 1 along the real axis to -∞, continuous from
     above.

 -- Function: cmath.asinh (x)
     Return the hyperbolic arc sine of _x_. There are two branch cuts:
     One extends from `1j' along the imaginary axis to `∞j', continuous
     from the right.  The other extends from `-1j' along the imaginary
     axis to `-∞j', continuous from the left.

     Changed in version 2.6: branch cuts moved to match those
     recommended by the C99 standard

 -- Function: cmath.atanh (x)
     Return the hyperbolic arc tangent of _x_. There are two branch
     cuts: One extends from `1' along the real axis to `∞', continuous
     from below. The other extends from `-1' along the real axis to
     `-∞', continuous from above.

     Changed in version 2.6: direction of continuity of right cut
     reversed

 -- Function: cmath.cosh (x)
     Return the hyperbolic cosine of _x_.

 -- Function: cmath.sinh (x)
     Return the hyperbolic sine of _x_.

 -- Function: cmath.tanh (x)
     Return the hyperbolic tangent of _x_.


File: python.info,  Node: Classification functions,  Next: Constants<2>,  Prev: Hyperbolic functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.5 Classification functions
................................

 -- Function: cmath.isinf (x)
     Return _True_ if the real or the imaginary part of x is positive
     or negative infinity.

     New in version 2.6.

 -- Function: cmath.isnan (x)
     Return _True_ if the real or imaginary part of x is not a number
     (NaN).

     New in version 2.6.


File: python.info,  Node: Constants<2>,  Prev: Classification functions,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.6 Constants
.................

 -- Data: cmath.pi
     The mathematical constant _π_, as a float.

 -- Data: cmath.e
     The mathematical constant _e_, as a float.

  Note that the selection of functions is similar, but not identical,
to that in module *note math: 10c.  The reason for having two modules
is that some users aren't interested in complex numbers, and perhaps
don't even know what they are.  They would rather have `math.sqrt(-1)'
raise an exception than return a complex number. Also note that the
functions defined in *note cmath: 60. always return a complex number,
even if the answer can be expressed as a real number (in which case the
complex number has an imaginary part of zero).

  A note on branch cuts: They are curves along which the given function
fails to be continuous.  They are a necessary feature of many complex
functions.  It is assumed that if you need to compute with complex
functions, you will understand about branch cuts.  Consult almost any
(not too elementary) book on complex variables for enlightenment.  For
information of the proper choice of branch cuts for numerical purposes,
a good reference should be the following:

See also
........

Kahan, W:  Branch cuts for complex elementary functions; or, Much ado
about nothing's sign bit.  In Iserles, A., and Powell, M. (eds.), The
state of the art in numerical analysis. Clarendon Press (1987)
pp165-211.


File: python.info,  Node: decimal --- Decimal fixed point and floating point arithmetic,  Next: fractions --- Rational numbers,  Prev: cmath --- Mathematical functions for complex numbers,  Up: Numeric and Mathematical Modules

5.9.4 `decimal' -- Decimal fixed point and floating point arithmetic
--------------------------------------------------------------------

New in version 2.4.

  The *note decimal: 80. module provides support for decimal floating
point arithmetic.  It offers several advantages over the *note float:
1e8. datatype:

   * Decimal "is based on a floating-point model which was designed
     with people in mind, and necessarily has a paramount guiding
     principle - computers must provide an arithmetic that works in the
     same way as the arithmetic that people learn at school." - excerpt
     from the decimal arithmetic specification.

   * Decimal numbers can be represented exactly.  In contrast, numbers
     like `1.1' and `2.2' do not have exact representations in binary
     floating point.  End users typically would not expect `1.1 + 2.2'
     to display as `3.3000000000000003' as it does with binary floating
     point.

   * The exactness carries over into arithmetic.  In decimal floating
     point, `0.1 + 0.1 + 0.1 - 0.3' is exactly equal to zero.  In
     binary floating point, the result is `5.5511151231257827e-017'.
     While near to zero, the differences prevent reliable equality
     testing and differences can accumulate. For this reason, decimal
     is preferred in accounting applications which have strict equality
     invariants.

   * The decimal module incorporates a notion of significant places so
     that `1.30 + 1.20' is `2.50'.  The trailing zero is kept to
     indicate significance.  This is the customary presentation for
     monetary applications. For multiplication, the "schoolbook"
     approach uses all the figures in the multiplicands.  For instance,
     `1.3 * 1.2' gives `1.56' while `1.30 * 1.20' gives `1.5600'.

   * Unlike hardware based binary floating point, the decimal module
     has a user alterable precision (defaulting to 28 places) which can
     be as large as needed for a given problem:

         >>> from decimal import *
         >>> getcontext().prec = 6
         >>> Decimal(1) / Decimal(7)
         Decimal('0.142857')
         >>> getcontext().prec = 28
         >>> Decimal(1) / Decimal(7)
         Decimal('0.1428571428571428571428571429')


   * Both binary and decimal floating point are implemented in terms of
     published standards.  While the built-in float type exposes only a
     modest portion of its capabilities, the decimal module exposes all
     required parts of the standard.  When needed, the programmer has
     full control over rounding and signal handling.  This includes an
     option to enforce exact arithmetic by using exceptions to block
     any inexact operations.

   * The decimal module was designed to support "without prejudice,
     both exact unrounded decimal arithmetic (sometimes called
     fixed-point arithmetic) and rounded floating-point arithmetic."  -
     excerpt from the decimal arithmetic specification.

  The module design is centered around three concepts:  the decimal
number, the context for arithmetic, and signals.

  A decimal number is immutable.  It has a sign, coefficient digits,
and an exponent.  To preserve significance, the coefficient digits do
not truncate trailing zeros.  Decimals also include special values such
as `Infinity', `-Infinity', and `NaN'.  The standard also
differentiates `-0' from `+0'.

  The context for arithmetic is an environment specifying precision,
rounding rules, limits on exponents, flags indicating the results of
operations, and trap enablers which determine whether signals are
treated as exceptions.  Rounding options include `ROUND_CEILING',
`ROUND_DOWN', `ROUND_FLOOR', `ROUND_HALF_DOWN', `ROUND_HALF_EVEN',
`ROUND_HALF_UP', `ROUND_UP', and `ROUND_05UP'.

  Signals are groups of exceptional conditions arising during the
course of computation.  Depending on the needs of the application,
signals may be ignored, considered as informational, or treated as
exceptions. The signals in the decimal module are: *note Clamped: c90,
*note InvalidOperation: 2d9, *note DivisionByZero: c91, *note Inexact:
c92, *note Rounded: c93, *note Subnormal: c94, *note Overflow: c95, and
*note Underflow: c96.

  For each signal there is a flag and a trap enabler.  When a signal is
encountered, its flag is set to one, then, if the trap enabler is set
to one, an exception is raised.  Flags are sticky, so the user needs to
reset them before monitoring a calculation.

See also
........

   * IBM's General Decimal Arithmetic Specification, The General
     Decimal Arithmetic Specification(1).

   * IEEE standard 854-1987, Unofficial IEEE 854 Text(2).

* Menu:

* Quick-start Tutorial::
* Decimal objects::
* Context objects::
* Signals::
* Floating Point Notes::
* Working with threads::
* Recipes::
* Decimal FAQ::

  ---------- Footnotes ----------

  (1) http://speleotrove.com/decimal/

  (2) http://754r.ucbtest.org/standards/854.pdf


File: python.info,  Node: Quick-start Tutorial,  Next: Decimal objects,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.1 Quick-start Tutorial
............................

The usual start to using decimals is importing the module, viewing the
current context with *note getcontext(): c99. and, if necessary,
setting new values for precision, rounding, or enabled traps:

    >>> from decimal import *
    >>> getcontext()
    Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
            capitals=1, flags=[], traps=[Overflow, DivisionByZero,
            InvalidOperation])

    >>> getcontext().prec = 7       # Set a new precision

Decimal instances can be constructed from integers, strings, floats, or
tuples.  Construction from an integer or a float performs an exact
conversion of the value of that integer or float.  Decimal numbers
include special values such as `NaN' which stands for "Not a number",
positive and negative `Infinity', and `-0'.

    >>> getcontext().prec = 28
    >>> Decimal(10)
    Decimal('10')
    >>> Decimal('3.14')
    Decimal('3.14')
    >>> Decimal(3.14)
    Decimal('3.140000000000000124344978758017532527446746826171875')
    >>> Decimal((0, (3, 1, 4), -2))
    Decimal('3.14')
    >>> Decimal(str(2.0 ** 0.5))
    Decimal('1.41421356237')
    >>> Decimal(2) ** Decimal('0.5')
    Decimal('1.414213562373095048801688724')
    >>> Decimal('NaN')
    Decimal('NaN')
    >>> Decimal('-Infinity')
    Decimal('-Infinity')

The significance of a new Decimal is determined solely by the number of
digits input.  Context precision and rounding only come into play
during arithmetic operations.

    >>> getcontext().prec = 6
    >>> Decimal('3.0')
    Decimal('3.0')
    >>> Decimal('3.1415926535')
    Decimal('3.1415926535')
    >>> Decimal('3.1415926535') + Decimal('2.7182818285')
    Decimal('5.85987')
    >>> getcontext().rounding = ROUND_UP
    >>> Decimal('3.1415926535') + Decimal('2.7182818285')
    Decimal('5.85988')

Decimals interact well with much of the rest of Python.  Here is a
small decimal floating point flying circus:

    >>> data = map(Decimal, '1.34 1.87 3.45 2.35 1.00 0.03 9.25'.split())
    >>> max(data)
    Decimal('9.25')
    >>> min(data)
    Decimal('0.03')
    >>> sorted(data)
    [Decimal('0.03'), Decimal('1.00'), Decimal('1.34'), Decimal('1.87'),
     Decimal('2.35'), Decimal('3.45'), Decimal('9.25')]
    >>> sum(data)
    Decimal('19.29')
    >>> a,b,c = data[:3]
    >>> str(a)
    '1.34'
    >>> float(a)
    1.34
    >>> round(a, 1)     # round() first converts to binary floating point
    1.3
    >>> int(a)
    1
    >>> a * 5
    Decimal('6.70')
    >>> a * b
    Decimal('2.5058')
    >>> c % a
    Decimal('0.77')

And some mathematical functions are also available to Decimal:

    >>> getcontext().prec = 28
    >>> Decimal(2).sqrt()
    Decimal('1.414213562373095048801688724')
    >>> Decimal(1).exp()
    Decimal('2.718281828459045235360287471')
    >>> Decimal('10').ln()
    Decimal('2.302585092994045684017991455')
    >>> Decimal('10').log10()
    Decimal('1')

The `quantize()' method rounds a number to a fixed exponent.  This
method is useful for monetary applications that often round results to
a fixed number of places:

    >>> Decimal('7.325').quantize(Decimal('.01'), rounding=ROUND_DOWN)
    Decimal('7.32')
    >>> Decimal('7.325').quantize(Decimal('1.'), rounding=ROUND_UP)
    Decimal('8')

As shown above, the *note getcontext(): c99. function accesses the
current context and allows the settings to be changed.  This approach
meets the needs of most applications.

  For more advanced work, it may be useful to create alternate contexts
using the Context() constructor.  To make an alternate active, use the
*note setcontext(): c9a.  function.

  In accordance with the standard, the `Decimal' module provides two
ready to use standard contexts, *note BasicContext: c9b. and *note
ExtendedContext: c9c. The former is especially useful for debugging
because many of the traps are enabled:

    >>> myothercontext = Context(prec=60, rounding=ROUND_HALF_DOWN)
    >>> setcontext(myothercontext)
    >>> Decimal(1) / Decimal(7)
    Decimal('0.142857142857142857142857142857142857142857142857142857142857')

    >>> ExtendedContext
    Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
            capitals=1, flags=[], traps=[])
    >>> setcontext(ExtendedContext)
    >>> Decimal(1) / Decimal(7)
    Decimal('0.142857143')
    >>> Decimal(42) / Decimal(0)
    Decimal('Infinity')

    >>> setcontext(BasicContext)
    >>> Decimal(42) / Decimal(0)
    Traceback (most recent call last):
      File "<pyshell#143>", line 1, in -toplevel-
        Decimal(42) / Decimal(0)
    DivisionByZero: x / 0

Contexts also have signal flags for monitoring exceptional conditions
encountered during computations.  The flags remain set until explicitly
cleared, so it is best to clear the flags before each set of monitored
computations by using the `clear_flags()' method.

    >>> setcontext(ExtendedContext)
    >>> getcontext().clear_flags()
    >>> Decimal(355) / Decimal(113)
    Decimal('3.14159292')
    >>> getcontext()
    Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
            capitals=1, flags=[Rounded, Inexact], traps=[])

The _flags_ entry shows that the rational approximation to `Pi' was
rounded (digits beyond the context precision were thrown away) and that
the result is inexact (some of the discarded digits were non-zero).

  Individual traps are set using the dictionary in the `traps' field of
a context:

    >>> setcontext(ExtendedContext)
    >>> Decimal(1) / Decimal(0)
    Decimal('Infinity')
    >>> getcontext().traps[DivisionByZero] = 1
    >>> Decimal(1) / Decimal(0)
    Traceback (most recent call last):
      File "<pyshell#112>", line 1, in -toplevel-
        Decimal(1) / Decimal(0)
    DivisionByZero: x / 0

Most programs adjust the current context only once, at the beginning of
the program.  And, in many applications, data is converted to *note
Decimal: 1b4. with a single cast inside a loop.  With context set and
decimals created, the bulk of the program manipulates the data no
differently than with other Python numeric types.


File: python.info,  Node: Decimal objects,  Next: Context objects,  Prev: Quick-start Tutorial,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.2 Decimal objects
.......................

 -- Class: decimal.Decimal ([value[, context]])
     Construct a new *note Decimal: 1b4. object based from _value_.

     _value_ can be an integer, string, tuple, *note float: 1e8, or
     another *note Decimal: 1b4.  object. If no _value_ is given,
     returns `Decimal('0')'.  If _value_ is a string, it should conform
     to the decimal numeric string syntax after leading and trailing
     whitespace characters are removed:

         sign           ::=  '+' | '-'
         digit          ::=  '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'
         indicator      ::=  'e' | 'E'
         digits         ::=  digit [digit]...
         decimal-part   ::=  digits '.' [digits] | ['.'] digits
         exponent-part  ::=  indicator [sign] digits
         infinity       ::=  'Infinity' | 'Inf'
         nan            ::=  'NaN' [digits] | 'sNaN' [digits]
         numeric-value  ::=  decimal-part [exponent-part] | infinity
         numeric-string ::=  [sign] numeric-value | [sign] nan

     If _value_ is a unicode string then other Unicode decimal digits
     are also permitted where `digit' appears above.  These include
     decimal digits from various other alphabets (for example,
     Arabic-Indic and Devanāgarī digits) along with the fullwidth digits
     `u'\uff10'' through `u'\uff19''.

     If _value_ is a *note tuple: 401, it should have three components,
     a sign (`0' for positive or `1' for negative), a *note tuple: 401.
     of digits, and an integer exponent. For example, `Decimal((0, (1,
     4, 1, 4), -3))' returns `Decimal('1.414')'.

     If _value_ is a *note float: 1e8, the binary floating point value
     is losslessly converted to its exact decimal equivalent.  This
     conversion can often require 53 or more digits of precision.  For
     example, `Decimal(float('1.1'))' converts to
     `Decimal('1.100000000000000088817841970012523233890533447265625')'.

     The _context_ precision does not affect how many digits are
     stored. That is determined exclusively by the number of digits in
     _value_. For example, `Decimal('3.00000')' records all five zeros
     even if the context precision is only three.

     The purpose of the _context_ argument is determining what to do if
     _value_ is a malformed string.  If the context traps *note
     InvalidOperation: 2d9, an exception is raised; otherwise, the
     constructor returns a new Decimal with the value of `NaN'.

     Once constructed, *note Decimal: 1b4. objects are immutable.

     Changed in version 2.6: leading and trailing whitespace characters
     are permitted when creating a Decimal instance from a string.

     Changed in version 2.7: The argument to the constructor is now
     permitted to be a *note float: 1e8. instance.

     Decimal floating point objects share many properties with the
     other built-in numeric types such as *note float: 1e8. and *note
     int: 1ef.  All of the usual math operations and special methods
     apply.  Likewise, decimal objects can be copied, pickled, printed,
     used as dictionary keys, used as set elements, compared, sorted,
     and coerced to another type (such as *note float: 1e8. or *note
     long: 1f0.).

     There are some small differences between arithmetic on Decimal
     objects and arithmetic on integers and floats.  When the remainder
     operator `%' is applied to Decimal objects, the sign of the result
     is the sign of the _dividend_ rather than the sign of the divisor:

         >>> (-7) % 4
         1
         >>> Decimal(-7) % Decimal(4)
         Decimal('-3')

     The integer division operator `//' behaves analogously, returning
     the integer part of the true quotient (truncating towards zero)
     rather than its floor, so as to preserve the usual identity `x ==
     (x // y) * y + x % y':

         >>> -7 // 4
         -2
         >>> Decimal(-7) // Decimal(4)
         Decimal('-1')

     The `%' and `//' operators implement the `remainder' and
     `divide-integer' operations (respectively) as described in the
     specification.

     Decimal objects cannot generally be combined with floats in
     arithmetic operations: an attempt to add a *note Decimal: 1b4. to a
     *note float: 1e8, for example, will raise a *note TypeError: 215.
     There's one exception to this rule: it's possible to use Python's
     comparison operators to compare a *note float: 1e8. instance `x'
     with a *note Decimal: 1b4. instance `y'.  Without this exception,
     comparisons between *note Decimal: 1b4. and *note float: 1e8.
     instances would follow the general rules for comparing objects of
     different types described in the *note Expressions: 75a. section
     of the reference manual, leading to confusing results.

     Changed in version 2.7: A comparison between a *note float: 1e8.
     instance `x' and a *note Decimal: 1b4. instance `y' now returns a
     result based on the values of `x' and `y'.  In earlier versions `x
     < y' returned the same (arbitrary) result for any *note Decimal:
     1b4.  instance `x' and any *note float: 1e8. instance `y'.

     In addition to the standard numeric properties, decimal floating
     point objects also have a number of specialized methods:

      -- Method: adjusted ()
          Return the adjusted exponent after shifting out the
          coefficient's rightmost digits until only the lead digit
          remains: `Decimal('321e+5').adjusted()' returns seven.  Used
          for determining the position of the most significant digit
          with respect to the decimal point.

      -- Method: as_tuple ()
          Return a *note named tuple: a0f. representation of the number:
          `DecimalTuple(sign, digits, exponent)'.

          Changed in version 2.6: Use a named tuple.

      -- Method: canonical ()
          Return the canonical encoding of the argument.  Currently,
          the encoding of a *note Decimal: 1b4. instance is always
          canonical, so this operation returns its argument unchanged.

          New in version 2.6.

      -- Method: compare (other[, context])
          Compare the values of two Decimal instances.  This operation
          behaves in the same way as the usual comparison method *note
          __cmp__(): 21e, except that *note compare(): ca2. returns a
          Decimal instance rather than an integer, and if either
          operand is a NaN then the result is a NaN:

              a or b is a NaN ==> Decimal('NaN')
              a < b           ==> Decimal('-1')
              a == b          ==> Decimal('0')
              a > b           ==> Decimal('1')



      -- Method: compare_signal (other[, context])
          This operation is identical to the *note compare(): ca2.
          method, except that all NaNs signal.  That is, if neither
          operand is a signaling NaN then any quiet NaN operand is
          treated as though it were a signaling NaN.

          New in version 2.6.

      -- Method: compare_total (other)
          Compare two operands using their abstract representation
          rather than their numerical value.  Similar to the *note
          compare(): ca2. method, but the result gives a total ordering
          on *note Decimal: 1b4. instances.  Two *note Decimal: 1b4.
          instances with the same numeric value but different
          representations compare unequal in this ordering:

              >>> Decimal('12.0').compare_total(Decimal('12'))
              Decimal('-1')

          Quiet and signaling NaNs are also included in the total
          ordering.  The result of this function is `Decimal('0')' if
          both operands have the same representation, `Decimal('-1')'
          if the first operand is lower in the total order than the
          second, and `Decimal('1')' if the first operand is higher in
          the total order than the second operand.  See the
          specification for details of the total order.

          New in version 2.6.

      -- Method: compare_total_mag (other)
          Compare two operands using their abstract representation
          rather than their value as in *note compare_total(): ca4, but
          ignoring the sign of each operand.  `x.compare_total_mag(y)'
          is equivalent to `x.copy_abs().compare_total(y.copy_abs())'.

          New in version 2.6.

      -- Method: conjugate ()
          Just returns self, this method is only to comply with the
          Decimal Specification.

          New in version 2.6.

      -- Method: copy_abs ()
          Return the absolute value of the argument.  This operation is
          unaffected by the context and is quiet: no flags are changed
          and no rounding is performed.

          New in version 2.6.

      -- Method: copy_negate ()
          Return the negation of the argument.  This operation is
          unaffected by the context and is quiet: no flags are changed
          and no rounding is performed.

          New in version 2.6.

      -- Method: copy_sign (other)
          Return a copy of the first operand with the sign set to be
          the same as the sign of the second operand.  For example:

              >>> Decimal('2.3').copy_sign(Decimal('-1.5'))
              Decimal('-2.3')

          This operation is unaffected by the context and is quiet: no
          flags are changed and no rounding is performed.

          New in version 2.6.

      -- Method: exp ([context])
          Return the value of the (natural) exponential function `e**x'
          at the given number.  The result is correctly rounded using
          the `ROUND_HALF_EVEN' rounding mode.

              >>> Decimal(1).exp()
              Decimal('2.718281828459045235360287471')
              >>> Decimal(321).exp()
              Decimal('2.561702493119680037517373933E+139')

          New in version 2.6.

      -- Method: from_float (f)
          Classmethod that converts a float to a decimal number,
          exactly.

          Note `Decimal.from_float(0.1)' is not the same as
          `Decimal('0.1')'.  Since 0.1 is not exactly representable in
          binary floating point, the value is stored as the nearest
          representable value which is `0x1.999999999999ap-4'.  That
          equivalent value in decimal is
          `0.1000000000000000055511151231257827021181583404541015625'.

               Note: From Python 2.7 onwards, a *note Decimal: 1b4.
               instance can also be constructed directly from a *note
               float: 1e8.

              >>> Decimal.from_float(0.1)
              Decimal('0.1000000000000000055511151231257827021181583404541015625')
              >>> Decimal.from_float(float('nan'))
              Decimal('NaN')
              >>> Decimal.from_float(float('inf'))
              Decimal('Infinity')
              >>> Decimal.from_float(float('-inf'))
              Decimal('-Infinity')

          New in version 2.7.

      -- Method: fma (other, third[, context])
          Fused multiply-add.  Return self*other+third with no rounding
          of the intermediate product self*other.

              >>> Decimal(2).fma(3, 5)
              Decimal('11')

          New in version 2.6.

      -- Method: is_canonical ()
          Return *note True: 3a9. if the argument is canonical and
          *note False: 3aa.  otherwise.  Currently, a *note Decimal:
          1b4. instance is always canonical, so this operation always
          returns *note True: 3a9.

          New in version 2.6.

      -- Method: is_finite ()
          Return *note True: 3a9. if the argument is a finite number,
          and *note False: 3aa. if the argument is an infinity or a NaN.

          New in version 2.6.

      -- Method: is_infinite ()
          Return *note True: 3a9. if the argument is either positive or
          negative infinity and *note False: 3aa. otherwise.

          New in version 2.6.

      -- Method: is_nan ()
          Return *note True: 3a9. if the argument is a (quiet or
          signaling) NaN and *note False: 3aa. otherwise.

          New in version 2.6.

      -- Method: is_normal ()
          Return *note True: 3a9. if the argument is a _normal_ finite
          non-zero number with an adjusted exponent greater than or
          equal to _Emin_.  Return *note False: 3aa. if the argument is
          zero, subnormal, infinite or a NaN.  Note, the term _normal_
          is used here in a different sense with the *note normalize():
          cb1. method which is used to create canonical values.

          New in version 2.6.

      -- Method: is_qnan ()
          Return *note True: 3a9. if the argument is a quiet NaN, and
          *note False: 3aa. otherwise.

          New in version 2.6.

      -- Method: is_signed ()
          Return *note True: 3a9. if the argument has a negative sign
          and *note False: 3aa. otherwise.  Note that zeros and NaNs
          can both carry signs.

          New in version 2.6.

      -- Method: is_snan ()
          Return *note True: 3a9. if the argument is a signaling NaN
          and *note False: 3aa.  otherwise.

          New in version 2.6.

      -- Method: is_subnormal ()
          Return *note True: 3a9. if the argument is subnormal, and
          *note False: 3aa.  otherwise. A number is subnormal is if it
          is nonzero, finite, and has an adjusted exponent less than
          _Emin_.

          New in version 2.6.

      -- Method: is_zero ()
          Return *note True: 3a9. if the argument is a (positive or
          negative) zero and *note False: 3aa. otherwise.

          New in version 2.6.

      -- Method: ln ([context])
          Return the natural (base e) logarithm of the operand.  The
          result is correctly rounded using the `ROUND_HALF_EVEN'
          rounding mode.

          New in version 2.6.

      -- Method: log10 ([context])
          Return the base ten logarithm of the operand.  The result is
          correctly rounded using the `ROUND_HALF_EVEN' rounding mode.

          New in version 2.6.

      -- Method: logb ([context])
          For a nonzero number, return the adjusted exponent of its
          operand as a *note Decimal: 1b4. instance.  If the operand is
          a zero then `Decimal('-Infinity')' is returned and the *note
          DivisionByZero: c91. flag is raised.  If the operand is an
          infinity then `Decimal('Infinity')' is returned.

          New in version 2.6.

      -- Method: logical_and (other[, context])
          *note logical_and(): cba. is a logical operation which takes
          two _logical operands_ (see *note Logical operands: cbb.).
          The result is the digit-wise `and' of the two operands.

          New in version 2.6.

      -- Method: logical_invert ([context])
          *note logical_invert(): cbc. is a logical operation.  The
          result is the digit-wise inversion of the operand.

          New in version 2.6.

      -- Method: logical_or (other[, context])
          *note logical_or(): cbd. is a logical operation which takes
          two _logical operands_ (see *note Logical operands: cbb.).
          The result is the digit-wise `or' of the two operands.

          New in version 2.6.

      -- Method: logical_xor (other[, context])
          *note logical_xor(): cbe. is a logical operation which takes
          two _logical operands_ (see *note Logical operands: cbb.).
          The result is the digit-wise exclusive or of the two operands.

          New in version 2.6.

      -- Method: max (other[, context])
          Like `max(self, other)' except that the context rounding rule
          is applied before returning and that `NaN' values are either
          signaled or ignored (depending on the context and whether
          they are signaling or quiet).

      -- Method: max_mag (other[, context])
          Similar to the *note max(): cbf. method, but the comparison
          is done using the absolute values of the operands.

          New in version 2.6.

      -- Method: min (other[, context])
          Like `min(self, other)' except that the context rounding rule
          is applied before returning and that `NaN' values are either
          signaled or ignored (depending on the context and whether
          they are signaling or quiet).

      -- Method: min_mag (other[, context])
          Similar to the *note min(): cc1. method, but the comparison
          is done using the absolute values of the operands.

          New in version 2.6.

      -- Method: next_minus ([context])
          Return the largest number representable in the given context
          (or in the current thread's context if no context is given)
          that is smaller than the given operand.

          New in version 2.6.

      -- Method: next_plus ([context])
          Return the smallest number representable in the given context
          (or in the current thread's context if no context is given)
          that is larger than the given operand.

          New in version 2.6.

      -- Method: next_toward (other[, context])
          If the two operands are unequal, return the number closest to
          the first operand in the direction of the second operand.  If
          both operands are numerically equal, return a copy of the
          first operand with the sign set to be the same as the sign of
          the second operand.

          New in version 2.6.

      -- Method: normalize ([context])
          Normalize the number by stripping the rightmost trailing
          zeros and converting any result equal to `Decimal('0')' to
          `Decimal('0e0')'. Used for producing canonical values for
          attributes of an equivalence class. For example,
          `Decimal('32.100')' and `Decimal('0.321000e+2')' both
          normalize to the equivalent value `Decimal('32.1')'.

      -- Method: number_class ([context])
          Return a string describing the _class_ of the operand.  The
          returned value is one of the following ten strings.

             * `"-Infinity"', indicating that the operand is negative
               infinity.

             * `"-Normal"', indicating that the operand is a negative
               normal number.

             * `"-Subnormal"', indicating that the operand is negative
               and subnormal.

             * `"-Zero"', indicating that the operand is a negative
               zero.

             * `"+Zero"', indicating that the operand is a positive
               zero.

             * `"+Subnormal"', indicating that the operand is positive
               and subnormal.

             * `"+Normal"', indicating that the operand is a positive
               normal number.

             * `"+Infinity"', indicating that the operand is positive
               infinity.

             * `"NaN"', indicating that the operand is a quiet NaN (Not
               a Number).

             * `"sNaN"', indicating that the operand is a signaling NaN.

          New in version 2.6.

      -- Method: quantize (exp[, rounding[, context[, watchexp]]])
          Return a value equal to the first operand after rounding and
          having the exponent of the second operand.

              >>> Decimal('1.41421356').quantize(Decimal('1.000'))
              Decimal('1.414')

          Unlike other operations, if the length of the coefficient
          after the quantize operation would be greater than precision,
          then an *note InvalidOperation: 2d9. is signaled. This
          guarantees that, unless there is an error condition, the
          quantized exponent is always equal to that of the right-hand
          operand.

          Also unlike other operations, quantize never signals
          Underflow, even if the result is subnormal and inexact.

          If the exponent of the second operand is larger than that of
          the first then rounding may be necessary.  In this case, the
          rounding mode is determined by the `rounding' argument if
          given, else by the given `context' argument; if neither
          argument is given the rounding mode of the current thread's
          context is used.

          If _watchexp_ is set (default), then an error is returned
          whenever the resulting exponent is greater than `Emax' or
          less than `Etiny'.

      -- Method: radix ()
          Return `Decimal(10)', the radix (base) in which the *note
          Decimal: 1b4.  class does all its arithmetic.  Included for
          compatibility with the specification.

          New in version 2.6.

      -- Method: remainder_near (other[, context])
          Return the remainder from dividing _self_ by _other_.  This
          differs from `self % other' in that the sign of the remainder
          is chosen so as to minimize its absolute value.  More
          precisely, the return value is `self - n * other' where `n'
          is the integer nearest to the exact value of `self / other',
          and if two integers are equally near then the even one is
          chosen.

          If the result is zero then its sign will be the sign of
          _self_.

              >>> Decimal(18).remainder_near(Decimal(10))
              Decimal('-2')
              >>> Decimal(25).remainder_near(Decimal(10))
              Decimal('5')
              >>> Decimal(35).remainder_near(Decimal(10))
              Decimal('-5')



      -- Method: rotate (other[, context])
          Return the result of rotating the digits of the first operand
          by an amount specified by the second operand.  The second
          operand must be an integer in the range -precision through
          precision.  The absolute value of the second operand gives
          the number of places to rotate.  If the second operand is
          positive then rotation is to the left; otherwise rotation is
          to the right.  The coefficient of the first operand is padded
          on the left with zeros to length precision if necessary.  The
          sign and exponent of the first operand are unchanged.

          New in version 2.6.

      -- Method: same_quantum (other[, context])
          Test whether self and other have the same exponent or whether
          both are `NaN'.

      -- Method: scaleb (other[, context])
          Return the first operand with exponent adjusted by the second.
          Equivalently, return the first operand multiplied by
          `10**other'.  The second operand must be an integer.

          New in version 2.6.

      -- Method: shift (other[, context])
          Return the result of shifting the digits of the first operand
          by an amount specified by the second operand.  The second
          operand must be an integer in the range -precision through
          precision.  The absolute value of the second operand gives
          the number of places to shift.  If the second operand is
          positive then the shift is to the left; otherwise the shift
          is to the right.  Digits shifted into the coefficient are
          zeros.  The sign and exponent of the first operand are
          unchanged.

          New in version 2.6.

      -- Method: sqrt ([context])
          Return the square root of the argument to full precision.

      -- Method: to_eng_string ([context])
          Convert to an engineering-type string.

          Engineering notation has an exponent which is a multiple of
          3, so there are up to 3 digits left of the decimal place.
          For example, converts `Decimal('123E+1')' to
          `Decimal('1.23E+3')'

      -- Method: to_integral ([rounding[, context]])
          Identical to the *note to_integral_value(): cd1. method.  The
          `to_integral' name has been kept for compatibility with older
          versions.

      -- Method: to_integral_exact ([rounding[, context]])
          Round to the nearest integer, signaling *note Inexact: c92. or
          *note Rounded: c93. as appropriate if rounding occurs.  The
          rounding mode is determined by the `rounding' parameter if
          given, else by the given `context'.  If neither parameter is
          given then the rounding mode of the current context is used.

          New in version 2.6.

      -- Method: to_integral_value ([rounding[, context]])
          Round to the nearest integer without signaling *note Inexact:
          c92. or *note Rounded: c93.  If given, applies _rounding_;
          otherwise, uses the rounding method in either the supplied
          _context_ or the current context.

          Changed in version 2.6: renamed from `to_integral' to
          `to_integral_value'.  The old name remains valid for
          compatibility.

* Menu:

* Logical operands::


File: python.info,  Node: Logical operands,  Up: Decimal objects

5.9.4.3 Logical operands
........................

The `logical_and()', `logical_invert()', `logical_or()', and
`logical_xor()' methods expect their arguments to be _logical
operands_.  A _logical operand_ is a *note Decimal: 1b4. instance whose
exponent and sign are both zero, and whose digits are all either `0' or
`1'.


File: python.info,  Node: Context objects,  Next: Signals,  Prev: Decimal objects,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.4 Context objects
.......................

Contexts are environments for arithmetic operations.  They govern
precision, set rules for rounding, determine which signals are treated
as exceptions, and limit the range for exponents.

  Each thread has its own current context which is accessed or changed
using the *note getcontext(): c99. and *note setcontext(): c9a.
functions:

 -- Function: decimal.getcontext ()
     Return the current context for the active thread.

 -- Function: decimal.setcontext (c)
     Set the current context for the active thread to _c_.

  Beginning with Python 2.5, you can also use the *note with: 1bd.
statement and the *note localcontext(): 90e. function to temporarily
change the active context.

 -- Function: decimal.localcontext ([c])
     Return a context manager that will set the current context for the
     active thread to a copy of _c_ on entry to the with-statement and
     restore the previous context when exiting the with-statement. If
     no context is specified, a copy of the current context is used.

     New in version 2.5.

     For example, the following code sets the current decimal precision
     to 42 places, performs a calculation, and then automatically
     restores the previous context:

         from decimal import localcontext

         with localcontext() as ctx:
             ctx.prec = 42   # Perform a high precision calculation
             s = calculate_something()
         s = +s  # Round the final result back to the default precision

         with localcontext(BasicContext):      # temporarily use the BasicContext
             print Decimal(1) / Decimal(7)
             print Decimal(355) / Decimal(113)



  New contexts can also be created using the *note Context: 210.
constructor described below. In addition, the module provides three
pre-made contexts:

 -- Class: decimal.BasicContext
     This is a standard context defined by the General Decimal
     Arithmetic Specification.  Precision is set to nine.  Rounding is
     set to `ROUND_HALF_UP'.  All flags are cleared.  All traps are
     enabled (treated as exceptions) except *note Inexact: c92, *note
     Rounded: c93, and *note Subnormal: c94.

     Because many of the traps are enabled, this context is useful for
     debugging.

 -- Class: decimal.ExtendedContext
     This is a standard context defined by the General Decimal
     Arithmetic Specification.  Precision is set to nine.  Rounding is
     set to `ROUND_HALF_EVEN'.  All flags are cleared.  No traps are
     enabled (so that exceptions are not raised during computations).

     Because the traps are disabled, this context is useful for
     applications that prefer to have result value of `NaN' or
     `Infinity' instead of raising exceptions.  This allows an
     application to complete a run in the presence of conditions that
     would otherwise halt the program.

 -- Class: decimal.DefaultContext
     This context is used by the *note Context: 210. constructor as a
     prototype for new contexts.  Changing a field (such a precision)
     has the effect of changing the default for new contexts created by
     the *note Context: 210. constructor.

     This context is most useful in multi-threaded environments.
     Changing one of the fields before threads are started has the
     effect of setting system-wide defaults.  Changing the fields after
     threads have started is not recommended as it would require thread
     synchronization to prevent race conditions.

     In single threaded environments, it is preferable to not use this
     context at all.  Instead, simply create contexts explicitly as
     described below.

     The default values are precision=28, rounding=ROUND_HALF_EVEN, and
     enabled traps for Overflow, InvalidOperation, and DivisionByZero.

  In addition to the three supplied contexts, new contexts can be
created with the *note Context: 210. constructor.

 -- Class: decimal.Context (prec=None, rounding=None, traps=None,
          flags=None, Emin=None, Emax=None, capitals=1)
     Creates a new context.  If a field is not specified or is *note
     None: 393, the default values are copied from the *note
     DefaultContext: cd6.  If the _flags_ field is not specified or is
     *note None: 393, all flags are cleared.

     The _prec_ field is a positive integer that sets the precision for
     arithmetic operations in the context.

     The _rounding_ option is one of:

        * `ROUND_CEILING' (towards `Infinity'),

        * `ROUND_DOWN' (towards zero),

        * `ROUND_FLOOR' (towards `-Infinity'),

        * `ROUND_HALF_DOWN' (to nearest with ties going towards zero),

        * `ROUND_HALF_EVEN' (to nearest with ties going to nearest even
          integer),

        * `ROUND_HALF_UP' (to nearest with ties going away from zero),
          or

        * `ROUND_UP' (away from zero).

        * `ROUND_05UP' (away from zero if last digit after rounding
          towards zero would have been 0 or 5; otherwise towards zero)

     The _traps_ and _flags_ fields list any signals to be set.
     Generally, new contexts should only set traps and leave the flags
     clear.

     The _Emin_ and _Emax_ fields are integers specifying the outer
     limits allowable for exponents.

     The _capitals_ field is either `0' or `1' (the default). If set to
     `1', exponents are printed with a capital `E'; otherwise, a
     lowercase `e' is used: `Decimal('6.02e+23')'.

     Changed in version 2.6: The `ROUND_05UP' rounding mode was added.

     The *note Context: 210. class defines several general purpose
     methods as well as a large number of methods for doing arithmetic
     directly in a given context.  In addition, for each of the *note
     Decimal: 1b4. methods described above (with the exception of the
     `adjusted()' and `as_tuple()' methods) there is a corresponding
     *note Context: 210. method.  For example, for a *note Context: 210.
     instance `C' and *note Decimal: 1b4. instance `x', `C.exp(x)' is
     equivalent to `x.exp(context=C)'.  Each *note Context: 210. method
     accepts a Python integer (an instance of *note int: 1ef. or *note
     long: 1f0.) anywhere that a Decimal instance is accepted.

      -- Method: clear_flags ()
          Resets all of the flags to `0'.

      -- Method: copy ()
          Return a duplicate of the context.

      -- Method: copy_decimal (num)
          Return a copy of the Decimal instance num.

      -- Method: create_decimal (num)
          Creates a new Decimal instance from _num_ but using _self_ as
          context. Unlike the *note Decimal: 1b4. constructor, the
          context precision, rounding method, flags, and traps are
          applied to the conversion.

          This is useful because constants are often given to a greater
          precision than is needed by the application.  Another benefit
          is that rounding immediately eliminates unintended effects
          from digits beyond the current precision. In the following
          example, using unrounded inputs means that adding zero to a
          sum can change the result:

              >>> getcontext().prec = 3
              >>> Decimal('3.4445') + Decimal('1.0023')
              Decimal('4.45')
              >>> Decimal('3.4445') + Decimal(0) + Decimal('1.0023')
              Decimal('4.44')

          This method implements the to-number operation of the IBM
          specification.  If the argument is a string, no leading or
          trailing whitespace is permitted.

      -- Method: create_decimal_from_float (f)
          Creates a new Decimal instance from a float _f_ but rounding
          using _self_ as the context.  Unlike the *note
          Decimal.from_float(): 20f. class method, the context
          precision, rounding method, flags, and traps are applied to
          the conversion.

              >>> context = Context(prec=5, rounding=ROUND_DOWN)
              >>> context.create_decimal_from_float(math.pi)
              Decimal('3.1415')
              >>> context = Context(prec=5, traps=[Inexact])
              >>> context.create_decimal_from_float(math.pi)
              Traceback (most recent call last):
                  ...
              Inexact: None

          New in version 2.7.

      -- Method: Etiny ()
          Returns a value equal to `Emin - prec + 1' which is the
          minimum exponent value for subnormal results.  When underflow
          occurs, the exponent is set to *note Etiny: cdc.

      -- Method: Etop ()
          Returns a value equal to `Emax - prec + 1'.

     The usual approach to working with decimals is to create *note
     Decimal: 1b4.  instances and then apply arithmetic operations
     which take place within the current context for the active thread.
     An alternative approach is to use context methods for calculating
     within a specific context.  The methods are similar to those for
     the *note Decimal: 1b4. class and are only briefly recounted here.

      -- Method: abs (x)
          Returns the absolute value of _x_.

      -- Method: add (x, y)
          Return the sum of _x_ and _y_.

      -- Method: canonical (x)
          Returns the same Decimal object _x_.

      -- Method: compare (x, y)
          Compares _x_ and _y_ numerically.

      -- Method: compare_signal (x, y)
          Compares the values of the two operands numerically.

      -- Method: compare_total (x, y)
          Compares two operands using their abstract representation.

      -- Method: compare_total_mag (x, y)
          Compares two operands using their abstract representation,
          ignoring sign.

      -- Method: copy_abs (x)
          Returns a copy of _x_ with the sign set to 0.

      -- Method: copy_negate (x)
          Returns a copy of _x_ with the sign inverted.

      -- Method: copy_sign (x, y)
          Copies the sign from _y_ to _x_.

      -- Method: divide (x, y)
          Return _x_ divided by _y_.

      -- Method: divide_int (x, y)
          Return _x_ divided by _y_, truncated to an integer.

      -- Method: divmod (x, y)
          Divides two numbers and returns the integer part of the
          result.

      -- Method: exp (x)
          Returns `e ** x'.

      -- Method: fma (x, y, z)
          Returns _x_ multiplied by _y_, plus _z_.

      -- Method: is_canonical (x)
          Returns True if _x_ is canonical; otherwise returns False.

      -- Method: is_finite (x)
          Returns True if _x_ is finite; otherwise returns False.

      -- Method: is_infinite (x)
          Returns True if _x_ is infinite; otherwise returns False.

      -- Method: is_nan (x)
          Returns True if _x_ is a qNaN or sNaN; otherwise returns
          False.

      -- Method: is_normal (x)
          Returns True if _x_ is a normal number; otherwise returns
          False.

      -- Method: is_qnan (x)
          Returns True if _x_ is a quiet NaN; otherwise returns False.

      -- Method: is_signed (x)
          Returns True if _x_ is negative; otherwise returns False.

      -- Method: is_snan (x)
          Returns True if _x_ is a signaling NaN; otherwise returns
          False.

      -- Method: is_subnormal (x)
          Returns True if _x_ is subnormal; otherwise returns False.

      -- Method: is_zero (x)
          Returns True if _x_ is a zero; otherwise returns False.

      -- Method: ln (x)
          Returns the natural (base e) logarithm of _x_.

      -- Method: log10 (x)
          Returns the base 10 logarithm of _x_.

      -- Method: logb (x)
          Returns the exponent of the magnitude of the operand's MSD.

      -- Method: logical_and (x, y)
          Applies the logical operation _and_ between each operand's
          digits.

      -- Method: logical_invert (x)
          Invert all the digits in _x_.

      -- Method: logical_or (x, y)
          Applies the logical operation _or_ between each operand's
          digits.

      -- Method: logical_xor (x, y)
          Applies the logical operation _xor_ between each operand's
          digits.

      -- Method: max (x, y)
          Compares two values numerically and returns the maximum.

      -- Method: max_mag (x, y)
          Compares the values numerically with their sign ignored.

      -- Method: min (x, y)
          Compares two values numerically and returns the minimum.

      -- Method: min_mag (x, y)
          Compares the values numerically with their sign ignored.

      -- Method: minus (x)
          Minus corresponds to the unary prefix minus operator in
          Python.

      -- Method: multiply (x, y)
          Return the product of _x_ and _y_.

      -- Method: next_minus (x)
          Returns the largest representable number smaller than _x_.

      -- Method: next_plus (x)
          Returns the smallest representable number larger than _x_.

      -- Method: next_toward (x, y)
          Returns the number closest to _x_, in direction towards _y_.

      -- Method: normalize (x)
          Reduces _x_ to its simplest form.

      -- Method: number_class (x)
          Returns an indication of the class of _x_.

      -- Method: plus (x)
          Plus corresponds to the unary prefix plus operator in Python.
          This operation applies the context precision and rounding, so
          it is _not_ an identity operation.

      -- Method: power (x, y[, modulo])
          Return `x' to the power of `y', reduced modulo `modulo' if
          given.

          With two arguments, compute `x**y'.  If `x' is negative then
          `y' must be integral.  The result will be inexact unless `y'
          is integral and the result is finite and can be expressed
          exactly in 'precision' digits.  The result should always be
          correctly rounded, using the rounding mode of the current
          thread's context.

          With three arguments, compute `(x**y) % modulo'.  For the
          three argument form, the following restrictions on the
          arguments hold:

                  - all three arguments must be integral

                  - `y' must be nonnegative

                  - at least one of `x' or `y' must be nonzero

                  - `modulo' must be nonzero and have at most
                    'precision' digits

          The value resulting from `Context.power(x, y, modulo)' is
          equal to the value that would be obtained by computing `(x**y)
          % modulo' with unbounded precision, but is computed more
          efficiently.  The exponent of the result is zero, regardless
          of the exponents of `x', `y' and `modulo'.  The result is
          always exact.

          Changed in version 2.6: `y' may now be nonintegral in `x**y'.
          Stricter requirements for the three-argument version.

      -- Method: quantize (x, y)
          Returns a value equal to _x_ (rounded), having the exponent
          of _y_.

      -- Method: radix ()
          Just returns 10, as this is Decimal, :)

      -- Method: remainder (x, y)
          Returns the remainder from integer division.

          The sign of the result, if non-zero, is the same as that of
          the original dividend.

      -- Method: remainder_near (x, y)
          Returns `x - y * n', where _n_ is the integer nearest the
          exact value of `x / y' (if the result is 0 then its sign will
          be the sign of _x_).

      -- Method: rotate (x, y)
          Returns a rotated copy of _x_, _y_ times.

      -- Method: same_quantum (x, y)
          Returns True if the two operands have the same exponent.

      -- Method: scaleb (x, y)
          Returns the first operand after adding the second value its
          exp.

      -- Method: shift (x, y)
          Returns a shifted copy of _x_, _y_ times.

      -- Method: sqrt (x)
          Square root of a non-negative number to context precision.

      -- Method: subtract (x, y)
          Return the difference between _x_ and _y_.

      -- Method: to_eng_string (x)
          Converts a number to a string, using scientific notation.

      -- Method: to_integral_exact (x)
          Rounds to an integer.

      -- Method: to_sci_string (x)
          Converts a number to a string using scientific notation.


File: python.info,  Node: Signals,  Next: Floating Point Notes,  Prev: Context objects,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.5 Signals
...............

Signals represent conditions that arise during computation. Each
corresponds to one context flag and one context trap enabler.

  The context flag is set whenever the condition is encountered. After
the computation, flags may be checked for informational purposes (for
instance, to determine whether a computation was exact). After checking
the flags, be sure to clear all flags before starting the next
computation.

  If the context's trap enabler is set for the signal, then the
condition causes a Python exception to be raised.  For example, if the
*note DivisionByZero: c91. trap is set, then a *note DivisionByZero:
c91. exception is raised upon encountering the condition.

 -- Class: decimal.Clamped
     Altered an exponent to fit representation constraints.

     Typically, clamping occurs when an exponent falls outside the
     context's `Emin' and `Emax' limits.  If possible, the exponent is
     reduced to fit by adding zeros to the coefficient.

 -- Class: decimal.DecimalException
     Base class for other signals and a subclass of *note
     ArithmeticError: 934.

 -- Class: decimal.DivisionByZero
     Signals the division of a non-infinite number by zero.

     Can occur with division, modulo division, or when raising a number
     to a negative power.  If this signal is not trapped, returns
     `Infinity' or `-Infinity' with the sign determined by the inputs
     to the calculation.

 -- Class: decimal.Inexact
     Indicates that rounding occurred and the result is not exact.

     Signals when non-zero digits were discarded during rounding. The
     rounded result is returned.  The signal flag or trap is used to
     detect when results are inexact.

 -- Class: decimal.InvalidOperation
     An invalid operation was performed.

     Indicates that an operation was requested that does not make
     sense. If not trapped, returns `NaN'.  Possible causes include:

         Infinity - Infinity
         0 * Infinity
         Infinity / Infinity
         x % 0
         Infinity % x
         x._rescale( non-integer )
         sqrt(-x) and x > 0
         0 ** 0
         x ** (non-integer)
         x ** Infinity



 -- Class: decimal.Overflow
     Numerical overflow.

     Indicates the exponent is larger than `Emax' after rounding has
     occurred.  If not trapped, the result depends on the rounding
     mode, either pulling inward to the largest representable finite
     number or rounding outward to `Infinity'.  In either case, *note
     Inexact: c92. and *note Rounded: c93.  are also signaled.

 -- Class: decimal.Rounded
     Rounding occurred though possibly no information was lost.

     Signaled whenever rounding discards digits; even if those digits
     are zero (such as rounding `5.00' to `5.0').  If not trapped,
     returns the result unchanged.  This signal is used to detect loss
     of significant digits.

 -- Class: decimal.Subnormal
     Exponent was lower than `Emin' prior to rounding.

     Occurs when an operation result is subnormal (the exponent is too
     small). If not trapped, returns the result unchanged.

 -- Class: decimal.Underflow
     Numerical underflow with result rounded to zero.

     Occurs when a subnormal result is pushed to zero by rounding.
     *note Inexact: c92.  and *note Subnormal: c94. are also signaled.

  The following table summarizes the hierarchy of signals:

    exceptions.ArithmeticError(exceptions.StandardError)
        DecimalException
            Clamped
            DivisionByZero(DecimalException, exceptions.ZeroDivisionError)
            Inexact
                Overflow(Inexact, Rounded)
                Underflow(Inexact, Rounded, Subnormal)
            InvalidOperation
            Rounded
            Subnormal



File: python.info,  Node: Floating Point Notes,  Next: Working with threads,  Prev: Signals,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.6 Floating Point Notes
............................

* Menu:

* Mitigating round-off error with increased precision::
* Special values::


File: python.info,  Node: Mitigating round-off error with increased precision,  Next: Special values,  Up: Floating Point Notes

5.9.4.7 Mitigating round-off error with increased precision
...........................................................

The use of decimal floating point eliminates decimal representation
error (making it possible to represent `0.1' exactly); however, some
operations can still incur round-off error when non-zero digits exceed
the fixed precision.

  The effects of round-off error can be amplified by the addition or
subtraction of nearly offsetting quantities resulting in loss of
significance.  Knuth provides two instructive examples where rounded
floating point arithmetic with insufficient precision causes the
breakdown of the associative and distributive properties of addition:

    # Examples from Seminumerical Algorithms, Section 4.2.2.
    >>> from decimal import Decimal, getcontext
    >>> getcontext().prec = 8

    >>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
    >>> (u + v) + w
    Decimal('9.5111111')
    >>> u + (v + w)
    Decimal('10')

    >>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
    >>> (u*v) + (u*w)
    Decimal('0.01')
    >>> u * (v+w)
    Decimal('0.0060000')

The *note decimal: 80. module makes it possible to restore the
identities by expanding the precision sufficiently to avoid loss of
significance:

    >>> getcontext().prec = 20
    >>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
    >>> (u + v) + w
    Decimal('9.51111111')
    >>> u + (v + w)
    Decimal('9.51111111')
    >>>
    >>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
    >>> (u*v) + (u*w)
    Decimal('0.0060000')
    >>> u * (v+w)
    Decimal('0.0060000')



File: python.info,  Node: Special values,  Prev: Mitigating round-off error with increased precision,  Up: Floating Point Notes

5.9.4.8 Special values
......................

The number system for the *note decimal: 80. module provides special
values including `NaN', `sNaN', `-Infinity', `Infinity', and two zeros,
`+0' and `-0'.

  Infinities can be constructed directly with:  `Decimal('Infinity')'.
Also, they can arise from dividing by zero when the *note
DivisionByZero: c91. signal is not trapped.  Likewise, when the *note
Overflow: c95. signal is not trapped, infinity can result from rounding
beyond the limits of the largest representable number.

  The infinities are signed (affine) and can be used in arithmetic
operations where they get treated as very large, indeterminate numbers.
For instance, adding a constant to infinity gives another infinite
result.

  Some operations are indeterminate and return `NaN', or if the *note
InvalidOperation: 2d9. signal is trapped, raise an exception.  For
example, `0/0' returns `NaN' which means "not a number".  This variety
of `NaN' is quiet and, once created, will flow through other
computations always resulting in another `NaN'.  This behavior can be
useful for a series of computations that occasionally have missing
inputs -- it allows the calculation to proceed while flagging specific
results as invalid.

  A variant is `sNaN' which signals rather than remaining quiet after
every operation.  This is a useful return value when an invalid result
needs to interrupt a calculation for special handling.

  The behavior of Python's comparison operators can be a little
surprising where a `NaN' is involved.  A test for equality where one of
the operands is a quiet or signaling `NaN' always returns *note False:
3aa. (even when doing `Decimal('NaN')==Decimal('NaN')'), while a test
for inequality always returns *note True: 3a9.  An attempt to compare
two Decimals using any of the `<', `<=', `>' or `>=' operators will
raise the *note InvalidOperation: 2d9. signal if either operand is a
`NaN', and return *note False: 3aa. if this signal is not trapped.
Note that the General Decimal Arithmetic specification does not specify
the behavior of direct comparisons; these rules for comparisons
involving a `NaN' were taken from the IEEE 854 standard (see Table 3 in
section 5.7).  To ensure strict standards-compliance, use the
`compare()' and `compare-signal()' methods instead.

  The signed zeros can result from calculations that underflow. They
keep the sign that would have resulted if the calculation had been
carried out to greater precision.  Since their magnitude is zero, both
positive and negative zeros are treated as equal and their sign is
informational.

  In addition to the two signed zeros which are distinct yet equal,
there are various representations of zero with differing precisions yet
equivalent in value.  This takes a bit of getting used to.  For an eye
accustomed to normalized floating point representations, it is not
immediately obvious that the following calculation returns a value
equal to zero:

    >>> 1 / Decimal('Infinity')
    Decimal('0E-1000000026')



File: python.info,  Node: Working with threads,  Next: Recipes,  Prev: Floating Point Notes,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.9 Working with threads
............................

The *note getcontext(): c99. function accesses a different *note
Context: 210. object for each thread.  Having separate thread contexts
means that threads may make changes (such as `getcontext.prec=10')
without interfering with other threads.

  Likewise, the *note setcontext(): c9a. function automatically assigns
its target to the current thread.

  If *note setcontext(): c9a. has not been called before *note
getcontext(): c99, then *note getcontext(): c99. will automatically
create a new context for use in the current thread.

  The new context is copied from a prototype context called
_DefaultContext_. To control the defaults so that each thread will use
the same values throughout the application, directly modify the
_DefaultContext_ object. This should be done _before_ any threads are
started so that there won't be a race condition between threads calling
*note getcontext(): c99. For example:

    # Set applicationwide defaults for all threads about to be launched
    DefaultContext.prec = 12
    DefaultContext.rounding = ROUND_DOWN
    DefaultContext.traps = ExtendedContext.traps.copy()
    DefaultContext.traps[InvalidOperation] = 1
    setcontext(DefaultContext)

    # Afterwards, the threads can be started
    t1.start()
    t2.start()
    t3.start()
     . . .



File: python.info,  Node: Recipes,  Next: Decimal FAQ,  Prev: Working with threads,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.10 Recipes
................

Here are a few recipes that serve as utility functions and that
demonstrate ways to work with the *note Decimal: 1b4. class:

    def moneyfmt(value, places=2, curr='', sep=',', dp='.',
                 pos='', neg='-', trailneg=''):
        """Convert Decimal to a money formatted string.

        places:  required number of places after the decimal point
        curr:    optional currency symbol before the sign (may be blank)
        sep:     optional grouping separator (comma, period, space, or blank)
        dp:      decimal point indicator (comma or period)
                 only specify as blank when places is zero
        pos:     optional sign for positive numbers: '+', space or blank
        neg:     optional sign for negative numbers: '-', '(', space or blank
        trailneg:optional trailing minus indicator:  '-', ')', space or blank

        >>> d = Decimal('-1234567.8901')
        >>> moneyfmt(d, curr='$')
        '-$1,234,567.89'
        >>> moneyfmt(d, places=0, sep='.', dp='', neg='', trailneg='-')
        '1.234.568-'
        >>> moneyfmt(d, curr='$', neg='(', trailneg=')')
        '($1,234,567.89)'
        >>> moneyfmt(Decimal(123456789), sep=' ')
        '123 456 789.00'
        >>> moneyfmt(Decimal('-0.02'), neg='<', trailneg='>')
        '<0.02>'

        """
        q = Decimal(10) ** -places      # 2 places --> '0.01'
        sign, digits, exp = value.quantize(q).as_tuple()
        result = []
        digits = map(str, digits)
        build, next = result.append, digits.pop
        if sign:
            build(trailneg)
        for i in range(places):
            build(next() if digits else '0')
        build(dp)
        if not digits:
            build('0')
        i = 0
        while digits:
            build(next())
            i += 1
            if i == 3 and digits:
                i = 0
                build(sep)
        build(curr)
        build(neg if sign else pos)
        return ''.join(reversed(result))

    def pi():
        """Compute Pi to the current precision.

        >>> print pi()
        3.141592653589793238462643383

        """
        getcontext().prec += 2  # extra digits for intermediate steps
        three = Decimal(3)      # substitute "three=3.0" for regular floats
        lasts, t, s, n, na, d, da = 0, three, 3, 1, 0, 0, 24
        while s != lasts:
            lasts = s
            n, na = n+na, na+8
            d, da = d+da, da+32
            t = (t * n) / d
            s += t
        getcontext().prec -= 2
        return +s               # unary plus applies the new precision

    def exp(x):
        """Return e raised to the power of x.  Result type matches input type.

        >>> print exp(Decimal(1))
        2.718281828459045235360287471
        >>> print exp(Decimal(2))
        7.389056098930650227230427461
        >>> print exp(2.0)
        7.38905609893
        >>> print exp(2+0j)
        (7.38905609893+0j)

        """
        getcontext().prec += 2
        i, lasts, s, fact, num = 0, 0, 1, 1, 1
        while s != lasts:
            lasts = s
            i += 1
            fact *= i
            num *= x
            s += num / fact
        getcontext().prec -= 2
        return +s

    def cos(x):
        """Return the cosine of x as measured in radians.

        >>> print cos(Decimal('0.5'))
        0.8775825618903727161162815826
        >>> print cos(0.5)
        0.87758256189
        >>> print cos(0.5+0j)
        (0.87758256189+0j)

        """
        getcontext().prec += 2
        i, lasts, s, fact, num, sign = 0, 0, 1, 1, 1, 1
        while s != lasts:
            lasts = s
            i += 2
            fact *= i * (i-1)
            num *= x * x
            sign *= -1
            s += num / fact * sign
        getcontext().prec -= 2
        return +s

    def sin(x):
        """Return the sine of x as measured in radians.

        >>> print sin(Decimal('0.5'))
        0.4794255386042030002732879352
        >>> print sin(0.5)
        0.479425538604
        >>> print sin(0.5+0j)
        (0.479425538604+0j)

        """
        getcontext().prec += 2
        i, lasts, s, fact, num, sign = 1, 0, x, 1, x, 1
        while s != lasts:
            lasts = s
            i += 2
            fact *= i * (i-1)
            num *= x * x
            sign *= -1
            s += num / fact * sign
        getcontext().prec -= 2
        return +s



File: python.info,  Node: Decimal FAQ,  Prev: Recipes,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.11 Decimal FAQ
....................

Q. It is cumbersome to type `decimal.Decimal('1234.5')'.  Is there a
way to minimize typing when using the interactive interpreter?

  A. Some users abbreviate the constructor to just a single letter:

    >>> D = decimal.Decimal
    >>> D('1.23') + D('3.45')
    Decimal('4.68')

Q. In a fixed-point application with two decimal places, some inputs
have many places and need to be rounded.  Others are not supposed to
have excess digits and need to be validated.  What methods should be
used?

  A. The `quantize()' method rounds to a fixed number of decimal
places. If the *note Inexact: c92. trap is set, it is also useful for
validation:

    >>> TWOPLACES = Decimal(10) ** -2       # same as Decimal('0.01')


    >>> # Round to two places
    >>> Decimal('3.214').quantize(TWOPLACES)
    Decimal('3.21')


    >>> # Validate that a number does not exceed two places
    >>> Decimal('3.21').quantize(TWOPLACES, context=Context(traps=[Inexact]))
    Decimal('3.21')


    >>> Decimal('3.214').quantize(TWOPLACES, context=Context(traps=[Inexact]))
    Traceback (most recent call last):
       ...
    Inexact: None

Q. Once I have valid two place inputs, how do I maintain that invariant
throughout an application?

  A. Some operations like addition, subtraction, and multiplication by
an integer will automatically preserve fixed point.  Others operations,
like division and non-integer multiplication, will change the number of
decimal places and need to be followed-up with a `quantize()' step:

    >>> a = Decimal('102.72')           # Initial fixed-point values
    >>> b = Decimal('3.17')
    >>> a + b                           # Addition preserves fixed-point
    Decimal('105.89')
    >>> a - b
    Decimal('99.55')
    >>> a * 42                          # So does integer multiplication
    Decimal('4314.24')
    >>> (a * b).quantize(TWOPLACES)     # Must quantize non-integer multiplication
    Decimal('325.62')
    >>> (b / a).quantize(TWOPLACES)     # And quantize division
    Decimal('0.03')

In developing fixed-point applications, it is convenient to define
functions to handle the `quantize()' step:

    >>> def mul(x, y, fp=TWOPLACES):
    ...     return (x * y).quantize(fp)
    >>> def div(x, y, fp=TWOPLACES):
    ...     return (x / y).quantize(fp)


    >>> mul(a, b)                       # Automatically preserve fixed-point
    Decimal('325.62')
    >>> div(b, a)
    Decimal('0.03')

Q. There are many ways to express the same value.  The numbers `200',
`200.000', `2E2', and `02E+4' all have the same value at various
precisions. Is there a way to transform them to a single recognizable
canonical value?

  A. The `normalize()' method maps all equivalent values to a single
representative:

    >>> values = map(Decimal, '200 200.000 2E2 .02E+4'.split())
    >>> [v.normalize() for v in values]
    [Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2')]

Q. Some decimal values always print with exponential notation.  Is
there a way to get a non-exponential representation?

  A. For some values, exponential notation is the only way to express
the number of significant places in the coefficient.  For example,
expressing `5.0E+3' as `5000' keeps the value constant but cannot show
the original's two-place significance.

  If an application does not care about tracking significance, it is
easy to remove the exponent and trailing zeros, losing significance,
but keeping the value unchanged:

    def remove_exponent(d):
        '''Remove exponent and trailing zeros.

        >>> remove_exponent(Decimal('5E+3'))
        Decimal('5000')

        '''
        return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()

Q. Is there a way to convert a regular float to a *note Decimal: 1b4.?

  A. Yes, any binary floating point number can be exactly expressed as a
Decimal though an exact conversion may take more precision than
intuition would suggest:

    >>> Decimal(math.pi)
    Decimal('3.141592653589793115997963468544185161590576171875')

Q. Within a complex calculation, how can I make sure that I haven't
gotten a spurious result because of insufficient precision or rounding
anomalies.

  A. The decimal module makes it easy to test results.  A best practice
is to re-run calculations using greater precision and with various
rounding modes.  Widely differing results indicate insufficient
precision, rounding mode issues, ill-conditioned inputs, or a
numerically unstable algorithm.

  Q. I noticed that context precision is applied to the results of
operations but not to the inputs.  Is there anything to watch out for
when mixing values of different precisions?

  A. Yes.  The principle is that all values are considered to be exact
and so is the arithmetic on those values.  Only the results are
rounded.  The advantage for inputs is that "what you type is what you
get".  A disadvantage is that the results can look odd if you forget
that the inputs haven't been rounded:

    >>> getcontext().prec = 3
    >>> Decimal('3.104') + Decimal('2.104')
    Decimal('5.21')
    >>> Decimal('3.104') + Decimal('0.000') + Decimal('2.104')
    Decimal('5.20')

The solution is either to increase precision or to force rounding of
inputs using the unary plus operation:

    >>> getcontext().prec = 3
    >>> +Decimal('1.23456789')      # unary plus triggers rounding
    Decimal('1.23')

Alternatively, inputs can be rounded upon creation using the *note
Context.create_decimal(): cda. method:

    >>> Context(prec=5, rounding=ROUND_DOWN).create_decimal('1.2345678')
    Decimal('1.2345')



File: python.info,  Node: fractions --- Rational numbers,  Next: random --- Generate pseudo-random numbers,  Prev: decimal --- Decimal fixed point and floating point arithmetic,  Up: Numeric and Mathematical Modules

5.9.5 `fractions' -- Rational numbers
-------------------------------------

New in version 2.6.

  *Source code:* Lib/fractions.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note fractions: d6. module provides support for rational number
arithmetic.

  A Fraction instance can be constructed from a pair of integers, from
another rational number, or from a string.

 -- Class: fractions.Fraction (numerator=0, denominator=1)
 -- Class: fractions.Fraction (other_fraction)
 -- Class: fractions.Fraction (float)
 -- Class: fractions.Fraction (decimal)
 -- Class: fractions.Fraction (string)
     The first version requires that _numerator_ and _denominator_ are
     instances of *note numbers.Rational: 323. and returns a new *note
     Fraction: 214. instance with value `numerator/denominator'. If
     _denominator_ is `0', it raises a *note ZeroDivisionError: 5a0.
     The second version requires that _other_fraction_ is an instance
     of *note numbers.Rational: 323. and returns a *note Fraction: 214.
     instance with the same value.  The next two versions accept either
     a *note float: 1e8. or a *note decimal.Decimal: 1b4. instance, and
     return a *note Fraction: 214. instance with exactly the same
     value.  Note that due to the usual issues with binary
     floating-point (see *note Floating Point Arithmetic; Issues and
     Limitations: 611.), the argument to `Fraction(1.1)' is not exactly
     equal to 11/10, and so `Fraction(1.1)' does _not_ return
     `Fraction(11, 10)' as one might expect.  (But see the
     documentation for the *note limit_denominator(): d25. method
     below.)  The last version of the constructor expects a string or
     unicode instance.  The usual form for this instance is:

         [sign] numerator ['/' denominator]

     where the optional `sign' may be either '+' or '-' and `numerator'
     and `denominator' (if present) are strings of decimal digits.  In
     addition, any string that represents a finite value and is
     accepted by the *note float: 1e8. constructor is also accepted by
     the *note Fraction: 214. constructor.  In either form the input
     string may also have leading and/or trailing whitespace.  Here are
     some examples:

         >>> from fractions import Fraction
         >>> Fraction(16, -10)
         Fraction(-8, 5)
         >>> Fraction(123)
         Fraction(123, 1)
         >>> Fraction()
         Fraction(0, 1)
         >>> Fraction('3/7')
         Fraction(3, 7)
         >>> Fraction(' -3/7 ')
         Fraction(-3, 7)
         >>> Fraction('1.414213 \t\n')
         Fraction(1414213, 1000000)
         >>> Fraction('-.125')
         Fraction(-1, 8)
         >>> Fraction('7e-6')
         Fraction(7, 1000000)
         >>> Fraction(2.25)
         Fraction(9, 4)
         >>> Fraction(1.1)
         Fraction(2476979795053773, 2251799813685248)
         >>> from decimal import Decimal
         >>> Fraction(Decimal('1.1'))
         Fraction(11, 10)

     The *note Fraction: 214. class inherits from the abstract base
     class *note numbers.Rational: 323, and implements all of the
     methods and operations from that class.  *note Fraction: 214.
     instances are hashable, and should be treated as immutable.  In
     addition, *note Fraction: 214. has the following methods:

     Changed in version 2.7: The *note Fraction: 214. constructor now
     accepts *note float: 1e8. and *note decimal.Decimal: 1b4.
     instances.

      -- Method: from_float (flt)
          This class method constructs a *note Fraction: 214.
          representing the exact value of _flt_, which must be a *note
          float: 1e8. Beware that `Fraction.from_float(0.3)' is not the
          same value as `Fraction(3, 10)'

               Note: From Python 2.7 onwards, you can also construct a
               *note Fraction: 214. instance directly from a *note
               float: 1e8.

      -- Method: from_decimal (dec)
          This class method constructs a *note Fraction: 214.
          representing the exact value of _dec_, which must be a *note
          decimal.Decimal: 1b4.

               Note: From Python 2.7 onwards, you can also construct a
               *note Fraction: 214. instance directly from a *note
               decimal.Decimal: 1b4.  instance.

      -- Method: limit_denominator (max_denominator=1000000)
          Finds and returns the closest *note Fraction: 214. to `self'
          that has denominator at most max_denominator.  This method is
          useful for finding rational approximations to a given
          floating-point number:

              >>> from fractions import Fraction
              >>> Fraction('3.1415926535897932').limit_denominator(1000)
              Fraction(355, 113)

          or for recovering a rational number that's represented as a
          float:

              >>> from math import pi, cos
              >>> Fraction(cos(pi/3))
              Fraction(4503599627370497, 9007199254740992)
              >>> Fraction(cos(pi/3)).limit_denominator()
              Fraction(1, 2)
              >>> Fraction(1.1).limit_denominator()
              Fraction(11, 10)



 -- Function: fractions.gcd (a, b)
     Return the greatest common divisor of the integers _a_ and _b_.
     If either _a_ or _b_ is nonzero, then the absolute value of
     `gcd(a, b)' is the largest integer that divides both _a_ and _b_.
     `gcd(a,b)' has the same sign as _b_ if _b_ is nonzero; otherwise
     it takes the sign of _a_.  `gcd(0, 0)' returns `0'.

See also
........

Module *note numbers: 125.
     The abstract base classes making up the numeric tower.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/fractions.py


File: python.info,  Node: random --- Generate pseudo-random numbers,  Next: itertools --- Functions creating iterators for efficient looping,  Prev: fractions --- Rational numbers,  Up: Numeric and Mathematical Modules

5.9.6 `random' -- Generate pseudo-random numbers
------------------------------------------------

*Source code:* Lib/random.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module implements pseudo-random number generators for various
distributions.

  For integers, uniform selection from a range. For sequences, uniform
selection of a random element, a function to generate a random
permutation of a list in-place, and a function for random sampling
without replacement.

  On the real line, there are functions to compute uniform, normal
(Gaussian), lognormal, negative exponential, gamma, and beta
distributions. For generating distributions of angles, the von Mises
distribution is available.

  Almost all module functions depend on the basic function *note
random(): 142, which generates a random float uniformly in the
semi-open range [0.0, 1.0).  Python uses the Mersenne Twister as the
core generator.  It produces 53-bit precision floats and has a period
of 2**19937-1.  The underlying implementation in C is both fast and
threadsafe.  The Mersenne Twister is one of the most extensively tested
random number generators in existence.  However, being completely
deterministic, it is not suitable for all purposes, and is completely
unsuitable for cryptographic purposes.

  The functions supplied by this module are actually bound methods of a
hidden instance of the `random.Random' class.  You can instantiate your
own instances of `Random' to get generators that don't share state.
This is especially useful for multi-threaded programs, creating a
different instance of `Random' for each thread, and using the *note
jumpahead(): d2b. method to make it likely that the generated sequences
seen by each thread don't overlap.

  Class `Random' can also be subclassed if you want to use a different
basic generator of your own devising: in that case, override the *note
random(): 142, *note seed(): d2c, *note getstate(): d2d, *note
setstate(): d2e. and *note jumpahead(): d2b. methods.  Optionally, a
new generator can supply a *note getrandbits(): d2f. method -- this
allows *note randrange(): d30. to produce selections over an
arbitrarily large range.

  New in version 2.4: the *note getrandbits(): d2f. method.

  As an example of subclassing, the *note random: 142. module provides
the *note WichmannHill: d31. class that implements an alternative
generator in pure Python.  The class provides a backward compatible way
to reproduce results from earlier versions of Python, which used the
Wichmann-Hill algorithm as the core generator.  Note that this
Wichmann-Hill generator can no longer be recommended: its period is too
short by contemporary standards, and the sequence generated is known to
fail some stringent randomness tests.  See the references below for a
recent variant that repairs these flaws.

  Changed in version 2.3: MersenneTwister replaced Wichmann-Hill as the
default generator.

  The *note random: 142. module also provides the *note SystemRandom:
d32. class which uses the system function *note os.urandom(): d33. to
generate random numbers from sources provided by the operating system.

  Bookkeeping functions:

 -- Function: random.seed ([x])
     Initialize the basic random number generator. Optional argument
     _x_ can be any *note hashable: 6e5. object. If _x_ is omitted or
     `None', current system time is used; current system time is also
     used to initialize the generator when the module is first
     imported.  If randomness sources are provided by the operating
     system, they are used instead of the system time (see the *note
     os.urandom(): d33. function for details on availability).

     Changed in version 2.4: formerly, operating system resources were
     not used.

 -- Function: random.getstate ()
     Return an object capturing the current internal state of the
     generator.  This object can be passed to *note setstate(): d2e. to
     restore the state.

     New in version 2.1.

     Changed in version 2.6: State values produced in Python 2.6 cannot
     be loaded into earlier versions.

 -- Function: random.setstate (state)
     _state_ should have been obtained from a previous call to *note
     getstate(): d2d, and *note setstate(): d2e. restores the internal
     state of the generator to what it was at the time *note
     getstate(): d2d. was called.

     New in version 2.1.

 -- Function: random.jumpahead (n)
     Change the internal state to one different from and likely far
     away from the current state.  _n_ is a non-negative integer which
     is used to scramble the current state vector.  This is most useful
     in multi-threaded programs, in conjunction with multiple instances
     of the `Random' class: *note setstate(): d2e. or *note seed():
     d2c. can be used to force all instances into the same internal
     state, and then *note jumpahead(): d2b. can be used to force the
     instances' states far apart.

     New in version 2.1.

     Changed in version 2.3: Instead of jumping to a specific state,
     _n_ steps ahead, `jumpahead(n)' jumps to another state likely to
     be separated by many steps.

 -- Function: random.getrandbits (k)
     Returns a python *note long: 1f0. int with _k_ random bits. This
     method is supplied with the MersenneTwister generator and some
     other generators may also provide it as an optional part of the
     API. When available, *note getrandbits(): d2f. enables *note
     randrange(): d30. to handle arbitrarily large ranges.

     New in version 2.4.

  Functions for integers:

 -- Function: random.randrange (stop)
 -- Function: random.randrange (start, stop[, step])
     Return a randomly selected element from `range(start, stop,
     step)'.  This is equivalent to `choice(range(start, stop, step))',
     but doesn't actually build a range object.

     New in version 1.5.2.

 -- Function: random.randint (a, b)
     Return a random integer _N_ such that `a <= N <= b'.

  Functions for sequences:

 -- Function: random.choice (seq)
     Return a random element from the non-empty sequence _seq_. If
     _seq_ is empty, raises *note IndexError: 4d8.

 -- Function: random.shuffle (x[, random])
     Shuffle the sequence _x_ in place. The optional argument _random_
     is a 0-argument function returning a random float in [0.0, 1.0);
     by default, this is the function *note random(): 142.

     Note that for even rather small `len(x)', the total number of
     permutations of _x_ is larger than the period of most random
     number generators; this implies that most permutations of a long
     sequence can never be generated.

 -- Function: random.sample (population, k)
     Return a _k_ length list of unique elements chosen from the
     population sequence.  Used for random sampling without replacement.

     New in version 2.3.

     Returns a new list containing elements from the population while
     leaving the original population unchanged.  The resulting list is
     in selection order so that all sub-slices will also be valid
     random samples.  This allows raffle winners (the sample) to be
     partitioned into grand prize and second place winners (the
     subslices).

     Members of the population need not be *note hashable: 6e5. or
     unique.  If the population contains repeats, then each occurrence
     is a possible selection in the sample.

     To choose a sample from a range of integers, use an *note
     xrange(): 454. object as an argument.  This is especially fast and
     space efficient for sampling from a large population:
     `sample(xrange(10000000), 60)'.

  The following functions generate specific real-valued distributions.
Function parameters are named after the corresponding variables in the
distribution's equation, as used in common mathematical practice; most
of these equations can be found in any statistics text.

 -- Function: random.random ()
     Return the next random floating point number in the range [0.0,
     1.0).

 -- Function: random.uniform (a, b)
     Return a random floating point number _N_ such that `a <= N <= b'
     for `a <= b' and `b <= N <= a' for `b < a'.

     The end-point value `b' may or may not be included in the range
     depending on floating-point rounding in the equation `a + (b-a) *
     random()'.

 -- Function: random.triangular (low, high, mode)
     Return a random floating point number _N_ such that `low <= N <=
     high' and with the specified _mode_ between those bounds.  The
     _low_ and _high_ bounds default to zero and one.  The _mode_
     argument defaults to the midpoint between the bounds, giving a
     symmetric distribution.

     New in version 2.6.

 -- Function: random.betavariate (alpha, beta)
     Beta distribution.  Conditions on the parameters are `alpha > 0'
     and `beta > 0'. Returned values range between 0 and 1.

 -- Function: random.expovariate (lambd)
     Exponential distribution.  _lambd_ is 1.0 divided by the desired
     mean.  It should be nonzero.  (The parameter would be called
     "lambda", but that is a reserved word in Python.)  Returned values
     range from 0 to positive infinity if _lambd_ is positive, and from
     negative infinity to 0 if _lambd_ is negative.

 -- Function: random.gammavariate (alpha, beta)
     Gamma distribution.  (_Not_ the gamma function!)  Conditions on the
     parameters are `alpha > 0' and `beta > 0'.

     The probability distribution function is:

                   x ** (alpha - 1) * math.exp(-x / beta)
         pdf(x) =  --------------------------------------
                     math.gamma(alpha) * beta ** alpha



 -- Function: random.gauss (mu, sigma)
     Gaussian distribution.  _mu_ is the mean, and _sigma_ is the
     standard deviation.  This is slightly faster than the *note
     normalvariate(): d3f. function defined below.

 -- Function: random.lognormvariate (mu, sigma)
     Log normal distribution.  If you take the natural logarithm of this
     distribution, you'll get a normal distribution with mean _mu_ and
     standard deviation _sigma_.  _mu_ can have any value, and _sigma_
     must be greater than zero.

 -- Function: random.normalvariate (mu, sigma)
     Normal distribution.  _mu_ is the mean, and _sigma_ is the
     standard deviation.

 -- Function: random.vonmisesvariate (mu, kappa)
     _mu_ is the mean angle, expressed in radians between 0 and 2*_pi_,
     and _kappa_ is the concentration parameter, which must be greater
     than or equal to zero.  If _kappa_ is equal to zero, this
     distribution reduces to a uniform random angle over the range 0 to
     2*_pi_.

 -- Function: random.paretovariate (alpha)
     Pareto distribution.  _alpha_ is the shape parameter.

 -- Function: random.weibullvariate (alpha, beta)
     Weibull distribution.  _alpha_ is the scale parameter and _beta_
     is the shape parameter.

  Alternative Generators:

 -- Class: random.WichmannHill ([seed])
     Class that implements the Wichmann-Hill algorithm as the core
     generator. Has all of the same methods as `Random' plus the *note
     whseed(): d44. method described below.  Because this class is
     implemented in pure Python, it is not threadsafe and may require
     locks between calls.  The period of the generator is
     6,953,607,871,644 which is small enough to require care that two
     independent random sequences do not overlap.

 -- Function: random.whseed ([x])
     This is obsolete, supplied for bit-level compatibility with
     versions of Python prior to 2.1. See *note seed(): d2c. for
     details.  *note whseed(): d44. does not guarantee that distinct
     integer arguments yield distinct internal states, and can yield no
     more than about 2**24 distinct internal states in all.

 -- Class: random.SystemRandom ([seed])
     Class that uses the *note os.urandom(): d33. function for
     generating random numbers from sources provided by the operating
     system. Not available on all systems.  Does not rely on software
     state and sequences are not reproducible. Accordingly, the *note
     seed(): d2c. and *note jumpahead(): d2b. methods have no effect
     and are ignored.  The *note getstate(): d2d. and *note setstate():
     d2e. methods raise *note NotImplementedError: 93b. if called.

     New in version 2.4.

  Examples of basic usage:

    >>> random.random()        # Random float x, 0.0 <= x < 1.0
    0.37444887175646646
    >>> random.uniform(1, 10)  # Random float x, 1.0 <= x < 10.0
    1.1800146073117523
    >>> random.randint(1, 10)  # Integer from 1 to 10, endpoints included
    7
    >>> random.randrange(0, 101, 2)  # Even integer from 0 to 100
    26
    >>> random.choice('abcdefghij')  # Choose a random element
    'c'

    >>> items = [1, 2, 3, 4, 5, 6, 7]
    >>> random.shuffle(items)
    >>> items
    [7, 3, 2, 5, 6, 4, 1]

    >>> random.sample([1, 2, 3, 4, 5],  3)  # Choose 3 elements
    [4, 1, 5]


See also
........

M. Matsumoto and T. Nishimura, "Mersenne Twister: A 623-dimensionally
equidistributed uniform pseudorandom number generator", ACM
Transactions on Modeling and Computer Simulation Vol. 8, No. 1, January
pp.3-30 1998.

  Wichmann, B. A. & Hill, I. D., "Algorithm AS 183: An efficient and
portable pseudo-random number generator", Applied Statistics 31 (1982)
188-190.

  Complementary-Multiply-with-Carry recipe(2) for a compatible
alternative random number generator with a long period and
comparatively simple update operations.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/random.py

  (2) http://code.activestate.com/recipes/576707/


File: python.info,  Node: itertools --- Functions creating iterators for efficient looping,  Next: functools --- Higher-order functions and operations on callable objects,  Prev: random --- Generate pseudo-random numbers,  Up: Numeric and Mathematical Modules

5.9.7 `itertools' -- Functions creating iterators for efficient looping
-----------------------------------------------------------------------

New in version 2.3.

  This module implements a number of *note iterator: 869. building
blocks inspired by constructs from APL, Haskell, and SML.  Each has
been recast in a form suitable for Python.

  The module standardizes a core set of fast, memory efficient tools
that are useful by themselves or in combination.  Together, they form
an "iterator algebra" making it possible to construct specialized tools
succinctly and efficiently in pure Python.

  For instance, SML provides a tabulation tool: `tabulate(f)' which
produces a sequence `f(0), f(1), ...'.  The same effect can be achieved
in Python by combining *note imap(): d47. and *note count(): 231. to
form `imap(f, count())'.

  These tools and their built-in counterparts also work well with the
high-speed functions in the *note operator: 126. module.  For example,
the multiplication operator can be mapped across two vectors to form an
efficient dot-product: `sum(imap(operator.mul, vector1, vector2))'.

  *Infinite Iterators:*

Iterator               Arguments             Results                                               Example
------------------------------------------------------------------------------------------------------------------------------------------------- 
*note count(): 231.    start, [step]         start, start+step, start+2*step, ...                  `count(10) --> 10 11 12 13 14 ...'
*note cycle(): d48.    p                     p0, p1, ... plast, p0, p1, ...                        `cycle('ABCD') --> A B C D A B C D ...'
*note repeat(): b4f.   elem [,n]             elem, elem, elem, ... endlessly or up to n times      `repeat(10, 3) --> 10 10 10'

  *Iterators terminating on the shortest input sequence:*

Iterator                 Arguments                        Results                                               Example
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- 
*note chain(): 878.      p, q, ...                        p0, p1, ... plast, q0, q1, ...                        `chain('ABC', 'DEF') --> A B C D E F'
*note compress(): d49.   data, selectors                  (d[0] if s[0]), (d[1] if s[1]), ...                   `compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F'
*note dropwhile(): d4a.  pred, seq                        seq[n], seq[n+1], starting when pred fails            `dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1'
*note groupby(): d4b.    iterable[, keyfunc]              sub-iterators grouped by value of keyfunc(v)          
*note ifilter(): 86b.    pred, seq                        elements of seq where pred(elem) is True              `ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9'
*note ifilterfalse():    pred, seq                        elements of seq where pred(elem) is False             `ifilterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8'
86c.                                                                                                            
*note islice(): 3ba.     seq, [start,] stop [, step]      elements from seq[start:stop:step]                    `islice('ABCDEFG', 2, None) --> C D E F G'
*note imap(): d47.       func, p, q, ...                  func(p0, q0), func(p1, q1), ...                       `imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000'
*note starmap(): d4c.    func, seq                        func(*seq[0]), func(*seq[1]), ...                     `starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000'
*note tee(): d4d.        it, n                            it1, it2 , ... itn  splits one iterator into n        
*note takewhile(): d4e.  pred, seq                        seq[0], seq[1], until pred fails                      `takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4'
*note izip(): 3ff.       p, q, ...                        (p[0], q[0]), (p[1], q[1]), ...                       `izip('ABCD', 'xy') --> Ax By'
*note izip_longest():    p, q, ...                        (p[0], q[0]), (p[1], q[1]), ...                       `izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-'
d4f.                                                                                                            

  *Combinatoric generators:*

Iterator                                           Arguments                Results
---------------------------------------------------------------------------------------------------------------------------------------------- 
*note product(): 232.                              p, q, ... [repeat=1]     cartesian product, equivalent to a nested for-loop
*note permutations(): d50.                         p[, r]                   r-length tuples, all possible orderings, no repeated elements
*note combinations(): 230.                         p, r                     r-length tuples, in sorted order, no repeated elements
*note combinations_with_replacement(): b3f.        p, r                     r-length tuples, in sorted order, with repeated elements
`product('ABCD', repeat=2)'                                                 `AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD'
`permutations('ABCD', 2)'                                                   `AB AC AD BA BC BD CA CB CD DA DB DC'
`combinations('ABCD', 2)'                                                   `AB AC AD BC BD CD'
`combinations_with_replacement('ABCD', 2)'                                  `AA AB AC AD BB BC BD CC CD DD'

* Menu:

* Itertool functions::
* Recipes: Recipes<2>.


File: python.info,  Node: Itertool functions,  Next: Recipes<2>,  Up: itertools --- Functions creating iterators for efficient looping

5.9.7.1 Itertool functions
..........................

The following module functions all construct and return iterators. Some
provide streams of infinite length, so they should only be accessed by
functions or loops that truncate the stream.

 -- Function: itertools.chain (*iterables)
     Make an iterator that returns elements from the first iterable
     until it is exhausted, then proceeds to the next iterable, until
     all of the iterables are exhausted.  Used for treating consecutive
     sequences as a single sequence.  Equivalent to:

         def chain(*iterables):
             # chain('ABC', 'DEF') --> A B C D E F
             for it in iterables:
                 for element in it:
                     yield element



 -- Class Method: chain.from_iterable (iterable)
     Alternate constructor for *note chain(): 878.  Gets chained inputs
     from a single iterable argument that is evaluated lazily.  Roughly
     equivalent to:

         def from_iterable(iterables):
             # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
             for it in iterables:
                 for element in it:
                     yield element

     New in version 2.6.

 -- Function: itertools.combinations (iterable, r)
     Return _r_ length subsequences of elements from the input
     _iterable_.

     Combinations are emitted in lexicographic sort order.  So, if the
     input _iterable_ is sorted, the combination tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, there will be
     no repeat values in each combination.

     Equivalent to:

         def combinations(iterable, r):
             # combinations('ABCD', 2) --> AB AC AD BC BD CD
             # combinations(range(4), 3) --> 012 013 023 123
             pool = tuple(iterable)
             n = len(pool)
             if r > n:
                 return
             indices = range(r)
             yield tuple(pool[i] for i in indices)
             while True:
                 for i in reversed(range(r)):
                     if indices[i] != i + n - r:
                         break
                 else:
                     return
                 indices[i] += 1
                 for j in range(i+1, r):
                     indices[j] = indices[j-1] + 1
                 yield tuple(pool[i] for i in indices)

     The code for *note combinations(): 230. can be also expressed as a
     subsequence of *note permutations(): d50. after filtering entries
     where the elements are not in sorted order (according to their
     position in the input pool):

         def combinations(iterable, r):
             pool = tuple(iterable)
             n = len(pool)
             for indices in permutations(range(n), r):
                 if sorted(indices) == list(indices):
                     yield tuple(pool[i] for i in indices)

     The number of items returned is `n! / r! / (n-r)!' when `0 <= r <=
     n' or zero when `r > n'.

     New in version 2.6.

 -- Function: itertools.combinations_with_replacement (iterable, r)
     Return _r_ length subsequences of elements from the input
     _iterable_ allowing individual elements to be repeated more than
     once.

     Combinations are emitted in lexicographic sort order.  So, if the
     input _iterable_ is sorted, the combination tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, the generated
     combinations will also be unique.

     Equivalent to:

         def combinations_with_replacement(iterable, r):
             # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
             pool = tuple(iterable)
             n = len(pool)
             if not n and r:
                 return
             indices = [0] * r
             yield tuple(pool[i] for i in indices)
             while True:
                 for i in reversed(range(r)):
                     if indices[i] != n - 1:
                         break
                 else:
                     return
                 indices[i:] = [indices[i] + 1] * (r - i)
                 yield tuple(pool[i] for i in indices)

     The code for *note combinations_with_replacement(): b3f. can be
     also expressed as a subsequence of *note product(): 232. after
     filtering entries where the elements are not in sorted order
     (according to their position in the input pool):

         def combinations_with_replacement(iterable, r):
             pool = tuple(iterable)
             n = len(pool)
             for indices in product(range(n), repeat=r):
                 if sorted(indices) == list(indices):
                     yield tuple(pool[i] for i in indices)

     The number of items returned is `(n+r-1)! / r! / (n-1)!' when `n >
     0'.

     New in version 2.7.

 -- Function: itertools.compress (data, selectors)
     Make an iterator that filters elements from _data_ returning only
     those that have a corresponding element in _selectors_ that
     evaluates to `True'.  Stops when either the _data_ or _selectors_
     iterables has been exhausted.  Equivalent to:

         def compress(data, selectors):
             # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
             return (d for d, s in izip(data, selectors) if s)

     New in version 2.7.

 -- Function: itertools.count (start=0, step=1)
     Make an iterator that returns evenly spaced values starting with
     _n_. Often used as an argument to *note imap(): d47. to generate
     consecutive data points.  Also, used with *note izip(): 3ff. to
     add sequence numbers.  Equivalent to:

         def count(start=0, step=1):
             # count(10) --> 10 11 12 13 14 ...
             # count(2.5, 0.5) -> 2.5 3.0 3.5 ...
             n = start
             while True:
                 yield n
                 n += step

     When counting with floating point numbers, better accuracy can
     sometimes be achieved by substituting multiplicative code such as:
     `(start + step * i for i in count())'.

     Changed in version 2.7: added _step_ argument and allowed
     non-integer arguments.

 -- Function: itertools.cycle (iterable)
     Make an iterator returning elements from the iterable and saving a
     copy of each.  When the iterable is exhausted, return elements
     from the saved copy.  Repeats indefinitely.  Equivalent to:

         def cycle(iterable):
             # cycle('ABCD') --> A B C D A B C D A B C D ...
             saved = []
             for element in iterable:
                 yield element
                 saved.append(element)
             while saved:
                 for element in saved:
                       yield element

     Note, this member of the toolkit may require significant auxiliary
     storage (depending on the length of the iterable).

 -- Function: itertools.dropwhile (predicate, iterable)
     Make an iterator that drops elements from the iterable as long as
     the predicate is true; afterwards, returns every element.  Note,
     the iterator does not produce _any_ output until the predicate
     first becomes false, so it may have a lengthy start-up time.
     Equivalent to:

         def dropwhile(predicate, iterable):
             # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
             iterable = iter(iterable)
             for x in iterable:
                 if not predicate(x):
                     yield x
                     break
             for x in iterable:
                 yield x



 -- Function: itertools.groupby (iterable[, key])
     Make an iterator that returns consecutive keys and groups from the
     _iterable_.  The _key_ is a function computing a key value for
     each element.  If not specified or is `None', _key_ defaults to an
     identity function and returns the element unchanged.  Generally,
     the iterable needs to already be sorted on the same key function.

     The operation of *note groupby(): d4b. is similar to the `uniq'
     filter in Unix.  It generates a break or new group every time the
     value of the key function changes (which is why it is usually
     necessary to have sorted the data using the same key function).
     That behavior differs from SQL's GROUP BY which aggregates common
     elements regardless of their input order.

     The returned group is itself an iterator that shares the
     underlying iterable with *note groupby(): d4b.  Because the source
     is shared, when the *note groupby(): d4b.  object is advanced, the
     previous group is no longer visible.  So, if that data is needed
     later, it should be stored as a list:

         groups = []
         uniquekeys = []
         data = sorted(data, key=keyfunc)
         for k, g in groupby(data, keyfunc):
             groups.append(list(g))      # Store group iterator as a list
             uniquekeys.append(k)

     *note groupby(): d4b. is equivalent to:

         class groupby(object):
             # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
             # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
             def __init__(self, iterable, key=None):
                 if key is None:
                     key = lambda x: x
                 self.keyfunc = key
                 self.it = iter(iterable)
                 self.tgtkey = self.currkey = self.currvalue = object()
             def __iter__(self):
                 return self
             def next(self):
                 while self.currkey == self.tgtkey:
                     self.currvalue = next(self.it)    # Exit on StopIteration
                     self.currkey = self.keyfunc(self.currvalue)
                 self.tgtkey = self.currkey
                 return (self.currkey, self._grouper(self.tgtkey))
             def _grouper(self, tgtkey):
                 while self.currkey == tgtkey:
                     yield self.currvalue
                     self.currvalue = next(self.it)    # Exit on StopIteration
                     self.currkey = self.keyfunc(self.currvalue)

     New in version 2.4.

 -- Function: itertools.ifilter (predicate, iterable)
     Make an iterator that filters elements from iterable returning
     only those for which the predicate is `True'. If _predicate_ is
     `None', return the items that are true. Equivalent to:

         def ifilter(predicate, iterable):
             # ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9
             if predicate is None:
                 predicate = bool
             for x in iterable:
                 if predicate(x):
                     yield x



 -- Function: itertools.ifilterfalse (predicate, iterable)
     Make an iterator that filters elements from iterable returning
     only those for which the predicate is `False'. If _predicate_ is
     `None', return the items that are false. Equivalent to:

         def ifilterfalse(predicate, iterable):
             # ifilterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
             if predicate is None:
                 predicate = bool
             for x in iterable:
                 if not predicate(x):
                     yield x



 -- Function: itertools.imap (function, *iterables)
     Make an iterator that computes the function using arguments from
     each of the iterables.  If _function_ is set to `None', then *note
     imap(): d47. returns the arguments as a tuple.  Like *note map():
     2fd. but stops when the shortest iterable is exhausted instead of
     filling in `None' for shorter iterables.  The reason for the
     difference is that infinite iterator arguments are typically an
     error for *note map(): 2fd. (because the output is fully
     evaluated) but represent a common and useful way of supplying
     arguments to *note imap(): d47. Equivalent to:

         def imap(function, *iterables):
             # imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000
             iterables = map(iter, iterables)
             while True:
                 args = [next(it) for it in iterables]
                 if function is None:
                     yield tuple(args)
                 else:
                     yield function(*args)



 -- Function: itertools.islice (iterable, stop)
 -- Function: itertools.islice (iterable, start, stop[, step])
     Make an iterator that returns selected elements from the iterable.
     If _start_ is non-zero, then elements from the iterable are
     skipped until start is reached.  Afterward, elements are returned
     consecutively unless _step_ is set higher than one which results
     in items being skipped.  If _stop_ is `None', then iteration
     continues until the iterator is exhausted, if at all; otherwise,
     it stops at the specified position.  Unlike regular slicing, *note
     islice(): 3ba. does not support negative values for _start_,
     _stop_, or _step_.  Can be used to extract related fields from
     data where the internal structure has been flattened (for example,
     a multi-line report may list a name field on every third line).
     Equivalent to:

         def islice(iterable, *args):
             # islice('ABCDEFG', 2) --> A B
             # islice('ABCDEFG', 2, 4) --> C D
             # islice('ABCDEFG', 2, None) --> C D E F G
             # islice('ABCDEFG', 0, None, 2) --> A C E G
             s = slice(*args)
             it = iter(xrange(s.start or 0, s.stop or sys.maxint, s.step or 1))
             nexti = next(it)
             for i, element in enumerate(iterable):
                 if i == nexti:
                     yield element
                     nexti = next(it)

     If _start_ is `None', then iteration starts at zero. If _step_ is
     `None', then the step defaults to one.

     Changed in version 2.5: accept `None' values for default _start_
     and _step_.

 -- Function: itertools.izip (*iterables)
     Make an iterator that aggregates elements from each of the
     iterables. Like *note zip(): 3fe. except that it returns an
     iterator instead of a list.  Used for lock-step iteration over
     several iterables at a time.  Equivalent to:

         def izip(*iterables):
             # izip('ABCD', 'xy') --> Ax By
             iterators = map(iter, iterables)
             while iterators:
                 yield tuple(map(next, iterators))

     Changed in version 2.4: When no iterables are specified, returns a
     zero length iterator instead of raising a *note TypeError: 215.
     exception.

     The left-to-right evaluation order of the iterables is guaranteed.
     This makes possible an idiom for clustering a data series into
     n-length groups using `izip(*[iter(s)]*n)'.

     *note izip(): 3ff. should only be used with unequal length inputs
     when you don't care about trailing, unmatched values from the
     longer iterables.  If those values are important, use *note
     izip_longest(): d4f. instead.

 -- Function: itertools.izip_longest (*iterables[, fillvalue])
     Make an iterator that aggregates elements from each of the
     iterables. If the iterables are of uneven length, missing values
     are filled-in with _fillvalue_.  Iteration continues until the
     longest iterable is exhausted.  Equivalent to:

         class ZipExhausted(Exception):
             pass

         def izip_longest(*args, **kwds):
             # izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
             fillvalue = kwds.get('fillvalue')
             counter = [len(args) - 1]
             def sentinel():
                 if not counter[0]:
                     raise ZipExhausted
                 counter[0] -= 1
                 yield fillvalue
             fillers = repeat(fillvalue)
             iterators = [chain(it, sentinel(), fillers) for it in args]
             try:
                 while iterators:
                     yield tuple(map(next, iterators))
             except ZipExhausted:
                 pass

     If one of the iterables is potentially infinite, then the *note
     izip_longest(): d4f. function should be wrapped with something
     that limits the number of calls (for example *note islice(): 3ba.
     or *note takewhile(): d4e.).  If not specified, _fillvalue_
     defaults to `None'.

     New in version 2.6.

 -- Function: itertools.permutations (iterable[, r])
     Return successive _r_ length permutations of elements in the
     _iterable_.

     If _r_ is not specified or is `None', then _r_ defaults to the
     length of the _iterable_ and all possible full-length permutations
     are generated.

     Permutations are emitted in lexicographic sort order.  So, if the
     input _iterable_ is sorted, the permutation tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, there will be
     no repeat values in each permutation.

     Equivalent to:

         def permutations(iterable, r=None):
             # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
             # permutations(range(3)) --> 012 021 102 120 201 210
             pool = tuple(iterable)
             n = len(pool)
             r = n if r is None else r
             if r > n:
                 return
             indices = range(n)
             cycles = range(n, n-r, -1)
             yield tuple(pool[i] for i in indices[:r])
             while n:
                 for i in reversed(range(r)):
                     cycles[i] -= 1
                     if cycles[i] == 0:
                         indices[i:] = indices[i+1:] + indices[i:i+1]
                         cycles[i] = n - i
                     else:
                         j = cycles[i]
                         indices[i], indices[-j] = indices[-j], indices[i]
                         yield tuple(pool[i] for i in indices[:r])
                         break
                 else:
                     return

     The code for *note permutations(): d50. can be also expressed as a
     subsequence of *note product(): 232, filtered to exclude entries
     with repeated elements (those from the same position in the input
     pool):

         def permutations(iterable, r=None):
             pool = tuple(iterable)
             n = len(pool)
             r = n if r is None else r
             for indices in product(range(n), repeat=r):
                 if len(set(indices)) == r:
                     yield tuple(pool[i] for i in indices)

     The number of items returned is `n! / (n-r)!' when `0 <= r <= n'
     or zero when `r > n'.

     New in version 2.6.

 -- Function: itertools.product (*iterables[, repeat])
     Cartesian product of input iterables.

     Equivalent to nested for-loops in a generator expression. For
     example, `product(A, B)' returns the same as `((x,y) for x in A
     for y in B)'.

     The nested loops cycle like an odometer with the rightmost element
     advancing on every iteration.  This pattern creates a
     lexicographic ordering so that if the input's iterables are
     sorted, the product tuples are emitted in sorted order.

     To compute the product of an iterable with itself, specify the
     number of repetitions with the optional _repeat_ keyword argument.
     For example, `product(A, repeat=4)' means the same as `product(A,
     A, A, A)'.

     This function is equivalent to the following code, except that the
     actual implementation does not build up intermediate results in
     memory:

         def product(*args, **kwds):
             # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
             # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
             pools = map(tuple, args) * kwds.get('repeat', 1)
             result = [[]]
             for pool in pools:
                 result = [x+[y] for x in result for y in pool]
             for prod in result:
                 yield tuple(prod)

     New in version 2.6.

 -- Function: itertools.repeat (object[, times])
     Make an iterator that returns _object_ over and over again. Runs
     indefinitely unless the _times_ argument is specified. Used as
     argument to *note imap(): d47. for invariant function parameters.
     Also used with *note izip(): 3ff. to create constant fields in a
     tuple record.  Equivalent to:

         def repeat(object, times=None):
             # repeat(10, 3) --> 10 10 10
             if times is None:
                 while True:
                     yield object
             else:
                 for i in xrange(times):
                     yield object

     A common use for _repeat_ is to supply a stream of constant values
     to _imap_ or _zip_:

         >>> list(imap(pow, xrange(10), repeat(2)))
         [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]



 -- Function: itertools.starmap (function, iterable)
     Make an iterator that computes the function using arguments
     obtained from the iterable.  Used instead of *note imap(): d47.
     when argument parameters are already grouped in tuples from a
     single iterable (the data has been "pre-zipped").  The difference
     between *note imap(): d47. and *note starmap(): d4c. parallels the
     distinction between `function(a,b)' and `function(*c)'. Equivalent
     to:

         def starmap(function, iterable):
             # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
             for args in iterable:
                 yield function(*args)

     Changed in version 2.6: Previously, *note starmap(): d4c. required
     the function arguments to be tuples.  Now, any iterable is allowed.

 -- Function: itertools.takewhile (predicate, iterable)
     Make an iterator that returns elements from the iterable as long
     as the predicate is true.  Equivalent to:

         def takewhile(predicate, iterable):
             # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
             for x in iterable:
                 if predicate(x):
                     yield x
                 else:
                     break



 -- Function: itertools.tee (iterable[, n=2])
     Return _n_ independent iterators from a single iterable.
     Equivalent to:

         def tee(iterable, n=2):
             it = iter(iterable)
             deques = [collections.deque() for i in range(n)]
             def gen(mydeque):
                 while True:
                     if not mydeque:             # when the local deque is empty
                         newval = next(it)       # fetch a new value and
                         for d in deques:        # load it to all the deques
                             d.append(newval)
                     yield mydeque.popleft()
             return tuple(gen(d) for d in deques)

     Once *note tee(): d4d. has made a split, the original _iterable_
     should not be used anywhere else; otherwise, the _iterable_ could
     get advanced without the tee objects being informed.

     This itertool may require significant auxiliary storage (depending
     on how much temporary data needs to be stored). In general, if one
     iterator uses most or all of the data before another iterator
     starts, it is faster to use *note list(): 3b5. instead of *note
     tee(): d4d.

     New in version 2.4.


File: python.info,  Node: Recipes<2>,  Prev: Itertool functions,  Up: itertools --- Functions creating iterators for efficient looping

5.9.7.2 Recipes
...............

This section shows recipes for creating an extended toolset using the
existing itertools as building blocks.

  The extended tools offer the same high performance as the underlying
toolset.  The superior memory performance is kept by processing
elements one at a time rather than bringing the whole iterable into
memory all at once. Code volume is kept small by linking the tools
together in a functional style which helps eliminate temporary
variables.  High speed is retained by preferring "vectorized" building
blocks over the use of for-loops and *note generator: 5cd.s which incur
interpreter overhead.

    def take(n, iterable):
        "Return first n items of the iterable as a list"
        return list(islice(iterable, n))

    def tabulate(function, start=0):
        "Return function(0), function(1), ..."
        return imap(function, count(start))

    def consume(iterator, n):
        "Advance the iterator n-steps ahead. If n is none, consume entirely."
        # Use functions that consume iterators at C speed.
        if n is None:
            # feed the entire iterator into a zero-length deque
            collections.deque(iterator, maxlen=0)
        else:
            # advance to the empty slice starting at position n
            next(islice(iterator, n, n), None)

    def nth(iterable, n, default=None):
        "Returns the nth item or a default value"
        return next(islice(iterable, n, None), default)

    def quantify(iterable, pred=bool):
        "Count how many times the predicate is true"
        return sum(imap(pred, iterable))

    def padnone(iterable):
        """Returns the sequence elements and then returns None indefinitely.

        Useful for emulating the behavior of the built-in map() function.
        """
        return chain(iterable, repeat(None))

    def ncycles(iterable, n):
        "Returns the sequence elements n times"
        return chain.from_iterable(repeat(tuple(iterable), n))

    def dotproduct(vec1, vec2):
        return sum(imap(operator.mul, vec1, vec2))

    def flatten(listOfLists):
        "Flatten one level of nesting"
        return chain.from_iterable(listOfLists)

    def repeatfunc(func, times=None, *args):
        """Repeat calls to func with specified arguments.

        Example:  repeatfunc(random.random)
        """
        if times is None:
            return starmap(func, repeat(args))
        return starmap(func, repeat(args, times))

    def pairwise(iterable):
        "s -> (s0,s1), (s1,s2), (s2, s3), ..."
        a, b = tee(iterable)
        next(b, None)
        return izip(a, b)

    def grouper(iterable, n, fillvalue=None):
        "Collect data into fixed-length chunks or blocks"
        # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx
        args = [iter(iterable)] * n
        return izip_longest(fillvalue=fillvalue, *args)

    def roundrobin(*iterables):
        "roundrobin('ABC', 'D', 'EF') --> A D E B F C"
        # Recipe credited to George Sakkis
        pending = len(iterables)
        nexts = cycle(iter(it).next for it in iterables)
        while pending:
            try:
                for next in nexts:
                    yield next()
            except StopIteration:
                pending -= 1
                nexts = cycle(islice(nexts, pending))

    def powerset(iterable):
        "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
        s = list(iterable)
        return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))

    def unique_everseen(iterable, key=None):
        "List unique elements, preserving order. Remember all elements ever seen."
        # unique_everseen('AAAABBBCCDAABBB') --> A B C D
        # unique_everseen('ABBCcAD', str.lower) --> A B C D
        seen = set()
        seen_add = seen.add
        if key is None:
            for element in ifilterfalse(seen.__contains__, iterable):
                seen_add(element)
                yield element
        else:
            for element in iterable:
                k = key(element)
                if k not in seen:
                    seen_add(k)
                    yield element

    def unique_justseen(iterable, key=None):
        "List unique elements, preserving order. Remember only the element just seen."
        # unique_justseen('AAAABBBCCDAABBB') --> A B C D A B
        # unique_justseen('ABBCcAD', str.lower) --> A B C A D
        return imap(next, imap(itemgetter(1), groupby(iterable, key)))

    def iter_except(func, exception, first=None):
        """ Call a function repeatedly until an exception is raised.

        Converts a call-until-exception interface to an iterator interface.
        Like __builtin__.iter(func, sentinel) but uses an exception instead
        of a sentinel to end the loop.

        Examples:
            bsddbiter = iter_except(db.next, bsddb.error, db.first)
            heapiter = iter_except(functools.partial(heappop, h), IndexError)
            dictiter = iter_except(d.popitem, KeyError)
            dequeiter = iter_except(d.popleft, IndexError)
            queueiter = iter_except(q.get_nowait, Queue.Empty)
            setiter = iter_except(s.pop, KeyError)

        """
        try:
            if first is not None:
                yield first()
            while 1:
                yield func()
        except exception:
            pass

    def random_product(*args, **kwds):
        "Random selection from itertools.product(*args, **kwds)"
        pools = map(tuple, args) * kwds.get('repeat', 1)
        return tuple(random.choice(pool) for pool in pools)

    def random_permutation(iterable, r=None):
        "Random selection from itertools.permutations(iterable, r)"
        pool = tuple(iterable)
        r = len(pool) if r is None else r
        return tuple(random.sample(pool, r))

    def random_combination(iterable, r):
        "Random selection from itertools.combinations(iterable, r)"
        pool = tuple(iterable)
        n = len(pool)
        indices = sorted(random.sample(xrange(n), r))
        return tuple(pool[i] for i in indices)

    def random_combination_with_replacement(iterable, r):
        "Random selection from itertools.combinations_with_replacement(iterable, r)"
        pool = tuple(iterable)
        n = len(pool)
        indices = sorted(random.randrange(n) for i in xrange(r))
        return tuple(pool[i] for i in indices)

    def tee_lookahead(t, i):
        """Inspect the i-th upcomping value from a tee object
           while leaving the tee object at its current position.

           Raise an IndexError if the underlying iterator doesn't
           have enough values.

        """
        for value in islice(t.__copy__(), i, None):
            return value
        raise IndexError(i)

Note, many of the above recipes can be optimized by replacing global
lookups with local variables defined as default values.  For example,
the _dotproduct_ recipe can be written as:

    def dotproduct(vec1, vec2, sum=sum, imap=imap, mul=operator.mul):
        return sum(imap(mul, vec1, vec2))



File: python.info,  Node: functools --- Higher-order functions and operations on callable objects,  Next: operator --- Standard operators as functions,  Prev: itertools --- Functions creating iterators for efficient looping,  Up: Numeric and Mathematical Modules

5.9.8 `functools' -- Higher-order functions and operations on callable objects
------------------------------------------------------------------------------

New in version 2.5.

  *Source code:* Lib/functools.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note functools: d9. module is for higher-order functions:
functions that act on or return other functions. In general, any
callable object can be treated as a function for the purposes of this
module.

  The *note functools: d9. module defines the following functions:

 -- Function: functools.cmp_to_key (func)
     Transform an old-style comparison function to a key function.
     Used with tools that accept key functions (such as *note sorted():
     220, *note min(): 221, *note max(): 222, *note heapq.nlargest():
     b70, *note heapq.nsmallest(): b71, *note itertools.groupby():
     d4b.).  This function is primarily used as a transition tool for
     programs being converted to Python 3 where comparison functions are
     no longer supported.

     A comparison function is any callable that accept two arguments,
     compares them, and returns a negative number for less-than, zero
     for equality, or a positive number for greater-than.  A key
     function is a callable that accepts one argument and returns
     another value that indicates the position in the desired collation
     sequence.

     Example:

         sorted(iterable, key=cmp_to_key(locale.strcoll))  # locale-aware sort order

     New in version 2.7.

 -- Function: functools.total_ordering (cls)
     Given a class defining one or more rich comparison ordering
     methods, this class decorator supplies the rest.  This simplifies
     the effort involved in specifying all of the possible rich
     comparison operations:

     The class must define one of *note __lt__(): 21a, *note __le__():
     21b, *note __gt__(): 21c, or *note __ge__(): 21d.  In addition,
     the class should supply an *note __eq__(): 219. method.

     For example:

         @total_ordering
         class Student:
             def __eq__(self, other):
                 return ((self.lastname.lower(), self.firstname.lower()) ==
                         (other.lastname.lower(), other.firstname.lower()))
             def __lt__(self, other):
                 return ((self.lastname.lower(), self.firstname.lower()) <
                         (other.lastname.lower(), other.firstname.lower()))

     New in version 2.7.

 -- Function: functools.reduce (function, iterable[, initializer])
     This is the same function as *note reduce(): 2e2.  It is made
     available in this module to allow writing code more
     forward-compatible with Python 3.

     New in version 2.6.

 -- Function: functools.partial (func[,*args][, **keywords])
     Return a new *note partial: d58. object which when called will
     behave like _func_ called with the positional arguments _args_ and
     keyword arguments _keywords_. If more arguments are supplied to
     the call, they are appended to _args_. If additional keyword
     arguments are supplied, they extend and override _keywords_.
     Roughly equivalent to:

         def partial(func, *args, **keywords):
             def newfunc(*fargs, **fkeywords):
                 newkeywords = keywords.copy()
                 newkeywords.update(fkeywords)
                 return func(*(args + fargs), **newkeywords)
             newfunc.func = func
             newfunc.args = args
             newfunc.keywords = keywords
             return newfunc

     The *note partial(): d58. is used for partial function application
     which "freezes" some portion of a function's arguments and/or
     keywords resulting in a new object with a simplified signature.
     For example, *note partial(): d58. can be used to create a
     callable that behaves like the *note int(): 1ef. function where
     the _base_ argument defaults to two:

         >>> from functools import partial
         >>> basetwo = partial(int, base=2)
         >>> basetwo.__doc__ = 'Convert base 2 string to an int.'
         >>> basetwo('10010')
         18



 -- Function: functools.update_wrapper (wrapper, wrapped[, assigned][,
          updated])
     Update a _wrapper_ function to look like the _wrapped_ function.
     The optional arguments are tuples to specify which attributes of
     the original function are assigned directly to the matching
     attributes on the wrapper function and which attributes of the
     wrapper function are updated with the corresponding attributes
     from the original function. The default values for these arguments
     are the module level constants _WRAPPER_ASSIGNMENTS_ (which
     assigns to the wrapper function's ___name___, ___module___ and
     ___doc___, the documentation string) and _WRAPPER_UPDATES_ (which
     updates the wrapper function's ___dict___, i.e. the instance
     dictionary).

     The main intended use for this function is in *note decorator:
     841. functions which wrap the decorated function and return the
     wrapper. If the wrapper function is not updated, the metadata of
     the returned function will reflect the wrapper definition rather
     than the original function definition, which is typically less
     than helpful.

 -- Function: functools.wraps (wrapped[, assigned][, updated])
     This is a convenience function for invoking
     `partial(update_wrapper, wrapped=wrapped, assigned=assigned,
     updated=updated)' as a function decorator when defining a wrapper
     function. For example:

         >>> from functools import wraps
         >>> def my_decorator(f):
         ...     @wraps(f)
         ...     def wrapper(*args, **kwds):
         ...         print 'Calling decorated function'
         ...         return f(*args, **kwds)
         ...     return wrapper
         ...
         >>> @my_decorator
         ... def example():
         ...     """Docstring"""
         ...     print 'Called example function'
         ...
         >>> example()
         Calling decorated function
         Called example function
         >>> example.__name__
         'example'
         >>> example.__doc__
         'Docstring'

     Without the use of this decorator factory, the name of the example
     function would have been `'wrapper'', and the docstring of the
     original `example()' would have been lost.

* Menu:

* partial Objects::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/functools.py


File: python.info,  Node: partial Objects,  Up: functools --- Higher-order functions and operations on callable objects

5.9.8.1 `partial' Objects
.........................

*note partial: d58. objects are callable objects created by *note
partial(): d58. They have three read-only attributes:

 -- Attribute: partial.func
     A callable object or function.  Calls to the *note partial: d58.
     object will be forwarded to *note func: d5d. with new arguments
     and keywords.

 -- Attribute: partial.args
     The leftmost positional arguments that will be prepended to the
     positional arguments provided to a *note partial: d58. object call.

 -- Attribute: partial.keywords
     The keyword arguments that will be supplied when the *note
     partial: d58. object is called.

  *note partial: d58. objects are like `function' objects in that they
are callable, weak referencable, and can have attributes.  There are
some important differences.  For instance, the `__name__' and `__doc__'
attributes are not created automatically.  Also, *note partial: d58.
objects defined in classes behave like static methods and do not
transform into bound methods during instance attribute look-up.


File: python.info,  Node: operator --- Standard operators as functions,  Prev: functools --- Higher-order functions and operations on callable objects,  Up: Numeric and Mathematical Modules

5.9.9 `operator' -- Standard operators as functions
---------------------------------------------------

The *note operator: 126. module exports a set of efficient functions
corresponding to the intrinsic operators of Python.  For example,
`operator.add(x, y)' is equivalent to the expression `x+y'.  The
function names are those used for special class methods; variants
without leading and trailing `__' are also provided for convenience.

  The functions fall into categories that perform object comparisons,
logical operations, mathematical operations, sequence operations, and
abstract type tests.

  The object comparison functions are useful for all objects, and are
named after the rich comparison operators they support:

 -- Function: operator.lt (a, b)
 -- Function: operator.le (a, b)
 -- Function: operator.eq (a, b)
 -- Function: operator.ne (a, b)
 -- Function: operator.ge (a, b)
 -- Function: operator.gt (a, b)
 -- Function: operator.__lt__ (a, b)
 -- Function: operator.__le__ (a, b)
 -- Function: operator.__eq__ (a, b)
 -- Function: operator.__ne__ (a, b)
 -- Function: operator.__ge__ (a, b)
 -- Function: operator.__gt__ (a, b)
     Perform "rich comparisons" between _a_ and _b_. Specifically,
     `lt(a, b)' is equivalent to `a < b', `le(a, b)' is equivalent to
     `a <= b', `eq(a, b)' is equivalent to `a == b', `ne(a, b)' is
     equivalent to `a != b', `gt(a, b)' is equivalent to `a > b' and
     `ge(a, b)' is equivalent to `a >= b'.  Note that unlike the
     built-in *note cmp(): 4b5, these functions can return any value,
     which may or may not be interpretable as a Boolean value.  See
     *note Comparisons: 7c7. for more information about rich
     comparisons.

     New in version 2.2.

  The logical operations are also generally applicable to all objects,
and support truth tests, identity tests, and boolean operations:

 -- Function: operator.not_ (obj)
 -- Function: operator.__not__ (obj)
     Return the outcome of *note not: 7d0. _obj_.  (Note that there is
     no *note __not__(): d6f. method for object instances; only the
     interpreter core defines this operation.  The result is affected
     by the *note __nonzero__(): 6f9. and *note __len__(): 403.
     methods.)

 -- Function: operator.truth (obj)
     Return *note True: 3a9. if _obj_ is true, and *note False: 3aa.
     otherwise.  This is equivalent to using the *note bool: 435.
     constructor.

 -- Function: operator.is_ (a, b)
     Return `a is b'.  Tests object identity.

     New in version 2.3.

 -- Function: operator.is_not (a, b)
     Return `a is not b'.  Tests object identity.

     New in version 2.3.

  The mathematical and bitwise operations are the most numerous:

 -- Function: operator.abs (obj)
 -- Function: operator.__abs__ (obj)
     Return the absolute value of _obj_.

 -- Function: operator.add (a, b)
 -- Function: operator.__add__ (a, b)
     Return `a + b', for _a_ and _b_ numbers.

 -- Function: operator.and_ (a, b)
 -- Function: operator.__and__ (a, b)
     Return the bitwise and of _a_ and _b_.

 -- Function: operator.div (a, b)
 -- Function: operator.__div__ (a, b)
     Return `a / b' when `__future__.division' is not in effect.  This
     is also known as "classic" division.

 -- Function: operator.floordiv (a, b)
 -- Function: operator.__floordiv__ (a, b)
     Return `a // b'.

     New in version 2.2.

 -- Function: operator.index (a)
 -- Function: operator.__index__ (a)
     Return _a_ converted to an integer.  Equivalent to `a.__index__()'.

     New in version 2.5.

 -- Function: operator.inv (obj)
 -- Function: operator.invert (obj)
 -- Function: operator.__inv__ (obj)
 -- Function: operator.__invert__ (obj)
     Return the bitwise inverse of the number _obj_.  This is
     equivalent to `~obj'.

     New in version 2.0: The names *note invert(): d7f. and *note
     __invert__(): d81.

 -- Function: operator.lshift (a, b)
 -- Function: operator.__lshift__ (a, b)
     Return _a_ shifted left by _b_.

 -- Function: operator.mod (a, b)
 -- Function: operator.__mod__ (a, b)
     Return `a % b'.

 -- Function: operator.mul (a, b)
 -- Function: operator.__mul__ (a, b)
     Return `a * b', for _a_ and _b_ numbers.

 -- Function: operator.neg (obj)
 -- Function: operator.__neg__ (obj)
     Return _obj_ negated (`-obj').

 -- Function: operator.or_ (a, b)
 -- Function: operator.__or__ (a, b)
     Return the bitwise or of _a_ and _b_.

 -- Function: operator.pos (obj)
 -- Function: operator.__pos__ (obj)
     Return _obj_ positive (`+obj').

 -- Function: operator.pow (a, b)
 -- Function: operator.__pow__ (a, b)
     Return `a ** b', for _a_ and _b_ numbers.

     New in version 2.3.

 -- Function: operator.rshift (a, b)
 -- Function: operator.__rshift__ (a, b)
     Return _a_ shifted right by _b_.

 -- Function: operator.sub (a, b)
 -- Function: operator.__sub__ (a, b)
     Return `a - b'.

 -- Function: operator.truediv (a, b)
 -- Function: operator.__truediv__ (a, b)
     Return `a / b' when `__future__.division' is in effect.  This is
     also known as "true" division.

     New in version 2.2.

 -- Function: operator.xor (a, b)
 -- Function: operator.__xor__ (a, b)
     Return the bitwise exclusive or of _a_ and _b_.

  Operations which work with sequences (some of them with mappings too)
include:

 -- Function: operator.concat (a, b)
 -- Function: operator.__concat__ (a, b)
     Return `a + b' for _a_ and _b_ sequences.

 -- Function: operator.contains (a, b)
 -- Function: operator.__contains__ (a, b)
     Return the outcome of the test `b in a'. Note the reversed
     operands.

     New in version 2.0: The name *note __contains__(): d9b.

 -- Function: operator.countOf (a, b)
     Return the number of occurrences of _b_ in _a_.

 -- Function: operator.delitem (a, b)
 -- Function: operator.__delitem__ (a, b)
     Remove the value of _a_ at index _b_.

 -- Function: operator.delslice (a, b, c)
 -- Function: operator.__delslice__ (a, b, c)
     Delete the slice of _a_ from index _b_ to index _c-1_.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *note delitem(): d9d. with a slice index.

 -- Function: operator.getitem (a, b)
 -- Function: operator.__getitem__ (a, b)
     Return the value of _a_ at index _b_.

 -- Function: operator.getslice (a, b, c)
 -- Function: operator.__getslice__ (a, b, c)
     Return the slice of _a_ from index _b_ to index _c-1_.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *note getitem(): da1. with a slice index.

 -- Function: operator.indexOf (a, b)
     Return the index of the first of occurrence of _b_ in _a_.

 -- Function: operator.repeat (a, b)
 -- Function: operator.__repeat__ (a, b)
     Deprecated since version 2.7: Use *note __mul__(): d87. instead.

     Return `a * b' where _a_ is a sequence and _b_ is an integer.

 -- Function: operator.sequenceIncludes (...)
     Deprecated since version 2.0: Use *note contains(): d9a. instead.

     Alias for *note contains(): d9a.

 -- Function: operator.setitem (a, b, c)
 -- Function: operator.__setitem__ (a, b, c)
     Set the value of _a_ at index _b_ to _c_.

 -- Function: operator.setslice (a, b, c, v)
 -- Function: operator.__setslice__ (a, b, c, v)
     Set the slice of _a_ from index _b_ to index _c-1_ to the sequence
     _v_.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *note setitem(): da8. with a slice index.

  Example use of operator functions:

    >>> # Elementwise multiplication
    >>> map(mul, [0, 1, 2, 3], [10, 20, 30, 40])
    [0, 20, 60, 120]

    >>> # Dot product
    >>> sum(map(mul, [0, 1, 2, 3], [10, 20, 30, 40]))
    200

Many operations have an "in-place" version.  The following functions
provide a more primitive access to in-place operators than the usual
syntax does; for example, the *note statement: dac. `x += y' is
equivalent to `x = operator.iadd(x, y)'.  Another way to put it is to
say that `z = operator.iadd(x, y)' is equivalent to the compound
statement `z = x; z += y'.

 -- Function: operator.iadd (a, b)
 -- Function: operator.__iadd__ (a, b)
     `a = iadd(a, b)' is equivalent to `a += b'.

     New in version 2.5.

 -- Function: operator.iand (a, b)
 -- Function: operator.__iand__ (a, b)
     `a = iand(a, b)' is equivalent to `a &= b'.

     New in version 2.5.

 -- Function: operator.iconcat (a, b)
 -- Function: operator.__iconcat__ (a, b)
     `a = iconcat(a, b)' is equivalent to `a += b' for _a_ and _b_
     sequences.

     New in version 2.5.

 -- Function: operator.idiv (a, b)
 -- Function: operator.__idiv__ (a, b)
     `a = idiv(a, b)' is equivalent to `a /= b' when
     `__future__.division' is not in effect.

     New in version 2.5.

 -- Function: operator.ifloordiv (a, b)
 -- Function: operator.__ifloordiv__ (a, b)
     `a = ifloordiv(a, b)' is equivalent to `a //= b'.

     New in version 2.5.

 -- Function: operator.ilshift (a, b)
 -- Function: operator.__ilshift__ (a, b)
     `a = ilshift(a, b)' is equivalent to `a <<= b'.

     New in version 2.5.

 -- Function: operator.imod (a, b)
 -- Function: operator.__imod__ (a, b)
     `a = imod(a, b)' is equivalent to `a %= b'.

     New in version 2.5.

 -- Function: operator.imul (a, b)
 -- Function: operator.__imul__ (a, b)
     `a = imul(a, b)' is equivalent to `a *= b'.

     New in version 2.5.

 -- Function: operator.ior (a, b)
 -- Function: operator.__ior__ (a, b)
     `a = ior(a, b)' is equivalent to `a |= b'.

     New in version 2.5.

 -- Function: operator.ipow (a, b)
 -- Function: operator.__ipow__ (a, b)
     `a = ipow(a, b)' is equivalent to `a **= b'.

     New in version 2.5.

 -- Function: operator.irepeat (a, b)
 -- Function: operator.__irepeat__ (a, b)
     Deprecated since version 2.7: Use *note __imul__(): dbc. instead.

     `a = irepeat(a, b)' is equivalent to `a *= b' where _a_ is a
     sequence and _b_ is an integer.

     New in version 2.5.

 -- Function: operator.irshift (a, b)
 -- Function: operator.__irshift__ (a, b)
     `a = irshift(a, b)' is equivalent to `a >>= b'.

     New in version 2.5.

 -- Function: operator.isub (a, b)
 -- Function: operator.__isub__ (a, b)
     `a = isub(a, b)' is equivalent to `a -= b'.

     New in version 2.5.

 -- Function: operator.itruediv (a, b)
 -- Function: operator.__itruediv__ (a, b)
     `a = itruediv(a, b)' is equivalent to `a /= b' when
     `__future__.division' is in effect.

     New in version 2.5.

 -- Function: operator.ixor (a, b)
 -- Function: operator.__ixor__ (a, b)
     `a = ixor(a, b)' is equivalent to `a ^= b'.

     New in version 2.5.

  The *note operator: 126. module also defines a few predicates to test
the type of objects; however, these are not all reliable.  It is
preferable to test abstract base classes instead (see *note
collections: 65. and *note numbers: 125. for details).

 -- Function: operator.isCallable (obj)
     Deprecated since version 2.0: Use `isinstance(x,
     collections.Callable)' instead.

     Returns true if the object _obj_ can be called like a function,
     otherwise it returns false.  True is returned for functions, bound
     and unbound methods, class objects, and instance objects which
     support the *note __call__(): 6ea. method.

 -- Function: operator.isMappingType (obj)
     Deprecated since version 2.7: Use `isinstance(x,
     collections.Mapping)' instead.

     Returns true if the object _obj_ supports the mapping interface.
     This is true for dictionaries and all instance objects defining
     *note __getitem__(): da2.

 -- Function: operator.isNumberType (obj)
     Deprecated since version 2.7: Use `isinstance(x, numbers.Number)'
     instead.

     Returns true if the object _obj_ represents a number.  This is
     true for all numeric types implemented in C.

 -- Function: operator.isSequenceType (obj)
     Deprecated since version 2.7: Use `isinstance(x,
     collections.Sequence)' instead.

     Returns true if the object _obj_ supports the sequence protocol.
     This returns true for all objects which define sequence methods in
     C, and for all instance objects defining *note __getitem__(): da2.

  The *note operator: 126. module also defines tools for generalized
attribute and item lookups.  These are useful for making fast field
extractors as arguments for *note map(): 2fd, *note sorted(): 220,
*note itertools.groupby(): d4b, or other functions that expect a
function argument.

 -- Function: operator.attrgetter (attr)
 -- Function: operator.attrgetter (*attrs)
     Return a callable object that fetches _attr_ from its operand.  If
     more than one attribute is requested, returns a tuple of
     attributes.  The attribute names can also contain dots. For
     example:

        * After `f = attrgetter('name')', the call `f(b)' returns
          `b.name'.

        * After `f = attrgetter('name', 'date')', the call `f(b)'
          returns `(b.name, b.date)'.

        * After `f = attrgetter('name.first', 'name.last')', the call
          `f(b)' returns `(r.name.first, r.name.last)'.

     Equivalent to:

         def attrgetter(*items):
             if len(items) == 1:
                 attr = items[0]
                 def g(obj):
                     return resolve_attr(obj, attr)
             else:
                 def g(obj):
                     return tuple(resolve_att(obj, attr) for attr in items)
             return g

         def resolve_attr(obj, attr):
             for name in attr.split("."):
                 obj = getattr(obj, name)
             return obj

     New in version 2.4.

     Changed in version 2.5: Added support for multiple attributes.

     Changed in version 2.6: Added support for dotted attributes.

 -- Function: operator.itemgetter (item)
 -- Function: operator.itemgetter (*items)
     Return a callable object that fetches _item_ from its operand
     using the operand's *note __getitem__(): da2. method.  If multiple
     items are specified, returns a tuple of lookup values.  For
     example:

        * After `f = itemgetter(2)', the call `f(r)' returns `r[2]'.

        * After `g = itemgetter(2, 5, 3)', the call `g(r)' returns
          `(r[2], r[5], r[3])'.

     Equivalent to:

         def itemgetter(*items):
             if len(items) == 1:
                 item = items[0]
                 def g(obj):
                     return obj[item]
             else:
                 def g(obj):
                     return tuple(obj[item] for item in items)
             return g

     The items can be any type accepted by the operand's *note
     __getitem__(): da2.  method.  Dictionaries accept any hashable
     value.  Lists, tuples, and strings accept an index or a slice:

         >>> itemgetter(1)('ABCDEFG')
         'B'
         >>> itemgetter(1,3,5)('ABCDEFG')
         ('B', 'D', 'F')
         >>> itemgetter(slice(2,None))('ABCDEFG')
         'CDEFG'

     New in version 2.4.

     Changed in version 2.5: Added support for multiple item extraction.

     Example of using *note itemgetter(): dcf. to retrieve specific
     fields from a tuple record:

         >>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]
         >>> getcount = itemgetter(1)
         >>> map(getcount, inventory)
         [3, 2, 5, 1]
         >>> sorted(inventory, key=getcount)
         [('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]



 -- Function: operator.methodcaller (name[, args...])
     Return a callable object that calls the method _name_ on its
     operand.  If additional arguments and/or keyword arguments are
     given, they will be given to the method as well.  For example:

        * After `f = methodcaller('name')', the call `f(b)' returns
          `b.name()'.

        * After `f = methodcaller('name', 'foo', bar=1)', the call
          `f(b)' returns `b.name('foo', bar=1)'.

     Equivalent to:

         def methodcaller(name, *args, **kwargs):
             def caller(obj):
                 return getattr(obj, name)(*args, **kwargs)
             return caller

     New in version 2.6.

* Menu:

* Mapping Operators to Functions::


File: python.info,  Node: Mapping Operators to Functions,  Up: operator --- Standard operators as functions

5.9.9.1 Mapping Operators to Functions
......................................

This table shows how abstract operations correspond to operator symbols
in the Python syntax and the functions in the *note operator: 126.
module.

Operation                   Syntax                        Function
------------------------------------------------------------------------------------------------------ 
Addition                    `a + b'                       `add(a, b)'
Concatenation               `seq1 + seq2'                 `concat(seq1, seq2)'
Containment Test            `obj in seq'                  `contains(seq, obj)'
Division                    `a / b'                       `div(a, b)' (without `__future__.division')
Division                    `a / b'                       `truediv(a, b)' (with
                                                          `__future__.division')
Division                    `a // b'                      `floordiv(a, b)'
Bitwise And                 `a & b'                       `and_(a, b)'
Bitwise Exclusive Or        `a ^ b'                       `xor(a, b)'
Bitwise Inversion           `~ a'                         `invert(a)'
Bitwise Or                  `a | b'                       `or_(a, b)'
Exponentiation              `a ** b'                      `pow(a, b)'
Identity                    `a is b'                      `is_(a, b)'
Identity                    `a is not b'                  `is_not(a, b)'
Indexed Assignment          `obj[k] = v'                  `setitem(obj, k, v)'
Indexed Deletion            `del obj[k]'                  `delitem(obj, k)'
Indexing                    `obj[k]'                      `getitem(obj, k)'
Left Shift                  `a << b'                      `lshift(a, b)'
Modulo                      `a % b'                       `mod(a, b)'
Multiplication              `a * b'                       `mul(a, b)'
Negation (Arithmetic)       `- a'                         `neg(a)'
Negation (Logical)          `not a'                       `not_(a)'
Positive                    `+ a'                         `pos(a)'
Right Shift                 `a >> b'                      `rshift(a, b)'
Sequence Repetition         `seq * i'                     `repeat(seq, i)'
Slice Assignment            `seq[i:j] = values'           `setitem(seq, slice(i, j), values)'
Slice Deletion              `del seq[i:j]'                `delitem(seq, slice(i, j))'
Slicing                     `seq[i:j]'                    `getitem(seq, slice(i, j))'
String Formatting           `s % obj'                     `mod(s, obj)'
Subtraction                 `a - b'                       `sub(a, b)'
Truth Test                  `obj'                         `truth(obj)'
Ordering                    `a < b'                       `lt(a, b)'
Ordering                    `a <= b'                      `le(a, b)'
Equality                    `a == b'                      `eq(a, b)'
Difference                  `a != b'                      `ne(a, b)'
Ordering                    `a >= b'                      `ge(a, b)'
Ordering                    `a > b'                       `gt(a, b)'


File: python.info,  Node: File and Directory Access,  Next: Data Persistence,  Prev: Numeric and Mathematical Modules,  Up: The Python Standard Library

5.10 File and Directory Access
==============================

The modules described in this chapter deal with disk files and
directories.  For example, there are modules for reading the properties
of files, manipulating paths in a portable way, and creating temporary
files.  The full list of modules in this chapter is:

* Menu:

* os.path: os path --- Common pathname manipulations. Common pathname manipulations
* fileinput: fileinput --- Iterate over lines from multiple input streams. Iterate over lines from multiple input streams
* stat: stat --- Interpreting stat results. Interpreting stat() results
* statvfs: statvfs --- Constants used with os statvfs. Constants used with os.statvfs()
* filecmp: filecmp --- File and Directory Comparisons. File and Directory Comparisons
* tempfile: tempfile --- Generate temporary files and directories. Generate temporary files and directories
* glob: glob --- Unix style pathname pattern expansion. Unix style pathname pattern expansion
* fnmatch: fnmatch --- Unix filename pattern matching. Unix filename pattern matching
* linecache: linecache --- Random access to text lines. Random access to text lines
* shutil: shutil --- High-level file operations. High-level file operations
* dircache: dircache --- Cached directory listings. Cached directory listings
* macpath: macpath --- Mac OS 9 path manipulation functions. Mac OS 9 path manipulation functions


File: python.info,  Node: os path --- Common pathname manipulations,  Next: fileinput --- Iterate over lines from multiple input streams,  Up: File and Directory Access

5.10.1 `os.path' -- Common pathname manipulations
-------------------------------------------------

This module implements some useful functions on pathnames. To read or
write files see *note open(): 2d3, and for accessing the filesystem see
the *note os: 128. module.

     Note: On Windows, many of these functions do not properly support
     UNC pathnames.  *note splitunc(): dd8. and *note ismount(): dd9.
     do handle them correctly.

  Unlike a unix shell, Python does not do any _automatic_ path
expansions.  Functions such as *note expanduser(): dda. and *note
expandvars(): 34d. can be invoked explicitly when an application
desires shell-like path expansion.  (See also the *note glob: e3.
module.)

     Note: Since different operating systems have different path name
     conventions, there are several versions of this module in the
     standard library.  The *note os.path: 129. module is always the
     path module suitable for the operating system Python is running
     on, and therefore usable for local paths.  However, you can also
     import and use the individual modules if you want to manipulate a
     path that is _always_ in one of the different formats.  They all
     have the same interface:

        * `posixpath' for UNIX-style paths

        * `ntpath' for Windows paths

        * *note macpath: 107. for old-style MacOS paths

        * `os2emxpath' for OS/2 EMX paths

 -- Function: os.path.abspath (path)
     Return a normalized absolutized version of the pathname _path_. On
     most platforms, this is equivalent to calling the function *note
     normpath(): 242. as follows: `normpath(join(os.getcwd(), path))'.

     New in version 1.5.2.

 -- Function: os.path.basename (path)
     Return the base name of pathname _path_.  This is the second
     element of the pair returned by passing _path_ to the function
     *note split(): ddc.  Note that the result of this function is
     different from the Unix *basename* program; where *basename* for
     `'/foo/bar/'' returns `'bar'', the *note basename(): ddb. function
     returns an empty string (`''').

 -- Function: os.path.commonprefix (list)
     Return the longest path prefix (taken character-by-character) that
     is a prefix of all paths in  _list_.  If _list_ is empty, return
     the empty string (`''').  Note that this may return invalid paths
     because it works a character at a time.

 -- Function: os.path.dirname (path)
     Return the directory name of pathname _path_.  This is the first
     element of the pair returned by passing _path_ to the function
     *note split(): ddc.

 -- Function: os.path.exists (path)
     Return `True' if _path_ refers to an existing path.  Returns
     `False' for broken symbolic links. On some platforms, this
     function may return `False' if permission is not granted to
     execute *note os.stat(): 3bd. on the requested file, even if the
     _path_ physically exists.

 -- Function: os.path.lexists (path)
     Return `True' if _path_ refers to an existing path. Returns `True'
     for broken symbolic links.   Equivalent to *note exists(): ddf. on
     platforms lacking *note os.lstat(): de1.

     New in version 2.4.

 -- Function: os.path.expanduser (path)
     On Unix and Windows, return the argument with an initial component
     of `~' or `~user' replaced by that _user_'s home directory.

     On Unix, an initial `~' is replaced by the environment variable `HOME'
     if it is set; otherwise the current user's home directory is
     looked up in the password directory through the built-in module
     *note pwd: 13c. An initial `~user' is looked up directly in the
     password directory.

     On Windows, `HOME' and `USERPROFILE' will be used if set,
     otherwise a combination of `HOMEPATH' and `HOMEDRIVE' will be
     used.  An initial `~user' is handled by stripping the last
     directory component from the created user path derived above.

     If the expansion fails or if the path does not begin with a tilde,
     the path is returned unchanged.

 -- Function: os.path.expandvars (path)
     Return the argument with environment variables expanded.
     Substrings of the form `$name' or `${name}' are replaced by the
     value of environment variable _name_.  Malformed variable names
     and references to non-existing variables are left unchanged.

     On Windows, `%name%' expansions are supported in addition to
     `$name' and `${name}'.

 -- Function: os.path.getatime (path)
     Return the time of last access of _path_.  The return value is a
     number giving the number of seconds since the epoch (see the
     *note time: 17a. module).  Raise *note os.error: de3. if the file
     does not exist or is inaccessible.

     New in version 1.5.2.

     Changed in version 2.3: If *note os.stat_float_times(): 45b.
     returns True, the result is a floating point number.

 -- Function: os.path.getmtime (path)
     Return the time of last modification of _path_.  The return value
     is a number giving the number of seconds since the epoch (see the
     *note time: 17a. module).  Raise *note os.error: de3. if the file
     does not exist or is inaccessible.

     New in version 1.5.2.

     Changed in version 2.3: If *note os.stat_float_times(): 45b.
     returns True, the result is a floating point number.

 -- Function: os.path.getctime (path)
     Return the system's ctime which, on some systems (like Unix) is
     the time of the last change, and, on others (like Windows), is the
     creation time for _path_.  The return value is a number giving the
     number of seconds since the epoch (see the  *note time: 17a.
     module).  Raise *note os.error: de3. if the file does not exist or
     is inaccessible.

     New in version 2.3.

 -- Function: os.path.getsize (path)
     Return the size, in bytes, of _path_.  Raise *note os.error: de3.
     if the file does not exist or is inaccessible.

     New in version 1.5.2.

 -- Function: os.path.isabs (path)
     Return `True' if _path_ is an absolute pathname.  On Unix, that
     means it begins with a slash, on Windows that it begins with a
     (back)slash after chopping off a potential drive letter.

 -- Function: os.path.isfile (path)
     Return `True' if _path_ is an existing regular file.  This follows
     symbolic links, so both *note islink(): de9. and *note isfile():
     de8. can be true for the same path.

 -- Function: os.path.isdir (path)
     Return `True' if _path_ is an existing directory.  This follows
     symbolic links, so both *note islink(): de9. and *note isdir():
     dea. can be true for the same path.

 -- Function: os.path.islink (path)
     Return `True' if _path_ refers to a directory entry that is a
     symbolic link.  Always `False' if symbolic links are not supported.

 -- Function: os.path.ismount (path)
     Return `True' if pathname _path_ is a _mount point_: a point in a
     file system where a different file system has been mounted.  The
     function checks whether _path_'s parent, `path/..', is on a
     different device than _path_, or whether `path/..' and _path_
     point to the same i-node on the same device -- this should detect
     mount points for all Unix and POSIX variants.

 -- Function: os.path.join (path1[, path2[, ...]])
     Join one or more path components intelligently.  If any component
     is an absolute path, all previous components (on Windows,
     including the previous drive letter, if there was one) are thrown
     away, and joining continues.  The return value is the
     concatenation of _path1_, and optionally _path2_, etc., with
     exactly one directory separator (`os.sep') following each
     non-empty part except the last.  (This means that an empty last
     part will result in a path that ends with a separator.)  Note that
     on Windows, since there is a current directory for each drive,
     `os.path.join("c:", "foo")' represents a path relative to the
     current directory on drive `C:' (`c:foo'), not `c:\foo'.

 -- Function: os.path.normcase (path)
     Normalize the case of a pathname.  On Unix and Mac OS X, this
     returns the path unchanged; on case-insensitive filesystems, it
     converts the path to lowercase.  On Windows, it also converts
     forward slashes to backward slashes.

 -- Function: os.path.normpath (path)
     Normalize a pathname by collapsing redundant separators and
     up-level references so that `A//B', `A/B/', `A/./B' and
     `A/foo/../B' all become `A/B'.  This string manipulation may
     change the meaning of a path that contains symbolic links.  On
     Windows, it converts forward slashes to backward slashes. To
     normalize case, use *note normcase(): dec.

 -- Function: os.path.realpath (path)
     Return the canonical path of the specified filename, eliminating
     any symbolic links encountered in the path (if they are supported
     by the operating system).

     New in version 2.2.

 -- Function: os.path.relpath (path[, start])
     Return a relative filepath to _path_ either from the current
     directory or from an optional _start_ point.

     _start_ defaults to *note os.curdir: def.

     Availability:  Windows, Unix.

     New in version 2.6.

 -- Function: os.path.samefile (path1, path2)
     Return `True' if both pathname arguments refer to the same file or
     directory (as indicated by device number and i-node number). Raise
     an exception if a *note os.stat(): 3bd. call on either pathname
     fails.

     Availability: Unix.

 -- Function: os.path.sameopenfile (fp1, fp2)
     Return `True' if the file descriptors _fp1_ and _fp2_ refer to the
     same file.

     Availability: Unix.

 -- Function: os.path.samestat (stat1, stat2)
     Return `True' if the stat tuples _stat1_ and _stat2_ refer to the
     same file.  These structures may have been returned by `fstat()',
     `lstat()', or *note stat(): 161.  This function implements the
     underlying comparison used by *note samefile(): df0. and *note
     sameopenfile(): df1.

     Availability: Unix.

 -- Function: os.path.split (path)
     Split the pathname _path_ into a pair, `(head, tail)' where _tail_
     is the last pathname component and _head_ is everything leading up
     to that.  The _tail_ part will never contain a slash; if _path_
     ends in a slash, _tail_ will be empty.  If there is no slash in
     _path_, _head_ will be empty.  If _path_ is empty, both _head_ and
     _tail_ are empty.  Trailing slashes are stripped from _head_
     unless it is the root (one or more slashes only).  In all cases,
     `join(head, tail)' returns a path to the same location as _path_
     (but the strings may differ).  Also see the functions *note
     dirname(): dde. and *note basename(): ddb.

 -- Function: os.path.splitdrive (path)
     Split the pathname _path_ into a pair `(drive, tail)' where
     _drive_ is either a drive specification or the empty string.  On
     systems which do not use drive specifications, _drive_ will always
     be the empty string.  In all cases, `drive + tail' will be the
     same as _path_.

     New in version 1.3.

 -- Function: os.path.splitext (path)
     Split the pathname _path_ into a pair `(root, ext)'  such that
     `root + ext == path', and _ext_ is empty or begins with a period
     and contains at most one period. Leading periods on the basename
     are  ignored; `splitext('.cshrc')' returns  `('.cshrc', '')'.

     Changed in version 2.6: Earlier versions could produce an empty
     root when the only period was the first character.

 -- Function: os.path.splitunc (path)
     Split the pathname _path_ into a pair `(unc, rest)' so that _unc_
     is the UNC mount point (such as `r'\\host\mount''), if present,
     and _rest_ the rest of the path (such as  `r'\path\file.ext'').
     For paths containing drive letters, _unc_ will always be the empty
     string.

     Availability:  Windows.

 -- Function: os.path.walk (path, visit, arg)
     Calls the function _visit_ with arguments `(arg, dirname, names)'
     for each directory in the directory tree rooted at _path_
     (including _path_ itself, if it is a directory).  The argument
     _dirname_ specifies the visited directory, the argument _names_
     lists the files in the directory (gotten from
     `os.listdir(dirname)'). The _visit_ function may modify _names_ to
     influence the set of directories visited below _dirname_, e.g. to
     avoid visiting certain parts of the tree.  (The object referred to
     by _names_ must be modified in place, using *note del: 55f. or
     slice assignment.)

          Note: Symbolic links to directories are not treated as
          subdirectories, and that *note walk(): df5. therefore will
          not visit them. To visit linked directories you must identify
          them with `os.path.islink(file)' and `os.path.isdir(file)',
          and invoke *note walk(): df5. as necessary.

          Note: This function is deprecated and has been removed in
          Python 3 in favor of *note os.walk(): 34c.

 -- Data: os.path.supports_unicode_filenames
     True if arbitrary Unicode strings can be used as file names
     (within limitations imposed by the file system).

     New in version 2.3.


File: python.info,  Node: fileinput --- Iterate over lines from multiple input streams,  Next: stat --- Interpreting stat results,  Prev: os path --- Common pathname manipulations,  Up: File and Directory Access

5.10.2 `fileinput' -- Iterate over lines from multiple input streams
--------------------------------------------------------------------

*Source code:* Lib/fileinput.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module implements a helper class and functions to quickly write a
loop over standard input or a list of files. If you just want to read or
write one file see *note open(): 2d3.

  The typical use is:

    import fileinput
    for line in fileinput.input():
        process(line)

This iterates over the lines of all files listed in `sys.argv[1:]',
defaulting to `sys.stdin' if the list is empty.  If a filename is
`'-'', it is also replaced by `sys.stdin'.  To specify an alternative
list of filenames, pass it as the first argument to *note input(): df8.
A single file name is also allowed.

  All files are opened in text mode by default, but you can override
this by specifying the _mode_ parameter in the call to *note input():
df8. or *note FileInput(): df9.  If an I/O error occurs during opening
or reading a file, *note IOError: 1f7. is raised.

  If `sys.stdin' is used more than once, the second and further use
will return no lines, except perhaps for interactive use, or if it has
been explicitly reset (e.g. using `sys.stdin.seek(0)').

  Empty files are opened and immediately closed; the only time their
presence in the list of filenames is noticeable at all is when the last
file opened is empty.

  Lines are returned with any newlines intact, which means that the
last line in a file may not have one.

  You can control how files are opened by providing an opening hook via
the _openhook_ parameter to *note fileinput.input(): df8. or *note
FileInput(): df9. The hook must be a function that takes two arguments,
_filename_ and _mode_, and returns an accordingly opened file-like
object. Two useful hooks are already provided by this module.

  The following function is the primary interface of this module:

 -- Function: fileinput.input ([files[, inplace[, backup[, mode[,
          openhook]]]]])
     Create an instance of the *note FileInput: df9. class.  The
     instance will be used as global state for the functions of this
     module, and is also returned to use during iteration.  The
     parameters to this function will be passed along to the
     constructor of the *note FileInput: df9. class.

     Changed in version 2.5: Added the _mode_ and _openhook_ parameters.

  The following functions use the global state created by *note
fileinput.input(): df8.; if there is no active state, *note
RuntimeError: 394. is raised.

 -- Function: fileinput.filename ()
     Return the name of the file currently being read.  Before the
     first line has been read, returns `None'.

 -- Function: fileinput.fileno ()
     Return the integer "file descriptor" for the current file. When no
     file is opened (before the first line and between files), returns
     `-1'.

     New in version 2.5.

 -- Function: fileinput.lineno ()
     Return the cumulative line number of the line that has just been
     read.  Before the first line has been read, returns `0'.  After
     the last line of the last file has been read, returns the line
     number of that line.

 -- Function: fileinput.filelineno ()
     Return the line number in the current file.  Before the first line
     has been read, returns `0'.  After the last line of the last file
     has been read, returns the line number of that line within the
     file.

 -- Function: fileinput.isfirstline ()
     Returns true if the line just read is the first line of its file,
     otherwise returns false.

 -- Function: fileinput.isstdin ()
     Returns true if the last line was read from `sys.stdin', otherwise
     returns false.

 -- Function: fileinput.nextfile ()
     Close the current file so that the next iteration will read the
     first line from the next file (if any); lines not read from the
     file will not count towards the cumulative line count.  The
     filename is not changed until after the first line of the next
     file has been read.  Before the first line has been read, this
     function has no effect; it cannot be used to skip the first file.
     After the last line of the last file has been read, this function
     has no effect.

 -- Function: fileinput.close ()
     Close the sequence.

  The class which implements the sequence behavior provided by the
module is available for subclassing as well:

 -- Class: fileinput.FileInput ([files[, inplace[, backup[, mode[,
          openhook]]]]])
     Class *note FileInput: df9. is the implementation; its methods
     *note filename(): dfa, *note fileno(): dfb, *note lineno(): dfc,
     *note filelineno(): dfd, *note isfirstline(): dfe, *note
     isstdin(): dff, *note nextfile(): e00. and *note close(): e01.
     correspond to the functions of the same name in the module. In
     addition it has a *note readline(): 144. method which returns the
     next input line, and a *note __getitem__(): 448. method which
     implements the sequence behavior.  The sequence must be accessed
     in strictly sequential order; random access and *note readline():
     144. cannot be mixed.

     With _mode_ you can specify which file mode will be passed to
     *note open(): 2d3. It must be one of `'r'', `'rU'', `'U'' and
     `'rb''.

     The _openhook_, when given, must be a function that takes two
     arguments, _filename_ and _mode_, and returns an accordingly
     opened file-like object. You cannot use _inplace_ and _openhook_
     together.

     Changed in version 2.5: Added the _mode_ and _openhook_ parameters.

  *Optional in-place filtering:* if the keyword argument `inplace=1' is
passed to *note fileinput.input(): df8. or to the *note FileInput: df9.
constructor, the file is moved to a backup file and standard output is
directed to the input file (if a file of the same name as the backup
file already exists, it will be replaced silently).  This makes it
possible to write a filter that rewrites its input file in place.  If
the _backup_ parameter is given (typically as `backup='.<some
extension>''), it specifies the extension for the backup file, and the
backup file remains around; by default, the extension is `'.bak'' and
it is deleted when the output file is closed.  In-place filtering is
disabled when standard input is read.

     Note: The current implementation does not work for MS-DOS 8+3
     filesystems.

  The two following opening hooks are provided by this module:

 -- Function: fileinput.hook_compressed (filename, mode)
     Transparently opens files compressed with gzip and bzip2
     (recognized by the extensions `'.gz'' and `'.bz2'') using the
     *note gzip: e5. and *note bz2: 1e.  modules.  If the filename
     extension is not `'.gz'' or `'.bz2'', the file is opened normally
     (ie, using *note open(): 2d3. without any decompression).

     Usage example:  `fi =
     fileinput.FileInput(openhook=fileinput.hook_compressed)'

     New in version 2.5.

 -- Function: fileinput.hook_encoded (encoding)
     Returns a hook which opens each file with *note codecs.open():
     a48, using the given _encoding_ to read the file.

     Usage example: `fi =
     fileinput.FileInput(openhook=fileinput.hook_encoded("iso-8859-1"))'

          Note: With this hook, *note FileInput: df9. might return
          Unicode strings depending on the specified _encoding_.

     New in version 2.5.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/fileinput.py


File: python.info,  Node: stat --- Interpreting stat results,  Next: statvfs --- Constants used with os statvfs,  Prev: fileinput --- Iterate over lines from multiple input streams,  Up: File and Directory Access

5.10.3 `stat' -- Interpreting `stat()' results
----------------------------------------------

*Source code:* Lib/stat.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note stat: 161. module defines constants and functions for
interpreting the results of *note os.stat(): 3bd, *note os.fstat():
e06. and *note os.lstat(): de1. (if they exist).  For complete details
about the `stat()', `fstat()' and `lstat()' calls, consult the
documentation for your system.

  The *note stat: 161. module defines the following functions to test
for specific file types:

 -- Function: stat.S_ISDIR (mode)
     Return non-zero if the mode is from a directory.

 -- Function: stat.S_ISCHR (mode)
     Return non-zero if the mode is from a character special device
     file.

 -- Function: stat.S_ISBLK (mode)
     Return non-zero if the mode is from a block special device file.

 -- Function: stat.S_ISREG (mode)
     Return non-zero if the mode is from a regular file.

 -- Function: stat.S_ISFIFO (mode)
     Return non-zero if the mode is from a FIFO (named pipe).

 -- Function: stat.S_ISLNK (mode)
     Return non-zero if the mode is from a symbolic link.

 -- Function: stat.S_ISSOCK (mode)
     Return non-zero if the mode is from a socket.

  Two additional functions are defined for more general manipulation of
the file's mode:

 -- Function: stat.S_IMODE (mode)
     Return the portion of the file's mode that can be set by *note
     os.chmod(): e0f.--that is, the file's permission bits, plus the
     sticky bit, set-group-id, and set-user-id bits (on systems that
     support them).

 -- Function: stat.S_IFMT (mode)
     Return the portion of the file's mode that describes the file type
     (used by the `S_IS*()' functions above).

  Normally, you would use the `os.path.is*()' functions for testing the
type of a file; the functions here are useful when you are doing
multiple tests of the same file and wish to avoid the overhead of the
`stat()' system call for each test.  These are also useful when
checking for information about a file that isn't handled by *note
os.path: 129, like the tests for block and character devices.

  Example:

    import os, sys
    from stat import *

    def walktree(top, callback):
        '''recursively descend the directory tree rooted at top,
           calling the callback function for each regular file'''

        for f in os.listdir(top):
            pathname = os.path.join(top, f)
            mode = os.stat(pathname).st_mode
            if S_ISDIR(mode):
                # It's a directory, recurse into it
                walktree(pathname, callback)
            elif S_ISREG(mode):
                # It's a file, call the callback function
                callback(pathname)
            else:
                # Unknown file type, print a message
                print 'Skipping %s' % pathname

    def visitfile(file):
        print 'visiting', file

    if __name__ == '__main__':
        walktree(sys.argv[1], visitfile)

All the variables below are simply symbolic indexes into the 10-tuple
returned by *note os.stat(): 3bd, *note os.fstat(): e06. or *note
os.lstat(): de1.

 -- Data: stat.ST_MODE
     Inode protection mode.

 -- Data: stat.ST_INO
     Inode number.

 -- Data: stat.ST_DEV
     Device inode resides on.

 -- Data: stat.ST_NLINK
     Number of links to the inode.

 -- Data: stat.ST_UID
     User id of the owner.

 -- Data: stat.ST_GID
     Group id of the owner.

 -- Data: stat.ST_SIZE
     Size in bytes of a plain file; amount of data waiting on some
     special files.

 -- Data: stat.ST_ATIME
     Time of last access.

 -- Data: stat.ST_MTIME
     Time of last modification.

 -- Data: stat.ST_CTIME
     The "ctime" as reported by the operating system.  On some systems
     (like Unix) is the time of the last metadata change, and, on
     others (like Windows), is the creation time (see platform
     documentation for details).

  The interpretation of "file size" changes according to the file type.
For plain files this is the size of the file in bytes.  For FIFOs and
sockets under most flavors of Unix (including Linux in particular), the
"size" is the number of bytes waiting to be read at the time of the
call to *note os.stat(): 3bd, *note os.fstat(): e06, or *note
os.lstat(): de1.; this can sometimes be useful, especially for polling
one of these special files after a non-blocking open.  The meaning of
the size field for other character and block devices varies more,
depending on the implementation of the underlying system call.

  The variables below define the flags used in the *note ST_MODE: e11.
field.

  Use of the functions above is more portable than use of the first set
of flags:

 -- Data: stat.S_IFSOCK
     Socket.

 -- Data: stat.S_IFLNK
     Symbolic link.

 -- Data: stat.S_IFREG
     Regular file.

 -- Data: stat.S_IFBLK
     Block device.

 -- Data: stat.S_IFDIR
     Directory.

 -- Data: stat.S_IFCHR
     Character device.

 -- Data: stat.S_IFIFO
     FIFO.

  The following flags can also be used in the _mode_ argument of *note
os.chmod(): e0f.:

 -- Data: stat.S_ISUID
     Set UID bit.

 -- Data: stat.S_ISGID
     Set-group-ID bit.  This bit has several special uses.  For a
     directory it indicates that BSD semantics is to be used for that
     directory: files created there inherit their group ID from the
     directory, not from the effective group ID of the creating
     process, and directories created there will also get the *note
     S_ISGID: e23. bit set.  For a file that does not have the group
     execution bit (*note S_IXGRP: e24.)  set, the set-group-ID bit
     indicates mandatory file/record locking (see also *note S_ENFMT:
     e25.).

 -- Data: stat.S_ISVTX
     Sticky bit.  When this bit is set on a directory it means that a
     file in that directory can be renamed or deleted only by the owner
     of the file, by the owner of the directory, or by a privileged
     process.

 -- Data: stat.S_IRWXU
     Mask for file owner permissions.

 -- Data: stat.S_IRUSR
     Owner has read permission.

 -- Data: stat.S_IWUSR
     Owner has write permission.

 -- Data: stat.S_IXUSR
     Owner has execute permission.

 -- Data: stat.S_IRWXG
     Mask for group permissions.

 -- Data: stat.S_IRGRP
     Group has read permission.

 -- Data: stat.S_IWGRP
     Group has write permission.

 -- Data: stat.S_IXGRP
     Group has execute permission.

 -- Data: stat.S_IRWXO
     Mask for permissions for others (not in group).

 -- Data: stat.S_IROTH
     Others have read permission.

 -- Data: stat.S_IWOTH
     Others have write permission.

 -- Data: stat.S_IXOTH
     Others have execute permission.

 -- Data: stat.S_ENFMT
     System V file locking enforcement.  This flag is shared with *note
     S_ISGID: e23.: file/record locking is enforced on files that do
     not have the group execution bit (*note S_IXGRP: e24.) set.

 -- Data: stat.S_IREAD
     Unix V7 synonym for *note S_IRUSR: e28.

 -- Data: stat.S_IWRITE
     Unix V7 synonym for *note S_IWUSR: e29.

 -- Data: stat.S_IEXEC
     Unix V7 synonym for *note S_IXUSR: e2a.

  The following flags can be used in the _flags_ argument of *note
os.chflags(): e35.:

 -- Data: stat.UF_NODUMP
     Do not dump the file.

 -- Data: stat.UF_IMMUTABLE
     The file may not be changed.

 -- Data: stat.UF_APPEND
     The file may only be appended to.

 -- Data: stat.UF_OPAQUE
     The directory is opaque when viewed through a union stack.

 -- Data: stat.UF_NOUNLINK
     The file may not be renamed or deleted.

 -- Data: stat.UF_COMPRESSED
     The file is stored compressed (Mac OS X 10.6+).

 -- Data: stat.UF_HIDDEN
     The file should not be displayed in a GUI (Mac OS X 10.5+).

 -- Data: stat.SF_ARCHIVED
     The file may be archived.

 -- Data: stat.SF_IMMUTABLE
     The file may not be changed.

 -- Data: stat.SF_APPEND
     The file may only be appended to.

 -- Data: stat.SF_NOUNLINK
     The file may not be renamed or deleted.

 -- Data: stat.SF_SNAPSHOT
     The file is a snapshot file.

  See the *BSD or Mac OS systems man page `chflags(2)' for more
information.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/stat.py


File: python.info,  Node: statvfs --- Constants used with os statvfs,  Next: filecmp --- File and Directory Comparisons,  Prev: stat --- Interpreting stat results,  Up: File and Directory Access

5.10.4 `statvfs' -- Constants used with `os.statvfs()'
------------------------------------------------------

Deprecated since version 2.6: The *note statvfs: 162. module has been
removed in Python 3.

  The *note statvfs: 162. module defines constants so interpreting the
result if *note os.statvfs(): e44, which returns a tuple, can be made
without remembering "magic numbers."  Each of the constants defined in
this module is the _index_ of the entry in the tuple returned by *note
os.statvfs(): e44. that contains the specified information.

 -- Data: statvfs.F_BSIZE
     Preferred file system block size.

 -- Data: statvfs.F_FRSIZE
     Fundamental file system block size.

 -- Data: statvfs.F_BLOCKS
     Total number of blocks in the filesystem.

 -- Data: statvfs.F_BFREE
     Total number of free blocks.

 -- Data: statvfs.F_BAVAIL
     Free blocks available to non-super user.

 -- Data: statvfs.F_FILES
     Total number of file nodes.

 -- Data: statvfs.F_FFREE
     Total number of free file nodes.

 -- Data: statvfs.F_FAVAIL
     Free nodes available to non-super user.

 -- Data: statvfs.F_FLAG
     Flags. System dependent: see `statvfs()' man page.

 -- Data: statvfs.F_NAMEMAX
     Maximum file name length.


File: python.info,  Node: filecmp --- File and Directory Comparisons,  Next: tempfile --- Generate temporary files and directories,  Prev: statvfs --- Constants used with os statvfs,  Up: File and Directory Access

5.10.5 `filecmp' -- File and Directory Comparisons
--------------------------------------------------

*Source code:* Lib/filecmp.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note filecmp: cb. module defines functions to compare files and
directories, with various optional time/correctness trade-offs. For
comparing files, see also the *note difflib: 82. module.

  The *note filecmp: cb. module defines the following functions:

 -- Function: filecmp.cmp (f1, f2[, shallow])
     Compare the files named _f1_ and _f2_, returning `True' if they
     seem equal, `False' otherwise.

     Unless _shallow_ is given and is false, files with identical *note
     os.stat(): 3bd.  signatures are taken to be equal.

     Files that were compared using this function will not be compared
     again unless their *note os.stat(): 3bd. signature changes.

     Note that no external programs are called from this function,
     giving it portability and efficiency.

 -- Function: filecmp.cmpfiles (dir1, dir2, common[, shallow])
     Compare the files in the two directories _dir1_ and _dir2_ whose
     names are given by _common_.

     Returns three lists of file names: _match_, _mismatch_, _errors_.
     _match_ contains the list of files that match, _mismatch_ contains
     the names of those that don't, and _errors_ lists the names of
     files which could not be compared.  Files are listed in _errors_
     if they don't exist in one of the directories, the user lacks
     permission to read them or if the comparison could not be done for
     some other reason.

     The _shallow_ parameter has the same meaning and default value as
     for *note filecmp.cmp(): e51.

     For example, `cmpfiles('a', 'b', ['c', 'd/e'])' will compare `a/c'
     with `b/c' and `a/d/e' with `b/d/e'.  `'c'' and `'d/e'' will each
     be in one of the three returned lists.

  Example:

    >>> import filecmp
    >>> filecmp.cmp('undoc.rst', 'undoc.rst') # doctest: +SKIP
    True
    >>> filecmp.cmp('undoc.rst', 'index.rst') # doctest: +SKIP
    False


* Menu:

* The dircmp class::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/filecmp.py


File: python.info,  Node: The dircmp class,  Up: filecmp --- File and Directory Comparisons

5.10.5.1 The `dircmp' class
...........................

*note dircmp: e55. instances are built using this constructor:

 -- Class: filecmp.dircmp (a, b[, ignore[, hide]])
     Construct a new directory comparison object, to compare the
     directories _a_ and _b_. _ignore_ is a list of names to ignore,
     and defaults to `['RCS', 'CVS', 'tags']'. _hide_ is a list of
     names to hide, and defaults to `[os.curdir, os.pardir]'.

     The *note dircmp: e55. class compares files by doing _shallow_
     comparisons as described for *note filecmp.cmp(): e51.

     The *note dircmp: e55. class provides the following methods:

      -- Method: report ()
          Print (to `sys.stdout') a comparison between _a_ and _b_.

      -- Method: report_partial_closure ()
          Print a comparison between _a_ and _b_ and common immediate
          subdirectories.

      -- Method: report_full_closure ()
          Print a comparison between _a_ and _b_ and common
          subdirectories (recursively).

     The *note dircmp: e55. class offers a number of interesting
     attributes that may be used to get various bits of information
     about the directory trees being compared.

     Note that via *note __getattr__(): 32a. hooks, all attributes are
     computed lazily, so there is no speed penalty if only those
     attributes which are lightweight to compute are used.

      -- Attribute: left
          The directory _a_.

      -- Attribute: right
          The directory _b_.

      -- Attribute: left_list
          Files and subdirectories in _a_, filtered by _hide_ and
          _ignore_.

      -- Attribute: right_list
          Files and subdirectories in _b_, filtered by _hide_ and
          _ignore_.

      -- Attribute: common
          Files and subdirectories in both _a_ and _b_.

      -- Attribute: left_only
          Files and subdirectories only in _a_.

      -- Attribute: right_only
          Files and subdirectories only in _b_.

      -- Attribute: common_dirs
          Subdirectories in both _a_ and _b_.

      -- Attribute: common_files
          Files in both _a_ and _b_

      -- Attribute: common_funny
          Names in both _a_ and _b_, such that the type differs between
          the directories, or names for which *note os.stat(): 3bd.
          reports an error.

      -- Attribute: same_files
          Files which are identical in both _a_ and _b_, using the
          class's file comparison operator.

      -- Attribute: diff_files
          Files which are in both _a_ and _b_, whose contents differ
          according to the class's file comparison operator.

      -- Attribute: funny_files
          Files which are in both _a_ and _b_, but could not be
          compared.

      -- Attribute: subdirs
          A dictionary mapping names in *note common_dirs: e60. to
          *note dircmp: e55. objects.

  Here is a simplified example of using the `subdirs' attribute to
search recursively through two directories to show common different
files:

    >>> from filecmp import dircmp
    >>> def print_diff_files(dcmp):
    ...     for name in dcmp.diff_files:
    ...         print "diff_file %s found in %s and %s" % (name, dcmp.left,
    ...               dcmp.right)
    ...     for sub_dcmp in dcmp.subdirs.values():
    ...         print_diff_files(sub_dcmp)
    ...
    >>> dcmp = dircmp('dir1', 'dir2') # doctest: +SKIP
    >>> print_diff_files(dcmp) # doctest: +SKIP



File: python.info,  Node: tempfile --- Generate temporary files and directories,  Next: glob --- Unix style pathname pattern expansion,  Prev: filecmp --- File and Directory Comparisons,  Up: File and Directory Access

5.10.6 `tempfile' -- Generate temporary files and directories
-------------------------------------------------------------

*Source code:* Lib/tempfile.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module generates temporary files and directories.  It works on
all supported platforms.

  In version 2.3 of Python, this module was overhauled for enhanced
security.  It now provides three new functions, *note
NamedTemporaryFile(): 353, *note mkstemp(): e69, and *note mkdtemp():
e6a, which should eliminate all remaining need to use the insecure
*note mktemp(): e6b. function.  Temporary file names created by this
module no longer contain the process ID; instead a string of six random
characters is used.

  Also, all the user-callable functions now take additional arguments
which allow direct control over the location and name of temporary
files.  It is no longer necessary to use the global _tempdir_ and
_template_ variables.  To maintain backward compatibility, the argument
order is somewhat odd; it is recommended to use keyword arguments for
clarity.

  The module defines the following user-callable functions:

 -- Function: tempfile.TemporaryFile ([mode='w+b'[, bufsize=-1[,
          suffix=''[, prefix='tmp'[, dir=None]]]]])
     Return a file-like object that can be used as a temporary storage
     area.  The file is created using *note mkstemp(): e69. It will be
     destroyed as soon as it is closed (including an implicit close
     when the object is garbage collected).  Under Unix, the directory
     entry for the file is removed immediately after the file is
     created.  Other platforms do not support this; your code should
     not rely on a temporary file created using this function having or
     not having a visible name in the file system.

     The _mode_ parameter defaults to `'w+b'' so that the file created
     can be read and written without being closed.  Binary mode is used
     so that it behaves consistently on all platforms without regard
     for the data that is stored.  _bufsize_ defaults to `-1', meaning
     that the operating system default is used.

     The _dir_, _prefix_ and _suffix_ parameters are passed to *note
     mkstemp(): e69.

     The returned object is a true file object on POSIX platforms.  On
     other platforms, it is a file-like object whose `file' attribute
     is the underlying true file object. This file-like object can be
     used in a *note with: 1bd. statement, just like a normal file.

 -- Function: tempfile.NamedTemporaryFile ([mode='w+b'[, bufsize=-1[,
          suffix=''[, prefix='tmp'[, dir=None[, delete=True]]]]]])
     This function operates exactly as *note TemporaryFile(): e6c.
     does, except that the file is guaranteed to have a visible name in
     the file system (on Unix, the directory entry is not unlinked).
     That name can be retrieved from the `name' attribute of the file
     object.  Whether the name can be used to open the file a second
     time, while the named temporary file is still open, varies across
     platforms (it can be so used on Unix; it cannot on Windows NT or
     later).  If _delete_ is true (the default), the file is deleted as
     soon as it is closed.

     The returned object is always a file-like object whose `file'
     attribute is the underlying true file object. This file-like
     object can be used in a *note with: 1bd. statement, just like a
     normal file.

     New in version 2.3.

     New in version 2.6: The _delete_ parameter.

 -- Function: tempfile.SpooledTemporaryFile ([max_size=0[, mode='w+b'[,
          bufsize=-1[, suffix=''[, prefix='tmp'[, dir=None]]]]]])
     This function operates exactly as *note TemporaryFile(): e6c.
     does, except that data is spooled in memory until the file size
     exceeds _max_size_, or until the file's `fileno()' method is
     called, at which point the contents are written to disk and
     operation proceeds as with *note TemporaryFile(): e6c.  Also, it's
     `truncate' method does not accept a `size' argument.

     The resulting file has one additional method, `rollover()', which
     causes the file to roll over to an on-disk file regardless of its
     size.

     The returned object is a file-like object whose `_file' attribute
     is either a *note StringIO: 164. object or a true file object,
     depending on whether `rollover()' has been called. This file-like
     object can be used in a *note with: 1bd. statement, just like a
     normal file.

     New in version 2.6.

 -- Function: tempfile.mkstemp ([suffix=''[, prefix='tmp'[, dir=None[,
          text=False]]]])
     Creates a temporary file in the most secure manner possible.
     There are no race conditions in the file's creation, assuming that
     the platform properly implements the *note os.O_EXCL: e6e. flag
     for *note os.open(): 5d5.  The file is readable and writable only
     by the creating user ID.  If the platform uses permission bits to
     indicate whether a file is executable, the file is executable by
     no one.  The file descriptor is not inherited by child processes.

     Unlike *note TemporaryFile(): e6c, the user of *note mkstemp():
     e69. is responsible for deleting the temporary file when done with
     it.

     If _suffix_ is specified, the file name will end with that suffix,
     otherwise there will be no suffix.  *note mkstemp(): e69. does not
     put a dot between the file name and the suffix; if you need one,
     put it at the beginning of _suffix_.

     If _prefix_ is specified, the file name will begin with that
     prefix; otherwise, a default prefix is used.

     If _dir_ is specified, the file will be created in that directory;
     otherwise, a default directory is used.  The default directory is
     chosen from a platform-dependent list, but the user of the
     application can control the directory location by setting the
     _TMPDIR_, _TEMP_ or _TMP_ environment variables.  There is thus no
     guarantee that the generated filename will have any nice
     properties, such as not requiring quoting when passed to external
     commands via `os.popen()'.

     If _text_ is specified, it indicates whether to open the file in
     binary mode (the default) or text mode.  On some platforms, this
     makes no difference.

     *note mkstemp(): e69. returns a tuple containing an OS-level
     handle to an open file (as would be returned by *note os.open():
     5d5.) and the absolute pathname of that file, in that order.

     New in version 2.3.

 -- Function: tempfile.mkdtemp ([suffix=''[, prefix='tmp'[, dir=None]]])
     Creates a temporary directory in the most secure manner possible.
     There are no race conditions in the directory's creation.  The
     directory is readable, writable, and searchable only by the
     creating user ID.

     The user of *note mkdtemp(): e6a. is responsible for deleting the
     temporary directory and its contents when done with it.

     The _prefix_, _suffix_, and _dir_ arguments are the same as for
     *note mkstemp(): e69.

     *note mkdtemp(): e6a. returns the absolute pathname of the new
     directory.

     New in version 2.3.

 -- Function: tempfile.mktemp ([suffix=''[, prefix='tmp'[, dir=None]]])
     Deprecated since version 2.3: Use *note mkstemp(): e69. instead.

     Return an absolute pathname of a file that did not exist at the
     time the call is made.  The _prefix_, _suffix_, and _dir_
     arguments are the same as for *note mkstemp(): e69.

          Warning: Use of this function may introduce a security hole
          in your program.  By the time you get around to doing
          anything with the file name it returns, someone else may have
          beaten you to the punch.  *note mktemp(): e6b. usage can be
          replaced easily with *note NamedTemporaryFile(): 353, passing
          it the `delete=False' parameter:

              >>> f = NamedTemporaryFile(delete=False)
              >>> f
              <open file '<fdopen>', mode 'w+b' at 0x384698>
              >>> f.name
              '/var/folders/5q/5qTPn6xq2RaWqk+1Ytw3-U+++TI/-Tmp-/tmpG7V1Y0'
              >>> f.write("Hello World!\n")
              >>> f.close()
              >>> os.unlink(f.name)
              >>> os.path.exists(f.name)
              False



  The module uses two global variables that tell it how to construct a
temporary name.  They are initialized at the first call to any of the
functions above.  The caller may change them, but this is discouraged;
use the appropriate function arguments, instead.

 -- Data: tempfile.tempdir
     When set to a value other than `None', this variable defines the
     default value for the _dir_ argument to all the functions defined
     in this module.

     If `tempdir' is unset or `None' at any call to any of the above
     functions, Python searches a standard list of directories and sets
     _tempdir_ to the first one which the calling user can create files
     in.  The list is:

       1. The directory named by the `TMPDIR' environment variable.

       2. The directory named by the `TEMP' environment variable.

       3. The directory named by the `TMP' environment variable.

       4. A platform-specific location:

             * On RiscOS, the directory named by the `Wimp$ScrapDir'
               environment variable.

             * On Windows, the directories `C:\TEMP', `C:\TMP',
               `\TEMP', and `\TMP', in that order.

             * On all other platforms, the directories `/tmp',
               `/var/tmp', and `/usr/tmp', in that order.

       5. As a last resort, the current working directory.

 -- Function: tempfile.gettempdir ()
     Return the directory currently selected to create temporary files
     in. If *note tempdir: e6f. is not `None', this simply returns its
     contents; otherwise, the search described above is performed, and
     the result returned.

     New in version 2.3.

 -- Data: tempfile.template
     Deprecated since version 2.0: Use *note gettempprefix(): e72.
     instead.

     When set to a value other than `None', this variable defines the
     prefix of the final component of the filenames returned by *note
     mktemp(): e6b.  A string of six random letters and digits is
     appended to the prefix to make the filename unique.  The default
     prefix is `tmp'.

     Older versions of this module used to require that `template' be
     set to `None' after a call to *note os.fork(): 241.; this has not
     been necessary since version 1.5.2.

 -- Function: tempfile.gettempprefix ()
     Return the filename prefix used to create temporary files.  This
     does not contain the directory component.  Using this function is
     preferred over reading the _template_ variable directly.

     New in version 1.5.2.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/tempfile.py


File: python.info,  Node: glob --- Unix style pathname pattern expansion,  Next: fnmatch --- Unix filename pattern matching,  Prev: tempfile --- Generate temporary files and directories,  Up: File and Directory Access

5.10.7 `glob' -- Unix style pathname pattern expansion
------------------------------------------------------

*Source code:* Lib/glob.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note glob: e3. module finds all the pathnames matching a
specified pattern according to the rules used by the Unix shell.  No
tilde expansion is done, but `*', `?', and character ranges expressed
with `[]' will be correctly matched.  This is done by using the *note
os.listdir(): 2cf. and *note fnmatch.fnmatch(): e75. functions in
concert, and not by actually invoking a subshell.  Note that unlike
*note fnmatch.fnmatch(): e75, *note glob: e3. treats filenames
beginning with a dot (`.') as special cases.  (For tilde and shell
variable expansion, use *note os.path.expanduser(): dda. and *note
os.path.expandvars(): 34d.)

  For a literal match, wrap the meta-characters in brackets.  For
example, `'[?]'' matches the character `'?''.

 -- Function: glob.glob (pathname)
     Return a possibly-empty list of path names that match _pathname_,
     which must be a string containing a path specification. _pathname_
     can be either absolute (like `/usr/src/Python-1.5/Makefile') or
     relative (like `../../Tools/*/*.gif'), and can contain shell-style
     wildcards. Broken symlinks are included in the results (as in the
     shell).

 -- Function: glob.iglob (pathname)
     Return an *note iterator: 869. which yields the same values as
     *note glob(): e3.  without actually storing them all
     simultaneously.

     New in version 2.5.

  For example, consider a directory containing only the following files:
`1.gif', `2.txt', and `card.gif'.  *note glob(): e3. will produce the
following results.  Notice how any leading components of the path are
preserved.

    >>> import glob
    >>> glob.glob('./[0-9].*')
    ['./1.gif', './2.txt']
    >>> glob.glob('*.gif')
    ['1.gif', 'card.gif']
    >>> glob.glob('?.gif')
    ['1.gif']

If the directory contains files starting with `.' they won't be matched
by default. For example, consider a directory containing `card.gif' and
`.card.gif':

    >>> import glob
    >>> glob.glob('*.gif')
    ['card.gif']
    >>> glob.glob('.c*')
    ['.card.gif']


See also
........

Module *note fnmatch: d2.
     Shell-style filename (not path) expansion

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/glob.py


File: python.info,  Node: fnmatch --- Unix filename pattern matching,  Next: linecache --- Random access to text lines,  Prev: glob --- Unix style pathname pattern expansion,  Up: File and Directory Access

5.10.8 `fnmatch' -- Unix filename pattern matching
--------------------------------------------------

*Source code:* Lib/fnmatch.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module provides support for Unix shell-style wildcards, which
are _not_ the same as regular expressions (which are documented in the
*note re: 143. module).  The special characters used in shell-style
wildcards are:

Pattern          Meaning
---------------------------------------------------------- 
`*'              matches everything
`?'              matches any single character
`[seq]'          matches any character in _seq_
`[!seq]'         matches any character not in _seq_

  For a literal match, wrap the meta-characters in brackets.  For
example, `'[?]'' matches the character `'?''.

  Note that the filename separator (`'/'' on Unix) is _not_ special to
this module.  See module *note glob: e3. for pathname expansion (*note
glob: e3. uses *note fnmatch(): d2. to match pathname segments).
Similarly, filenames starting with a period are not special for this
module, and are matched by the `*' and `?' patterns.

 -- Function: fnmatch.fnmatch (filename, pattern)
     Test whether the _filename_ string matches the _pattern_ string,
     returning *note True: 3a9. or *note False: 3aa.  If the operating
     system is case-insensitive, then both parameters will be
     normalized to all lower- or upper-case before the comparison is
     performed.  *note fnmatchcase(): e79. can be used to perform a
     case-sensitive comparison, regardless of whether that's standard
     for the operating system.

     This example will print all file names in the current directory
     with the extension `.txt':

         import fnmatch
         import os

         for file in os.listdir('.'):
             if fnmatch.fnmatch(file, '*.txt'):
                 print file



 -- Function: fnmatch.fnmatchcase (filename, pattern)
     Test whether _filename_ matches _pattern_, returning *note True:
     3a9. or *note False: 3aa.; the comparison is case-sensitive.

 -- Function: fnmatch.filter (names, pattern)
     Return the subset of the list of _names_ that match _pattern_. It
     is the same as `[n for n in names if fnmatch(n, pattern)]', but
     implemented more efficiently.

     New in version 2.2.

 -- Function: fnmatch.translate (pattern)
     Return the shell-style _pattern_ converted to a regular expression.

     Example:

         >>> import fnmatch, re
         >>>
         >>> regex = fnmatch.translate('*.txt')
         >>> regex
         '.*\\.txt$'
         >>> reobj = re.compile(regex)
         >>> reobj.match('foobar.txt')
         <_sre.SRE_Match object at 0x...>



See also
........

Module *note glob: e3.
     Unix shell-style path expansion.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/fnmatch.py


File: python.info,  Node: linecache --- Random access to text lines,  Next: shutil --- High-level file operations,  Prev: fnmatch --- Unix filename pattern matching,  Up: File and Directory Access

5.10.9 `linecache' -- Random access to text lines
-------------------------------------------------

*Source code:* Lib/linecache.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note linecache: ff. module allows one to get any line from any
file, while attempting to optimize internally, using a cache, the
common case where many lines are read from a single file.  This is used
by the *note traceback: 181. module to retrieve source lines for
inclusion in  the formatted traceback.

  The *note linecache: ff. module defines the following functions:

 -- Function: linecache.getline (filename, lineno[, module_globals])
     Get line _lineno_ from file named _filename_. This function will
     never raise an exception -- it will return `''' on errors (the
     terminating newline character will be included for lines that are
     found).

     If a file named _filename_ is not found, the function will look
     for it in the module search path, `sys.path', after first checking
     for a PEP 302(2) `__loader__' in _module_globals_, in case the
     module was imported from a zipfile or other non-filesystem import
     source.

     New in version 2.5: The _module_globals_ parameter was added.

 -- Function: linecache.clearcache ()
     Clear the cache.  Use this function if you no longer need lines
     from files previously read using *note getline(): e7e.

 -- Function: linecache.checkcache ([filename])
     Check the cache for validity.  Use this function if files in the
     cache  may have changed on disk, and you require the updated
     version.  If _filename_ is omitted, it will check all the entries
     in the cache.

  Example:

    >>> import linecache
    >>> linecache.getline('/etc/passwd', 4)
    'sys:x:3:3:sys:/dev:/bin/sh\n'


  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/linecache.py

  (2) http://www.python.org/dev/peps/pep-0302


File: python.info,  Node: shutil --- High-level file operations,  Next: dircache --- Cached directory listings,  Prev: linecache --- Random access to text lines,  Up: File and Directory Access

5.10.10 `shutil' -- High-level file operations
----------------------------------------------

*Source code:* Lib/shutil.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note shutil: 154. module offers a number of high-level
operations on files and collections of files.  In particular, functions
are provided  which support file copying and removal. For operations on
individual files, see also the *note os: 128. module.

     Warning: Even the higher-level file copying functions (*note
     shutil.copy(): e83, *note shutil.copy2(): e84.) can't copy all
     file metadata.

     On POSIX platforms, this means that file owner and group are lost
     as well as ACLs.  On Mac OS, the resource fork and other metadata
     are not used.  This means that resources will be lost and file
     type and creator codes will not be correct. On Windows, file
     owners, ACLs and alternate data streams are not copied.

* Menu:

* Directory and files operations::
* Archiving operations::

Directory and files operations

* copytree example::

Archiving operations

* Archiving example::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/shutil.py


File: python.info,  Node: Directory and files operations,  Next: Archiving operations,  Up: shutil --- High-level file operations

5.10.10.1 Directory and files operations
........................................

 -- Function: shutil.copyfileobj (fsrc, fdst[, length])
     Copy the contents of the file-like object _fsrc_ to the file-like
     object _fdst_.  The integer _length_, if given, is the buffer
     size. In particular, a negative _length_ value means to copy the
     data without looping over the source data in chunks; by default
     the data is read in chunks to avoid uncontrolled memory
     consumption. Note that if the current file position of the _fsrc_
     object is not 0, only the contents from the current file position
     to the end of the file will be copied.

 -- Function: shutil.copyfile (src, dst)
     Copy the contents (no metadata) of the file named _src_ to a file
     named _dst_.  _dst_ must be the complete target file name; look at
     *note shutil.copy(): e83. for a copy that accepts a target
     directory path.  If _src_ and _dst_ are the same files, *note
     Error: e88. is raised.  The destination location must be writable;
     otherwise,  an *note IOError: 1f7. exception will be raised. If
     _dst_ already exists, it will be replaced.   Special files such as
     character or block devices and pipes cannot be copied with this
     function.  _src_ and _dst_ are path names given as strings.

 -- Function: shutil.copymode (src, dst)
     Copy the permission bits from _src_ to _dst_.  The file contents,
     owner, and group are unaffected.  _src_ and _dst_ are path names
     given as strings.

 -- Function: shutil.copystat (src, dst)
     Copy the permission bits, last access time, last modification
     time, and flags from _src_ to _dst_.  The file contents, owner,
     and group are unaffected.  _src_ and _dst_ are path names given as
     strings.

 -- Function: shutil.copy (src, dst)
     Copy the file _src_ to the file or directory _dst_.  If _dst_ is a
     directory, a file with the same basename as _src_  is created (or
     overwritten) in the directory specified.  Permission bits are
     copied.  _src_ and _dst_ are path names given as strings.

 -- Function: shutil.copy2 (src, dst)
     Similar to *note shutil.copy(): e83, but metadata is copied as
     well - in fact, this is just *note shutil.copy(): e83. followed by
     *note copystat(): e8a.  This is similar to the Unix command *cp
     -p*.

 -- Function: shutil.ignore_patterns (*patterns)
     This factory function creates a function that can be used as a
     callable for *note copytree(): 24a.'s _ignore_ argument, ignoring
     files and directories that match one of the glob-style _patterns_
     provided.  See the example below.

     New in version 2.6.

 -- Function: shutil.copytree (src, dst, symlinks=False, ignore=None)
     Recursively copy an entire directory tree rooted at _src_.  The
     destination directory, named by _dst_, must not already exist; it
     will be created as well as missing parent directories.
     Permissions and times of directories are copied with *note
     copystat(): e8a, individual files are copied using *note
     shutil.copy2(): e84.

     If _symlinks_ is true, symbolic links in the source tree are
     represented as symbolic links in the new tree, but the metadata of
     the original links is NOT copied; if false or omitted, the
     contents and metadata of the linked files are copied to the new
     tree.

     If _ignore_ is given, it must be a callable that will receive as
     its arguments the directory being visited by *note copytree():
     24a, and a list of its contents, as returned by *note
     os.listdir(): 2cf.  Since *note copytree(): 24a. is called
     recursively, the _ignore_ callable will be called once for each
     directory that is copied.  The callable must return a sequence of
     directory and file names relative to the current directory (i.e. a
     subset of the items in its second argument); these names will then
     be ignored in the copy process.  *note ignore_patterns(): e8b. can
     be used to create such a callable that ignores names based on
     glob-style patterns.

     If exception(s) occur, an *note Error: e88. is raised with a list
     of reasons.

     The source code for this should be considered an example rather
     than the ultimate tool.

     Changed in version 2.3: *note Error: e88. is raised if any
     exceptions occur during copying, rather than printing a message.

     Changed in version 2.5: Create intermediate directories needed to
     create _dst_, rather than raising an error. Copy permissions and
     times of directories using *note copystat(): e8a.

     Changed in version 2.6: Added the _ignore_ argument to be able to
     influence what is being copied.

 -- Function: shutil.rmtree (path[, ignore_errors[, onerror]])
     Delete an entire directory tree; _path_ must point to a directory
     (but not a symbolic link to a directory).  If _ignore_errors_ is
     true, errors resulting from failed removals will be ignored; if
     false or omitted, such errors are handled by calling a handler
     specified by _onerror_ or, if that is omitted, they raise an
     exception.

     If _onerror_ is provided, it must be a callable that accepts three
     parameters: _function_, _path_, and _excinfo_. The first parameter,
     _function_, is the function which raised the exception; it will be
     *note os.path.islink(): de9, *note os.listdir(): 2cf, *note
     os.remove(): e8d. or *note os.rmdir(): e8e.  The second parameter,
     _path_, will be the path name passed to _function_.  The third
     parameter, _excinfo_, will be the exception information return by
     *note sys.exc_info(): 2ec.  Exceptions raised by _onerror_ will
     not be caught.

     Changed in version 2.6: Explicitly check for _path_ being a
     symbolic link and raise *note OSError: 22e.  in that case.

 -- Function: shutil.move (src, dst)
     Recursively move a file or directory (_src_) to another location
     (_dst_).

     If the destination is a directory or a symlink to a directory,
     then _src_ is moved inside that directory.

     The destination directory must not already exist.  If the
     destination already exists but is not a directory, it may be
     overwritten depending on *note os.rename(): e90. semantics.

     If the destination is on the current filesystem, then *note
     os.rename(): e90. is used.  Otherwise, _src_ is copied (using
     *note shutil.copy2(): e84.) to _dst_ and then removed.

     New in version 2.3.

 -- Exception: shutil.Error
     This exception collects exceptions that are raised during a
     multi-file operation. For *note copytree(): 24a, the exception
     argument is a list of 3-tuples (_srcname_, _dstname_, _exception_).

     New in version 2.3.

* Menu:

* copytree example::


File: python.info,  Node: copytree example,  Up: Directory and files operations

5.10.10.2 copytree example
..........................

This example is the implementation of the *note copytree(): 24a.
function, described above, with the docstring omitted.  It demonstrates
many of the other functions provided by this module.

    def copytree(src, dst, symlinks=False, ignore=None):
        names = os.listdir(src)
        if ignore is not None:
            ignored_names = ignore(src, names)
        else:
            ignored_names = set()

        os.makedirs(dst)
        errors = []
        for name in names:
            if name in ignored_names:
                continue
            srcname = os.path.join(src, name)
            dstname = os.path.join(dst, name)
            try:
                if symlinks and os.path.islink(srcname):
                    linkto = os.readlink(srcname)
                    os.symlink(linkto, dstname)
                elif os.path.isdir(srcname):
                    copytree(srcname, dstname, symlinks, ignore)
                else:
                    copy2(srcname, dstname)
                # XXX What about devices, sockets etc.?
            except (IOError, os.error) as why:
                errors.append((srcname, dstname, str(why)))
            # catch the Error from the recursive copytree so that we can
            # continue with other files
            except Error as err:
                errors.extend(err.args[0])
        try:
            copystat(src, dst)
        except WindowsError:
            # can't copy file access times on Windows
            pass
        except OSError as why:
            errors.extend((src, dst, str(why)))
        if errors:
            raise Error(errors)

Another example that uses the *note ignore_patterns(): e8b. helper:

    from shutil import copytree, ignore_patterns

    copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))

This will copy everything except `.pyc' files and files or directories
whose name starts with `tmp'.

  Another example that uses the _ignore_ argument to add a logging call:

    from shutil import copytree
    import logging

    def _logpath(path, names):
        logging.info('Working in %s' % path)
        return []   # nothing will be ignored

    copytree(source, destination, ignore=_logpath)



File: python.info,  Node: Archiving operations,  Prev: Directory and files operations,  Up: shutil --- High-level file operations

5.10.10.3 Archiving operations
..............................

High-level utilities to create and read compressed and archived files
are also provided.  They rely on the *note zipfile: 1ab. and *note
tarfile: 171. modules.

 -- Function: shutil.make_archive (base_name, format[, root_dir[,
          base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])
     Create an archive file (eg. zip or tar) and returns its name.

     _base_name_ is the name of the file to create, including the path,
     minus any format-specific extension. _format_ is the archive
     format: one of "zip", "tar", "bztar" or "gztar".

     _root_dir_ is a directory that will be the root directory of the
     archive; ie. we typically chdir into _root_dir_ before creating the
     archive.

     _base_dir_ is the directory where we start archiving from; ie.
     _base_dir_ will be the common prefix of all files and directories
     in the archive.

     _root_dir_ and _base_dir_ both default to the current directory.

     _owner_ and _group_ are used when creating a tar archive. By
     default, uses the current owner and group.

     _logger_ must be an object compatible with PEP 282(1), usually an
     instance of *note logging.Logger: 1da.

     New in version 2.7.

 -- Function: shutil.get_archive_formats ()
     Return a list of supported formats for archiving.  Each element of
     the returned sequence is a tuple `(name, description)'

     By default *note shutil: 154. provides these formats:

        - _gztar_: gzip'ed tar-file

        - _bztar_: bzip2'ed tar-file

        - _tar_: uncompressed tar file

        - _zip_: ZIP file

     You can register new formats or provide your own archiver for any
     existing formats, by using *note register_archive_format(): e96.

     New in version 2.7.

 -- Function: shutil.register_archive_format (name, function[,
          extra_args[, description]])
     Register an archiver for the format _name_. _function_ is a
     callable that will be used to invoke the archiver.

     If given, _extra_args_ is a sequence of `(name, value)' that will
     be used as extra keywords arguments when the archiver callable is
     used.

     _description_ is used by *note get_archive_formats(): e95. which
     returns the list of archivers. Defaults to an empty list.

     New in version 2.7.

 -- Function: shutil.unregister_archive_format (name)
     Remove the archive format _name_ from the list of supported
     formats.

     New in version 2.7.

* Menu:

* Archiving example::

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0282


File: python.info,  Node: Archiving example,  Up: Archiving operations

5.10.10.4 Archiving example
...........................

In this example, we create a gzip'ed tar-file archive containing all
files found in the `.ssh' directory of the user:

    >>> from shutil import make_archive
    >>> import os
    >>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive'))
    >>> root_dir = os.path.expanduser(os.path.join('~', '.ssh'))
    >>> make_archive(archive_name, 'gztar', root_dir)
    '/Users/tarek/myarchive.tar.gz'

The resulting archive contains:

    $ tar -tzvf /Users/tarek/myarchive.tar.gz
    drwx------ tarek/staff       0 2010-02-01 16:23:40 ./
    -rw-r--r-- tarek/staff     609 2008-06-09 13:26:54 ./authorized_keys
    -rwxr-xr-x tarek/staff      65 2008-06-09 13:26:54 ./config
    -rwx------ tarek/staff     668 2008-06-09 13:26:54 ./id_dsa
    -rwxr-xr-x tarek/staff     609 2008-06-09 13:26:54 ./id_dsa.pub
    -rw------- tarek/staff    1675 2008-06-09 13:26:54 ./id_rsa
    -rw-r--r-- tarek/staff     397 2008-06-09 13:26:54 ./id_rsa.pub
    -rw-r--r-- tarek/staff   37192 2010-02-06 18:23:10 ./known_hosts



File: python.info,  Node: dircache --- Cached directory listings,  Next: macpath --- Mac OS 9 path manipulation functions,  Prev: shutil --- High-level file operations,  Up: File and Directory Access

5.10.11 `dircache' -- Cached directory listings
-----------------------------------------------

Deprecated since version 2.6: The *note dircache: 83. module has been
removed in Python 3.

  The *note dircache: 83. module defines a function for reading
directory listing using a cache, and cache invalidation using the
_mtime_ of the directory.  Additionally, it defines a function to
annotate directories by appending a slash.

  The *note dircache: 83. module defines the following functions:

 -- Function: dircache.reset ()
     Resets the directory cache.

 -- Function: dircache.listdir (path)
     Return a directory listing of _path_, as gotten from *note
     os.listdir(): 2cf. Note that unless _path_ changes, further call
     to *note listdir(): 419. will not re-read the directory structure.

     Note that the list returned should be regarded as read-only.
     (Perhaps a future version should change it to return a tuple?)

 -- Function: dircache.opendir (path)
     Same as *note listdir(): 419. Defined for backwards compatibility.

 -- Function: dircache.annotate (head, list)
     Assume _list_ is a list of paths relative to _head_, and append,
     in place, a `'/'' to each path which points to a directory.

    >>> import dircache
    >>> a = dircache.listdir('/')
    >>> a = a[:] # Copy the return value so we can change 'a'
    >>> a
    ['bin', 'boot', 'cdrom', 'dev', 'etc', 'floppy', 'home', 'initrd', 'lib', 'lost+
    found', 'mnt', 'proc', 'root', 'sbin', 'tmp', 'usr', 'var', 'vmlinuz']
    >>> dircache.annotate('/', a)
    >>> a
    ['bin/', 'boot/', 'cdrom/', 'dev/', 'etc/', 'floppy/', 'home/', 'initrd/', 'lib/
    ', 'lost+found/', 'mnt/', 'proc/', 'root/', 'sbin/', 'tmp/', 'usr/', 'var/', 'vm
    linuz']



File: python.info,  Node: macpath --- Mac OS 9 path manipulation functions,  Prev: dircache --- Cached directory listings,  Up: File and Directory Access

5.10.12 `macpath' -- Mac OS 9 path manipulation functions
---------------------------------------------------------

This module is the Mac OS 9 (and earlier) implementation of the *note
os.path: 129.  module. It can be used to manipulate old-style Macintosh
pathnames on Mac OS X (or any other platform).

  The following functions are available in this module: `normcase()',
`normpath()', `isabs()', `join()', `split()', `isdir()', `isfile()',
`walk()', `exists()'. For other functions available in *note os.path:
129. dummy counterparts are available.

See also
........

Section *note File Objects: 630.
     A description of Python's built-in file objects.

Module *note os: 128.
     Operating system interfaces, including functions to work with
     files at a lower level than the built-in file object.


File: python.info,  Node: Data Persistence,  Next: Data Compression and Archiving,  Prev: File and Directory Access,  Up: The Python Standard Library

5.11 Data Persistence
=====================

The modules described in this chapter support storing Python data in a
persistent form on disk.  The *note pickle: 12d. and *note marshal:
10b. modules can turn many Python data types into a stream of bytes and
then recreate the objects from the bytes.  The various DBM-related
modules support a family of hash-based file formats that store a
mapping of strings to other strings.  The *note bsddb: 1c.  module also
provides such disk-based string-to-string mappings based on hashing,
and also supports B-Tree and record-based formats.

  The list of modules described in this chapter is:

* Menu:

* pickle: pickle --- Python object serialization. Python object serialization
* cPickle: cPickle --- A faster pickle. A faster pickle
* copy_reg: copy_reg --- Register pickle support functions. Register pickle support functions
* shelve: shelve --- Python object persistence. Python object persistence
* marshal: marshal --- Internal Python object serialization. Internal Python object serialization
* anydbm: anydbm --- Generic access to DBM-style databases. Generic access to DBM-style databases
* whichdb: whichdb --- Guess which DBM module created a database. Guess which DBM module created a database
* dbm: dbm --- Simple "database" interface. Simple "database" interface
* gdbm: gdbm --- GNU's reinterpretation of dbm. GNU's reinterpretation of dbm
* dbhash: dbhash --- DBM-style interface to the BSD database library. DBM-style interface to the BSD database library
* bsddb: bsddb --- Interface to Berkeley DB library. Interface to Berkeley DB library
* dumbdbm: dumbdbm --- Portable DBM implementation. Portable DBM implementation
* sqlite3: sqlite3 --- DB-API 2 0 interface for SQLite databases. DB-API 2.0 interface for SQLite databases

pickle --- Python object serialization

* Relationship to other Python modules::
* Data stream format::
* Usage::
* What can be pickled and unpickled?::
* The pickle protocol::
* Subclassing Unpicklers::
* Example: Example<3>.

The pickle protocol

* Pickling and unpickling normal class instances::
* Pickling and unpickling extension types::
* Pickling and unpickling external objects::

copy_reg --- Register pickle support functions

* Example: Example<4>.

shelve --- Python object persistence

* Restrictions::
* Example: Example<5>.

dbhash --- DBM-style interface to the BSD database library

* Database Objects::

bsddb --- Interface to Berkeley DB library

* Hash, BTree and Record Objects: Hash BTree and Record Objects.

dumbdbm --- Portable DBM implementation

* Dumbdbm Objects::

sqlite3 --- DB-API 2.0 interface for SQLite databases

* Module functions and constants::
* Connection Objects::
* Cursor Objects::
* Row Objects::
* SQLite and Python types::
* Controlling Transactions::
* Using sqlite3 efficiently::
* Common issues::

SQLite and Python types

* Introduction: Introduction<6>.
* Using adapters to store additional Python types in SQLite databases::
* Converting SQLite values to custom Python types::
* Default adapters and converters::

Using adapters to store additional Python types in SQLite databases

* Letting your object adapt itself::
* Registering an adapter callable::

Using sqlite3 efficiently

* Using shortcut methods::
* Accessing columns by name instead of by index::
* Using the connection as a context manager::

Common issues

* Multithreading::


File: python.info,  Node: pickle --- Python object serialization,  Next: cPickle --- A faster pickle,  Up: Data Persistence

5.11.1 `pickle' -- Python object serialization
----------------------------------------------

The *note pickle: 12d. module implements a fundamental, but powerful
algorithm for serializing and de-serializing a Python object structure.
"Pickling" is the process whereby a Python object hierarchy is
converted into a byte stream, and "unpickling" is the inverse
operation, whereby a byte stream is converted back into an object
hierarchy.  Pickling (and unpickling) is alternatively known as
"serialization", "marshalling," (1) or "flattening", however, to avoid
confusion, the terms used here are "pickling" and "unpickling".

  This documentation describes both the *note pickle: 12d. module and
the *note cPickle: 73. module.

     Warning: The *note pickle: 12d. module is not intended to be
     secure against erroneous or maliciously constructed data.  Never
     unpickle data received from an untrusted or unauthenticated source.

* Menu:

* Relationship to other Python modules::
* Data stream format::
* Usage::
* What can be pickled and unpickled?::
* The pickle protocol::
* Subclassing Unpicklers::
* Example: Example<3>.

  ---------- Footnotes ----------

  (1) Don't confuse this with the *note marshal: 10b. module


File: python.info,  Node: Relationship to other Python modules,  Next: Data stream format,  Up: pickle --- Python object serialization

5.11.1.1 Relationship to other Python modules
.............................................

The *note pickle: 12d. module has an optimized cousin called the *note
cPickle: 73.  module.  As its name implies, *note cPickle: 73. is
written in C, so it can be up to 1000 times faster than *note pickle:
12d.  However it does not support subclassing of the *note Pickler():
ea7. and *note Unpickler(): ea8. classes, because in *note cPickle: 73.
these are functions, not classes.  Most applications have no need for
this functionality, and can benefit from the improved performance of
*note cPickle: 73.  Other than that, the interfaces of the two modules
are nearly identical; the common interface is described in this manual
and differences are pointed out where necessary.  In the following
discussions, we use the term "pickle" to collectively describe the
*note pickle: 12d. and *note cPickle: 73. modules.

  The data streams the two modules produce are guaranteed to be
interchangeable.

  Python has a more primitive serialization module called *note
marshal: 10b, but in general *note pickle: 12d. should always be the
preferred way to serialize Python objects.  *note marshal: 10b. exists
primarily to support Python's `.pyc' files.

  The *note pickle: 12d. module differs from *note marshal: 10b. in
several significant ways:

   * The *note pickle: 12d. module keeps track of the objects it has
     already serialized, so that later references to the same object
     won't be serialized again.  *note marshal: 10b. doesn't do this.

     This has implications both for recursive objects and object
     sharing.  Recursive objects are objects that contain references to
     themselves.  These are not handled by marshal, and in fact,
     attempting to marshal recursive objects will crash your Python
     interpreter.  Object sharing happens when there are multiple
     references to the same object in different places in the object
     hierarchy being serialized.  *note pickle: 12d. stores such
     objects only once, and ensures that all other references point to
     the master copy.  Shared objects remain shared, which can be very
     important for mutable objects.

   * *note marshal: 10b. cannot be used to serialize user-defined
     classes and their instances.  *note pickle: 12d. can save and
     restore class instances transparently, however the class
     definition must be importable and live in the same module as when
     the object was stored.

   * The *note marshal: 10b. serialization format is not guaranteed to
     be portable across Python versions.  Because its primary job in
     life is to support `.pyc' files, the Python implementers reserve
     the right to change the serialization format in non-backwards
     compatible ways should the need arise.  The *note pickle: 12d.
     serialization format is guaranteed to be backwards compatible
     across Python releases.

  Note that serialization is a more primitive notion than persistence;
although *note pickle: 12d. reads and writes file objects, it does not
handle the issue of naming persistent objects, nor the (even more
complicated) issue of concurrent access to persistent objects.  The
*note pickle: 12d. module can transform a complex object into a byte
stream and it can transform the byte stream into an object with the
same internal structure.  Perhaps the most obvious thing to do with
these byte streams is to write them onto a file, but it is also
conceivable to send them across a network or store them in a database.
The module *note shelve: 152. provides a simple interface to pickle and
unpickle objects on DBM-style database files.


File: python.info,  Node: Data stream format,  Next: Usage,  Prev: Relationship to other Python modules,  Up: pickle --- Python object serialization

5.11.1.2 Data stream format
...........................

The data format used by *note pickle: 12d. is Python-specific.  This
has the advantage that there are no restrictions imposed by external
standards such as XDR (which can't represent pointer sharing); however
it means that non-Python programs may not be able to reconstruct
pickled Python objects.

  By default, the *note pickle: 12d. data format uses a printable ASCII
representation.  This is slightly more voluminous than a binary
representation.  The big advantage of using printable ASCII (and of
some other characteristics of *note pickle: 12d.'s representation) is
that for debugging or recovery purposes it is possible for a human to
read the pickled file with a standard text editor.

  There are currently 3 different protocols which can be used for
pickling.

   * Protocol version 0 is the original ASCII protocol and is backwards
     compatible with earlier versions of Python.

   * Protocol version 1 is the old binary format which is also
     compatible with earlier versions of Python.

   * Protocol version 2 was introduced in Python 2.3.  It provides much
     more efficient pickling of *note new-style class: 5c3.es.

  Refer to PEP 307(1) for more information.

  If a _protocol_ is not specified, protocol 0 is used. If _protocol_
is specified as a negative value or *note HIGHEST_PROTOCOL: 442, the
highest protocol version available will be used.

  Changed in version 2.3: Introduced the _protocol_ parameter.

  A binary format, which is slightly more efficient, can be chosen by
specifying a _protocol_ version >= 1.

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0307


File: python.info,  Node: Usage,  Next: What can be pickled and unpickled?,  Prev: Data stream format,  Up: pickle --- Python object serialization

5.11.1.3 Usage
..............

To serialize an object hierarchy, you first create a pickler, then you
call the pickler's *note dump(): eab. method.  To de-serialize a data
stream, you first create an unpickler, then you call the unpickler's
*note load(): eac. method.  The *note pickle: 12d. module provides the
following constant:

 -- Data: pickle.HIGHEST_PROTOCOL
     The highest protocol version available.  This value can be passed
     as a _protocol_ value.

     New in version 2.3.

     Note: Be sure to always open pickle files created with protocols
     >= 1 in binary mode.  For the old ASCII-based pickle protocol 0
     you can use either text mode or binary mode as long as you stay
     consistent.

     A pickle file written with protocol 0 in binary mode will contain
     lone linefeeds as line terminators and therefore will look "funny"
     when viewed in Notepad or other editors which do not support this
     format.

  The *note pickle: 12d. module provides the following functions to
make the pickling process more convenient:

 -- Function: pickle.dump (obj, file[, protocol])
     Write a pickled representation of _obj_ to the open file object
     _file_.  This is equivalent to `Pickler(file, protocol).dump(obj)'.

     If the _protocol_ parameter is omitted, protocol 0 is used. If
     _protocol_ is specified as a negative value or *note
     HIGHEST_PROTOCOL: 442, the highest protocol version will be used.

     Changed in version 2.3: Introduced the _protocol_ parameter.

     _file_ must have a `write()' method that accepts a single string
     argument.  It can thus be a file object opened for writing, a
     *note StringIO: 164. object, or any other custom object that meets
     this interface.

 -- Function: pickle.load (file)
     Read a string from the open file object _file_ and interpret it as
     a pickle data stream, reconstructing and returning the original
     object hierarchy.  This is equivalent to `Unpickler(file).load()'.

     _file_ must have two methods, a `read()' method that takes an
     integer argument, and a *note readline(): 144. method that
     requires no arguments.  Both methods should return a string.  Thus
     _file_ can be a file object opened for reading, a *note StringIO:
     164. object, or any other custom object that meets this interface.

     This function automatically determines whether the data stream was
     written in binary mode or not.

 -- Function: pickle.dumps (obj[, protocol])
     Return the pickled representation of the object as a string,
     instead of writing it to a file.

     If the _protocol_ parameter is omitted, protocol 0 is used. If
     _protocol_ is specified as a negative value or *note
     HIGHEST_PROTOCOL: 442, the highest protocol version will be used.

     Changed in version 2.3: The _protocol_ parameter was added.

 -- Function: pickle.loads (string)
     Read a pickled object hierarchy from a string.  Characters in the
     string past the pickled object's representation are ignored.

  The *note pickle: 12d. module also defines three exceptions:

 -- Exception: pickle.PickleError
     A common base class for the other exceptions defined below.  This
     inherits from *note Exception: 332.

 -- Exception: pickle.PicklingError
     This exception is raised when an unpicklable object is passed to
     the *note dump(): eab. method.

 -- Exception: pickle.UnpicklingError
     This exception is raised when there is a problem unpickling an
     object. Note that other exceptions may also be raised during
     unpickling, including (but not necessarily limited to) *note
     AttributeError: 1f5, *note EOFError: 874, *note ImportError: 369,
     and *note IndexError: 4d8.

  The *note pickle: 12d. module also exports two callables (1), *note
Pickler: ea7. and *note Unpickler: ea8.:

 -- Class: pickle.Pickler (file[, protocol])
     This takes a file-like object to which it will write a pickle data
     stream.

     If the _protocol_ parameter is omitted, protocol 0 is used. If
     _protocol_ is specified as a negative value or *note
     HIGHEST_PROTOCOL: 442, the highest protocol version will be used.

     Changed in version 2.3: Introduced the _protocol_ parameter.

     _file_ must have a `write()' method that accepts a single string
     argument.  It can thus be an open file object, a *note StringIO:
     164. object, or any other custom object that meets this interface.

     *note Pickler: ea7. objects define one (or two) public methods:

      -- Method: dump (obj)
          Write a pickled representation of _obj_ to the open file
          object given in the constructor.  Either the binary or ASCII
          format will be used, depending on the value of the _protocol_
          argument passed to the constructor.

      -- Method: clear_memo ()
          Clears the pickler's "memo".  The memo is the data structure
          that remembers which objects the pickler has already seen, so
          that shared or recursive objects pickled by reference and not
          by value.  This method is useful when re-using picklers.

               Note: Prior to Python 2.3, *note clear_memo(): eb3. was
               only available on the picklers created by *note cPickle:
               73.  In the *note pickle: 12d. module, picklers have an
               instance variable called `memo' which is a Python
               dictionary.  So to clear the memo for a *note pickle:
               12d. module pickler, you could do the following:

                   mypickler.memo.clear()

               Code that does not need to support older versions of
               Python should simply use *note clear_memo(): eb3.

  It is possible to make multiple calls to the *note dump(): eab.
method of the same *note Pickler: ea7. instance.  These must then be
matched to the same number of calls to the *note load(): eac. method of
the corresponding *note Unpickler: ea8.  instance.  If the same object
is pickled by multiple *note dump(): eab. calls, the *note load(): eac.
will all yield references to the same object. (2)

  *note Unpickler: ea8. objects are defined as:

 -- Class: pickle.Unpickler (file)
     This takes a file-like object from which it will read a pickle
     data stream.  This class automatically determines whether the data
     stream was written in binary mode or not, so it does not need a
     flag as in the *note Pickler: ea7.  factory.

     _file_ must have two methods, a `read()' method that takes an
     integer argument, and a *note readline(): 144. method that
     requires no arguments.  Both methods should return a string.  Thus
     _file_ can be a file object opened for reading, a *note StringIO:
     164. object, or any other custom object that meets this interface.

     *note Unpickler: ea8. objects have one (or two) public methods:

      -- Method: load ()
          Read a pickled object representation from the open file
          object given in the constructor, and return the reconstituted
          object hierarchy specified therein.

          This method automatically determines whether the data stream
          was written in binary mode or not.

      -- Method: noload ()
          This is just like *note load(): eac. except that it doesn't
          actually create any objects.  This is useful primarily for
          finding what's called "persistent ids" that may be referenced
          in a pickle data stream.  See section *note The pickle
          protocol: eb6. below for more details.

          *Note_* the *note noload(): eb5. method is currently only
          available on *note Unpickler: ea8. objects created with the
          *note cPickle: 73. module.  *note pickle: 12d. module *note
          Unpickler: ea8.s do not have the *note noload(): eb5.  method.

  ---------- Footnotes ----------

  (1) In the *note pickle: 12d. module these callables are classes,
which you could subclass to customize the behavior.  However, in the
*note cPickle: 73. module these callables are factory functions and so
cannot be subclassed.  One common reason to subclass is to control what
objects can actually be unpickled.  See section *note Subclassing
Unpicklers: eb1. for more details.

  (2) _Warning_: this is intended for pickling multiple objects without
intervening modifications to the objects or their parts.  If you modify
an object and then pickle it again using the same `Pickler' instance,
the object is not pickled again -- a reference to it is pickled and the
`Unpickler' will return the old value, not the modified one. There are
two problems here: (1) detecting changes, and (2) marshalling a minimal
set of changes.  Garbage Collection may also become a problem here.


File: python.info,  Node: What can be pickled and unpickled?,  Next: The pickle protocol,  Prev: Usage,  Up: pickle --- Python object serialization

5.11.1.4 What can be pickled and unpickled?
...........................................

The following types can be pickled:

   * `None', `True', and `False'

   * integers, long integers, floating point numbers, complex numbers

   * normal and Unicode strings

   * tuples, lists, sets, and dictionaries containing only picklable
     objects

   * functions defined at the top level of a module

   * built-in functions defined at the top level of a module

   * classes that are defined at the top level of a module

   * instances of such classes whose `__dict__' or the result of calling
     *note __getstate__(): 443. is picklable  (see section *note The
     pickle protocol: eb6. for details).

  Attempts to pickle unpicklable objects will raise the *note
PicklingError: eaf.  exception; when this happens, an unspecified
number of bytes may have already been written to the underlying file.
Trying to pickle a highly recursive data structure may exceed the
maximum recursion depth, a *note RuntimeError: 394. will be raised in
this case. You can carefully raise this limit with *note
sys.setrecursionlimit(): 4de.

  Note that functions (built-in and user-defined) are pickled by "fully
qualified" name reference, not by value.  This means that only the
function name is pickled, along with the name of the module the
function is defined in.  Neither the function's code, nor any of its
function attributes are pickled.  Thus the defining module must be
importable in the unpickling environment, and the module must contain
the named object, otherwise an exception will be raised. (1)

  Similarly, classes are pickled by named reference, so the same
restrictions in the unpickling environment apply.  Note that none of
the class's code or data is pickled, so in the following example the
class attribute `attr' is not restored in the unpickling environment:

    class Foo:
        attr = 'a class attr'

    picklestring = pickle.dumps(Foo)

These restrictions are why picklable functions and classes must be
defined in the top level of a module.

  Similarly, when class instances are pickled, their class's code and
data are not pickled along with them.  Only the instance data are
pickled.  This is done on purpose, so you can fix bugs in a class or
add methods to the class and still load objects that were created with
an earlier version of the class.  If you plan to have long-lived
objects that will see many versions of a class, it may be worthwhile to
put a version number in the objects so that suitable conversions can be
made by the class's *note __setstate__(): 444. method.

  ---------- Footnotes ----------

  (1) The exception raised will likely be an *note ImportError: 369. or
an *note AttributeError: 1f5. but it could be something else.


File: python.info,  Node: The pickle protocol,  Next: Subclassing Unpicklers,  Prev: What can be pickled and unpickled?,  Up: pickle --- Python object serialization

5.11.1.5 The pickle protocol
............................

This section describes the "pickling protocol" that defines the
interface between the pickler/unpickler and the objects that are being
serialized.  This protocol provides a standard way for you to define,
customize, and control how your objects are serialized and
de-serialized.  The description in this section doesn't cover specific
customizations that you can employ to make the unpickling environment
slightly safer from untrusted pickle data streams; see section *note
Subclassing Unpicklers: eb1. for more details.

* Menu:

* Pickling and unpickling normal class instances::
* Pickling and unpickling extension types::
* Pickling and unpickling external objects::


File: python.info,  Node: Pickling and unpickling normal class instances,  Next: Pickling and unpickling extension types,  Up: The pickle protocol

5.11.1.6 Pickling and unpickling normal class instances
.......................................................

 -- Method: object.__getinitargs__ ()
     When a pickled class instance is unpickled, its *note __init__():
     375. method is normally _not_ invoked.  If it is desirable that
     the *note __init__(): 375. method be called on unpickling, an
     old-style class can define a method *note __getinitargs__(): ebb,
     which should return a _tuple_ containing the arguments to be
     passed to the class constructor (*note __init__(): 375. for
     example).  The *note __getinitargs__(): ebb. method is called at
     pickle time; the tuple it returns is incorporated in the pickle
     for the instance.

 -- Method: object.__getnewargs__ ()
     New-style types can provide a *note __getnewargs__(): 445. method
     that is used for protocol 2.  Implementing this method is needed
     if the type establishes some internal invariants when the instance
     is created, or if the memory allocation is affected by the values
     passed to the *note __new__(): 6e9. method for the type (as it is
     for tuples and strings).  Instances of a *note new-style class:
     5c3.  `C' are created using

         obj = C.__new__(C, *args)

     where _args_ is the result of calling *note __getnewargs__(): 445.
     on the original object; if there is no *note __getnewargs__():
     445, an empty tuple is assumed.

 -- Method: object.__getstate__ ()
     Classes can further influence how their instances are pickled; if
     the class defines the method *note __getstate__(): 443, it is
     called and the return state is pickled as the contents for the
     instance, instead of the contents of the instance's dictionary.
     If there is no *note __getstate__(): 443. method, the instance's
     *note __dict__: 928. is pickled.

 -- Method: object.__setstate__ (state)
     Upon unpickling, if the class also defines the method *note
     __setstate__(): 444, it is called with the unpickled state. (1) If
     there is no *note __setstate__(): 444. method, the pickled state
     must be a dictionary and its items are assigned to the new
     instance's dictionary.  If a class defines both *note
     __getstate__(): 443. and *note __setstate__(): 444, the state
     object needn't be a dictionary and these methods can do what they
     want. (2)

          Note: For *note new-style class: 5c3.es, if *note
          __getstate__(): 443. returns a false value, the *note
          __setstate__(): 444. method will not be called.

     Note: At unpickling time, some methods like *note __getattr__():
     32a, *note __getattribute__(): 334, or *note __setattr__(): 481.
     may be called upon the instance.  In case those methods rely on
     some internal invariant being true, the type should implement
     either *note __getinitargs__(): ebb. or *note __getnewargs__():
     445. to establish such an invariant; otherwise, neither *note
     __new__(): 6e9. nor *note __init__(): 375. will be called.

  ---------- Footnotes ----------

  (1) These methods can also be used to implement copying class
instances.

  (2) This protocol is also used by the shallow and deep copying
operations defined in the *note copy: 71. module.


File: python.info,  Node: Pickling and unpickling extension types,  Next: Pickling and unpickling external objects,  Prev: Pickling and unpickling normal class instances,  Up: The pickle protocol

5.11.1.7 Pickling and unpickling extension types
................................................

 -- Method: object.__reduce__ ()
     When the `Pickler' encounters an object of a type it knows nothing
     about -- such as an extension type -- it looks in two places for a
     hint of how to pickle it.  One alternative is for the object to
     implement a *note __reduce__(): 3c5. method.  If provided, at
     pickling time *note __reduce__(): 3c5.  will be called with no
     arguments, and it must return either a string or a tuple.

     If a string is returned, it names a global variable whose contents
     are pickled as normal.  The string returned by *note __reduce__():
     3c5. should be the object's local name relative to its module; the
     pickle module searches the module namespace to determine the
     object's module.

     When a tuple is returned, it must be between two and five elements
     long.  Optional elements can either be omitted, or `None' can be
     provided as their value.  The contents of this tuple are pickled
     as normal and used to reconstruct the object at unpickling time.
     The semantics of each element are:

        * A callable object that will be called to create the initial
          version of the object.  The next element of the tuple will
          provide arguments for this callable, and later elements
          provide additional state information that will subsequently
          be used to fully reconstruct the pickled data.

          In the unpickling environment this object must be either a
          class, a callable registered as a "safe constructor" (see
          below), or it must have an attribute
          `__safe_for_unpickling__' with a true value. Otherwise, an
          `UnpicklingError' will be raised in the unpickling
          environment.  Note that as usual, the callable itself is
          pickled by name.

        * A tuple of arguments for the callable object.

          Changed in version 2.5: Formerly, this argument could also be
          `None'.

        * Optionally, the object's state, which will be passed to the
          object's *note __setstate__(): 444. method as described in
          section *note Pickling and unpickling normal class instances:
          eba.  If the object has no *note __setstate__(): 444. method,
          then, as above, the value must be a dictionary and it will be
          added to the object's *note __dict__: 928.

        * Optionally, an iterator (and not a sequence) yielding
          successive list items.  These list items will be pickled, and
          appended to the object using either `obj.append(item)' or
          `obj.extend(list_of_items)'.  This is primarily used for list
          subclasses, but may be used by other classes as long as they
          have `append()' and `extend()' methods with the appropriate
          signature.  (Whether `append()' or `extend()' is used depends
          on which pickle protocol version is used as well as the
          number of items to append, so both must be supported.)

        * Optionally, an iterator (not a sequence) yielding successive
          dictionary items, which should be tuples of the form `(key,
          value)'.  These items will be pickled and stored to the
          object using `obj[key] = value'. This is primarily used for
          dictionary subclasses, but may be used by other classes as
          long as they implement *note __setitem__(): 45e.

 -- Method: object.__reduce_ex__ (protocol)
     It is sometimes useful to know the protocol version when
     implementing *note __reduce__(): 3c5.  This can be done by
     implementing a method named *note __reduce_ex__(): ebd. instead of
     *note __reduce__(): 3c5. *note __reduce_ex__(): ebd, when it
     exists, is called in preference over *note __reduce__(): 3c5. (you
     may still provide *note __reduce__(): 3c5. for backwards
     compatibility).  The *note __reduce_ex__(): ebd. method will be
     called with a single integer argument, the protocol version.

     The *note object: 1ee. class implements both *note __reduce__():
     3c5. and *note __reduce_ex__(): ebd.; however, if a subclass
     overrides *note __reduce__(): 3c5.  but not *note __reduce_ex__():
     ebd, the *note __reduce_ex__(): ebd. implementation detects this
     and calls *note __reduce__(): 3c5.

  An alternative to implementing a *note __reduce__(): 3c5. method on
the object to be pickled, is to register the callable with the *note
copy_reg: 72. module.  This module provides a way for programs to
register "reduction functions" and constructors for user-defined types.
 Reduction functions have the same semantics and interface as the *note
__reduce__(): 3c5. method described above, except that they are called
with a single argument, the object to be pickled.

  The registered constructor is deemed a "safe constructor" for
purposes of unpickling as described above.


File: python.info,  Node: Pickling and unpickling external objects,  Prev: Pickling and unpickling extension types,  Up: The pickle protocol

5.11.1.8 Pickling and unpickling external objects
.................................................

For the benefit of object persistence, the *note pickle: 12d. module
supports the notion of a reference to an object outside the pickled
data stream.  Such objects are referenced by a "persistent id", which
is just an arbitrary string of printable ASCII characters. The
resolution of such names is not defined by the *note pickle: 12d.
module; it will delegate this resolution to user defined functions on
the pickler and unpickler. (1)

  To define external persistent id resolution, you need to set the
`persistent_id' attribute of the pickler object and the
`persistent_load' attribute of the unpickler object.

  To pickle objects that have an external persistent id, the pickler
must have a custom `persistent_id()' method that takes an object as an
argument and returns either `None' or the persistent id for that
object.  When `None' is returned, the pickler simply pickles the object
as normal.  When a persistent id string is returned, the pickler will
pickle that string, along with a marker so that the unpickler will
recognize the string as a persistent id.

  To unpickle external objects, the unpickler must have a custom
`persistent_load()' function that takes a persistent id string and
returns the referenced object.

  Here's a silly example that _might_ shed more light:

    import pickle
    from cStringIO import StringIO

    src = StringIO()
    p = pickle.Pickler(src)

    def persistent_id(obj):
        if hasattr(obj, 'x'):
            return 'the value %d' % obj.x
        else:
            return None

    p.persistent_id = persistent_id

    class Integer:
        def __init__(self, x):
            self.x = x
        def __str__(self):
            return 'My name is integer %d' % self.x

    i = Integer(7)
    print i
    p.dump(i)

    datastream = src.getvalue()
    print repr(datastream)
    dst = StringIO(datastream)

    up = pickle.Unpickler(dst)

    class FancyInteger(Integer):
        def __str__(self):
            return 'I am the integer %d' % self.x

    def persistent_load(persid):
        if persid.startswith('the value '):
            value = int(persid.split()[2])
            return FancyInteger(value)
        else:
            raise pickle.UnpicklingError, 'Invalid persistent id'

    up.persistent_load = persistent_load

    j = up.load()
    print j

In the *note cPickle: 73. module, the unpickler's `persistent_load'
attribute can also be set to a Python list, in which case, when the
unpickler reaches a persistent id, the persistent id string will simply
be appended to this list.  This functionality exists so that a pickle
data stream can be "sniffed" for object references without actually
instantiating all the objects in a pickle.  (2)  Setting
`persistent_load' to a list is usually used in conjunction with the
`noload()' method on the Unpickler.

  ---------- Footnotes ----------

  (1) The actual mechanism for associating these user defined functions
is slightly different for *note pickle: 12d. and *note cPickle: 73.
The description given here works the same for both implementations.
Users of the *note pickle: 12d. module could also use subclassing to
effect the same results, overriding the `persistent_id()' and
`persistent_load()' methods in the derived classes.

  (2) We'll leave you with the image of Guido and Jim sitting around
sniffing pickles in their living rooms.


File: python.info,  Node: Subclassing Unpicklers,  Next: Example<3>,  Prev: The pickle protocol,  Up: pickle --- Python object serialization

5.11.1.9 Subclassing Unpicklers
...............................

By default, unpickling will import any class that it finds in the
pickle data.  You can control exactly what gets unpickled and what gets
called by customizing your unpickler.  Unfortunately, exactly how you
do this is different depending on whether you're using *note pickle:
12d. or *note cPickle: 73. (1)

  In the *note pickle: 12d. module, you need to derive a subclass from
`Unpickler', overriding the `load_global()' method.  `load_global()'
should read two lines from the pickle data stream where the first line
will the name of the module containing the class and the second line
will be the name of the instance's class.  It then looks up the class,
possibly importing the module and digging out the attribute, then it
appends what it finds to the unpickler's stack.  Later on, this class
will be assigned to the `__class__' attribute of an empty class, as a
way of magically creating an instance without calling its class's *note
__init__(): 375. Your job (should you choose to accept it), would be to
have `load_global()' push onto the unpickler's stack, a known safe
version of any class you deem safe to unpickle.  It is up to you to
produce such a class.  Or you could raise an error if you want to
disallow all unpickling of instances.  If this sounds like a hack,
you're right.  Refer to the source code to make this work.

  Things are a little cleaner with *note cPickle: 73, but not by much.
To control what gets unpickled, you can set the unpickler's
`find_global' attribute to a function or `None'.  If it is `None' then
any attempts to unpickle instances will raise an `UnpicklingError'.  If
it is a function, then it should accept a module name and a class name,
and return the corresponding class object.  It is responsible for
looking up the class and performing any necessary imports, and it may
raise an error to prevent instances of the class from being unpickled.

  The moral of the story is that you should be really careful about the
source of the strings your application unpickles.

  ---------- Footnotes ----------

  (1) A word of caution: the mechanisms described here use internal
attributes and methods, which are subject to change in future versions
of Python.  We intend to someday provide a common interface for
controlling this behavior, which will work in either *note pickle: 12d.
or *note cPickle: 73.



Local Variables:
coding: utf-8
End:
