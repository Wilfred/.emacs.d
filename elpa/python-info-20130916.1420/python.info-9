This is
/home/melpa/melpa/working/python-info-20130916.1420/python.info,
produced by makeinfo version 4.13 from
/home/melpa/melpa/working/python-info/python.texi.

Generated by Sphinx 1.1.3.
INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY

     Python 2.7.5, September 16, 2013

     Georg Brandl

     Copyright (C) 1990-2013, Python Software Foundation


File: python.info,  Node: Example<3>,  Prev: Subclassing Unpicklers,  Up: pickle --- Python object serialization

5.11.1.10 Example
.................

For the simplest code, use the `dump()' and `load()' functions.  Note
that a self-referencing list is pickled and restored correctly.

    import pickle

    data1 = {'a': [1, 2.0, 3, 4+6j],
             'b': ('string', u'Unicode string'),
             'c': None}

    selfref_list = [1, 2, 3]
    selfref_list.append(selfref_list)

    output = open('data.pkl', 'wb')

    # Pickle dictionary using protocol 0.
    pickle.dump(data1, output)

    # Pickle the list using the highest protocol available.
    pickle.dump(selfref_list, output, -1)

    output.close()

The following example reads the resulting pickled data.  When reading a
pickle-containing file, you should open the file in binary mode because
you can't be sure if the ASCII or binary format was used.

    import pprint, pickle

    pkl_file = open('data.pkl', 'rb')

    data1 = pickle.load(pkl_file)
    pprint.pprint(data1)

    data2 = pickle.load(pkl_file)
    pprint.pprint(data2)

    pkl_file.close()

Here's a larger example that shows how to modify pickling behavior for
a class.  The `TextReader' class opens a text file, and returns the
line number and line contents each time its *note readline(): 144.
method is called. If a `TextReader' instance is pickled, all attributes
_except_ the file object member are saved. When the instance is
unpickled, the file is reopened, and reading resumes from the last
location. The *note __setstate__(): 444. and *note __getstate__(): 443.
methods are used to implement this behavior.

    #!/usr/local/bin/python

    class TextReader:
        """Print and number lines in a text file."""
        def __init__(self, file):
            self.file = file
            self.fh = open(file)
            self.lineno = 0

        def readline(self):
            self.lineno = self.lineno + 1
            line = self.fh.readline()
            if not line:
                return None
            if line.endswith("\n"):
                line = line[:-1]
            return "%d: %s" % (self.lineno, line)

        def __getstate__(self):
            odict = self.__dict__.copy() # copy the dict since we change it
            del odict['fh']              # remove filehandle entry
            return odict

        def __setstate__(self, dict):
            fh = open(dict['file'])      # reopen file
            count = dict['lineno']       # read from file...
            while count:                 # until line count is restored
                fh.readline()
                count = count - 1
            self.__dict__.update(dict)   # update attributes
            self.fh = fh                 # save the file object

A sample usage might be something like this:

    >>> import TextReader
    >>> obj = TextReader.TextReader("TextReader.py")
    >>> obj.readline()
    '1: #!/usr/local/bin/python'
    >>> obj.readline()
    '2: '
    >>> obj.readline()
    '3: class TextReader:'
    >>> import pickle
    >>> pickle.dump(obj, open('save.p', 'wb'))

If you want to see that *note pickle: 12d. works across Python
processes, start another Python session, before continuing.  What
follows can happen from either the same process or a new process.

    >>> import pickle
    >>> reader = pickle.load(open('save.p', 'rb'))
    >>> reader.readline()
    '4:     """Print and number lines in a text file."""'


See also
........

Module *note copy_reg: 72.
     Pickle interface constructor registration for extension types.

Module *note shelve: 152.
     Indexed databases of objects; uses *note pickle: 12d.

Module *note copy: 71.
     Shallow and deep object copying.

Module *note marshal: 10b.
     High-performance serialization of built-in types.


File: python.info,  Node: cPickle --- A faster pickle,  Next: copy_reg --- Register pickle support functions,  Prev: pickle --- Python object serialization,  Up: Data Persistence

5.11.2 `cPickle' -- A faster `pickle'
-------------------------------------

The *note cPickle: 73. module supports serialization and
de-serialization of Python objects, providing an interface and
functionality nearly identical to the *note pickle: 12d. module.  There
are several differences, the most important being performance and
subclassability.

  First, *note cPickle: 73. can be up to 1000 times faster than *note
pickle: 12d. because the former is implemented in C.  Second, in the
*note cPickle: 73. module the callables `Pickler()' and `Unpickler()'
are functions, not classes.  This means that you cannot use them to
derive custom pickling and unpickling subclasses.  Most applications
have no need for this functionality and should benefit from the greatly
improved performance of the *note cPickle: 73. module.

  The pickle data stream produced by *note pickle: 12d. and *note
cPickle: 73. are identical, so it is possible to use *note pickle: 12d.
and *note cPickle: 73.  interchangeably with existing pickles. (1)

  There are additional minor differences in API between *note cPickle:
73. and *note pickle: 12d, however for most applications, they are
interchangeable.  More documentation is provided in the *note pickle:
12d. module documentation, which includes a list of the documented
differences.

  ---------- Footnotes ----------

  (1) Since the pickle data format is actually a tiny stack-oriented
programming language, and some freedom is taken in the encodings of
certain objects, it is possible that the two modules produce different
data streams for the same input objects.  However it is guaranteed that
they will always be able to read each other's data streams.


File: python.info,  Node: copy_reg --- Register pickle support functions,  Next: shelve --- Python object persistence,  Prev: cPickle --- A faster pickle,  Up: Data Persistence

5.11.3 `copy_reg' -- Register `pickle' support functions
--------------------------------------------------------

     Note: The *note copy_reg: 72. module has been renamed to `copyreg'
     in Python 3.  The *note 2to3: bbc. tool will automatically adapt
     imports when converting your sources to Python 3.

The *note copy_reg: 72. module offers a way to define fuctions used
while pickling specific objects.  The *note pickle: 12d, *note cPickle:
73, and *note copy: 71. modules use those functions when
pickling/copying those objects.  The module provides configuration
information about object constructors which are not classes.  Such
constructors may be factory functions or class instances.

 -- Function: copy_reg.constructor (object)
     Declares _object_ to be a valid constructor.  If _object_ is not
     callable (and hence not valid as a constructor), raises *note
     TypeError: 215.

 -- Function: copy_reg.pickle (type, function[, constructor])
     Declares that _function_ should be used as a "reduction" function
     for objects of type _type_; _type_ must not be a "classic" class
     object.  (Classic classes are handled differently; see the
     documentation for the *note pickle: 12d. module for details.)
     _function_ should return either a string or a tuple containing two
     or three elements.

     The optional _constructor_ parameter, if provided, is a callable
     object which can be used to reconstruct the object when called
     with the tuple of arguments returned by _function_ at pickling
     time.  *note TypeError: 215. will be raised if _object_ is a class
     or _constructor_ is not callable.

     See the *note pickle: 12d. module for more details on the
     interface expected of _function_ and _constructor_.

* Menu:

* Example: Example<4>.


File: python.info,  Node: Example<4>,  Up: copy_reg --- Register pickle support functions

5.11.3.1 Example
................

The example below would like to show how to register a pickle function
and how it will be used:

    >>> import copy_reg, copy, pickle
    >>> class C(object):
    ...     def __init__(self, a):
    ...         self.a = a
    ...
    >>> def pickle_c(c):
    ...     print("pickling a C instance...")
    ...     return C, (c.a,)
    ...
    >>> copy_reg.pickle(C, pickle_c)
    >>> c = C(1)
    >>> d = copy.copy(c)
    pickling a C instance...
    >>> p = pickle.dumps(c)
    pickling a C instance...



File: python.info,  Node: shelve --- Python object persistence,  Next: marshal --- Internal Python object serialization,  Prev: copy_reg --- Register pickle support functions,  Up: Data Persistence

5.11.4 `shelve' -- Python object persistence
--------------------------------------------

*Source code:* Lib/shelve.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  A "shelf" is a persistent, dictionary-like object.  The difference
with "dbm" databases is that the values (not the keys!) in a shelf can
be essentially arbitrary Python objects -- anything that the *note
pickle: 12d. module can handle.  This includes most class instances,
recursive data types, and objects containing lots of shared
sub-objects.  The keys are ordinary strings.

 -- Function: shelve.open (filename, flag='c', protocol=None,
          writeback=False)
     Open a persistent dictionary.  The filename specified is the base
     filename for the underlying database.  As a side-effect, an
     extension may be added to the filename and more than one file may
     be created.  By default, the underlying database file is opened
     for reading and writing.  The optional _flag_ parameter has the
     same interpretation as the _flag_ parameter of *note
     anydbm.open(): ecb.

     By default, version 0 pickles are used to serialize values.  The
     version of the pickle protocol can be specified with the
     _protocol_ parameter.

     Changed in version 2.3: The _protocol_ parameter was added.

     Because of Python semantics, a shelf cannot know when a mutable
     persistent-dictionary entry is modified.  By default modified
     objects are written _only_ when assigned to the shelf (see *note
     Example: ecc.).  If the optional _writeback_ parameter is set to
     _True_, all entries accessed are also cached in memory, and
     written back on *note sync(): ecd. and *note close(): ece.; this
     can make it handier to mutate mutable entries in the persistent
     dictionary, but, if many entries are accessed, it can consume vast
     amounts of memory for the cache, and it can make the close
     operation very slow since all accessed entries are written back
     (there is no way to determine which accessed entries are mutable,
     nor which ones were actually mutated).

     Like file objects, shelve objects should be closed explicitly to
     ensure that the persistent data is flushed to disk.

     Since the *note shelve: 152. module stores objects using *note
     pickle: 12d, the same security precautions apply.  Accordingly,
     you should avoid loading a shelf from an untrusted source.

  Shelf objects support all methods supported by dictionaries.  This
eases the transition from dictionary based scripts to those requiring
persistent storage.

  Two additional methods are supported:

 -- Method: Shelf.sync ()
     Write back all entries in the cache if the shelf was opened with
     _writeback_ set to *note True: 3a9.  Also empty the cache and
     synchronize the persistent dictionary on disk, if feasible.  This
     is called automatically when the shelf is closed with *note
     close(): ece.

 -- Method: Shelf.close ()
     Synchronize and close the persistent _dict_ object.  Operations on
     a closed shelf will fail with a *note ValueError: 233.

See also
........

Persistent dictionary recipe(2) with widely supported storage formats
and having the speed of native dictionaries.

* Menu:

* Restrictions::
* Example: Example<5>.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/shelve.py

  (2) http://code.activestate.com/recipes/576642/


File: python.info,  Node: Restrictions,  Next: Example<5>,  Up: shelve --- Python object persistence

5.11.4.1 Restrictions
.....................

 
   * The choice of which database package will be used (such as *note
     dbm: 7f, *note gdbm: dc. or *note bsddb: 1c.) depends on which
     interface is available.  Therefore it is not safe to open the
     database directly using *note dbm: 7f.  The database is also
     (unfortunately) subject to the limitations of *note dbm: 7f, if it
     is used -- this means that (the pickled representation of) the
     objects stored in the database should be fairly small, and in rare
     cases key collisions may cause the database to refuse updates.

   * The *note shelve: 152. module does not support _concurrent_
     read/write access to shelved objects.  (Multiple simultaneous read
     accesses are safe.)  When a program has a shelf open for writing,
     no other program should have it open for reading or writing.  Unix
     file locking can be used to solve this, but this differs across
     Unix versions and requires knowledge about the database
     implementation used.

 -- Class: shelve.Shelf (dict, protocol=None, writeback=False)
     A subclass of *note UserDict.DictMixin: be1. which stores pickled
     values in the _dict_ object.

     By default, version 0 pickles are used to serialize values.  The
     version of the pickle protocol can be specified with the
     _protocol_ parameter. See the *note pickle: 12d. documentation for
     a discussion of the pickle protocols.

     Changed in version 2.3: The _protocol_ parameter was added.

     If the _writeback_ parameter is `True', the object will hold a
     cache of all entries accessed and write them back to the _dict_ at
     sync and close times.  This allows natural operations on mutable
     entries, but can consume much more memory and make sync and close
     take a long time.

 -- Class: shelve.BsdDbShelf (dict, protocol=None, writeback=False)
     A subclass of *note Shelf: ed0. which exposes `first()', `next()',
     `previous()', `last()' and `set_location()' which are available in
     the *note bsddb: 1c. module but not in other database modules.
     The _dict_ object passed to the constructor must support those
     methods.  This is generally accomplished by calling one of *note
     bsddb.hashopen(): ed2, *note bsddb.btopen(): ed3. or *note
     bsddb.rnopen(): ed4.  The optional _protocol_ and _writeback_
     parameters have the same interpretation as for the *note Shelf:
     ed0. class.

 -- Class: shelve.DbfilenameShelf (filename, flag='c', protocol=None,
          writeback=False)
     A subclass of *note Shelf: ed0. which accepts a _filename_ instead
     of a dict-like object.  The underlying file will be opened using
     *note anydbm.open(): ecb.  By default, the file will be created
     and opened for both read and write.  The optional _flag_ parameter
     has the same interpretation as for the *note open(): eca.
     function.  The optional _protocol_ and _writeback_ parameters have
     the same interpretation as for the *note Shelf: ed0. class.


File: python.info,  Node: Example<5>,  Prev: Restrictions,  Up: shelve --- Python object persistence

5.11.4.2 Example
................

To summarize the interface (`key' is a string, `data' is an arbitrary
object):

    import shelve

    d = shelve.open(filename) # open -- file may get suffix added by low-level
                              # library

    d[key] = data   # store data at key (overwrites old data if
                    # using an existing key)
    data = d[key]   # retrieve a COPY of data at key (raise KeyError if no
                    # such key)
    del d[key]      # delete data stored at key (raises KeyError
                    # if no such key)
    flag = d.has_key(key)   # true if the key exists
    klist = d.keys() # a list of all existing keys (slow!)

    # as d was opened WITHOUT writeback=True, beware:
    d['xx'] = range(4)  # this works as expected, but...
    d['xx'].append(5)   # *this doesn't!* -- d['xx'] is STILL range(4)!

    # having opened d without writeback=True, you need to code carefully:
    temp = d['xx']      # extracts the copy
    temp.append(5)      # mutates the copy
    d['xx'] = temp      # stores the copy right back, to persist it

    # or, d=shelve.open(filename,writeback=True) would let you just code
    # d['xx'].append(5) and have it work as expected, BUT it would also
    # consume more memory and make the d.close() operation slower.

    d.close()       # close it


See also
........

Module *note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *note bsddb: 1c.
     BSD `db' database interface.

Module *note dbhash: 7e.
     Thin layer around the *note bsddb: 1c. which provides an *note
     open(): ed7.  function like the other database modules.

Module *note dbm: 7f.
     Standard Unix database interface.

Module *note dumbdbm: b7.
     Portable implementation of the `dbm' interface.

Module *note gdbm: dc.
     GNU database interface, based on the `dbm' interface.

Module *note pickle: 12d.
     Object serialization used by *note shelve: 152.

Module *note cPickle: 73.
     High-performance version of *note pickle: 12d.


File: python.info,  Node: marshal --- Internal Python object serialization,  Next: anydbm --- Generic access to DBM-style databases,  Prev: shelve --- Python object persistence,  Up: Data Persistence

5.11.5 `marshal' -- Internal Python object serialization
--------------------------------------------------------

This module contains functions that can read and write Python values in
a binary format.  The format is specific to Python, but independent of
machine architecture issues (e.g., you can write a Python value to a
file on a PC, transport the file to a Sun, and read it back there).
Details of the format are undocumented on purpose; it may change
between Python versions (although it rarely does). (1)

  This is not a general "persistence" module.  For general persistence
and transfer of Python objects through RPC calls, see the modules *note
pickle: 12d. and *note shelve: 152.  The *note marshal: 10b. module
exists mainly to support reading and writing the "pseudo-compiled" code
for Python modules of `.pyc' files.  Therefore, the Python maintainers
reserve the right to modify the marshal format in backward incompatible
ways should the need arise.  If you're serializing and de-serializing
Python objects, use the *note pickle: 12d. module instead - the
performance is comparable, version independence is guaranteed, and
pickle supports a substantially wider range of objects than marshal.

     Warning: The *note marshal: 10b. module is not intended to be
     secure against erroneous or maliciously constructed data.  Never
     unmarshal data received from an untrusted or unauthenticated
     source.

  Not all Python object types are supported; in general, only objects
whose value is independent from a particular invocation of Python can
be written and read by this module.  The following types are supported:
booleans, integers, long integers, floating point numbers, complex
numbers, strings, Unicode objects, tuples, lists, sets, frozensets,
dictionaries, and code objects, where it should be understood that
tuples, lists, sets, frozensets and dictionaries are only supported as
long as the values contained therein are themselves supported; and
recursive lists, sets and dictionaries should not be written (they will
cause infinite loops).  The singletons *note None: 393, *note Ellipsis:
881. and *note StopIteration: 32c. can also be marshalled and
unmarshalled.

     Warning: On machines where C's `long int' type has more than 32
     bits (such as the DEC Alpha), it is possible to create plain
     Python integers that are longer than 32 bits. If such an integer
     is marshaled and read back in on a machine where C's `long int'
     type has only 32 bits, a Python long integer object is returned
     instead.  While of a different type, the numeric value is the
     same.  (This behavior is new in Python 2.2.  In earlier versions,
     all but the least-significant 32 bits of the value were lost, and
     a warning message was printed.)

  There are functions that read/write files as well as functions
operating on strings.

  The module defines these functions:

 -- Function: marshal.dump (value, file[, version])
     Write the value on the open file.  The value must be a supported
     type.  The file must be an open file object such as `sys.stdout'
     or returned by *note open(): 2d3. or *note os.popen(): 6ed.  It
     must be opened in binary mode (`'wb'' or `'w+b'').

     If the value has (or contains an object that has) an unsupported
     type, a *note ValueError: 233. exception is raised -- but garbage
     data will also be written to the file.  The object will not be
     properly read back by *note load(): edb.

     New in version 2.4: The _version_ argument indicates the data
     format that `dump' should use (see below).

 -- Function: marshal.load (file)
     Read one value from the open file and return it.  If no valid
     value is read (e.g. because the data has a different Python
     version's incompatible marshal format), raise *note EOFError: 874,
     *note ValueError: 233. or *note TypeError: 215.  The file must be
     an open file object opened in binary mode (`'rb'' or `'r+b'').

          Note: If an object containing an unsupported type was
          marshalled with *note dump(): eda, *note load(): edb. will
          substitute `None' for the unmarshallable type.

 -- Function: marshal.dumps (value[, version])
     Return the string that would be written to a file by `dump(value,
     file)'.  The value must be a supported type.  Raise a *note
     ValueError: 233. exception if value has (or contains an object
     that has) an unsupported type.

     New in version 2.4: The _version_ argument indicates the data
     format that `dumps' should use (see below).

 -- Function: marshal.loads (string)
     Convert the string to a value.  If no valid value is found, raise
     *note EOFError: 874, *note ValueError: 233. or *note TypeError:
     215.  Extra characters in the string are ignored.

  In addition, the following constants are defined:

 -- Data: marshal.version
     Indicates the format that the module uses. Version 0 is the
     historical format, version 1 (added in Python 2.4) shares interned
     strings and version 2 (added in Python 2.5) uses a binary format
     for floating point numbers. The current version is 2.

     New in version 2.4.

  ---------- Footnotes ----------

  (1) The name of this module stems from a bit of terminology used by
the designers of Modula-3 (amongst others), who use the term
"marshalling" for shipping of data around in a self-contained form.
Strictly speaking, "to marshal" means to convert some data from
internal to external form (in an RPC buffer for instance) and
"unmarshalling" for the reverse process.


File: python.info,  Node: anydbm --- Generic access to DBM-style databases,  Next: whichdb --- Guess which DBM module created a database,  Prev: marshal --- Internal Python object serialization,  Up: Data Persistence

5.11.6 `anydbm' -- Generic access to DBM-style databases
--------------------------------------------------------

     Note: The *note anydbm: b. module has been renamed to *note dbm:
     7f. in Python 3.  The *note 2to3: bbc. tool will automatically
     adapt imports when converting your sources to Python 3.

*note anydbm: b. is a generic interface to variants of the DBM database
-- *note dbhash: 7e. (requires *note bsddb: 1c.), *note gdbm: dc, or
*note dbm: 7f.  If none of these modules is installed, the
slow-but-simple implementation in module *note dumbdbm: b7. will be
used.

 -- Function: anydbm.open (filename[, flag[, mode]])
     Open the database file _filename_ and return a corresponding
     object.

     If the database file already exists, the *note whichdb: 197.
     module is used to determine its type and the appropriate module is
     used; if it does not exist, the first module listed above that can
     be imported is used.

     The optional _flag_ argument must be one of these values:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn't exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     If not specified, the default value is `'r''.

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666' (and will be modified by the prevailing umask).

 -- Exception: anydbm.error
     A tuple containing the exceptions that can be raised by each of
     the supported modules, with a unique exception also named *note
     anydbm.error: ee1. as the first item -- the latter is used when
     *note anydbm.error: ee1. is raised.

  The object returned by *note open(): ecb. supports most of the same
functionality as dictionaries; keys and their corresponding values can
be stored, retrieved, and deleted, and the `has_key()' and `keys()'
methods are available.  Keys and values must always be strings.

  The following example records some hostnames and a corresponding
title,  and then prints out the contents of the database:

    import anydbm

    # Open database, creating it if necessary.
    db = anydbm.open('cache', 'c')

    # Record some values
    db['www.python.org'] = 'Python Website'
    db['www.cnn.com'] = 'Cable News Network'

    # Loop through contents.  Other dictionary methods
    # such as .keys(), .values() also work.
    for k, v in db.iteritems():
        print k, '\t', v

    # Storing a non-string key or value will raise an exception (most
    # likely a TypeError).
    db['www.yahoo.com'] = 4

    # Close when done.
    db.close()


See also
........

Module *note dbhash: 7e.
     BSD `db' database interface.

Module *note dbm: 7f.
     Standard Unix database interface.

Module *note dumbdbm: b7.
     Portable implementation of the `dbm' interface.

Module *note gdbm: dc.
     GNU database interface, based on the `dbm' interface.

Module *note shelve: 152.
     General object persistence built on top of  the Python `dbm'
     interface.

Module *note whichdb: 197.
     Utility module used to determine the type of an existing database.


File: python.info,  Node: whichdb --- Guess which DBM module created a database,  Next: dbm --- Simple "database" interface,  Prev: anydbm --- Generic access to DBM-style databases,  Up: Data Persistence

5.11.7 `whichdb' -- Guess which DBM module created a database
-------------------------------------------------------------

     Note: The *note whichdb: 197. module's only function has been put
     into the *note dbm: 7f.  module in Python 3.  The *note 2to3: bbc.
     tool will automatically adapt imports when converting your sources
     to Python 3.

The single function in this module attempts to guess which of the
several simple database modules available-*note dbm: 7f, *note gdbm:
dc, or *note dbhash: 7e.-should be used to open a given file.

 -- Function: whichdb.whichdb (filename)
     Returns one of the following values: `None' if the file can't be
     opened because it's unreadable or doesn't exist; the empty string
     (`''') if the file's format can't be guessed; or a string
     containing the required module name, such as `'dbm'' or `'gdbm''.


File: python.info,  Node: dbm --- Simple "database" interface,  Next: gdbm --- GNU's reinterpretation of dbm,  Prev: whichdb --- Guess which DBM module created a database,  Up: Data Persistence

5.11.8 `dbm' -- Simple "database" interface
-------------------------------------------

     Note: The *note dbm: 7f. module has been renamed to `dbm.ndbm' in
     Python 3.  The *note 2to3: bbc. tool will automatically adapt
     imports when converting your sources to Python 3.

The *note dbm: 7f. module provides an interface to the Unix "(n)dbm"
library.  Dbm objects behave like mappings (dictionaries), except that
keys and values are always strings. Printing a dbm object doesn't print
the keys and values, and the `items()' and `values()' methods are not
supported.

  This module can be used with the "classic" ndbm interface, the BSD DB
compatibility interface, or the GNU GDBM compatibility interface. On
Unix, the *configure* script will attempt to locate the appropriate
header file to simplify building this module.

  The module defines the following:

 -- Exception: dbm.error
     Raised on dbm-specific errors, such as I/O errors. *note KeyError:
     202. is raised for general mapping errors like specifying an
     incorrect key.

 -- Data: dbm.library
     Name of the `ndbm' implementation library used.

 -- Function: dbm.open (filename[, flag[, mode]])
     Open a dbm database and return a dbm object.  The _filename_
     argument is the name of the database file (without the `.dir' or
     `.pag' extensions; note that the BSD DB implementation of the
     interface will append the extension `.db' and only create one
     file).

     The optional _flag_ argument must be one of these values:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn't exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666' (and will be modified by the prevailing umask).

See also
........

Module *note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *note gdbm: dc.
     Similar interface to the GNU GDBM library.

Module *note whichdb: 197.
     Utility module used to determine the type of an existing database.


File: python.info,  Node: gdbm --- GNU's reinterpretation of dbm,  Next: dbhash --- DBM-style interface to the BSD database library,  Prev: dbm --- Simple "database" interface,  Up: Data Persistence

5.11.9 `gdbm' -- GNU's reinterpretation of dbm
----------------------------------------------

     Note: The *note gdbm: dc. module has been renamed to `dbm.gnu' in
     Python 3.  The *note 2to3: bbc. tool will automatically adapt
     imports when converting your sources to Python 3.

This module is quite similar to the *note dbm: 7f. module, but uses
`gdbm' instead to provide some additional functionality.  Please note
that the file formats created by `gdbm' and `dbm' are incompatible.

  The *note gdbm: dc. module provides an interface to the GNU DBM
library.  `gdbm' objects behave like mappings (dictionaries), except
that keys and values are always strings. Printing a `gdbm' object
doesn't print the keys and values, and the `items()' and `values()'
methods are not supported.

  The module defines the following constant and functions:

 -- Exception: gdbm.error
     Raised on `gdbm'-specific errors, such as I/O errors. *note
     KeyError: 202. is raised for general mapping errors like
     specifying an incorrect key.

 -- Function: gdbm.open (filename[, flag[, mode]])
     Open a `gdbm' database and return a `gdbm' object.  The _filename_
     argument is the name of the database file.

     The optional _flag_ argument can be:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn't exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     The following additional characters may be appended to the flag to
     control how the database is opened:

     Value         Meaning
     --------------------------------------------------------------- 
     `'f''         Open the database in fast mode.  Writes to the
                   database will not be synchronized.
     `'s''         Synchronized mode. This will cause changes to
                   the database to be immediately written to the
                   file.
     `'u''         Do not lock database.

     Not all flags are valid for all versions of `gdbm'.  The module
     constant `open_flags' is a string of supported flag characters.
     The exception *note error: eec. is raised if an invalid flag is
     specified.

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666'.

  In addition to the dictionary-like methods, `gdbm' objects have the
following methods:

 -- Function: gdbm.firstkey ()
     It's possible to loop over every key in the database using this
     method  and the *note nextkey(): eef. method.  The traversal is
     ordered by `gdbm''s internal hash values, and won't be sorted by
     the key values.  This method returns the starting key.

 -- Function: gdbm.nextkey (key)
     Returns the key that follows _key_ in the traversal.  The
     following code prints every key in the database `db', without
     having to create a list in memory that contains them all:

         k = db.firstkey()
         while k != None:
             print k
             k = db.nextkey(k)



 -- Function: gdbm.reorganize ()
     If you have carried out a lot of deletions and would like to
     shrink the space used by the `gdbm' file, this routine will
     reorganize the database.  `gdbm' will not shorten the length of a
     database file except by using this reorganization; otherwise,
     deleted file space will be kept and reused as new (key, value)
     pairs are added.

 -- Function: gdbm.sync ()
     When the database has been opened in fast mode, this method forces
     any unwritten data to be written to the disk.

See also
........

Module *note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *note whichdb: 197.
     Utility module used to determine the type of an existing database.


File: python.info,  Node: dbhash --- DBM-style interface to the BSD database library,  Next: bsddb --- Interface to Berkeley DB library,  Prev: gdbm --- GNU's reinterpretation of dbm,  Up: Data Persistence

5.11.10 `dbhash' -- DBM-style interface to the BSD database library
-------------------------------------------------------------------

Deprecated since version 2.6: The *note dbhash: 7e. module has been
removed in Python 3.

  The *note dbhash: 7e. module provides a function to open databases
using the BSD `db' library.  This module mirrors the interface of the
other Python database modules that provide access to DBM-style
databases.  The *note bsddb: 1c. module is required  to use *note
dbhash: 7e.

  This module provides an exception and a function:

 -- Exception: dbhash.error
     Exception raised on database errors other than *note KeyError:
     202.  It is a synonym for `bsddb.error'.

 -- Function: dbhash.open (path[, flag[, mode]])
     Open a `db' database and return the database object.  The _path_
     argument is the name of the database file.

     The _flag_ argument can be:

     Value         Meaning
     -------------------------------------------------------------- 
     `'r''         Open existing database for reading only
                   (default)
     `'w''         Open existing database for reading and writing
     `'c''         Open database for reading and writing,
                   creating it if it doesn't exist
     `'n''         Always create a new, empty database, open for
                   reading and writing

     For platforms on which the BSD `db' library supports locking, an
     `'l'' can be appended to indicate that locking should be used.

     The optional _mode_ parameter is used to indicate the Unix
     permission bits that should be set if a new database must be
     created; this will be masked by the current umask value for the
     process.

See also
........

Module *note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *note bsddb: 1c.
     Lower-level interface to the BSD `db' library.

Module *note whichdb: 197.
     Utility module used to determine the type of an existing database.

* Menu:

* Database Objects::


File: python.info,  Node: Database Objects,  Up: dbhash --- DBM-style interface to the BSD database library

5.11.10.1 Database Objects
..........................

The database objects returned by *note open(): ed7. provide the methods
common to all the DBM-style databases and mapping objects.  The
following methods are available in addition to the standard methods.

 -- Method: dbhash.first ()
     It's possible to loop over every key/value pair in the database
     using this method and the `next()' method.  The traversal is
     ordered by the databases internal hash values, and won't be sorted
     by the key values.  This method returns the starting key.

 -- Method: dbhash.last ()
     Return the last key/value pair in a database traversal.  This may
     be used to begin a reverse-order traversal; see *note previous():
     ef9.

 -- Method: dbhash.next ()
     Returns the key next key/value pair in a database traversal.  The
     following code prints every key in the database `db', without
     having to create a list in memory that contains them all:

         print db.first()
         for i in xrange(1, len(db)):
             print db.next()



 -- Method: dbhash.previous ()
     Returns the previous key/value pair in a forward-traversal of the
     database. In conjunction with *note last(): ef8, this may be used
     to implement a reverse-order traversal.

 -- Method: dbhash.sync ()
     This method forces any unwritten data to be written to the disk.


File: python.info,  Node: bsddb --- Interface to Berkeley DB library,  Next: dumbdbm --- Portable DBM implementation,  Prev: dbhash --- DBM-style interface to the BSD database library,  Up: Data Persistence

5.11.11 `bsddb' -- Interface to Berkeley DB library
---------------------------------------------------

Deprecated since version 2.6: The *note bsddb: 1c. module has been
removed in Python 3.

  The *note bsddb: 1c. module provides an interface to the Berkeley DB
library.  Users can create hash, btree or record based library files
using the appropriate open call. Bsddb objects behave generally like
dictionaries.  Keys and values must be strings, however, so to use
other objects as keys or to store other kinds of objects the user must
serialize them somehow, typically using *note marshal.dumps(): edc. or
*note pickle.dumps(): 441.

  The *note bsddb: 1c. module requires a Berkeley DB library version
from 4.0 thru 4.7.

See also
........

<http://www.jcea.es/programacion/pybsddb.htm>
     The website with documentation for the `bsddb.db' Python Berkeley
     DB interface that closely mirrors the object oriented interface
     provided in Berkeley DB 4.x itself.

<http://www.oracle.com/database/berkeley-db/>
     The Berkeley DB library.

  A more modern DB, DBEnv and DBSequence object interface is available
in the `bsddb.db' module which closely matches the Berkeley DB C API
documented at the above URLs.  Additional features provided by the
`bsddb.db' API include fine tuning, transactions, logging, and
multiprocess concurrent database access.

  The following is a description of the legacy *note bsddb: 1c.
interface compatible with the old Python bsddb module.  Starting in
Python 2.5 this interface should be safe for multithreaded access.  The
`bsddb.db' API is recommended for threading users as it provides better
control.

  The *note bsddb: 1c. module defines the following functions that
create objects that access the appropriate type of Berkeley DB file.
The first two arguments of each function are the same.  For ease of
portability, only the first two arguments should be used in most
instances.

 -- Function: bsddb.hashopen (filename[, flag[, mode[, pgsize[,
          ffactor[, nelem[, cachesize[, lorder[, hflags]]]]]]]])
     Open the hash format file named _filename_.  Files never intended
     to be preserved on disk may be created by passing `None' as the
     _filename_.  The optional _flag_ identifies the mode used to open
     the file.  It may be `'r'' (read only), `'w'' (read-write) , `'c''
     (read-write - create if necessary; the default) or `'n''
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level `dbopen()'
     function.  Consult the Berkeley DB documentation for their use and
     interpretation.

 -- Function: bsddb.btopen (filename[, flag[, mode[, btflags[,
          cachesize[, maxkeypage[, minkeypage[, pgsize[, lorder]]]]]]]])
     Open the btree format file named _filename_.  Files never intended
     to be preserved on disk may be created by passing `None' as the
     _filename_.  The optional _flag_ identifies the mode used to open
     the file.  It may be `'r'' (read only), `'w'' (read-write), `'c''
     (read-write - create if necessary; the default) or `'n''
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level dbopen function.
     Consult the Berkeley DB documentation for their use and
     interpretation.

 -- Function: bsddb.rnopen (filename[, flag[, mode[, rnflags[,
          cachesize[, pgsize[, lorder[, rlen[, delim[, source[,
          pad]]]]]]]]]])
     Open a DB record format file named _filename_.  Files never
     intended  to be preserved on disk may be created by passing `None'
     as the  _filename_.  The optional _flag_ identifies the mode used
     to open the file.  It may be `'r'' (read only), `'w''
     (read-write), `'c'' (read-write - create if necessary; the
     default) or `'n'' (read-write - truncate to zero length).  The
     other arguments are rarely used and are just passed to the
     low-level dbopen function.  Consult the Berkeley DB documentation
     for their use and interpretation.

     Note: Beginning in 2.3 some Unix versions of Python may have a
     `bsddb185' module.  This is present _only_ to allow backwards
     compatibility with systems which ship with the old Berkeley DB
     1.85 database library.  The `bsddb185' module should never be used
     directly in new code. The module has been removed in Python 3.  If
     you find you still need it look in PyPI.

See also
........

Module *note dbhash: 7e.
     DBM-style interface to the *note bsddb: 1c.

* Menu:

* Hash, BTree and Record Objects: Hash BTree and Record Objects.


File: python.info,  Node: Hash BTree and Record Objects,  Up: bsddb --- Interface to Berkeley DB library

5.11.11.1 Hash, BTree and Record Objects
........................................

Once instantiated, hash, btree and record objects support the same
methods as dictionaries.  In addition, they support the methods listed
below.

  Changed in version 2.3.1: Added dictionary methods.

 -- Method: bsddbobject.close ()
     Close the underlying file.  The object can no longer be accessed.
     Since there is no open *note open(): 2d3. method for these
     objects, to open the file again a new *note bsddb: 1c. module open
     function must be called.

 -- Method: bsddbobject.keys ()
     Return the list of keys contained in the DB file.  The order of
     the list is unspecified and should not be relied on.  In
     particular, the order of the list returned is different for
     different file formats.

 -- Method: bsddbobject.has_key (key)
     Return `1' if the DB file contains the argument as a key.

 -- Method: bsddbobject.set_location (key)
     Set the cursor to the item indicated by _key_ and return a tuple
     containing the key and its value.  For binary tree databases
     (opened using *note btopen(): ed3.), if _key_ does not actually
     exist in the database, the cursor will point to the next item in
     sorted order and return that key and value.  For other databases,
     *note KeyError: 202. will be raised if _key_ is not found in the
     database.

 -- Method: bsddbobject.first ()
     Set the cursor to the first item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case
     of B-Tree databases. This method raises `bsddb.error' if the
     database is empty.

 -- Method: bsddbobject.next ()
     Set the cursor to the next item in the DB file and return it.  The
     order of keys in the file is unspecified, except in the case of
     B-Tree databases.

 -- Method: bsddbobject.previous ()
     Set the cursor to the previous item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case
     of B-Tree databases.  This is not supported on hashtable databases
     (those opened with *note hashopen(): ed2.).

 -- Method: bsddbobject.last ()
     Set the cursor to the last item in the DB file and return it.  The
     order of keys in the file is unspecified.  This is not supported
     on hashtable databases (those opened with *note hashopen(): ed2.).
     This method raises `bsddb.error' if the database is empty.

 -- Method: bsddbobject.sync ()
     Synchronize the database on disk.

  Example:

    >>> import bsddb
    >>> db = bsddb.btopen('spam.db', 'c')
    >>> for i in range(10): db['%d'%i] = '%d'% (i*i)
    ...
    >>> db['3']
    '9'
    >>> db.keys()
    ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
    >>> db.first()
    ('0', '0')
    >>> db.next()
    ('1', '1')
    >>> db.last()
    ('9', '81')
    >>> db.set_location('2')
    ('2', '4')
    >>> db.previous()
    ('1', '1')
    >>> for k, v in db.iteritems():
    ...     print k, v
    0 0
    1 1
    2 4
    3 9
    4 16
    5 25
    6 36
    7 49
    8 64
    9 81
    >>> '8' in db
    True
    >>> db.sync()
    0



File: python.info,  Node: dumbdbm --- Portable DBM implementation,  Next: sqlite3 --- DB-API 2 0 interface for SQLite databases,  Prev: bsddb --- Interface to Berkeley DB library,  Up: Data Persistence

5.11.12 `dumbdbm' -- Portable DBM implementation
------------------------------------------------

     Note: The *note dumbdbm: b7. module has been renamed to `dbm.dumb'
     in Python 3.  The *note 2to3: bbc. tool will automatically adapt
     imports when converting your sources to Python 3.

     Note: The *note dumbdbm: b7. module is intended as a last resort
     fallback for the *note anydbm: b. module when no more robust
     module is available. The *note dumbdbm: b7.  module is not written
     for speed and is not nearly as heavily used as the other database
     modules.

The *note dumbdbm: b7. module provides a persistent dictionary-like
interface which is written entirely in Python.  Unlike other modules
such as *note gdbm: dc. and *note bsddb: 1c, no external library is
required.  As with other persistent mappings, the keys and values must
always be strings.

  The module defines the following:

 -- Exception: dumbdbm.error
     Raised on dumbdbm-specific errors, such as I/O errors.  *note
     KeyError: 202. is raised for general mapping errors like
     specifying an incorrect key.

 -- Function: dumbdbm.open (filename[, flag[, mode]])
     Open a dumbdbm database and return a dumbdbm object.  The
     _filename_ argument is the basename of the database file (without
     any specific extensions).  When a dumbdbm database is created,
     files with `.dat' and `.dir' extensions are created.

     The optional _flag_ argument is currently ignored; the database is
     always opened for update, and will be created if it does not exist.

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     `0666' (and will be modified by the prevailing umask).

     Changed in version 2.2: The _mode_ argument was ignored in earlier
     versions.

See also
........

Module *note anydbm: b.
     Generic interface to `dbm'-style databases.

Module *note dbm: 7f.
     Similar interface to the DBM/NDBM library.

Module *note gdbm: dc.
     Similar interface to the GNU GDBM library.

Module *note shelve: 152.
     Persistence module which stores non-string data.

Module *note whichdb: 197.
     Utility module used to determine the type of an existing database.

* Menu:

* Dumbdbm Objects::


File: python.info,  Node: Dumbdbm Objects,  Up: dumbdbm --- Portable DBM implementation

5.11.12.1 Dumbdbm Objects
.........................

In addition to the methods provided by the *note UserDict.DictMixin:
be1. class, *note dumbdbm: b7. objects provide the following methods.

 -- Method: dumbdbm.sync ()
     Synchronize the on-disk directory and data files.  This method is
     called by the *note sync(): f0f. method of `Shelve' objects.


File: python.info,  Node: sqlite3 --- DB-API 2 0 interface for SQLite databases,  Prev: dumbdbm --- Portable DBM implementation,  Up: Data Persistence

5.11.13 `sqlite3' -- DB-API 2.0 interface for SQLite databases
--------------------------------------------------------------

New in version 2.5.

  SQLite is a C library that provides a lightweight disk-based database
that doesn't require a separate server process and allows accessing the
database using a nonstandard variant of the SQL query language. Some
applications can use SQLite for internal data storage.  It's also
possible to prototype an application using SQLite and then port the
code to a larger database such as PostgreSQL or Oracle.

  The sqlite3 module was written by Gerhard Häring.  It provides a SQL
interface compliant with the DB-API 2.0 specification described by PEP
249(1).

  To use the module, you must first create a *note Connection: f12.
object that represents the database.  Here the data will be stored in
the `example.db' file:

    import sqlite3
    conn = sqlite3.connect('example.db')

You can also supply the special name `:memory:' to create a database in
RAM.

  Once you have a *note Connection: f12, you can create a *note Cursor:
f13.  object and call its *note execute(): f14. method to perform SQL
commands:

    c = conn.cursor()

    # Create table
    c.execute('''CREATE TABLE stocks
                 (date text, trans text, symbol text, qty real, price real)''')

    # Insert a row of data
    c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")

    # Save (commit) the changes
    conn.commit()

    # We can also close the connection if we are done with it.
    # Just be sure any changes have been committed or they will be lost.
    conn.close()

The data you've saved is persistent and is available in subsequent
sessions:

    import sqlite3
    conn = sqlite3.connect('example.db')
    c = conn.cursor()

Usually your SQL operations will need to use values from Python
variables.  You shouldn't assemble your query using Python's string
operations because doing so is insecure; it makes your program
vulnerable to an SQL injection attack (see <http://xkcd.com/327/> for
humorous example of what can go wrong).

  Instead, use the DB-API's parameter substitution.  Put `?' as a
placeholder wherever you want to use a value, and then provide a tuple
of values as the second argument to the cursor's *note execute(): f14.
method.  (Other database modules may use a different placeholder, such
as `%s' or `:1'.) For example:

    # Never do this -- insecure!
    symbol = 'RHAT'
    c.execute("SELECT * FROM stocks WHERE symbol = '%s'" % symbol)

    # Do this instead
    t = ('RHAT',)
    c.execute('SELECT * FROM stocks WHERE symbol=?', t)
    print c.fetchone()

    # Larger example that inserts many records at a time
    purchases = [('2006-03-28', 'BUY', 'IBM', 1000, 45.00),
                 ('2006-04-05', 'BUY', 'MSFT', 1000, 72.00),
                 ('2006-04-06', 'SELL', 'IBM', 500, 53.00),
                ]
    c.executemany('INSERT INTO stocks VALUES (?,?,?,?,?)', purchases)

To retrieve data after executing a SELECT statement, you can either
treat the cursor as an *note iterator: 869, call the cursor's *note
fetchone(): f15. method to retrieve a single matching row, or call
*note fetchall(): f16. to get a list of the matching rows.

  This example uses the iterator form:

    >>> for row in c.execute('SELECT * FROM stocks ORDER BY price'):
            print row

    (u'2006-01-05', u'BUY', u'RHAT', 100, 35.14)
    (u'2006-03-28', u'BUY', u'IBM', 1000, 45.0)
    (u'2006-04-06', u'SELL', u'IBM', 500, 53.0)
    (u'2006-04-05', u'BUY', u'MSFT', 1000, 72.0)


See also
........

<http://code.google.com/p/pysqlite/>
     The pysqlite web page - sqlite3 is developed externally under the
     name "pysqlite".

<http://www.sqlite.org>
     The SQLite web page; the documentation describes the syntax and the
     available data types for the supported SQL dialect.

<http://www.w3schools.com/sql/>
     Tutorial, reference and examples for learning SQL syntax.

PEP 249(2) - Database API Specification 2.0
     PEP written by Marc-André Lemburg.

* Menu:

* Module functions and constants::
* Connection Objects::
* Cursor Objects::
* Row Objects::
* SQLite and Python types::
* Controlling Transactions::
* Using sqlite3 efficiently::
* Common issues::

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0249

  (2) http://www.python.org/dev/peps/pep-0249


File: python.info,  Node: Module functions and constants,  Next: Connection Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.1 Module functions and constants
........................................

 -- Data: sqlite3.version
     The version number of this module, as a string. This is not the
     version of the SQLite library.

 -- Data: sqlite3.version_info
     The version number of this module, as a tuple of integers. This is
     not the version of the SQLite library.

 -- Data: sqlite3.sqlite_version
     The version number of the run-time SQLite library, as a string.

 -- Data: sqlite3.sqlite_version_info
     The version number of the run-time SQLite library, as a tuple of
     integers.

 -- Data: sqlite3.PARSE_DECLTYPES
     This constant is meant to be used with the _detect_types_
     parameter of the *note connect(): f1e. function.

     Setting it makes the *note sqlite3: 15f. module parse the declared
     type for each column it returns.  It will parse out the first word
     of the declared type, i. e.  for "integer primary key", it will
     parse out "integer", or for "number(10)" it will parse out
     "number". Then for that column, it will look into the converters
     dictionary and use the converter function registered for that type
     there.

 -- Data: sqlite3.PARSE_COLNAMES
     This constant is meant to be used with the _detect_types_
     parameter of the *note connect(): f1e. function.

     Setting this makes the SQLite interface parse the column name for
     each column it returns.  It will look for a string formed [mytype]
     in there, and then decide that 'mytype' is the type of the column.
     It will try to find an entry of 'mytype' in the converters
     dictionary and then use the converter function found there to
     return the value. The column name found in *note
     Cursor.description: f20.  is only the first word of the column
     name, i.  e. if you use something like `'as "x [datetime]"'' in
     your SQL, then we will parse out everything until the first blank
     for the column name: the column name would simply be "x".

 -- Function: sqlite3.connect (database[, timeout, detect_types,
          isolation_level, check_same_thread, factory,
          cached_statements])
     Opens a connection to the SQLite database file _database_. You can
     use `":memory:"' to open a database connection to a database that
     resides in RAM instead of on disk.

     When a database is accessed by multiple connections, and one of
     the processes modifies the database, the SQLite database is locked
     until that transaction is committed. The _timeout_ parameter
     specifies how long the connection should wait for the lock to go
     away until raising an exception. The default for the timeout
     parameter is 5.0 (five seconds).

     For the _isolation_level_ parameter, please see the *note
     Connection.isolation_level: f21. property of *note Connection:
     f12. objects.

     SQLite natively supports only the types TEXT, INTEGER, FLOAT, BLOB
     and NULL. If you want to use other types you must add support for
     them yourself. The _detect_types_ parameter and the using custom
     *converters* registered with the module-level *note
     register_converter(): f22. function allow you to easily do that.

     _detect_types_ defaults to 0 (i. e. off, no type detection), you
     can set it to any combination of *note PARSE_DECLTYPES: f1d. and
     *note PARSE_COLNAMES: f1f. to turn type detection on.

     By default, the *note sqlite3: 15f. module uses its *note
     Connection: f12. class for the connect call.  You can, however,
     subclass the *note Connection: f12. class and make *note
     connect(): f1e. use your class instead by providing your class for
     the _factory_ parameter.

     Consult the section *note SQLite and Python types: f23. of this
     manual for details.

     The *note sqlite3: 15f. module internally uses a statement cache
     to avoid SQL parsing overhead. If you want to explicitly set the
     number of statements that are cached for the connection, you can
     set the _cached_statements_ parameter. The currently implemented
     default is to cache 100 statements.

 -- Function: sqlite3.register_converter (typename, callable)
     Registers a callable to convert a bytestring from the database
     into a custom Python type. The callable will be invoked for all
     database values that are of the type _typename_. Confer the
     parameter _detect_types_ of the *note connect(): f1e.  function
     for how the type detection works. Note that the case of _typename_
     and the name of the type in your query must match!

 -- Function: sqlite3.register_adapter (type, callable)
     Registers a callable to convert the custom Python type _type_ into
     one of SQLite's supported types. The callable _callable_ accepts
     as single parameter the Python value, and must return a value of
     the following types: int, long, float, str (UTF-8 encoded),
     unicode or buffer.

 -- Function: sqlite3.complete_statement (sql)
     Returns *note True: 3a9. if the string _sql_ contains one or more
     complete SQL statements terminated by semicolons. It does not
     verify that the SQL is syntactically correct, only that there are
     no unclosed string literals and the statement is terminated by a
     semicolon.

     This can be used to build a shell for SQLite, as in the following
     example:

         # A minimal SQLite shell for experiments

         import sqlite3

         con = sqlite3.connect(":memory:")
         con.isolation_level = None
         cur = con.cursor()

         buffer = ""

         print "Enter your SQL commands to execute in sqlite3."
         print "Enter a blank line to exit."

         while True:
             line = raw_input()
             if line == "":
                 break
             buffer += line
             if sqlite3.complete_statement(buffer):
                 try:
                     buffer = buffer.strip()
                     cur.execute(buffer)

                     if buffer.lstrip().upper().startswith("SELECT"):
                         print cur.fetchall()
                 except sqlite3.Error as e:
                     print "An error occurred:", e.args[0]
                 buffer = ""

         con.close()



 -- Function: sqlite3.enable_callback_tracebacks (flag)
     By default you will not get any tracebacks in user-defined
     functions, aggregates, converters, authorizer callbacks etc. If
     you want to debug them, you can call this function with _flag_ as
     True. Afterwards, you will get tracebacks from callbacks on
     `sys.stderr'. Use *note False: 3aa. to disable the feature again.


File: python.info,  Node: Connection Objects,  Next: Cursor Objects,  Prev: Module functions and constants,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.2 Connection Objects
............................

 -- Class: sqlite3.Connection
     A SQLite database connection has the following attributes and
     methods:

      -- Attribute: isolation_level
          Get or set the current isolation level. *note None: 393. for
          autocommit mode or one of "DEFERRED", "IMMEDIATE" or
          "EXCLUSIVE". See section *note Controlling Transactions: f29.
          for a more detailed explanation.

      -- Method: cursor ([cursorClass])
          The cursor method accepts a single optional parameter
          _cursorClass_. If supplied, this must be a custom cursor
          class that extends *note sqlite3.Cursor: f13.

      -- Method: commit ()
          This method commits the current transaction. If you don't
          call this method, anything you did since the last call to
          `commit()' is not visible from other database connections. If
          you wonder why you don't see the data you've written to the
          database, please check you didn't forget to call this method.

      -- Method: rollback ()
          This method rolls back any changes to the database since the
          last call to *note commit(): f2b.

      -- Method: close ()
          This closes the database connection. Note that this does not
          automatically call *note commit(): f2b. If you just close
          your database connection without calling *note commit(): f2b.
          first, your changes will be lost!

      -- Method: execute (sql[, parameters])
          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor's *note execute: f14. method with the parameters given.

      -- Method: executemany (sql[, parameters])
          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor's *note executemany: f30. method with the parameters
          given.

      -- Method: executescript (sql_script)
          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor's *note executescript: f32. method with the parameters
          given.

      -- Method: create_function (name, num_params, func)
          Creates a user-defined function that you can later use from
          within SQL statements under the function name _name_.
          _num_params_ is the number of parameters the function
          accepts, and _func_ is a Python callable that is called as
          the SQL function.

          The function can return any of the types supported by SQLite:
          unicode, str, int, long, float, buffer and None.

          Example:

              import sqlite3
              import md5

              def md5sum(t):
                  return md5.md5(t).hexdigest()

              con = sqlite3.connect(":memory:")
              con.create_function("md5", 1, md5sum)
              cur = con.cursor()
              cur.execute("select md5(?)", ("foo",))
              print cur.fetchone()[0]



      -- Method: create_aggregate (name, num_params, aggregate_class)
          Creates a user-defined aggregate function.

          The aggregate class must implement a `step' method, which
          accepts the number of parameters _num_params_, and a
          `finalize' method which will return the final result of the
          aggregate.

          The `finalize' method can return any of the types supported
          by SQLite: unicode, str, int, long, float, buffer and None.

          Example:

              import sqlite3

              class MySum:
                  def __init__(self):
                      self.count = 0

                  def step(self, value):
                      self.count += value

                  def finalize(self):
                      return self.count

              con = sqlite3.connect(":memory:")
              con.create_aggregate("mysum", 1, MySum)
              cur = con.cursor()
              cur.execute("create table test(i)")
              cur.execute("insert into test(i) values (1)")
              cur.execute("insert into test(i) values (2)")
              cur.execute("select mysum(i) from test")
              print cur.fetchone()[0]



      -- Method: create_collation (name, callable)
          Creates a collation with the specified _name_ and _callable_.
          The callable will be passed two string arguments. It should
          return -1 if the first is ordered lower than the second, 0 if
          they are ordered equal and 1 if the first is ordered higher
          than the second.  Note that this controls sorting (ORDER BY
          in SQL) so your comparisons don't affect other SQL operations.

          Note that the callable will get its parameters as Python
          bytestrings, which will normally be encoded in UTF-8.

          The following example shows a custom collation that sorts
          "the wrong way":

              import sqlite3

              def collate_reverse(string1, string2):
                  return -cmp(string1, string2)

              con = sqlite3.connect(":memory:")
              con.create_collation("reverse", collate_reverse)

              cur = con.cursor()
              cur.execute("create table test(x)")
              cur.executemany("insert into test(x) values (?)", [("a",), ("b",)])
              cur.execute("select x from test order by x collate reverse")
              for row in cur:
                  print row
              con.close()

          To remove a collation, call `create_collation' with None as
          callable:

              con.create_collation("reverse", None)



      -- Method: interrupt ()
          You can call this method from a different thread to abort any
          queries that might be executing on the connection. The query
          will then abort and the caller will get an exception.

      -- Method: set_authorizer (authorizer_callback)
          This routine registers a callback. The callback is invoked
          for each attempt to access a column of a table in the
          database. The callback should return `SQLITE_OK' if access is
          allowed, `SQLITE_DENY' if the entire SQL statement should be
          aborted with an error and `SQLITE_IGNORE' if the column
          should be treated as a NULL value. These constants are
          available in the *note sqlite3: 15f. module.

          The first argument to the callback signifies what kind of
          operation is to be authorized. The second and third argument
          will be arguments or *note None: 393.  depending on the first
          argument. The 4th argument is the name of the database
          ("main", "temp", etc.) if applicable. The 5th argument is the
          name of the inner-most trigger or view that is responsible
          for the access attempt or *note None: 393. if this access
          attempt is directly from input SQL code.

          Please consult the SQLite documentation about the possible
          values for the first argument and the meaning of the second
          and third argument depending on the first one. All necessary
          constants are available in the *note sqlite3: 15f. module.

      -- Method: set_progress_handler (handler, n)
          This routine registers a callback. The callback is invoked
          for every _n_ instructions of the SQLite virtual machine.
          This is useful if you want to get called from SQLite during
          long-running operations, for example to update a GUI.

          If you want to clear any previously installed progress
          handler, call the method with *note None: 393. for _handler_.

          New in version 2.6.

      -- Method: enable_load_extension (enabled)
          This routine allows/disallows the SQLite engine to load
          SQLite extensions from shared libraries.  SQLite extensions
          can define new functions, aggregates or whole new virtual
          table implementations.  One well-known extension is the
          fulltext-search extension distributed with SQLite.

          Loadable extensions are disabled by default. See (1).

          New in version 2.7.

              import sqlite3

              con = sqlite3.connect(":memory:")

              # enable extension loading
              con.enable_load_extension(True)

              # Load the fulltext search extension
              con.execute("select load_extension('./fts3.so')")

              # alternatively you can load the extension using an API call:
              # con.load_extension("./fts3.so")

              # disable extension laoding again
              con.enable_load_extension(False)

              # example from SQLite wiki
              con.execute("create virtual table recipe using fts3(name, ingredients)")
              con.executescript("""
                  insert into recipe (name, ingredients) values ('broccoli stew', 'broccoli peppers cheese tomatoes');
                  insert into recipe (name, ingredients) values ('pumpkin stew', 'pumpkin onions garlic celery');
                  insert into recipe (name, ingredients) values ('broccoli pie', 'broccoli cheese onions flour');
                  insert into recipe (name, ingredients) values ('pumpkin pie', 'pumpkin sugar flour butter');
                  """)
              for row in con.execute("select rowid, name, ingredients from recipe where name match 'pie'"):
                  print row



      -- Method: load_extension (path)
          This routine loads a SQLite extension from a shared library.
          You have to enable extension loading with *note
          enable_load_extension(): f39. before you can use this routine.

          Loadable extensions are disabled by default. See (2).

          New in version 2.7.

      -- Attribute: row_factory
          You can change this attribute to a callable that accepts the
          cursor and the original row as a tuple and will return the
          real result row.  This way, you can implement more advanced
          ways of returning results, such  as returning an object that
          can also access columns by name.

          Example:

              import sqlite3

              def dict_factory(cursor, row):
                  d = {}
                  for idx, col in enumerate(cursor.description):
                      d[col[0]] = row[idx]
                  return d

              con = sqlite3.connect(":memory:")
              con.row_factory = dict_factory
              cur = con.cursor()
              cur.execute("select 1 as a")
              print cur.fetchone()["a"]

          If returning a tuple doesn't suffice and you want name-based
          access to columns, you should consider setting *note
          row_factory: f3a. to the highly-optimized *note sqlite3.Row:
          f3b. type. *note Row: f3b. provides both index-based and
          case-insensitive name-based access to columns with almost no
          memory overhead. It will probably be better than your own
          custom dictionary-based approach or even a db_row based
          solution.


      -- Attribute: text_factory
          Using this attribute you can control what objects are
          returned for the `TEXT' data type. By default, this attribute
          is set to *note unicode: 1f2. and the *note sqlite3: 15f.
          module will return Unicode objects for `TEXT'. If you want to
          return bytestrings instead, you can set it to *note str: 1e7.

          For efficiency reasons, there's also a way to return Unicode
          objects only for non-ASCII data, and bytestrings otherwise.
          To activate it, set this attribute to
          `sqlite3.OptimizedUnicode'.

          You can also set it to any other callable that accepts a
          single bytestring parameter and returns the resulting object.

          See the following example code for illustration:

              import sqlite3

              con = sqlite3.connect(":memory:")
              cur = con.cursor()

              AUSTRIA = u"\xd6sterreich"

              # by default, rows are returned as Unicode
              cur.execute("select ?", (AUSTRIA,))
              row = cur.fetchone()
              assert row[0] == AUSTRIA

              # but we can make sqlite3 always return bytestrings ...
              con.text_factory = str
              cur.execute("select ?", (AUSTRIA,))
              row = cur.fetchone()
              assert type(row[0]) is str
              # the bytestrings will be encoded in UTF-8, unless you stored garbage in the
              # database ...
              assert row[0] == AUSTRIA.encode("utf-8")

              # we can also implement a custom text_factory ...
              # here we implement one that will ignore Unicode characters that cannot be
              # decoded from UTF-8
              con.text_factory = lambda x: unicode(x, "utf-8", "ignore")
              cur.execute("select ?", ("this is latin1 and would normally create errors" +
                                       u"\xe4\xf6\xfc".encode("latin1"),))
              row = cur.fetchone()
              assert type(row[0]) is unicode

              # sqlite3 offers a built-in optimized text_factory that will return bytestring
              # objects, if the data is in ASCII only, and otherwise return unicode objects
              con.text_factory = sqlite3.OptimizedUnicode
              cur.execute("select ?", (AUSTRIA,))
              row = cur.fetchone()
              assert type(row[0]) is unicode

              cur.execute("select ?", ("Germany",))
              row = cur.fetchone()
              assert type(row[0]) is str



      -- Attribute: total_changes
          Returns the total number of database rows that have been
          modified, inserted, or deleted since the database connection
          was opened.

      -- Attribute: iterdump
          Returns an iterator to dump the database in an SQL text
          format.  Useful when saving an in-memory database for later
          restoration.  This function provides the same capabilities as
          the `.dump' command in the *sqlite3* shell.

          New in version 2.6.

          Example:

              # Convert file existing_db.db to SQL dump file dump.sql
              import sqlite3, os

              con = sqlite3.connect('existing_db.db')
              with open('dump.sql', 'w') as f:
                  for line in con.iterdump():
                      f.write('%s\n' % line)



---------- Footnotes ----------

  (1) The sqlite3 module is not built with loadable extension support by
default, because some platforms (notably Mac OS X) have SQLite libraries
which are compiled without this feature. To get loadable extension
support, you must modify setup.py and remove the line that sets
SQLITE_OMIT_LOAD_EXTENSION.

  (2) The sqlite3 module is not built with loadable extension support by
default, because some platforms (notably Mac OS X) have SQLite libraries
which are compiled without this feature. To get loadable extension
support, you must modify setup.py and remove the line that sets
SQLITE_OMIT_LOAD_EXTENSION.


File: python.info,  Node: Cursor Objects,  Next: Row Objects,  Prev: Connection Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.3 Cursor Objects
........................

 -- Class: sqlite3.Cursor
     A *note Cursor: f13. instance has the following attributes and
     methods.

      -- Method: execute (sql[, parameters])
          Executes an SQL statement. The SQL statement may be
          parameterized (i. e.  placeholders instead of SQL literals).
          The *note sqlite3: 15f. module supports two kinds of
          placeholders: question marks (qmark style) and named
          placeholders (named style).

          Here's an example of both styles:

              import sqlite3

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.execute("create table people (name_last, age)")

              who = "Yeltsin"
              age = 72

              # This is the qmark style:
              cur.execute("insert into people values (?, ?)", (who, age))

              # And this is the named style:
              cur.execute("select * from people where name_last=:who and age=:age", {"who": who, "age": age})

              print cur.fetchone()

          *note execute(): f14. will only execute a single SQL
          statement. If you try to execute more than one statement with
          it, it will raise a Warning. Use *note executescript(): f32.
          if you want to execute multiple SQL statements with one call.

      -- Method: executemany (sql, seq_of_parameters)
          Executes an SQL command against all parameter sequences or
          mappings found in the sequence _sql_.  The *note sqlite3:
          15f. module also allows using an *note iterator: 869.
          yielding parameters instead of a sequence.

              import sqlite3

              class IterChars:
                  def __init__(self):
                      self.count = ord('a')

                  def __iter__(self):
                      return self

                  def next(self):
                      if self.count > ord('z'):
                          raise StopIteration
                      self.count += 1
                      return (chr(self.count - 1),) # this is a 1-tuple

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.execute("create table characters(c)")

              theIter = IterChars()
              cur.executemany("insert into characters(c) values (?)", theIter)

              cur.execute("select c from characters")
              print cur.fetchall()

          Here's a shorter example using a *note generator: 5cd.:

              import sqlite3
              import string

              def char_generator():
                  for c in string.lowercase:
                      yield (c,)

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.execute("create table characters(c)")

              cur.executemany("insert into characters(c) values (?)", char_generator())

              cur.execute("select c from characters")
              print cur.fetchall()



      -- Method: executescript (sql_script)
          This is a nonstandard convenience method for executing
          multiple SQL statements at once. It issues a `COMMIT'
          statement first, then executes the SQL script it gets as a
          parameter.

          _sql_script_ can be a bytestring or a Unicode string.

          Example:

              import sqlite3

              con = sqlite3.connect(":memory:")
              cur = con.cursor()
              cur.executescript("""
                  create table person(
                      firstname,
                      lastname,
                      age
                  );

                  create table book(
                      title,
                      author,
                      published
                  );

                  insert into book(title, author, published)
                  values (
                      'Dirk Gently''s Holistic Detective Agency',
                      'Douglas Adams',
                      1987
                  );
                  """)



      -- Method: fetchone ()
          Fetches the next row of a query result set, returning a
          single sequence, or *note None: 393. when no more data is
          available.

      -- Method: fetchmany ([size=cursor.arraysize])
          Fetches the next set of rows of a query result, returning a
          list.  An empty list is returned when no more rows are
          available.

          The number of rows to fetch per call is specified by the
          _size_ parameter.  If it is not given, the cursor's arraysize
          determines the number of rows to be fetched. The method
          should try to fetch as many rows as indicated by the size
          parameter. If this is not possible due to the specified
          number of rows not being available, fewer rows may be
          returned.

          Note there are performance considerations involved with the
          _size_ parameter.  For optimal performance, it is usually
          best to use the arraysize attribute.  If the _size_ parameter
          is used, then it is best for it to retain the same value from
          one *note fetchmany(): f41. call to the next.

      -- Method: fetchall ()
          Fetches all (remaining) rows of a query result, returning a
          list.  Note that the cursor's arraysize attribute can affect
          the performance of this operation.  An empty list is returned
          when no rows are available.

      -- Attribute: rowcount
          Although the *note Cursor: f13. class of the *note sqlite3:
          15f. module implements this attribute, the database engine's
          own support for the determination of "rows affected"/"rows
          selected" is quirky.

          For *note executemany(): f30. statements, the number of
          modifications are summed up into *note rowcount: f42.

          As required by the Python DB API Spec, the *note rowcount:
          f42. attribute "is -1 in case no `executeXX()' has been
          performed on the cursor or the rowcount of the last operation
          is not determinable by the interface". This includes `SELECT'
          statements because we cannot determine the number of rows a
          query produced until all rows were fetched.

          With SQLite versions before 3.6.5, *note rowcount: f42. is
          set to 0 if you make a `DELETE FROM table' without any
          condition.

      -- Attribute: lastrowid
          This read-only attribute provides the rowid of the last
          modified row. It is only set if you issued a `INSERT'
          statement using the *note execute(): f14.  method. For
          operations other than `INSERT' or when *note executemany():
          f30. is called, *note lastrowid: f43. is set to *note None:
          393.

      -- Attribute: description
          This read-only attribute provides the column names of the
          last query. To remain compatible with the Python DB API, it
          returns a 7-tuple for each column where the last six items of
          each tuple are *note None: 393.

          It is set for `SELECT' statements without any matching rows
          as well.


File: python.info,  Node: Row Objects,  Next: SQLite and Python types,  Prev: Cursor Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.4 Row Objects
.....................

 -- Class: sqlite3.Row
     A *note Row: f3b. instance serves as a highly optimized *note
     row_factory: f3a. for *note Connection: f12. objects.  It tries to
     mimic a tuple in most of its features.

     It supports mapping access by column name and index, iteration,
     representation, equality testing and *note len(): 517.

     If two *note Row: f3b. objects have exactly the same columns and
     their members are equal, they compare equal.

     Changed in version 2.6: Added iteration and equality (hashability).

      -- Method: keys ()
          This method returns a tuple of column names. Immediately
          after a query, it is the first member of each tuple in *note
          Cursor.description: f20.

          New in version 2.6.

Let's assume we initialize a table as in the example given above:

    conn = sqlite3.connect(":memory:")
    c = conn.cursor()
    c.execute('''create table stocks
    (date text, trans text, symbol text,
     qty real, price real)''')
    c.execute("""insert into stocks
              values ('2006-01-05','BUY','RHAT',100,35.14)""")
    conn.commit()
    c.close()

Now we plug *note Row: f3b. in:

    >>> conn.row_factory = sqlite3.Row
    >>> c = conn.cursor()
    >>> c.execute('select * from stocks')
    <sqlite3.Cursor object at 0x7f4e7dd8fa80>
    >>> r = c.fetchone()
    >>> type(r)
    <type 'sqlite3.Row'>
    >>> r
    (u'2006-01-05', u'BUY', u'RHAT', 100.0, 35.14)
    >>> len(r)
    5
    >>> r[2]
    u'RHAT'
    >>> r.keys()
    ['date', 'trans', 'symbol', 'qty', 'price']
    >>> r['qty']
    100.0
    >>> for member in r:
    ...     print member
    ...
    2006-01-05
    BUY
    RHAT
    100.0
    35.14



File: python.info,  Node: SQLite and Python types,  Next: Controlling Transactions,  Prev: Row Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.5 SQLite and Python types
.................................

* Menu:

* Introduction: Introduction<6>.
* Using adapters to store additional Python types in SQLite databases::
* Converting SQLite values to custom Python types::
* Default adapters and converters::


File: python.info,  Node: Introduction<6>,  Next: Using adapters to store additional Python types in SQLite databases,  Up: SQLite and Python types

5.11.13.6 Introduction
......................

SQLite natively supports the following types: `NULL', `INTEGER',
`REAL', `TEXT', `BLOB'.

  The following Python types can thus be sent to SQLite without any
problem:

Python type                       SQLite type
---------------------------------------------------- 
*note None: 393.                  `NULL'
*note int: 1ef.                   `INTEGER'
*note long: 1f0.                  `INTEGER'
*note float: 1e8.                 `REAL'
*note str: 1e7. (UTF8-encoded)    `TEXT'
*note unicode: 1f2.               `TEXT'
*note buffer: 30f.                `BLOB'

  This is how SQLite types are converted to Python types by default:

SQLite type       Python type
--------------------------------------------------------------------- 
`NULL'            *note None: 393.
`INTEGER'         *note int: 1ef. or *note long: 1f0, depending on
                  size
`REAL'            *note float: 1e8.
`TEXT'            depends on *note text_factory: f3c, *note
                  unicode: 1f2. by default
`BLOB'            *note buffer: 30f.

  The type system of the *note sqlite3: 15f. module is extensible in
two ways: you can store additional Python types in a SQLite database
via object adaptation, and you can let the *note sqlite3: 15f. module
convert SQLite types to different Python types via converters.


File: python.info,  Node: Using adapters to store additional Python types in SQLite databases,  Next: Converting SQLite values to custom Python types,  Prev: Introduction<6>,  Up: SQLite and Python types

5.11.13.7 Using adapters to store additional Python types in SQLite databases
.............................................................................

As described before, SQLite supports only a limited set of types
natively. To use other Python types with SQLite, you must *adapt* them
to one of the sqlite3 module's supported types for SQLite: one of
NoneType, int, long, float, str, unicode, buffer.

  The *note sqlite3: 15f. module uses Python object adaptation, as
described in PEP 246(1) for this.  The protocol to use is
`PrepareProtocol'.

  There are two ways to enable the *note sqlite3: 15f. module to adapt
a custom Python type to one of the supported ones.

* Menu:

* Letting your object adapt itself::
* Registering an adapter callable::

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0246


File: python.info,  Node: Letting your object adapt itself,  Next: Registering an adapter callable,  Up: Using adapters to store additional Python types in SQLite databases

5.11.13.8 Letting your object adapt itself
..........................................

This is a good approach if you write the class yourself. Let's suppose
you have a class like this:

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

Now you want to store the point in a single SQLite column.  First
you'll have to choose one of the supported types first to be used for
representing the point.  Let's just use str and separate the
coordinates using a semicolon. Then you need to give your class a
method `__conform__(self, protocol)' which must return the converted
value. The parameter _protocol_ will be `PrepareProtocol'.

    import sqlite3

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

        def __conform__(self, protocol):
            if protocol is sqlite3.PrepareProtocol:
                return "%f;%f" % (self.x, self.y)

    con = sqlite3.connect(":memory:")
    cur = con.cursor()

    p = Point(4.0, -3.2)
    cur.execute("select ?", (p,))
    print cur.fetchone()[0]



File: python.info,  Node: Registering an adapter callable,  Prev: Letting your object adapt itself,  Up: Using adapters to store additional Python types in SQLite databases

5.11.13.9 Registering an adapter callable
.........................................

The other possibility is to create a function that converts the type to
the string representation and register the function with *note
register_adapter(): f24.

     Note: The type/class to adapt must be a *note new-style class:
     5c3, i. e. it must have *note object: 1ee. as one of its bases.

    import sqlite3

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

    def adapt_point(point):
        return "%f;%f" % (point.x, point.y)

    sqlite3.register_adapter(Point, adapt_point)

    con = sqlite3.connect(":memory:")
    cur = con.cursor()

    p = Point(4.0, -3.2)
    cur.execute("select ?", (p,))
    print cur.fetchone()[0]

The *note sqlite3: 15f. module has two default adapters for Python's
built-in *note datetime.date: 356. and *note datetime.datetime: 2d7.
types.  Now let's suppose we want to store *note datetime.datetime:
2d7. objects not in ISO representation, but as a Unix timestamp.

    import sqlite3
    import datetime, time

    def adapt_datetime(ts):
        return time.mktime(ts.timetuple())

    sqlite3.register_adapter(datetime.datetime, adapt_datetime)

    con = sqlite3.connect(":memory:")
    cur = con.cursor()

    now = datetime.datetime.now()
    cur.execute("select ?", (now,))
    print cur.fetchone()[0]



File: python.info,  Node: Converting SQLite values to custom Python types,  Next: Default adapters and converters,  Prev: Using adapters to store additional Python types in SQLite databases,  Up: SQLite and Python types

5.11.13.10 Converting SQLite values to custom Python types
..........................................................

Writing an adapter lets you send custom Python types to SQLite. But to
make it really useful we need to make the Python to SQLite to Python
roundtrip work.

  Enter converters.

  Let's go back to the `Point' class. We stored the x and y coordinates
separated via semicolons as strings in SQLite.

  First, we'll define a converter function that accepts the string as a
parameter and constructs a `Point' object from it.

     Note: Converter functions *always* get called with a string, no
     matter under which data type you sent the value to SQLite.

    def convert_point(s):
        x, y = map(float, s.split(";"))
        return Point(x, y)

Now you need to make the *note sqlite3: 15f. module know that what you
select from the database is actually a point. There are two ways of
doing this:

   * Implicitly via the declared type

   * Explicitly via the column name

  Both ways are described in section *note Module functions and
constants: f18, in the entries for the constants *note PARSE_DECLTYPES:
f1d. and *note PARSE_COLNAMES: f1f.

  The following example illustrates both approaches.

    import sqlite3

    class Point(object):
        def __init__(self, x, y):
            self.x, self.y = x, y

        def __repr__(self):
            return "(%f;%f)" % (self.x, self.y)

    def adapt_point(point):
        return "%f;%f" % (point.x, point.y)

    def convert_point(s):
        x, y = map(float, s.split(";"))
        return Point(x, y)

    # Register the adapter
    sqlite3.register_adapter(Point, adapt_point)

    # Register the converter
    sqlite3.register_converter("point", convert_point)

    p = Point(4.0, -3.2)

    #########################
    # 1) Using declared types
    con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES)
    cur = con.cursor()
    cur.execute("create table test(p point)")

    cur.execute("insert into test(p) values (?)", (p,))
    cur.execute("select p from test")
    print "with declared types:", cur.fetchone()[0]
    cur.close()
    con.close()

    #######################
    # 1) Using column names
    con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)
    cur = con.cursor()
    cur.execute("create table test(p)")

    cur.execute("insert into test(p) values (?)", (p,))
    cur.execute('select p as "p [point]" from test')
    print "with column names:", cur.fetchone()[0]
    cur.close()
    con.close()



File: python.info,  Node: Default adapters and converters,  Prev: Converting SQLite values to custom Python types,  Up: SQLite and Python types

5.11.13.11 Default adapters and converters
..........................................

There are default adapters for the date and datetime types in the
datetime module. They will be sent as ISO dates/ISO timestamps to
SQLite.

  The default converters are registered under the name "date" for *note
datetime.date: 356. and under the name "timestamp" for *note
datetime.datetime: 2d7.

  This way, you can use date/timestamps from Python without any
additional fiddling in most cases. The format of the adapters is also
compatible with the experimental SQLite date/time functions.

  The following example demonstrates this.

    import sqlite3
    import datetime

    con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)
    cur = con.cursor()
    cur.execute("create table test(d date, ts timestamp)")

    today = datetime.date.today()
    now = datetime.datetime.now()

    cur.execute("insert into test(d, ts) values (?, ?)", (today, now))
    cur.execute("select d, ts from test")
    row = cur.fetchone()
    print today, "=>", row[0], type(row[0])
    print now, "=>", row[1], type(row[1])

    cur.execute('select current_date as "d [date]", current_timestamp as "ts [timestamp]"')
    row = cur.fetchone()
    print "current_date", row[0], type(row[0])
    print "current_timestamp", row[1], type(row[1])

If a timestamp stored in SQLite has a fractional part longer than 6
numbers, its value will be truncated to microsecond precision by the
timestamp converter.


File: python.info,  Node: Controlling Transactions,  Next: Using sqlite3 efficiently,  Prev: SQLite and Python types,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.12 Controlling Transactions
...................................

By default, the *note sqlite3: 15f. module opens transactions
implicitly before a Data Modification Language (DML)  statement (i.e.
`INSERT'/`UPDATE'/`DELETE'/`REPLACE'), and commits transactions
implicitly before a non-DML, non-query statement (i. e.  anything other
than `SELECT' or the aforementioned).

  So if you are within a transaction and issue a command like `CREATE
TABLE ...', `VACUUM', `PRAGMA', the *note sqlite3: 15f. module will
commit implicitly before executing that command. There are two reasons
for doing that. The first is that some of these commands don't work
within transactions. The other reason is that sqlite3 needs to keep
track of the transaction state (if a transaction is active or not).

  You can control which kind of `BEGIN' statements sqlite3 implicitly
executes (or none at all) via the _isolation_level_ parameter to the
*note connect(): f1e.  call, or via the `isolation_level' property of
connections.

  If you want *autocommit mode*, then set `isolation_level' to None.

  Otherwise leave it at its default, which will result in a plain
"BEGIN" statement, or set it to one of SQLite's supported isolation
levels: "DEFERRED", "IMMEDIATE" or "EXCLUSIVE".


File: python.info,  Node: Using sqlite3 efficiently,  Next: Common issues,  Prev: Controlling Transactions,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.13 Using `sqlite3' efficiently
......................................

* Menu:

* Using shortcut methods::
* Accessing columns by name instead of by index::
* Using the connection as a context manager::


File: python.info,  Node: Using shortcut methods,  Next: Accessing columns by name instead of by index,  Up: Using sqlite3 efficiently

5.11.13.14 Using shortcut methods
.................................

Using the nonstandard `execute()', `executemany()' and
`executescript()' methods of the *note Connection: f12. object, your
code can be written more concisely because you don't have to create the
(often superfluous) *note Cursor: f13. objects explicitly. Instead, the
*note Cursor: f13.  objects are created implicitly and these shortcut
methods return the cursor objects. This way, you can execute a `SELECT'
statement and iterate over it directly using only a single call on the
*note Connection: f12. object.

    import sqlite3

    persons = [
        ("Hugo", "Boss"),
        ("Calvin", "Klein")
        ]

    con = sqlite3.connect(":memory:")

    # Create the table
    con.execute("create table person(firstname, lastname)")

    # Fill the table
    con.executemany("insert into person(firstname, lastname) values (?, ?)", persons)

    # Print the table contents
    for row in con.execute("select firstname, lastname from person"):
        print row

    print "I just deleted", con.execute("delete from person").rowcount, "rows"



File: python.info,  Node: Accessing columns by name instead of by index,  Next: Using the connection as a context manager,  Prev: Using shortcut methods,  Up: Using sqlite3 efficiently

5.11.13.15 Accessing columns by name instead of by index
........................................................

One useful feature of the *note sqlite3: 15f. module is the built-in
*note sqlite3.Row: f3b. class designed to be used as a row factory.

  Rows wrapped with this class can be accessed both by index (like
tuples) and case-insensitively by name:

    import sqlite3

    con = sqlite3.connect(":memory:")
    con.row_factory = sqlite3.Row

    cur = con.cursor()
    cur.execute("select 'John' as name, 42 as age")
    for row in cur:
        assert row[0] == row["name"]
        assert row["name"] == row["nAmE"]
        assert row[1] == row["age"]
        assert row[1] == row["AgE"]



File: python.info,  Node: Using the connection as a context manager,  Prev: Accessing columns by name instead of by index,  Up: Using sqlite3 efficiently

5.11.13.16 Using the connection as a context manager
....................................................

New in version 2.6.

  Connection objects can be used as context managers that automatically
commit or rollback transactions.  In the event of an exception, the
transaction is rolled back; otherwise, the transaction is committed:

    import sqlite3

    con = sqlite3.connect(":memory:")
    con.execute("create table person (id integer primary key, firstname varchar unique)")

    # Successful, con.commit() is called automatically afterwards
    with con:
        con.execute("insert into person(firstname) values (?)", ("Joe",))

    # con.rollback() is called after the with block finishes with an exception, the
    # exception is still raised and must be caught
    try:
        with con:
            con.execute("insert into person(firstname) values (?)", ("Joe",))
    except sqlite3.IntegrityError:
        print "couldn't add Joe twice"



File: python.info,  Node: Common issues,  Prev: Using sqlite3 efficiently,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.17 Common issues
........................

* Menu:

* Multithreading::


File: python.info,  Node: Multithreading,  Up: Common issues

5.11.13.18 Multithreading
.........................

Older SQLite versions had issues with sharing connections between
threads.  That's why the Python module disallows sharing connections
and cursors between threads. If you still try to do so, you will get an
exception at runtime.

  The only exception is calling the *note interrupt(): f36. method,
which only makes sense to call from a different thread.


File: python.info,  Node: Data Compression and Archiving,  Next: File Formats,  Prev: Data Persistence,  Up: The Python Standard Library

5.12 Data Compression and Archiving
===================================

The modules described in this chapter support data compression with the
zlib, gzip, and bzip2 algorithms, and  the creation of ZIP- and
tar-format archives.  See also *note Archiving operations: e93.
provided by the *note shutil: 154. module.

* Menu:

* zlib: zlib --- Compression compatible with gzip. Compression compatible with gzip
* gzip: gzip --- Support for gzip files. Support for gzip files
* bz2: bz2 --- Compression compatible with bzip2. Compression compatible with bzip2
* zipfile: zipfile --- Work with ZIP archives. Work with ZIP archives
* tarfile: tarfile --- Read and write tar archive files. Read and write tar archive files


File: python.info,  Node: zlib --- Compression compatible with gzip,  Next: gzip --- Support for gzip files,  Up: Data Compression and Archiving

5.12.1 `zlib' -- Compression compatible with *gzip*
---------------------------------------------------

For applications that require data compression, the functions in this
module allow compression and decompression, using the zlib library. The
zlib library has its own home page at <http://www.zlib.net>.   There
are known incompatibilities between the Python module and versions of
the zlib library earlier than 1.1.3; 1.1.3 has a security
vulnerability, so we recommend using 1.1.4 or later.

  zlib's functions have many options and often need to be used in a
particular order.  This documentation doesn't attempt to cover all of
the permutations; consult the zlib manual at
<http://www.zlib.net/manual.html> for authoritative information.

  For reading and writing `.gz' files see the *note gzip: e5. module.

  The available exception and functions in this module are:

 -- Exception: zlib.error
     Exception raised on compression and decompression errors.

 -- Function: zlib.adler32 (data[, value])
     Computes a Adler-32 checksum of _data_.  (An Adler-32 checksum is
     almost as reliable as a CRC32 but can be computed much more
     quickly.)  If _value_ is present, it is used as the starting value
     of the checksum; otherwise, a fixed default value is used.  This
     allows computing a running checksum over the concatenation of
     several inputs.  The algorithm is not cryptographically strong,
     and should not be used for authentication or digital signatures.
     Since the algorithm is designed for use as a checksum algorithm,
     it is not suitable for use as a general hash algorithm.

     This function always returns an integer object.

     Note: To generate the same numeric value across all Python
     versions and platforms use adler32(data) & 0xffffffff.  If you are
     only using the checksum in packed binary format this is not
     necessary as the return value is the correct 32bit binary
     representation regardless of sign.

  Changed in version 2.6: The return value is in the range [-2**31,
2**31-1] regardless of platform.  In older versions the value is signed
on some platforms and unsigned on others.

  Changed in version 3.0: The return value is unsigned and in the range
[0, 2**32-1] regardless of platform.

 -- Function: zlib.compress (string[, level])
     Compresses the data in _string_, returning a string contained
     compressed data.  _level_ is an integer from `0' to `9'
     controlling the level of compression; `1' is fastest and produces
     the least compression, `9' is slowest and produces the most.  `0'
     is no compression.  The default value is `6'.  Raises the *note
     error: f5a. exception if any error occurs.

 -- Function: zlib.compressobj ([level])
     Returns a compression object, to be used for compressing data
     streams that won't fit into memory at once.  _level_ is an integer
     from `0' to `9' controlling the level of compression; `1' is
     fastest and produces the least compression, `9' is slowest and
     produces the most.  `0' is no compression.  The default value is
     `6'.

 -- Function: zlib.crc32 (data[, value])
     Computes a CRC (Cyclic Redundancy Check)  checksum of _data_. If
     _value_ is present, it is used as the starting value of the
     checksum; otherwise, a fixed default value is used.  This allows
     computing a running checksum over the concatenation of several
     inputs.  The algorithm is not cryptographically strong, and should
     not be used for authentication or digital signatures.  Since the
     algorithm is designed for use as a checksum algorithm, it is not
     suitable for use as a general hash algorithm.

     This function always returns an integer object.

     Note: To generate the same numeric value across all Python
     versions and platforms use crc32(data) & 0xffffffff.  If you are
     only using the checksum in packed binary format this is not
     necessary as the return value is the correct 32bit binary
     representation regardless of sign.

  Changed in version 2.6: The return value is in the range [-2**31,
2**31-1] regardless of platform.  In older versions the value would be
signed on some platforms and unsigned on others.

  Changed in version 3.0: The return value is unsigned and in the range
[0, 2**32-1] regardless of platform.

 -- Function: zlib.decompress (string[, wbits[, bufsize]])
     Decompresses the data in _string_, returning a string containing
     the uncompressed data.  The _wbits_ parameter controls the size of
     the window buffer, and is discussed further below.  If _bufsize_
     is given, it is used as the initial size of the output buffer.
     Raises the *note error: f5a. exception if any error occurs.

     The absolute value of _wbits_ is the base two logarithm of the
     size of the history buffer (the "window size") used when
     compressing data.  Its absolute value should be between 8 and 15
     for the most recent versions of the zlib library, larger values
     resulting in better compression at the expense of greater memory
     usage.  When decompressing a stream, _wbits_ must not be smaller
     than the size originally used to compress the stream; using a
     too-small value will result in an exception. The default value is
     therefore the highest value, 15.  When _wbits_ is negative, the
     standard *gzip* header is suppressed.

     _bufsize_ is the initial size of the buffer used to hold
     decompressed data.  If more space is required, the buffer size
     will be increased as needed, so you don't have to get this value
     exactly right; tuning it will only save a few calls to `malloc()'.
     The default size is 16384.

 -- Function: zlib.decompressobj ([wbits])
     Returns a decompression object, to be used for decompressing data
     streams that won't fit into memory at once.  The _wbits_ parameter
     controls the size of the window buffer.

  Compression objects support the following methods:

 -- Method: Compress.compress (string)
     Compress _string_, returning a string containing compressed data
     for at least part of the data in _string_.  This data should be
     concatenated to the output produced by any preceding calls to the
     *note compress(): f5c. method.  Some input may be kept in internal
     buffers for later processing.

 -- Method: Compress.flush ([mode])
     All pending input is processed, and a string containing the
     remaining compressed output is returned.  _mode_ can be selected
     from the constants `Z_SYNC_FLUSH',  `Z_FULL_FLUSH',  or
     `Z_FINISH', defaulting to `Z_FINISH'.  `Z_SYNC_FLUSH' and
     `Z_FULL_FLUSH' allow compressing further strings of data, while
     `Z_FINISH' finishes the compressed stream and  prevents
     compressing any more data.  After calling *note flush(): f62. with
     _mode_ set to `Z_FINISH', the *note compress(): f5c. method cannot
     be called again; the only realistic action is to delete the object.

 -- Method: Compress.copy ()
     Returns a copy of the compression object.  This can be used to
     efficiently compress a set of data that share a common initial
     prefix.

     New in version 2.5.

  Decompression objects support the following methods, and two
attributes:

 -- Attribute: Decompress.unused_data
     A string which contains any bytes past the end of the compressed
     data. That is, this remains `""' until the last byte that contains
     compression data is available.  If the whole string turned out to
     contain compressed data, this is `""', the empty string.

     The only way to determine where a string of compressed data ends
     is by actually decompressing it.  This means that when compressed
     data is contained part of a larger file, you can only find the end
     of it by reading data and feeding it followed by some non-empty
     string into a decompression object's *note decompress(): f5f.
     method until the *note unused_data: f64. attribute is no longer
     the empty string.

 -- Attribute: Decompress.unconsumed_tail
     A string that contains any data that was not consumed by the last
     *note decompress(): f5f. call because it exceeded the limit for
     the uncompressed data buffer.  This data has not yet been seen by
     the zlib machinery, so you must feed it (possibly with further
     data concatenated to it) back to a subsequent *note decompress():
     f5f. method call in order to get correct output.

 -- Method: Decompress.decompress (string[, max_length])
     Decompress _string_, returning a string containing the
     uncompressed data corresponding to at least part of the data in
     _string_.  This data should be concatenated to the output produced
     by any preceding calls to the *note decompress(): f5f. method.
     Some of the input data may be preserved in internal buffers for
     later processing.

     If the optional parameter _max_length_ is supplied then the return
     value will be no longer than _max_length_. This may mean that not
     all of the compressed input can be processed; and unconsumed data
     will be stored in the attribute *note unconsumed_tail: f65. This
     string must be passed to a subsequent call to *note decompress():
     f5f. if decompression is to continue.  If _max_length_ is not
     supplied then the whole input is decompressed, and *note
     unconsumed_tail: f65. is an empty string.

 -- Method: Decompress.flush ([length])
     All pending input is processed, and a string containing the
     remaining uncompressed output is returned.  After calling *note
     flush(): f67, the *note decompress(): f5f. method cannot be called
     again; the only realistic action is to delete the object.

     The optional parameter _length_ sets the initial size of the
     output buffer.

 -- Method: Decompress.copy ()
     Returns a copy of the decompression object.  This can be used to
     save the state of the decompressor midway through the data stream
     in order to speed up random seeks into the stream at a future
     point.

     New in version 2.5.

See also
........

Module *note gzip: e5.
     Reading and writing *gzip*-format files.

<http://www.zlib.net>
     The zlib library home page.

<http://www.zlib.net/manual.html>
     The zlib manual explains  the semantics and usage of the library's
     many functions.


File: python.info,  Node: gzip --- Support for gzip files,  Next: bz2 --- Compression compatible with bzip2,  Prev: zlib --- Compression compatible with gzip,  Up: Data Compression and Archiving

5.12.2 `gzip' -- Support for *gzip* files
-----------------------------------------

*Source code:* Lib/gzip.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module provides a simple interface to compress and decompress
files just like the GNU programs *gzip* and *gunzip* would.

  The data compression is provided by the *note zlib: 1ad. module.

  The *note gzip: e5. module provides the *note GzipFile: 224. class
which is modeled after Python's File Object. The *note GzipFile: 224.
class reads and writes *gzip*-format files, automatically compressing
or decompressing the data so that it looks like an ordinary file object.

  Note that additional file formats which can be decompressed by the
*gzip* and *gunzip* programs, such  as those produced by *compress* and
*pack*, are not supported by this module.

  The module defines the following items:

 -- Class: gzip.GzipFile ([filename[, mode[, compresslevel[, fileobj[,
          mtime]]]]])
     Constructor for the *note GzipFile: 224. class, which simulates
     most of the methods of a file object, with the exception of the
     `readinto()' and `truncate()' methods.  At least one of _fileobj_
     and _filename_ must be given a non-trivial value.

     The new class instance is based on _fileobj_, which can be a
     regular file, a *note StringIO: 164. object, or any other object
     which simulates a file.  It defaults to `None', in which case
     _filename_ is opened to provide a file object.

     When _fileobj_ is not `None', the _filename_ argument is only used
     to be included in the *gzip* file header, which may includes the
     original filename of the uncompressed file.  It defaults to the
     filename of _fileobj_, if discernible; otherwise, it defaults to
     the empty string, and in this case the original filename is not
     included in the header.

     The _mode_ argument can be any of `'r'', `'rb'', `'a'', `'ab'',
     `'w'', or `'wb'', depending on whether the file will be read or
     written.  The default is the mode of _fileobj_ if discernible;
     otherwise, the default is `'rb''. If not given, the 'b' flag will
     be added to the mode to ensure the file is opened in binary mode
     for cross-platform portability.

     The _compresslevel_ argument is an integer from `0' to `9'
     controlling the level of compression; `1' is fastest and produces
     the least compression, and `9' is slowest and produces the most
     compression. `0' is no compression. The default is `9'.

     The _mtime_ argument is an optional numeric timestamp to be
     written to the stream when compressing.  All *gzip* compressed
     streams are required to contain a timestamp.  If omitted or
     `None', the current time is used.  This module ignores the
     timestamp when decompressing; however, some programs, such as
     *gunzip*, make use of it.  The format of the timestamp is the same
     as that of the return value of `time.time()' and of the `st_mtime'
     attribute of the object returned by `os.stat()'.

     Calling a *note GzipFile: 224. object's `close()' method does not
     close _fileobj_, since you might wish to append more material
     after the compressed data.  This also allows you to pass a *note
     StringIO: 164. object opened for writing as _fileobj_, and
     retrieve the resulting memory buffer using the *note StringIO:
     164. object's `getvalue()' method.

     *note GzipFile: 224. supports iteration and the *note with: 1bd.
     statement.

     Changed in version 2.7: Support for the *note with: 1bd. statement
     was added.

     Changed in version 2.7: Support for zero-padded files was added.

 -- Function: gzip.open (filename[, mode[, compresslevel]])
     This is a shorthand for `GzipFile(filename,' `mode,'
     `compresslevel)'.  The _filename_ argument is required; _mode_
     defaults to `'rb'' and _compresslevel_ defaults to `9'.

* Menu:

* Examples of usage::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/gzip.py


File: python.info,  Node: Examples of usage,  Up: gzip --- Support for gzip files

5.12.2.1 Examples of usage
..........................

Example of how to read a compressed file:

    import gzip
    f = gzip.open('file.txt.gz', 'rb')
    file_content = f.read()
    f.close()

Example of how to create a compressed GZIP file:

    import gzip
    content = "Lots of content here"
    f = gzip.open('file.txt.gz', 'wb')
    f.write(content)
    f.close()

Example of how to GZIP compress an existing file:

    import gzip
    f_in = open('file.txt', 'rb')
    f_out = gzip.open('file.txt.gz', 'wb')
    f_out.writelines(f_in)
    f_out.close()
    f_in.close()


See also
........

Module *note zlib: 1ad.
     The basic data compression module needed to support the *gzip* file
     format.


File: python.info,  Node: bz2 --- Compression compatible with bzip2,  Next: zipfile --- Work with ZIP archives,  Prev: gzip --- Support for gzip files,  Up: Data Compression and Archiving

5.12.3 `bz2' -- Compression compatible with *bzip2*
---------------------------------------------------

New in version 2.3.

  This module provides a comprehensive interface for the bz2
compression library.  It implements a complete file interface, one-shot
(de)compression functions, and types for sequential (de)compression.

  Here is a summary of the features offered by the bz2 module:

   * *note BZ2File: 201. class implements a complete file interface,
     including *note readline(): f70, *note readlines(): f71, *note
     writelines(): f72, *note seek(): f73, etc;

   * *note BZ2File: 201. class implements emulated *note seek(): f73.
     support;

   * *note BZ2File: 201. class implements universal newline support;

   * *note BZ2File: 201. class offers an optimized line iteration using
     the readahead algorithm borrowed from file objects;

   * Sequential (de)compression supported by *note BZ2Compressor: f74.
     and *note BZ2Decompressor: f75. classes;

   * One-shot (de)compression supported by *note compress(): f76. and
     *note decompress(): f77.  functions;

   * Thread safety uses individual locking mechanism.

* Menu:

* (De)compression of files: De compression of files.
* Sequential (de)compression: Sequential de compression.
* One-shot (de)compression: One-shot de compression.


File: python.info,  Node: De compression of files,  Next: Sequential de compression,  Up: bz2 --- Compression compatible with bzip2

5.12.3.1 (De)compression of files
.................................

Handling of compressed files is offered by the *note BZ2File: 201.
class.

 -- Class: bz2.BZ2File (filename[, mode[, buffering[, compresslevel]]])
     Open a bz2 file. Mode can be either `'r'' or `'w'', for reading
     (default) or writing. When opened for writing, the file will be
     created if it doesn't exist, and truncated otherwise. If
     _buffering_ is given, `0' means unbuffered, and larger numbers
     specify the buffer size; the default is `0'. If _compresslevel_ is
     given, it must be a number between `1' and `9'; the default is
     `9'. Add a `'U'' to mode to open the file for input in *note
     universal newlines: 30e. mode. Any line ending in the input file
     will be seen as a `'\n'' in Python.  Also, a file so opened gains
     the attribute `newlines'; the value for this attribute is one of
     `None' (no newline read yet), `'\r'', `'\n'', `'\r\n'' or a tuple
     containing all the newline types seen. Universal newlines are
     available only when reading. Instances support iteration in the
     same way as normal *note file: 1f6.  instances.

     *note BZ2File: 201. supports the *note with: 1bd. statement.

     Changed in version 2.7: Support for the *note with: 1bd. statement
     was added.

          Note: This class does not support input files containing
          multiple streams (such as those produced by the *pbzip2*
          tool). When reading such an input file, only the first stream
          will be accessible. If you require support for multi-stream
          files, consider using the third-party `bz2file' module
          (available from PyPI(1)). This module provides a backport of
          Python 3.3's *note BZ2File: 201. class, which does support
          multi-stream files.

      -- Method: close ()
          Close the file. Sets data attribute `closed' to true. A
          closed file cannot be used for further I/O operations. *note
          close(): f79. may be called more than once without error.

      -- Method: read ([size])
          Read at most _size_ uncompressed bytes, returned as a string.
          If the _size_ argument is negative or omitted, read until EOF
          is reached.

      -- Method: readline ([size])
          Return the next line from the file, as a string, retaining
          newline. A non-negative _size_ argument limits the maximum
          number of bytes to return (an incomplete line may be returned
          then). Return an empty string at EOF.

      -- Method: readlines ([size])
          Return a list of lines read. The optional _size_ argument, if
          given, is an approximate bound on the total number of bytes
          in the lines returned.

      -- Method: xreadlines ()
          For backward compatibility. *note BZ2File: 201. objects now
          include the performance optimizations previously implemented
          in the `xreadlines' module.

          Deprecated since version 2.3: This exists only for
          compatibility with the method by this name on *note file:
          1f6. objects, which is deprecated.  Use `for line in file'
          instead.

      -- Method: seek (offset[, whence])
          Move to new file position. Argument _offset_ is a byte count.
          Optional argument _whence_ defaults to `os.SEEK_SET' or `0'
          (offset from start of file; offset should be `>= 0'); other
          values are `os.SEEK_CUR' or `1' (move relative to current
          position; offset can be positive or negative), and
          `os.SEEK_END' or `2' (move relative to end of file; offset is
          usually negative, although many platforms allow seeking beyond
          the end of a file).

          Note that seeking of bz2 files is emulated, and depending on
          the parameters the operation may be extremely slow.

      -- Method: tell ()
          Return the current file position, an integer (may be a long
          integer).

      -- Method: write (data)
          Write string _data_ to file. Note that due to buffering,
          *note close(): f79. may be needed before the file on disk
          reflects the data written.

      -- Method: writelines (sequence_of_strings)
          Write the sequence of strings to the file. Note that newlines
          are not added. The sequence can be any iterable object
          producing strings. This is equivalent to calling write() for
          each string.

  ---------- Footnotes ----------

  (1) http://pypi.python.org/pypi/bz2file


File: python.info,  Node: Sequential de compression,  Next: One-shot de compression,  Prev: De compression of files,  Up: bz2 --- Compression compatible with bzip2

5.12.3.2 Sequential (de)compression
...................................

Sequential compression and decompression is done using the classes
*note BZ2Compressor: f74. and *note BZ2Decompressor: f75.

 -- Class: bz2.BZ2Compressor ([compresslevel])
     Create a new compressor object. This object may be used to
     compress data sequentially. If you want to compress data in one
     shot, use the *note compress(): f76. function instead. The
     _compresslevel_ parameter, if given, must be a number between `1'
     and `9'; the default is `9'.

      -- Method: compress (data)
          Provide more data to the compressor object. It will return
          chunks of compressed data whenever possible. When you've
          finished providing data to compress, call the *note flush():
          f80. method to finish the compression process, and return
          what is left in internal buffers.

      -- Method: flush ()
          Finish the compression process and return what is left in
          internal buffers. You must not use the compressor object
          after calling this method.

 -- Class: bz2.BZ2Decompressor
     Create a new decompressor object. This object may be used to
     decompress data sequentially. If you want to decompress data in
     one shot, use the *note decompress(): f77. function instead.

      -- Method: decompress (data)
          Provide more data to the decompressor object. It will return
          chunks of decompressed data whenever possible. If you try to
          decompress data after the end of stream is found, *note
          EOFError: 874. will be raised. If any data was found after
          the end of stream, it'll be ignored and saved in
          `unused_data' attribute.


File: python.info,  Node: One-shot de compression,  Prev: Sequential de compression,  Up: bz2 --- Compression compatible with bzip2

5.12.3.3 One-shot (de)compression
.................................

One-shot compression and decompression is provided through the *note
compress(): f76.  and *note decompress(): f77. functions.

 -- Function: bz2.compress (data[, compresslevel])
     Compress _data_ in one shot. If you want to compress data
     sequentially, use an instance of *note BZ2Compressor: f74.
     instead. The _compresslevel_ parameter, if given, must be a number
     between `1' and `9'; the default is `9'.

 -- Function: bz2.decompress (data)
     Decompress _data_ in one shot. If you want to decompress data
     sequentially, use an instance of *note BZ2Decompressor: f75.
     instead.


File: python.info,  Node: zipfile --- Work with ZIP archives,  Next: tarfile --- Read and write tar archive files,  Prev: bz2 --- Compression compatible with bzip2,  Up: Data Compression and Archiving

5.12.4 `zipfile' -- Work with ZIP archives
------------------------------------------

New in version 1.6.

  *Source code:* Lib/zipfile.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The ZIP file format is a common archive and compression standard.
This module provides tools to create, read, write, append, and list a
ZIP file.  Any advanced use of this module will require an
understanding of the format, as defined in PKZIP Application Note(2).

  This module does not currently handle multi-disk ZIP files.  It can
handle ZIP files that use the ZIP64 extensions (that is ZIP files that
are more than 4 GByte in size).  It supports decryption of encrypted
files in ZIP archives, but it currently cannot create an encrypted
file.  Decryption is extremely slow as it is implemented in native
Python rather than C.

  The module defines the following items:

 -- Exception: zipfile.BadZipfile
     The error raised for bad ZIP files (old name: `zipfile.error').

 -- Exception: zipfile.LargeZipFile
     The error raised when a ZIP file would require ZIP64 functionality
     but that has not been enabled.

 -- Class: zipfile.ZipFile
     The class for reading and writing ZIP files.  See section *note
     ZipFile Objects: f87. for constructor details.

 -- Class: zipfile.PyZipFile
     Class for creating ZIP archives containing Python libraries.

 -- Class: zipfile.ZipInfo ([filename[, date_time]])
     Class used to represent information about a member of an archive.
     Instances of this class are returned by the *note getinfo(): f8a.
     and *note infolist(): f8b.  methods of *note ZipFile: 269.
     objects.  Most users of the *note zipfile: 1ab. module will not
     need to create these, but only use those created by this module.
     _filename_ should be the full name of the archive member, and
     _date_time_ should be a tuple containing six fields which describe
     the time of the last modification to the file; the fields are
     described in section *note ZipInfo Objects: f8c.

 -- Function: zipfile.is_zipfile (filename)
     Returns `True' if _filename_ is a valid ZIP file based on its
     magic number, otherwise returns `False'.  _filename_ may be a file
     or file-like object too.

     Changed in version 2.7: Support for file and file-like objects.

 -- Data: zipfile.ZIP_STORED
     The numeric constant for an uncompressed archive member.

 -- Data: zipfile.ZIP_DEFLATED
     The numeric constant for the usual ZIP compression method.  This
     requires the *note zlib: 1ad. module.  No other compression
     methods are currently supported.

See also
........

PKZIP Application Note(3)
     Documentation on the ZIP file format by Phil Katz, the creator of
     the format and algorithms used.

Info-ZIP Home Page(4)
     Information about the Info-ZIP project's ZIP archive programs and
     development libraries.

* Menu:

* ZipFile Objects::
* PyZipFile Objects::
* ZipInfo Objects::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/zipfile.py

  (2) http://www.pkware.com/documents/casestudies/APPNOTE.TXT

  (3) http://www.pkware.com/documents/casestudies/APPNOTE.TXT

  (4) http://www.info-zip.org/


File: python.info,  Node: ZipFile Objects,  Next: PyZipFile Objects,  Up: zipfile --- Work with ZIP archives

5.12.4.1 ZipFile Objects
........................

 -- Class: zipfile.ZipFile (file[, mode[, compression[, allowZip64]]])
     Open a ZIP file, where _file_ can be either a path to a file (a
     string) or a file-like object.  The _mode_ parameter should be
     `'r'' to read an existing file, `'w'' to truncate and write a new
     file, or `'a'' to append to an existing file.  If _mode_ is `'a''
     and _file_ refers to an existing ZIP file, then additional files
     are added to it.  If _file_ does not refer to a ZIP file, then a
     new ZIP archive is appended to the file.  This is meant for adding
     a ZIP archive to another file (such as `python.exe').

     Changed in version 2.6: If _mode_ is `a' and the file does not
     exist at all, it is created.

     _compression_ is the ZIP compression method to use when writing
     the archive, and should be *note ZIP_STORED: f8d. or *note
     ZIP_DEFLATED: f8e.; unrecognized values will cause *note
     RuntimeError: 394. to be raised.  If *note ZIP_DEFLATED: f8e.  is
     specified but the *note zlib: 1ad. module is not available, *note
     RuntimeError: 394.  is also raised. The default is *note
     ZIP_STORED: f8d.  If _allowZip64_ is `True' zipfile will create
     ZIP files that use the ZIP64 extensions when the zipfile is larger
     than 2 GB. If it is  false (the default) *note zipfile: 1ab.  will
     raise an exception when the ZIP file would require ZIP64
     extensions.  ZIP64 extensions are disabled by default because the
     default *zip* and *unzip* commands on Unix (the InfoZIP utilities)
     don't support these extensions.

     Changed in version 2.7.1: If the file is created with mode `'a''
     or `'w'' and then *note closed: f90. without adding any files to
     the archive, the appropriate ZIP structures for an empty archive
     will be written to the file.

     ZipFile is also a context manager and therefore supports the *note
     with: 1bd. statement.  In the example, _myzip_ is closed after the
     *note with: 1bd. statement's suite is finished--even if an
     exception occurs:

         with ZipFile('spam.zip', 'w') as myzip:
             myzip.write('eggs.txt')

     New in version 2.7: Added the ability to use *note ZipFile: 269.
     as a context manager.

 -- Method: ZipFile.close ()
     Close the archive file.  You must call *note close(): f90. before
     exiting your program or essential records will not be written.

 -- Method: ZipFile.getinfo (name)
     Return a *note ZipInfo: f89. object with information about the
     archive member _name_.  Calling *note getinfo(): f8a. for a name
     not currently contained in the archive will raise a *note
     KeyError: 202.

 -- Method: ZipFile.infolist ()
     Return a list containing a *note ZipInfo: f89. object for each
     member of the archive.  The objects are in the same order as their
     entries in the actual ZIP file on disk if an existing archive was
     opened.

 -- Method: ZipFile.namelist ()
     Return a list of archive members by name.


 -- Method: ZipFile.open (name[, mode[, pwd]])
     Extract a member from the archive as a file-like object
     (ZipExtFile). _name_ is the name of the file in the archive, or a
     *note ZipInfo: f89. object. The _mode_ parameter, if included,
     must be one of the following: `'r'' (the default), `'U'', or
     `'rU''. Choosing `'U'' or  `'rU'' will enable *note universal
     newline: 30e.  support in the read-only object. _pwd_ is the
     password used for encrypted files.  Calling  *note open(): f92. on
     a closed ZipFile will raise a  *note RuntimeError: 394.

          Note: The file-like object is read-only and provides the
          following methods: `read()', `readline()', `readlines()',
          `__iter__()', `next()'.

          Note: If the ZipFile was created by passing in a file-like
          object as the  first argument to the constructor, then the
          object returned by *note open(): f92. shares the ZipFile's
          file pointer.  Under these  circumstances, the object
          returned by *note open(): f92. should not  be used after any
          additional operations are performed on the  ZipFile object.
          If the ZipFile was created by passing in a string (the
          filename) as the first argument to the constructor, then
          *note open(): f92. will create a new file object that will be
          held by the ZipExtFile, allowing it to operate independently
          of the  ZipFile.

          Note: The *note open(): f92, *note read(): 26a. and *note
          extract(): f93. methods can take a filename or a *note
          ZipInfo: f89. object.  You will appreciate this when trying
          to read a ZIP file that contains members with duplicate names.

     New in version 2.6.

 -- Method: ZipFile.extract (member[, path[, pwd]])
     Extract a member from the archive to the current working
     directory; _member_ must be its full name or a *note ZipInfo: f89.
     object).  Its file information is extracted as accurately as
     possible.  _path_ specifies a different directory to extract to.
     _member_ can be a filename or a *note ZipInfo: f89. object.  _pwd_
     is the password used for encrypted files.

     New in version 2.6.

          Note: If a member filename is an absolute path, a drive/UNC
          sharepoint and leading (back)slashes will be stripped, e.g.:
          `///foo/bar' becomes `foo/bar' on Unix, and `C:\foo\bar'
          becomes `foo\bar' on Windows.  And all `".."' components in a
          member filename will be removed, e.g.: `../../foo../../ba..r'
          becomes `foo../ba..r'.  On Windows illegal characters (`:',
          `<', `>', `|', `"', `?', and `*') replaced by underscore
          (`_').

 -- Method: ZipFile.extractall ([path[, members[, pwd]]])
     Extract all members from the archive to the current working
     directory.  _path_ specifies a different directory to extract to.
     _members_ is optional and must be a subset of the list returned by
     *note namelist(): f91.  _pwd_ is the password used for encrypted
     files.

          Warning: Never extract archives from untrusted sources
          without prior inspection.  It is possible that files are
          created outside of _path_, e.g. members that have absolute
          filenames starting with `"/"' or filenames with two dots
          `".."'.

     Changed in version 2.7.4: The zipfile module attempts to prevent
     that.  See *note extract(): f93. note.

     New in version 2.6.

 -- Method: ZipFile.printdir ()
     Print a table of contents for the archive to `sys.stdout'.

 -- Method: ZipFile.setpassword (pwd)
     Set _pwd_ as default password to extract encrypted files.

     New in version 2.6.

 -- Method: ZipFile.read (name[, pwd])
     Return the bytes of the file _name_ in the archive.  _name_ is the
     name of the file in the archive, or a *note ZipInfo: f89. object.
     The archive must be open for read or append. _pwd_ is the password
     used for encrypted  files and, if specified, it will override the
     default password set with *note setpassword(): f96.  Calling *note
     read(): 26a. on a closed ZipFile  will raise a *note RuntimeError:
     394.

     Changed in version 2.6: _pwd_ was added, and _name_ can now be a
     *note ZipInfo: f89. object.

 -- Method: ZipFile.testzip ()
     Read all the files in the archive and check their CRC's and file
     headers.  Return the name of the first bad file, or else return
     `None'. Calling *note testzip(): f97. on a closed ZipFile will
     raise a *note RuntimeError: 394.

 -- Method: ZipFile.write (filename[, arcname[, compress_type]])
     Write the file named _filename_ to the archive, giving it the
     archive name _arcname_ (by default, this will be the same as
     _filename_, but without a drive letter and with leading path
     separators removed).  If given, _compress_type_ overrides the
     value given for the _compression_ parameter to the constructor for
     the new entry.  The archive must be open with mode `'w'' or `'a''
     - calling *note write(): f98. on a ZipFile created with mode `'r''
     will raise a *note RuntimeError: 394.  Calling  *note write():
     f98. on a closed ZipFile will raise a *note RuntimeError: 394.

          Note: There is no official file name encoding for ZIP files.
          If you have unicode file names, you must convert them to byte
          strings in your desired encoding before passing them to *note
          write(): f98. WinZip interprets all file names as encoded in
          CP437, also known as DOS Latin.

          Note: Archive names should be relative to the archive root,
          that is, they should not start with a path separator.

          Note: If `arcname' (or `filename', if `arcname' is  not
          given) contains a null byte, the name of the file in the
          archive will be truncated at the null byte.

 -- Method: ZipFile.writestr (zinfo_or_arcname, bytes[, compress_type])
     Write the string _bytes_ to the archive; _zinfo_or_arcname_ is
     either the file name it will be given in the archive, or a *note
     ZipInfo: f89. instance.  If it's an instance, at least the
     filename, date, and time must be given.  If it's a name, the date
     and time is set to the current date and time. The archive must be
     opened with mode `'w'' or `'a'' - calling  *note writestr(): 26c.
     on a ZipFile created with mode `'r''  will raise a *note
     RuntimeError: 394.  Calling *note writestr(): 26c. on a closed
     ZipFile will raise a *note RuntimeError: 394.

     If given, _compress_type_ overrides the value given for the
     _compression_ parameter to the constructor for the new entry, or
     in the _zinfo_or_arcname_ (if that is a *note ZipInfo: f89.
     instance).

          Note: When passing a *note ZipInfo: f89. instance as the
          _zinfo_or_arcname_ parameter, the compression method used
          will be that specified in the _compress_type_ member of the
          given *note ZipInfo: f89. instance.  By default, the *note
          ZipInfo: f89. constructor sets this member to *note
          ZIP_STORED: f8d.

     Changed in version 2.7: The _compress_type_ argument.

  The following data attributes are also available:

 -- Attribute: ZipFile.debug
     The level of debug output to use.  This may be set from `0' (the
     default, no output) to `3' (the most output).  Debugging
     information is written to `sys.stdout'.

 -- Attribute: ZipFile.comment
     The comment text associated with the ZIP file.  If assigning a
     comment to a *note ZipFile: 269. instance created with mode 'a' or
     'w', this should be a string no longer than 65535 bytes.  Comments
     longer than this will be truncated in the written archive when
     *note close(): f90. is called.


File: python.info,  Node: PyZipFile Objects,  Next: ZipInfo Objects,  Prev: ZipFile Objects,  Up: zipfile --- Work with ZIP archives

5.12.4.2 PyZipFile Objects
..........................

The *note PyZipFile: f88. constructor takes the same parameters as the
*note ZipFile: 269. constructor.  Instances have one method in addition
to those of *note ZipFile: 269. objects.

 -- Method: PyZipFile.writepy (pathname[, basename])
     Search for files `*.py' and add the corresponding file to the
     archive.  The corresponding file is a `*.pyo' file if available,
     else a `*.pyc' file, compiling if necessary.  If the pathname is a
     file, the filename must end with `.py', and just the (corresponding
     `*.py[co]') file is added at the top level (no path information).
     If the pathname is a file that does not end with `.py', a *note
     RuntimeError: 394.  will be raised.  If it is a directory, and the
     directory is not a package directory, then all the files
     `*.py[co]' are added at the top level.  If the directory is a
     package directory, then all `*.py[co]' are added under the package
     name as a file path, and if any subdirectories are package
     directories, all of these are added recursively.  _basename_ is
     intended for internal use only.  The *note writepy(): f9d. method
     makes archives with file names like this:

         string.pyc                                # Top level name
         test/__init__.pyc                         # Package directory
         test/test_support.pyc                          # Module test.test_support
         test/bogus/__init__.pyc                   # Subpackage directory
         test/bogus/myfile.pyc                     # Submodule test.bogus.myfile




File: python.info,  Node: ZipInfo Objects,  Prev: PyZipFile Objects,  Up: zipfile --- Work with ZIP archives

5.12.4.3 ZipInfo Objects
........................

Instances of the *note ZipInfo: f89. class are returned by the *note
getinfo(): f8a. and *note infolist(): f8b. methods of *note ZipFile:
269. objects.  Each object stores information about a single member of
the ZIP archive.

  Instances have the following attributes:

 -- Attribute: ZipInfo.filename
     Name of the file in the archive.

 -- Attribute: ZipInfo.date_time
     The time and date of the last modification to the archive member.
     This is a tuple of six values:

     Index       Value
     ------------------------------------------- 
     `0'         Year (>= 1980)
     `1'         Month (one-based)
     `2'         Day of month (one-based)
     `3'         Hours (zero-based)
     `4'         Minutes (zero-based)
     `5'         Seconds (zero-based)

          Note: The ZIP file format does not support timestamps before
          1980.

 -- Attribute: ZipInfo.compress_type
     Type of compression for the archive member.

 -- Attribute: ZipInfo.comment
     Comment for the individual archive member.

 -- Attribute: ZipInfo.extra
     Expansion field data.  The PKZIP Application Note(1) contains some
     comments on the internal structure of the data contained in this
     string.

 -- Attribute: ZipInfo.create_system
     System which created ZIP archive.

 -- Attribute: ZipInfo.create_version
     PKZIP version which created ZIP archive.

 -- Attribute: ZipInfo.extract_version
     PKZIP version needed to extract archive.

 -- Attribute: ZipInfo.reserved
     Must be zero.

 -- Attribute: ZipInfo.flag_bits
     ZIP flag bits.

 -- Attribute: ZipInfo.volume
     Volume number of file header.

 -- Attribute: ZipInfo.internal_attr
     Internal attributes.

 -- Attribute: ZipInfo.external_attr
     External file attributes.

 -- Attribute: ZipInfo.header_offset
     Byte offset to the file header.

 -- Attribute: ZipInfo.CRC
     CRC-32 of the uncompressed file.

 -- Attribute: ZipInfo.compress_size
     Size of the compressed data.

 -- Attribute: ZipInfo.file_size
     Size of the uncompressed file.

  ---------- Footnotes ----------

  (1) http://www.pkware.com/documents/casestudies/APPNOTE.TXT


File: python.info,  Node: tarfile --- Read and write tar archive files,  Prev: zipfile --- Work with ZIP archives,  Up: Data Compression and Archiving

5.12.5 `tarfile' -- Read and write tar archive files
----------------------------------------------------

New in version 2.3.

  *Source code:* Lib/tarfile.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note tarfile: 171. module makes it possible to read and write tar
archives, including those using gzip or bz2 compression.  Use the *note
zipfile: 1ab. module to read or write `.zip' files, or the higher-level
functions in *note shutil: e93.

  Some facts and figures:

   * reads and writes *note gzip: e5. and *note bz2: 1e. compressed
     archives.

   * read/write support for the POSIX.1-1988 (ustar) format.

   * read/write support for the GNU tar format including _longname_ and
     _longlink_ extensions, read-only support for the _sparse_
     extension.

   * read/write support for the POSIX.1-2001 (pax) format.

     New in version 2.6.

   * handles directories, regular files, hardlinks, symbolic links,
     fifos, character devices and block devices and is able to acquire
     and restore file information like timestamp, access permissions
     and owner.

 -- Function: tarfile.open (name=None, mode='r', fileobj=None,
          bufsize=10240, **kwargs)
     Return a *note TarFile: 264. object for the pathname _name_. For
     detailed information on *note TarFile: 264. objects and the
     keyword arguments that are allowed, see *note TarFile Objects: fb3.

     _mode_ has to be a string of the form `'filemode[:compression]'',
     it defaults to `'r''. Here is a full list of mode combinations:

     mode                   action
     ------------------------------------------------------------------------- 
     `'r' or 'r:*''         Open for reading with transparent compression
                            (recommended).
     `'r:''                 Open for reading exclusively without compression.
     `'r:gz''               Open for reading with gzip compression.
     `'r:bz2''              Open for reading with bzip2 compression.
     `'a' or 'a:''          Open for appending with no compression. The file
                            is created if it does not exist.
     `'w' or 'w:''          Open for uncompressed writing.
     `'w:gz''               Open for gzip compressed writing.
     `'w:bz2''              Open for bzip2 compressed writing.

     Note that `'a:gz'' or `'a:bz2'' is not possible. If _mode_ is not
     suitable to open a certain (compressed) file for reading, *note
     ReadError: fb4. is raised. Use _mode_ `'r'' to avoid this.  If a
     compression method is not supported, *note CompressionError: fb5.
     is raised.

     If _fileobj_ is specified, it is used as an alternative to a file
     object opened for _name_. It is supposed to be at position 0.

     For special purposes, there is a second format for _mode_:
     `'filemode|[compression]''.  *note tarfile.open(): fb2. will
     return a *note TarFile: 264.  object that processes its data as a
     stream of blocks.  No random seeking will be done on the file. If
     given, _fileobj_ may be any object that has a `read()' or
     `write()' method (depending on the _mode_). _bufsize_ specifies
     the blocksize and defaults to `20 * 512' bytes. Use this variant
     in combination with e.g. `sys.stdin', a socket file object or a
     tape device. However, such a *note TarFile: 264. object is limited
     in that it does not allow to be accessed randomly, see *note
     Examples: fb6.  The currently possible modes:

     Mode              Action
     ------------------------------------------------------------------- 
     `'r|*''           Open a _stream_ of tar blocks for reading with
                       transparent compression.
     `'r|''            Open a _stream_ of uncompressed tar blocks for
                       reading.
     `'r|gz''          Open a gzip compressed _stream_ for reading.
     `'r|bz2''         Open a bzip2 compressed _stream_ for reading.
     `'w|''            Open an uncompressed _stream_ for writing.
     `'w|gz''          Open an gzip compressed _stream_ for writing.
     `'w|bz2''         Open an bzip2 compressed _stream_ for writing.


 -- Class: tarfile.TarFile
     Class for reading and writing tar archives. Do not use this class
     directly, better use *note tarfile.open(): fb2. instead. See *note
     TarFile Objects: fb3.

 -- Function: tarfile.is_tarfile (name)
     Return *note True: 3a9. if _name_ is a tar archive file, that the
     *note tarfile: 171.  module can read.

 -- Class: tarfile.TarFileCompat (filename, mode='r',
          compression=TAR_PLAIN)
     Class for limited access to tar archives with a *note zipfile:
     1ab.-like interface.  Please consult the documentation of the
     *note zipfile: 1ab. module for more details.  _compression_ must
     be one of the following constants:

      -- Data: TAR_PLAIN
          Constant for an uncompressed tar archive.

      -- Data: TAR_GZIPPED
          Constant for a *note gzip: e5. compressed tar archive.

     Deprecated since version 2.6: The *note TarFileCompat: fb8. class
     has been removed in Python 3.

 -- Exception: tarfile.TarError
     Base class for all *note tarfile: 171. exceptions.

 -- Exception: tarfile.ReadError
     Is raised when a tar archive is opened, that either cannot be
     handled by the *note tarfile: 171. module or is somehow invalid.

 -- Exception: tarfile.CompressionError
     Is raised when a compression method is not supported or when the
     data cannot be decoded properly.

 -- Exception: tarfile.StreamError
     Is raised for the limitations that are typical for stream-like
     *note TarFile: 264.  objects.

 -- Exception: tarfile.ExtractError
     Is raised for _non-fatal_ errors when using *note
     TarFile.extract(): fbe, but only if `TarFile.errorlevel'`== 2'.

 -- Exception: tarfile.HeaderError
     Is raised by *note TarInfo.frombuf(): fc0. if the buffer it gets
     is invalid.

     New in version 2.6.

  Each of the following constants defines a tar archive format that the
*note tarfile: 171. module is able to create. See section *note
Supported tar formats: fc1. for details.

 -- Data: tarfile.USTAR_FORMAT
     POSIX.1-1988 (ustar) format.

 -- Data: tarfile.GNU_FORMAT
     GNU tar format.

 -- Data: tarfile.PAX_FORMAT
     POSIX.1-2001 (pax) format.

 -- Data: tarfile.DEFAULT_FORMAT
     The default format for creating archives. This is currently *note
     GNU_FORMAT: fc3.

  The following variables are available on module level:

 -- Data: tarfile.ENCODING
     The default character encoding i.e. the value from either *note
     sys.getfilesystemencoding(): fc7. or *note
     sys.getdefaultencoding(): fc8.

See also
........

Module *note zipfile: 1ab.
     Documentation of the *note zipfile: 1ab. standard module.

GNU tar manual, Basic Tar Format(2)
     Documentation for tar archive files, including GNU tar extensions.

* Menu:

* TarFile Objects::
* TarInfo Objects::
* Examples: Examples<3>.
* Supported tar formats::
* Unicode issues::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/tarfile.py

  (2) http://www.gnu.org/software/tar/manual/html_node/Standard.html


File: python.info,  Node: TarFile Objects,  Next: TarInfo Objects,  Up: tarfile --- Read and write tar archive files

5.12.5.1 TarFile Objects
........................

The *note TarFile: 264. object provides an interface to a tar archive.
A tar archive is a sequence of blocks. An archive member (a stored
file) is made up of a header block followed by data blocks. It is
possible to store a file in a tar archive several times. Each archive
member is represented by a *note TarInfo: 262.  object, see *note
TarInfo Objects: fca. for details.

  A *note TarFile: 264. object can be used as a context manager in a
*note with: 1bd.  statement. It will automatically be closed when the
block is completed. Please note that in the event of an exception an
archive opened for writing will not be finalized; only the internally
used file object will be closed. See the *note Examples: fb6. section
for a use case.

  New in version 2.7: Added support for the context manager protocol.

 -- Class: tarfile.TarFile (name=None, mode='r', fileobj=None,
          format=DEFAULT_FORMAT, tarinfo=TarInfo, dereference=False,
          ignore_zeros=False, encoding=ENCODING, errors=None,
          pax_headers=None, debug=0, errorlevel=0)
     All following arguments are optional and can be accessed as
     instance attributes as well.

     _name_ is the pathname of the archive. It can be omitted if
     _fileobj_ is given.  In this case, the file object's `name'
     attribute is used if it exists.

     _mode_ is either `'r'' to read from an existing archive, `'a'' to
     append data to an existing file or `'w'' to create a new file
     overwriting an existing one.

     If _fileobj_ is given, it is used for reading or writing data. If
     it can be determined, _mode_ is overridden by _fileobj_'s mode.
     _fileobj_ will be used from position 0.

          Note: _fileobj_ is not closed, when *note TarFile: 264. is
          closed.

     _format_ controls the archive format. It must be one of the
     constants *note USTAR_FORMAT: fc2, *note GNU_FORMAT: fc3. or *note
     PAX_FORMAT: fc4. that are defined at module level.

     New in version 2.6.

     The _tarinfo_ argument can be used to replace the default *note
     TarInfo: 262. class with a different one.

     New in version 2.6.

     If _dereference_ is *note False: 3aa, add symbolic and hard links
     to the archive. If it is *note True: 3a9, add the content of the
     target files to the archive. This has no effect on systems that do
     not support symbolic links.

     If _ignore_zeros_ is *note False: 3aa, treat an empty block as the
     end of the archive.  If it is *note True: 3a9, skip empty (and
     invalid) blocks and try to get as many members as possible. This
     is only useful for reading concatenated or damaged archives.

     _debug_ can be set from `0' (no debug messages) up to `3' (all
     debug messages). The messages are written to `sys.stderr'.

     If _errorlevel_ is `0', all errors are ignored when using *note
     TarFile.extract(): fbe.  Nevertheless, they appear as error
     messages in the debug output, when debugging is enabled.  If `1',
     all _fatal_ errors are raised as *note OSError: 22e. or *note
     IOError: 1f7. exceptions. If `2', all _non-fatal_ errors are
     raised as *note TarError: fbb. exceptions as well.

     The _encoding_ and _errors_ arguments control the way strings are
     converted to unicode objects and vice versa. The default settings
     will work for most users.  See section *note Unicode issues: fcb.
     for in-depth information.

     New in version 2.6.

     The _pax_headers_ argument is an optional dictionary of unicode
     strings which will be added as a pax global header if _format_ is
     *note PAX_FORMAT: fc4.

     New in version 2.6.

 -- Method: TarFile.open (...)
     Alternative constructor. The *note tarfile.open(): fb2. function
     is actually a shortcut to this classmethod.

 -- Method: TarFile.getmember (name)
     Return a *note TarInfo: 262. object for member _name_. If _name_
     can not be found in the archive, *note KeyError: 202. is raised.

          Note: If a member occurs more than once in the archive, its
          last occurrence is assumed to be the most up-to-date version.

 -- Method: TarFile.getmembers ()
     Return the members of the archive as a list of *note TarInfo: 262.
     objects. The list has the same order as the members in the archive.

 -- Method: TarFile.getnames ()
     Return the members as a list of their names. It has the same order
     as the list returned by *note getmembers(): fce.

 -- Method: TarFile.list (verbose=True)
     Print a table of contents to `sys.stdout'. If _verbose_ is *note
     False: 3aa, only the names of the members are printed. If it is
     *note True: 3a9, output similar to that of *ls -l* is produced.

 -- Method: TarFile.next ()
     Return the next member of the archive as a *note TarInfo: 262.
     object, when *note TarFile: 264. is opened for reading. Return
     *note None: 393. if there is no more available.

 -- Method: TarFile.extractall (path=".", members=None)
     Extract all members from the archive to the current working
     directory or directory _path_. If optional _members_ is given, it
     must be a subset of the list returned by *note getmembers(): fce.
     Directory information like owner, modification time and
     permissions are set after all members have been extracted.  This
     is done to work around two problems: A directory's modification
     time is reset each time a file is created in it. And, if a
     directory's permissions do not allow writing, extracting files to
     it will fail.

          Warning: Never extract archives from untrusted sources
          without prior inspection.  It is possible that files are
          created outside of _path_, e.g. members that have absolute
          filenames starting with `"/"' or filenames with two dots
          `".."'.

     New in version 2.5.

 -- Method: TarFile.extract (member, path="")
     Extract a member from the archive to the current working
     directory, using its full name. Its file information is extracted
     as accurately as possible. _member_ may be a filename or a *note
     TarInfo: 262. object. You can specify a different directory using
     _path_.

          Note: The *note extract(): fbe. method does not take care of
          several extraction issues.  In most cases you should consider
          using the *note extractall(): fd2. method.

          Warning: See the warning for *note extractall(): fd2.

 -- Method: TarFile.extractfile (member)
     Extract a member from the archive as a file object. _member_ may
     be a filename or a *note TarInfo: 262. object. If _member_ is a
     regular file, a file-like object is returned. If _member_ is a
     link, a file-like object is constructed from the link's target. If
     _member_ is none of the above, *note None: 393. is returned.

          Note: The file-like object is read-only.  It provides the
          methods `read()', *note readline(): 144, `readlines()',
          `seek()', `tell()', and *note close(): fd4, and also supports
          iteration over its lines.

 -- Method: TarFile.add (name, arcname=None, recursive=True,
          exclude=None, filter=None)
     Add the file _name_ to the archive. _name_ may be any type of file
     (directory, fifo, symbolic link, etc.). If given, _arcname_
     specifies an alternative name for the file in the archive.
     Directories are added recursively by default. This can be avoided
     by setting _recursive_ to *note False: 3aa. If _exclude_ is given
     it must be a function that takes one filename argument and returns
     a boolean value. Depending on this value the respective file is
     either excluded (*note True: 3a9.) or added (*note False: 3aa.).
     If _filter_ is specified it must be a function that takes a *note
     TarInfo: 262. object argument and returns the changed *note
     TarInfo: 262. object. If it instead returns *note None: 393. the
     *note TarInfo: 262.  object will be excluded from the archive. See
     *note Examples: fb6. for an example.

     Changed in version 2.6: Added the _exclude_ parameter.

     Changed in version 2.7: Added the _filter_ parameter.

     Deprecated since version 2.7: The _exclude_ parameter is
     deprecated, please use the _filter_ parameter instead.  For
     maximum portability, _filter_ should be used as a keyword argument
     rather than as a positional argument so that code won't be
     affected when _exclude_ is ultimately removed.

 -- Method: TarFile.addfile (tarinfo, fileobj=None)
     Add the *note TarInfo: 262. object _tarinfo_ to the archive. If
     _fileobj_ is given, `tarinfo.size' bytes are read from it and
     added to the archive.  You can create *note TarInfo: 262. objects
     using *note gettarinfo(): fd6.

          Note: On Windows platforms, _fileobj_ should always be opened
          with mode `'rb'' to avoid irritation about the file size.

 -- Method: TarFile.gettarinfo (name=None, arcname=None, fileobj=None)
     Create a *note TarInfo: 262. object for either the file _name_ or
     the file object _fileobj_ (using *note os.fstat(): e06. on its
     file descriptor).  You can modify some of the *note TarInfo:
     262.'s attributes before you add it using *note addfile(): fd5.
     If given, _arcname_ specifies an alternative name for the file in
     the archive.

 -- Method: TarFile.close ()
     Close the *note TarFile: 264. In write mode, two finishing zero
     blocks are appended to the archive.

 -- Attribute: TarFile.posix
     Setting this to *note True: 3a9. is equivalent to setting the
     *note format: 1ec.  attribute to *note USTAR_FORMAT: fc2, *note
     False: 3aa. is equivalent to *note GNU_FORMAT: fc3.

     Changed in version 2.4: _posix_ defaults to *note False: 3aa.

     Deprecated since version 2.6: Use the *note format: 1ec. attribute
     instead.

 -- Attribute: TarFile.pax_headers
     A dictionary containing key-value pairs of pax global headers.

     New in version 2.6.


File: python.info,  Node: TarInfo Objects,  Next: Examples<3>,  Prev: TarFile Objects,  Up: tarfile --- Read and write tar archive files

5.12.5.2 TarInfo Objects
........................

A *note TarInfo: 262. object represents one member in a *note TarFile:
264. Aside from storing all required attributes of a file (like file
type, size, time, permissions, owner etc.), it provides some useful
methods to determine its type.  It does _not_ contain the file's data
itself.

  *note TarInfo: 262. objects are returned by *note TarFile: 264.'s
methods `getmember()', `getmembers()' and `gettarinfo()'.

 -- Class: tarfile.TarInfo (name="")
     Create a *note TarInfo: 262. object.

 -- Method: TarInfo.frombuf (buf)
     Create and return a *note TarInfo: 262. object from string buffer
     _buf_.

     New in version 2.6: Raises *note HeaderError: fbf. if the buffer
     is invalid..

 -- Method: TarInfo.fromtarfile (tarfile)
     Read the next member from the *note TarFile: 264. object _tarfile_
     and return it as a *note TarInfo: 262. object.

     New in version 2.6.

 -- Method: TarInfo.tobuf (format=DEFAULT_FORMAT, encoding=ENCODING,
          errors='strict')
     Create a string buffer from a *note TarInfo: 262. object. For
     information on the arguments see the constructor of the *note
     TarFile: 264. class.

     Changed in version 2.6: The arguments were added.

  A `TarInfo' object has the following public data attributes:

 -- Attribute: TarInfo.name
     Name of the archive member.

 -- Attribute: TarInfo.size
     Size in bytes.

 -- Attribute: TarInfo.mtime
     Time of last modification.

 -- Attribute: TarInfo.mode
     Permission bits.

 -- Attribute: TarInfo.type
     File type.  _type_ is usually one of these constants: `REGTYPE',
     `AREGTYPE', `LNKTYPE', `SYMTYPE', `DIRTYPE', `FIFOTYPE',
     `CONTTYPE', `CHRTYPE', `BLKTYPE', `GNUTYPE_SPARSE'.  To determine
     the type of a *note TarInfo: 262. object more conveniently, use
     the `is_*()' methods below.

 -- Attribute: TarInfo.linkname
     Name of the target file name, which is only present in *note
     TarInfo: 262. objects of type `LNKTYPE' and `SYMTYPE'.

 -- Attribute: TarInfo.uid
     User ID of the user who originally stored this member.

 -- Attribute: TarInfo.gid
     Group ID of the user who originally stored this member.

 -- Attribute: TarInfo.uname
     User name.

 -- Attribute: TarInfo.gname
     Group name.

 -- Attribute: TarInfo.pax_headers
     A dictionary containing key-value pairs of an associated pax
     extended header.

     New in version 2.6.

  A *note TarInfo: 262. object also provides some convenient query
methods:

 -- Method: TarInfo.isfile ()
     Return *note True: 3a9. if the `Tarinfo' object is a regular file.

 -- Method: TarInfo.isreg ()
     Same as *note isfile(): fe7.

 -- Method: TarInfo.isdir ()
     Return *note True: 3a9. if it is a directory.

 -- Method: TarInfo.issym ()
     Return *note True: 3a9. if it is a symbolic link.

 -- Method: TarInfo.islnk ()
     Return *note True: 3a9. if it is a hard link.

 -- Method: TarInfo.ischr ()
     Return *note True: 3a9. if it is a character device.

 -- Method: TarInfo.isblk ()
     Return *note True: 3a9. if it is a block device.

 -- Method: TarInfo.isfifo ()
     Return *note True: 3a9. if it is a FIFO.

 -- Method: TarInfo.isdev ()
     Return *note True: 3a9. if it is one of character device, block
     device or FIFO.


File: python.info,  Node: Examples<3>,  Next: Supported tar formats,  Prev: TarInfo Objects,  Up: tarfile --- Read and write tar archive files

5.12.5.3 Examples
.................

How to extract an entire tar archive to the current working directory:

    import tarfile
    tar = tarfile.open("sample.tar.gz")
    tar.extractall()
    tar.close()

How to extract a subset of a tar archive with *note
TarFile.extractall(): fd2. using a generator function instead of a list:

    import os
    import tarfile

    def py_files(members):
        for tarinfo in members:
            if os.path.splitext(tarinfo.name)[1] == ".py":
                yield tarinfo

    tar = tarfile.open("sample.tar.gz")
    tar.extractall(members=py_files(tar))
    tar.close()

How to create an uncompressed tar archive from a list of filenames:

    import tarfile
    tar = tarfile.open("sample.tar", "w")
    for name in ["foo", "bar", "quux"]:
        tar.add(name)
    tar.close()

The same example using the *note with: 1bd. statement:

    import tarfile
    with tarfile.open("sample.tar", "w") as tar:
        for name in ["foo", "bar", "quux"]:
            tar.add(name)

How to read a gzip compressed tar archive and display some member
information:

    import tarfile
    tar = tarfile.open("sample.tar.gz", "r:gz")
    for tarinfo in tar:
        print tarinfo.name, "is", tarinfo.size, "bytes in size and is",
        if tarinfo.isreg():
            print "a regular file."
        elif tarinfo.isdir():
            print "a directory."
        else:
            print "something else."
    tar.close()

How to create an archive and reset the user information using the
_filter_ parameter in *note TarFile.add(): 263.:

    import tarfile
    def reset(tarinfo):
        tarinfo.uid = tarinfo.gid = 0
        tarinfo.uname = tarinfo.gname = "root"
        return tarinfo
    tar = tarfile.open("sample.tar.gz", "w:gz")
    tar.add("foo", filter=reset)
    tar.close()



File: python.info,  Node: Supported tar formats,  Next: Unicode issues,  Prev: Examples<3>,  Up: tarfile --- Read and write tar archive files

5.12.5.4 Supported tar formats
..............................

There are three tar formats that can be created with the *note tarfile:
171. module:

   * The POSIX.1-1988 ustar format (*note USTAR_FORMAT: fc2.). It
     supports filenames up to a length of at best 256 characters and
     linknames up to 100 characters. The maximum file size is 8
     gigabytes. This is an old and limited but widely supported format.

   * The GNU tar format (*note GNU_FORMAT: fc3.). It supports long
     filenames and linknames, files bigger than 8 gigabytes and sparse
     files. It is the de facto standard on GNU/Linux systems. *note
     tarfile: 171. fully supports the GNU tar extensions for long
     names, sparse file support is read-only.

   * The POSIX.1-2001 pax format (*note PAX_FORMAT: fc4.). It is the
     most flexible format with virtually no limits. It supports long
     filenames and linknames, large files and stores pathnames in a
     portable way. However, not all tar implementations today are able
     to handle pax archives properly.

     The _pax_ format is an extension to the existing _ustar_ format.
     It uses extra headers for information that cannot be stored
     otherwise. There are two flavours of pax headers: Extended headers
     only affect the subsequent file header, global headers are valid
     for the complete archive and affect all following files. All the
     data in a pax header is encoded in _UTF-8_ for portability reasons.

  There are some more variants of the tar format which can be read, but
not created:

   * The ancient V7 format. This is the first tar format from Unix
     Seventh Edition, storing only regular files and directories. Names
     must not be longer than 100 characters, there is no user/group
     name information. Some archives have miscalculated header
     checksums in case of fields with non-ASCII characters.

   * The SunOS tar extended format. This format is a variant of the
     POSIX.1-2001 pax format, but is not compatible.


File: python.info,  Node: Unicode issues,  Prev: Supported tar formats,  Up: tarfile --- Read and write tar archive files

5.12.5.5 Unicode issues
.......................

The tar format was originally conceived to make backups on tape drives
with the main focus on preserving file system information. Nowadays tar
archives are commonly used for file distribution and exchanging
archives over networks. One problem of the original format (that all
other formats are merely variants of) is that there is no concept of
supporting different character encodings. For example, an ordinary tar
archive created on a _UTF-8_ system cannot be read correctly on a
_Latin-1_ system if it contains non-ASCII characters. Names (i.e.
filenames, linknames, user/group names) containing these characters
will appear damaged.  Unfortunately, there is no way to autodetect the
encoding of an archive.

  The pax format was designed to solve this problem. It stores
non-ASCII names using the universal character encoding _UTF-8_. When a
pax archive is read, these _UTF-8_ names are converted to the encoding
of the local file system.

  The details of unicode conversion are controlled by the _encoding_
and _errors_ keyword arguments of the *note TarFile: 264. class.

  The default value for _encoding_ is the local character encoding. It
is deduced from *note sys.getfilesystemencoding(): fc7. and *note
sys.getdefaultencoding(): fc8. In read mode, _encoding_ is used
exclusively to convert unicode names from a pax archive to strings in
the local character encoding. In write mode, the use of _encoding_
depends on the chosen archive format. In case of *note PAX_FORMAT: fc4,
input names that contain non-ASCII characters need to be decoded before
being stored as _UTF-8_ strings. The other formats do not make use of
_encoding_ unless unicode objects are used as input names. These are
converted to 8-bit character strings before they are added to the
archive.

  The _errors_ argument defines how characters are treated that cannot
be converted to or from _encoding_. Possible values are listed in
section *note Codec Base Classes: 8a7. In read mode, there is an
additional scheme `'utf-8'' which means that bad characters are
replaced by their _UTF-8_ representation. This is the default scheme.
In write mode the default value for _errors_ is `'strict'' to ensure
that name information is not altered unnoticed.


File: python.info,  Node: File Formats,  Next: Cryptographic Services,  Prev: Data Compression and Archiving,  Up: The Python Standard Library

5.13 File Formats
=================

The modules described in this chapter parse various miscellaneous file
formats that aren't markup languages or are related to e-mail.

* Menu:

* csv: csv --- CSV File Reading and Writing. CSV File Reading and Writing
* ConfigParser: ConfigParser --- Configuration file parser. Configuration file parser
* robotparser: robotparser --- Parser for robots txt. Parser for robots.txt
* netrc: netrc --- netrc file processing. netrc file processing
* xdrlib: xdrlib --- Encode and decode XDR data. Encode and decode XDR data
* plistlib: plistlib --- Generate and parse Mac OS X plist files. Generate and parse Mac OS X .plist files

csv --- CSV File Reading and Writing

* Module Contents: Module Contents<2>.
* Dialects and Formatting Parameters::
* Reader Objects::
* Writer Objects::
* Examples: Examples<4>.

ConfigParser --- Configuration file parser

* RawConfigParser Objects::
* ConfigParser Objects::
* SafeConfigParser Objects::
* Examples: Examples<5>.

netrc --- netrc file processing

* netrc Objects::

xdrlib --- Encode and decode XDR data

* Packer Objects::
* Unpacker Objects::
* Exceptions: Exceptions<3>.

plistlib --- Generate and parse Mac OS X .plist files

* Examples: Examples<6>.


File: python.info,  Node: csv --- CSV File Reading and Writing,  Next: ConfigParser --- Configuration file parser,  Up: File Formats

5.13.1 `csv' -- CSV File Reading and Writing
--------------------------------------------

New in version 2.3.

  The so-called CSV (Comma Separated Values) format is the most common
import and export format for spreadsheets and databases.  There is no
"CSV standard", so the format is operationally defined by the many
applications which read and write it.  The lack of a standard means
that subtle differences often exist in the data produced and consumed
by different applications.  These differences can make it annoying to
process CSV files from multiple sources.  Still, while the delimiters
and quoting characters vary, the overall format is similar enough that
it is possible to write a single module which can efficiently manipulate
such data, hiding the details of reading and writing the data from the
programmer.

  The *note csv: 77. module implements classes to read and write
tabular data in CSV format.  It allows programmers to say, "write this
data in the format preferred by Excel," or "read data from this file
which was generated by Excel," without knowing the precise details of
the CSV format used by Excel.  Programmers can also describe the CSV
formats understood by other applications or define their own
special-purpose CSV formats.

  The *note csv: 77. module's *note reader: ff8. and *note writer: 43e.
objects read and write sequences.  Programmers can also read and write
data in dictionary form using the *note DictReader: ff9. and *note
DictWriter: ffa. classes.

     Note: This version of the *note csv: 77. module doesn't support
     Unicode input.  Also, there are currently some issues regarding
     ASCII NUL characters.  Accordingly, all input should be UTF-8 or
     printable ASCII to be safe; see the examples in section *note
     Examples: ffb.

See also
........

PEP 305(1) - CSV File API
     The Python Enhancement Proposal which proposed this addition to
     Python.

* Menu:

* Module Contents: Module Contents<2>.
* Dialects and Formatting Parameters::
* Reader Objects::
* Writer Objects::
* Examples: Examples<4>.

  ---------- Footnotes ----------

  (1) http://www.python.org/dev/peps/pep-0305


File: python.info,  Node: Module Contents<2>,  Next: Dialects and Formatting Parameters,  Up: csv --- CSV File Reading and Writing

5.13.1.1 Module Contents
........................

The *note csv: 77. module defines the following functions:

 -- Function: csv.reader (csvfile, dialect='excel', **fmtparams)
     Return a reader object which will iterate over lines in the given
     _csvfile_.  _csvfile_ can be any object which supports the *note
     iterator: 869. protocol and returns a string each time its
     `next()' method is called -- file objects and list objects are
     both suitable.   If _csvfile_ is a file object, it must be opened
     with the 'b' flag on platforms where that makes a difference.  An
     optional _dialect_ parameter can be given which is used to define
     a set of parameters specific to a particular CSV dialect.  It may
     be an instance of a subclass of the *note Dialect: ffe. class or
     one of the strings returned by the *note list_dialects(): fff.
     function.  The other optional _fmtparams_ keyword arguments can be
     given to override individual formatting parameters in the current
     dialect.  For full details about the dialect and formatting
     parameters, see section *note Dialects and Formatting Parameters:
     1000.

     Each row read from the csv file is returned as a list of strings.
     No automatic data type conversion is performed.

     A short usage example:

         >>> import csv
         >>> with open('eggs.csv', 'rb') as csvfile:
         ...     spamreader = csv.reader(csvfile, delimiter=' ', quotechar='|')
         ...     for row in spamreader:
         ...         print ', '.join(row)
         Spam, Spam, Spam, Spam, Spam, Baked Beans
         Spam, Lovely Spam, Wonderful Spam

     Changed in version 2.5: The parser is now stricter with respect to
     multi-line quoted fields. Previously, if a line ended within a
     quoted field without a terminating newline character, a newline
     would be inserted into the returned field. This behavior caused
     problems when reading files which contained carriage return
     characters within fields.  The behavior was changed to return the
     field without inserting newlines. As a consequence, if newlines
     embedded within fields are important, the input should be split
     into lines in a manner which preserves the newline characters.

 -- Function: csv.writer (csvfile, dialect='excel', **fmtparams)
     Return a writer object responsible for converting the user's data
     into delimited strings on the given file-like object.  _csvfile_
     can be any object with a `write()' method.  If _csvfile_ is a file
     object, it must be opened with the 'b' flag on platforms where
     that makes a difference.  An optional _dialect_ parameter can be
     given which is used to define a set of parameters specific to a
     particular CSV dialect.  It may be an instance of a subclass of the
     *note Dialect: ffe. class or one of the strings returned by the
     *note list_dialects(): fff. function.  The other optional
     _fmtparams_ keyword arguments can be given to override individual
     formatting parameters in the current dialect.  For full details
     about the dialect and formatting parameters, see section *note
     Dialects and Formatting Parameters: 1000. To make it as easy as
     possible to interface with modules which implement the DB API, the
     value *note None: 393. is written as the empty string.  While this
     isn't a reversible transformation, it makes it easier to dump SQL
     NULL data values to CSV files without preprocessing the data
     returned from a `cursor.fetch*' call.  All other non-string data
     are stringified with *note str(): 1e7. before being written.

     A short usage example:

         import csv
         with open('eggs.csv', 'wb') as csvfile:
             spamwriter = csv.writer(csvfile, delimiter=' ',
                                     quotechar='|', quoting=csv.QUOTE_MINIMAL)
             spamwriter.writerow(['Spam'] * 5 + ['Baked Beans'])
             spamwriter.writerow(['Spam', 'Lovely Spam', 'Wonderful Spam'])



 -- Function: csv.register_dialect (name[, dialect], **fmtparams)
     Associate _dialect_ with _name_.  _name_ must be a string or
     Unicode object. The dialect can be specified either by passing a
     sub-class of *note Dialect: ffe, or by _fmtparams_ keyword
     arguments, or both, with keyword arguments overriding parameters
     of the dialect. For full details about the dialect and formatting
     parameters, see section *note Dialects and Formatting Parameters:
     1000.

 -- Function: csv.unregister_dialect (name)
     Delete the dialect associated with _name_ from the dialect
     registry.  An *note Error: 1003. is raised if _name_ is not a
     registered dialect name.

 -- Function: csv.get_dialect (name)
     Return the dialect associated with _name_.  An *note Error: 1003.
     is raised if _name_ is not a registered dialect name.

     Changed in version 2.5: This function now returns an immutable
     *note Dialect: ffe.  Previously an instance of the requested
     dialect was returned.  Users could modify the underlying class,
     changing the behavior of active readers and writers.

 -- Function: csv.list_dialects ()
     Return the names of all registered dialects.

 -- Function: csv.field_size_limit ([new_limit])
     Returns the current maximum field size allowed by the parser. If
     _new_limit_ is given, this becomes the new limit.

     New in version 2.5.

  The *note csv: 77. module defines the following classes:

 -- Class: csv.DictReader (csvfile, fieldnames=None, restkey=None,
          restval=None, dialect='excel', *args, **kwds)
     Create an object which operates like a regular reader but maps the
     information read into a dict whose keys are given by the optional
     _fieldnames_ parameter.  If the _fieldnames_ parameter is omitted,
     the values in the first row of the _csvfile_ will be used as the
     fieldnames.  If the row read has more fields than the fieldnames
     sequence, the remaining data is added as a sequence keyed by the
     value of _restkey_.  If the row read has fewer fields than the
     fieldnames sequence, the remaining keys take the value of the
     optional _restval_ parameter.  Any other optional or keyword
     arguments are passed to the underlying *note reader: ff8. instance.

 -- Class: csv.DictWriter (csvfile, fieldnames, restval='',
          extrasaction='raise', dialect='excel', *args, **kwds)
     Create an object which operates like a regular writer but maps
     dictionaries onto output rows.  The _fieldnames_ parameter
     identifies the order in which values in the dictionary passed to
     the `writerow()' method are written to the _csvfile_.  The
     optional _restval_ parameter specifies the value to be written if
     the dictionary is missing a key in _fieldnames_.  If the
     dictionary passed to the `writerow()' method contains a key not
     found in _fieldnames_, the optional _extrasaction_ parameter
     indicates what action to take.  If it is set to `'raise'' a *note
     ValueError: 233. is raised.  If it is set to `'ignore'', extra
     values in the dictionary are ignored.  Any other optional or
     keyword arguments are passed to the underlying *note writer: 43e.
     instance.

     Note that unlike the *note DictReader: ff9. class, the
     _fieldnames_ parameter of the *note DictWriter: ffa. is not
     optional.  Since Python's *note dict: 2fe. objects are not
     ordered, there is not enough information available to deduce the
     order in which the row should be written to the _csvfile_.

 -- Class: csv.Dialect
     The *note Dialect: ffe. class is a container class relied on
     primarily for its attributes, which are used to define the
     parameters for a specific *note reader: ff8. or *note writer: 43e.
     instance.

 -- Class: csv.excel
     The *note excel: 1006. class defines the usual properties of an
     Excel-generated CSV file.  It is registered with the dialect name
     `'excel''.

 -- Class: csv.excel_tab
     The *note excel_tab: 1007. class defines the usual properties of
     an Excel-generated TAB-delimited file.  It is registered with the
     dialect name `'excel-tab''.

 -- Class: csv.Sniffer
     The *note Sniffer: 1008. class is used to deduce the format of a
     CSV file.

     The *note Sniffer: 1008. class provides two methods:

      -- Method: sniff (sample, delimiters=None)
          Analyze the given _sample_ and return a *note Dialect: ffe.
          subclass reflecting the parameters found.  If the optional
          _delimiters_ parameter is given, it is interpreted as a
          string containing possible valid delimiter characters.

      -- Method: has_header (sample)
          Analyze the sample text (presumed to be in CSV format) and
          return *note True: 3a9. if the first row appears to be a
          series of column headers.

  An example for *note Sniffer: 1008. use:

    with open('example.csv', 'rb') as csvfile:
        dialect = csv.Sniffer().sniff(csvfile.read(1024))
        csvfile.seek(0)
        reader = csv.reader(csvfile, dialect)
        # ... process CSV file contents here ...

The *note csv: 77. module defines the following constants:

 -- Data: csv.QUOTE_ALL
     Instructs *note writer: 43e. objects to quote all fields.

 -- Data: csv.QUOTE_MINIMAL
     Instructs *note writer: 43e. objects to only quote those fields
     which contain special characters such as _delimiter_, _quotechar_
     or any of the characters in _lineterminator_.

 -- Data: csv.QUOTE_NONNUMERIC
     Instructs *note writer: 43e. objects to quote all non-numeric
     fields.

     Instructs the reader to convert all non-quoted fields to type
     _float_.

 -- Data: csv.QUOTE_NONE
     Instructs *note writer: 43e. objects to never quote fields.  When
     the current _delimiter_ occurs in output data it is preceded by
     the current _escapechar_ character.  If _escapechar_ is not set,
     the writer will raise *note Error: 1003. if any characters that
     require escaping are encountered.

     Instructs *note reader: ff8. to perform no special processing of
     quote characters.

  The *note csv: 77. module defines the following exception:

 -- Exception: csv.Error
     Raised by any of the functions when an error is detected.


File: python.info,  Node: Dialects and Formatting Parameters,  Next: Reader Objects,  Prev: Module Contents<2>,  Up: csv --- CSV File Reading and Writing

5.13.1.2 Dialects and Formatting Parameters
...........................................

To make it easier to specify the format of input and output records,
specific formatting parameters are grouped together into dialects.  A
dialect is a subclass of the *note Dialect: ffe. class having a set of
specific methods and a single `validate()' method.  When creating *note
reader: ff8. or *note writer: 43e. objects, the programmer can specify
a string or a subclass of the *note Dialect: ffe. class as the dialect
parameter.  In addition to, or instead of, the _dialect_ parameter, the
programmer can also specify individual formatting parameters, which
have the same names as the attributes defined below for the *note
Dialect: ffe. class.

  Dialects support the following attributes:

 -- Attribute: Dialect.delimiter
     A one-character string used to separate fields.  It defaults to
     `',''.

 -- Attribute: Dialect.doublequote
     Controls how instances of _quotechar_ appearing inside a field
     should be themselves be quoted.  When *note True: 3a9, the
     character is doubled. When *note False: 3aa, the _escapechar_ is
     used as a prefix to the _quotechar_.  It defaults to *note True:
     3a9.

     On output, if _doublequote_ is *note False: 3aa. and no
     _escapechar_ is set, *note Error: 1003. is raised if a _quotechar_
     is found in a field.

 -- Attribute: Dialect.escapechar
     A one-character string used by the writer to escape the
     _delimiter_ if _quoting_ is set to *note QUOTE_NONE: 100e. and the
     _quotechar_ if _doublequote_ is *note False: 3aa. On reading, the
     _escapechar_ removes any special meaning from the following
     character. It defaults to *note None: 393, which disables escaping.

 -- Attribute: Dialect.lineterminator
     The string used to terminate lines produced by the *note writer:
     43e. It defaults to `'\r\n''.

          Note: The *note reader: ff8. is hard-coded to recognise
          either `'\r'' or `'\n'' as end-of-line, and ignores
          _lineterminator_. This behavior may change in the future.

 -- Attribute: Dialect.quotechar
     A one-character string used to quote fields containing special
     characters, such as the _delimiter_ or _quotechar_, or which
     contain new-line characters.  It defaults to `'"''.

 -- Attribute: Dialect.quoting
     Controls when quotes should be generated by the writer and
     recognised by the reader.  It can take on any of the `QUOTE_*'
     constants (see section *note Module Contents: ffd.) and defaults
     to *note QUOTE_MINIMAL: 100c.

 -- Attribute: Dialect.skipinitialspace
     When *note True: 3a9, whitespace immediately following the
     _delimiter_ is ignored.  The default is *note False: 3aa.

 -- Attribute: Dialect.strict
     When `True', raise exception *note Error: 1003. on bad CSV input.
     The default is `False'.


File: python.info,  Node: Reader Objects,  Next: Writer Objects,  Prev: Dialects and Formatting Parameters,  Up: csv --- CSV File Reading and Writing

5.13.1.3 Reader Objects
.......................

Reader objects (*note DictReader: ff9. instances and objects returned
by the *note reader(): ff8. function) have the following public methods:

 -- Method: csvreader.next ()
     Return the next row of the reader's iterable object as a list,
     parsed according to the current dialect.

  Reader objects have the following public attributes:

 -- Attribute: csvreader.dialect
     A read-only description of the dialect in use by the parser.

 -- Attribute: csvreader.line_num
     The number of lines read from the source iterator. This is not the
     same as the number of records returned, as records can span
     multiple lines.

     New in version 2.5.

  DictReader objects have the following public attribute:

 -- Attribute: csvreader.fieldnames
     If not passed as a parameter when creating the object, this
     attribute is initialized upon first access or when the first
     record is read from the file.

     Changed in version 2.6.


File: python.info,  Node: Writer Objects,  Next: Examples<4>,  Prev: Reader Objects,  Up: csv --- CSV File Reading and Writing

5.13.1.4 Writer Objects
.......................

`Writer' objects (*note DictWriter: ffa. instances and objects returned
by the *note writer(): 43e. function) have the following public
methods.  A _row_ must be a sequence of strings or numbers for `Writer'
objects and a dictionary mapping fieldnames to strings or numbers (by
passing them through *note str(): 1e7.  first) for *note DictWriter:
ffa. objects.  Note that complex numbers are written out surrounded by
parens. This may cause some problems for other programs which read CSV
files (assuming they support complex numbers at all).

 -- Method: csvwriter.writerow (row)
     Write the _row_ parameter to the writer's file object, formatted
     according to the current dialect.

 -- Method: csvwriter.writerows (rows)
     Write all the _rows_ parameters (a list of _row_ objects as
     described above) to the writer's file object, formatted according
     to the current dialect.

  Writer objects have the following public attribute:

 -- Attribute: csvwriter.dialect
     A read-only description of the dialect in use by the writer.

  DictWriter objects have the following public method:

 -- Method: DictWriter.writeheader ()
     Write a row with the field names (as specified in the constructor).

     New in version 2.7.


File: python.info,  Node: Examples<4>,  Prev: Writer Objects,  Up: csv --- CSV File Reading and Writing

5.13.1.5 Examples
.................

The simplest example of reading a CSV file:

    import csv
    with open('some.csv', 'rb') as f:
        reader = csv.reader(f)
        for row in reader:
            print row

Reading a file with an alternate format:

    import csv
    with open('passwd', 'rb') as f:
        reader = csv.reader(f, delimiter=':', quoting=csv.QUOTE_NONE)
        for row in reader:
            print row

The corresponding simplest possible writing example is:

    import csv
    with open('some.csv', 'wb') as f:
        writer = csv.writer(f)
        writer.writerows(someiterable)

Registering a new dialect:

    import csv
    csv.register_dialect('unixpwd', delimiter=':', quoting=csv.QUOTE_NONE)
    with open('passwd', 'rb') as f:
        reader = csv.reader(f, 'unixpwd')

A slightly more advanced use of the reader -- catching and reporting
errors:

    import csv, sys
    filename = 'some.csv'
    with open(filename, 'rb') as f:
        reader = csv.reader(f)
        try:
            for row in reader:
                print row
        except csv.Error as e:
            sys.exit('file %s, line %d: %s' % (filename, reader.line_num, e))

And while the module doesn't directly support parsing strings, it can
easily be done:

    import csv
    for row in csv.reader(['one,two,three']):
        print row

The *note csv: 77. module doesn't directly support reading and writing
Unicode, but it is 8-bit-clean save for some problems with ASCII NUL
characters.  So you can write functions or classes that handle the
encoding and decoding for you as long as you avoid encodings like
UTF-16 that use NULs.  UTF-8 is recommended.

  `unicode_csv_reader()' below is a *note generator: 5cd. that wraps
*note csv.reader: ff8.  to handle Unicode CSV data (a list of Unicode
strings).  `utf_8_encoder()' is a *note generator: 5cd. that encodes
the Unicode strings as UTF-8, one string (or row) at a time.  The
encoded strings are parsed by the CSV reader, and
`unicode_csv_reader()' decodes the UTF-8-encoded cells back into
Unicode:

    import csv

    def unicode_csv_reader(unicode_csv_data, dialect=csv.excel, **kwargs):
        # csv.py doesn't do Unicode; encode temporarily as UTF-8:
        csv_reader = csv.reader(utf_8_encoder(unicode_csv_data),
                                dialect=dialect, **kwargs)
        for row in csv_reader:
            # decode UTF-8 back to Unicode, cell by cell:
            yield [unicode(cell, 'utf-8') for cell in row]

    def utf_8_encoder(unicode_csv_data):
        for line in unicode_csv_data:
            yield line.encode('utf-8')

For all other encodings the following `UnicodeReader' and
`UnicodeWriter' classes can be used. They take an additional _encoding_
parameter in their constructor and make sure that the data passes the
real reader or writer encoded as UTF-8:

    import csv, codecs, cStringIO

    class UTF8Recoder:
        """
        Iterator that reads an encoded stream and reencodes the input to UTF-8
        """
        def __init__(self, f, encoding):
            self.reader = codecs.getreader(encoding)(f)

        def __iter__(self):
            return self

        def next(self):
            return self.reader.next().encode("utf-8")

    class UnicodeReader:
        """
        A CSV reader which will iterate over lines in the CSV file "f",
        which is encoded in the given encoding.
        """

        def __init__(self, f, dialect=csv.excel, encoding="utf-8", **kwds):
            f = UTF8Recoder(f, encoding)
            self.reader = csv.reader(f, dialect=dialect, **kwds)

        def next(self):
            row = self.reader.next()
            return [unicode(s, "utf-8") for s in row]

        def __iter__(self):
            return self

    class UnicodeWriter:
        """
        A CSV writer which will write rows to CSV file "f",
        which is encoded in the given encoding.
        """

        def __init__(self, f, dialect=csv.excel, encoding="utf-8", **kwds):
            # Redirect output to a queue
            self.queue = cStringIO.StringIO()
            self.writer = csv.writer(self.queue, dialect=dialect, **kwds)
            self.stream = f
            self.encoder = codecs.getincrementalencoder(encoding)()

        def writerow(self, row):
            self.writer.writerow([s.encode("utf-8") for s in row])
            # Fetch UTF-8 output from the queue ...
            data = self.queue.getvalue()
            data = data.decode("utf-8")
            # ... and reencode it into the target encoding
            data = self.encoder.encode(data)
            # write to the target stream
            self.stream.write(data)
            # empty queue
            self.queue.truncate(0)

        def writerows(self, rows):
            for row in rows:
                self.writerow(row)



File: python.info,  Node: ConfigParser --- Configuration file parser,  Next: robotparser --- Parser for robots txt,  Prev: csv --- CSV File Reading and Writing,  Up: File Formats

5.13.2 `ConfigParser' -- Configuration file parser
--------------------------------------------------

     Note: The *note ConfigParser: 6d. module has been renamed to
     `configparser' in Python 3.  The *note 2to3: bbc. tool will
     automatically adapt imports when converting your sources to Python
     3.

This module defines the class *note ConfigParser: 6d.   The *note
ConfigParser: 6d.  class implements a basic configuration file parser
language which provides a structure similar to what you would find on
Microsoft Windows INI files.  You can use this to write Python programs
which can be customized by end users easily.

     Note: This library does _not_ interpret or write the value-type
     prefixes used in the Windows Registry extended version of INI
     syntax.

See also
........

Module *note shlex: 153.
     Support for a creating Unix shell-like mini-languages which can be
     used as an alternate format for application configuration files.

Module *note json: fc.
     The json module implements a subset of JavaScript syntax which can
     also be used for this purpose.

  The configuration file consists of sections, led by a `[section]'
header and followed by `name: value' entries, with continuations in the
style of RFC 822(1) (see section 3.1.1, "LONG HEADER FIELDS");
`name=value' is also accepted.  Note that leading whitespace is removed
from values. The optional values can contain format strings which refer
to other values in the same section, or values in a special `DEFAULT'
section.  Additional defaults can be provided on initialization and
retrieval.  Lines beginning with `'#'' or `';'' are ignored and may be
used to provide comments.

  Configuration files may include comments, prefixed by specific
characters (`#' and `;').  Comments may appear on their own in an
otherwise empty line, or may be entered in lines holding values or
section names.  In the latter case, they need to be preceded by a
whitespace character to be recognized as a comment.  (For backwards
compatibility, only `;' starts an inline comment, while `#' does not.)

  On top of the core functionality, *note SafeConfigParser: 1025.
supports interpolation.  This means values can contain format strings
which refer to other values in the same section, or values in a special
`DEFAULT' section.  Additional defaults can be provided on
initialization.

  For example:

    [My Section]
    foodir: %(dir)s/whatever
    dir=frob
    long: this value continues
       in the next line

would resolve the `%(dir)s' to the value of `dir' (`frob' in this case).
All reference expansions are done on demand.

  Default values can be specified by passing them into the *note
ConfigParser: 6d.  constructor as a dictionary.  Additional defaults
may be passed into the `get()' method which will override all others.

  Sections are normally stored in a built-in dictionary. An alternative
dictionary type can be passed to the *note ConfigParser: 6d.
constructor. For example, if a dictionary type is passed that sorts its
keys, the sections will be sorted on write-back, as will be the keys
within each section.

 -- Class: ConfigParser.RawConfigParser ([defaults[, dict_type[,
          allow_no_value]]])
     The basic configuration object.  When _defaults_ is given, it is
     initialized into the dictionary of intrinsic defaults.  When
     _dict_type_ is given, it will be used to create the dictionary
     objects for the list of sections, for the options within a
     section, and for the default values.  When _allow_no_value_ is
     true (default: `False'), options without values are accepted; the
     value presented for these is `None'.

     This class does not support the magical interpolation behavior.

     All option names are passed through the *note optionxform(): 1027.
     method.  Its default implementation converts option names to lower
     case.

     New in version 2.3.

     Changed in version 2.6: _dict_type_ was added.

     Changed in version 2.7: The default _dict_type_ is *note
     collections.OrderedDict: 1b5.  _allow_no_value_ was added.

 -- Class: ConfigParser.ConfigParser ([defaults[, dict_type[,
          allow_no_value]]])
     Derived class of *note RawConfigParser: 1026. that implements the
     magical interpolation feature and adds optional arguments to the
     *note get(): 1029. and *note items(): 102a. methods.  The values
     in _defaults_ must be appropriate for the `%()s' string
     interpolation.  Note that ___name___ is an intrinsic default; its
     value is the section name, and will override any value provided in
     _defaults_.

     All option names used in interpolation will be passed through the
     `optionxform()' method just like any other option name reference.
     Using the default implementation of `optionxform()', the values
     `foo %(bar)s' and `foo %(BAR)s' are equivalent.

     New in version 2.3.

     Changed in version 2.6: _dict_type_ was added.

     Changed in version 2.7: The default _dict_type_ is *note
     collections.OrderedDict: 1b5.  _allow_no_value_ was added.

 -- Class: ConfigParser.SafeConfigParser ([defaults[, dict_type[,
          allow_no_value]]])
     Derived class of *note ConfigParser: 6d. that implements a
     more-sane variant of the magical interpolation feature.  This
     implementation is more predictable as well. New applications
     should prefer this version if they don't need to be compatible
     with older versions of Python.

     New in version 2.3.

     Changed in version 2.6: _dict_type_ was added.

     Changed in version 2.7: The default _dict_type_ is *note
     collections.OrderedDict: 1b5.  _allow_no_value_ was added.

 -- Exception: ConfigParser.Error
     Base class for all other configparser exceptions.

 -- Exception: ConfigParser.NoSectionError
     Exception raised when a specified section is not found.

 -- Exception: ConfigParser.DuplicateSectionError
     Exception raised if `add_section()' is called with the name of a
     section that is already present.

 -- Exception: ConfigParser.NoOptionError
     Exception raised when a specified option is not found in the
     specified  section.

 -- Exception: ConfigParser.InterpolationError
     Base class for exceptions raised when problems occur performing
     string interpolation.

 -- Exception: ConfigParser.InterpolationDepthError
     Exception raised when string interpolation cannot be completed
     because the number of iterations exceeds *note
     MAX_INTERPOLATION_DEPTH: 1031. Subclass of *note
     InterpolationError: 102f.

 -- Exception: ConfigParser.InterpolationMissingOptionError
     Exception raised when an option referenced from a value does not
     exist. Subclass of *note InterpolationError: 102f.

     New in version 2.3.

 -- Exception: ConfigParser.InterpolationSyntaxError
     Exception raised when the source text into which substitutions are
     made does not conform to the required syntax. Subclass of *note
     InterpolationError: 102f.

     New in version 2.3.

 -- Exception: ConfigParser.MissingSectionHeaderError
     Exception raised when attempting to parse a file which has no
     section headers.

 -- Exception: ConfigParser.ParsingError
     Exception raised when errors occur attempting to parse a file.

 -- Data: ConfigParser.MAX_INTERPOLATION_DEPTH
     The maximum depth for recursive interpolation for `get()' when the
     _raw_ parameter is false.  This is relevant only for the *note
     ConfigParser: 6d. class.

See also
........

Module *note shlex: 153.
     Support for a creating Unix shell-like mini-languages which can be
     used as an alternate format for application configuration files.

* Menu:

* RawConfigParser Objects::
* ConfigParser Objects::
* SafeConfigParser Objects::
* Examples: Examples<5>.

  ---------- Footnotes ----------

  (1) http://tools.ietf.org/html/rfc822.html


File: python.info,  Node: RawConfigParser Objects,  Next: ConfigParser Objects,  Up: ConfigParser --- Configuration file parser

5.13.2.1 RawConfigParser Objects
................................

*note RawConfigParser: 1026. instances have the following methods:

 -- Method: RawConfigParser.defaults ()
     Return a dictionary containing the instance-wide defaults.

 -- Method: RawConfigParser.sections ()
     Return a list of the sections available; `DEFAULT' is not included
     in the list.

 -- Method: RawConfigParser.add_section (section)
     Add a section named _section_ to the instance.  If a section by
     the given name already exists, *note DuplicateSectionError: 102d.
     is raised. If the name `DEFAULT' (or any of it's case-insensitive
     variants) is passed, *note ValueError: 233. is raised.

 -- Method: RawConfigParser.has_section (section)
     Indicates whether the named section is present in the
     configuration. The `DEFAULT' section is not acknowledged.

 -- Method: RawConfigParser.options (section)
     Returns a list of options available in the specified _section_.

 -- Method: RawConfigParser.has_option (section, option)
     If the given section exists, and contains the given option, return
     *note True: 3a9.; otherwise return *note False: 3aa.

     New in version 1.6.

 -- Method: RawConfigParser.read (filenames)
     Attempt to read and parse a list of filenames, returning a list of
     filenames which were successfully parsed.  If _filenames_ is a
     string or Unicode string, it is treated as a single filename. If a
     file named in _filenames_ cannot be opened, that file will be
     ignored.  This is designed so that you can specify a list of
     potential configuration file locations (for example, the current
     directory, the user's home directory, and some system-wide
     directory), and all existing configuration files in the list will
     be read.  If none of the named files exist, the *note
     ConfigParser: 6d. instance will contain an empty dataset.  An
     application which requires initial values to be loaded from a file
     should load the required file or files using *note readfp(): 103f.
     before calling *note read(): 103e.  for any optional files:

         import ConfigParser, os

         config = ConfigParser.ConfigParser()
         config.readfp(open('defaults.cfg'))
         config.read(['site.cfg', os.path.expanduser('~/.myapp.cfg')])

     Changed in version 2.4: Returns list of successfully parsed
     filenames.

 -- Method: RawConfigParser.readfp (fp[, filename])
     Read and parse configuration data from the file or file-like
     object in _fp_ (only the *note readline(): 144. method is used).
     If _filename_ is omitted and _fp_ has a `name' attribute, that is
     used for _filename_; the default is `<???>'.

 -- Method: RawConfigParser.get (section, option)
     Get an _option_ value for the named _section_.

 -- Method: RawConfigParser.getint (section, option)
     A convenience method which coerces the _option_ in the specified
     _section_ to an integer.

 -- Method: RawConfigParser.getfloat (section, option)
     A convenience method which coerces the _option_ in the specified
     _section_ to a floating point number.

 -- Method: RawConfigParser.getboolean (section, option)
     A convenience method which coerces the _option_ in the specified
     _section_ to a Boolean value.  Note that the accepted values for
     the option are `"1"', `"yes"', `"true"', and `"on"', which cause
     this method to return `True', and `"0"', `"no"', `"false"', and
     `"off"', which cause it to return `False'.  These string values
     are checked in a case-insensitive manner.  Any other value will
     cause it to raise *note ValueError: 233.

 -- Method: RawConfigParser.items (section)
     Return a list of `(name, value)' pairs for each option in the
     given _section_.

 -- Method: RawConfigParser.set (section, option, value)
     If the given section exists, set the given option to the specified
     value; otherwise raise *note NoSectionError: 102c.  While it is
     possible to use *note RawConfigParser: 1026. (or *note
     ConfigParser: 6d. with _raw_ parameters set to true) for
     _internal_ storage of non-string values, full functionality
     (including interpolation and output to files) can only be achieved
     using string values.

     New in version 1.6.

 -- Method: RawConfigParser.write (fileobject)
     Write a representation of the configuration to the specified file
     object.  This representation can be parsed by a future *note
     read(): 103e. call.

     New in version 1.6.

 -- Method: RawConfigParser.remove_option (section, option)
     Remove the specified _option_ from the specified _section_. If the
     section does not exist, raise *note NoSectionError: 102c.  If the
     option existed to be removed, return *note True: 3a9.; otherwise
     return *note False: 3aa.

     New in version 1.6.

 -- Method: RawConfigParser.remove_section (section)
     Remove the specified _section_ from the configuration. If the
     section in fact existed, return `True'. Otherwise return `False'.

 -- Method: RawConfigParser.optionxform (option)
     Transforms the option name _option_ as found in an input file or
     as passed in by client code to the form that should be used in the
     internal structures.  The default implementation returns a
     lower-case version of _option_; subclasses may override this or
     client code can set an attribute of this name on instances to
     affect this behavior.

     You don't necessarily need to subclass a ConfigParser to use this
     method, you can also re-set it on an instance, to a function that
     takes a string argument.  Setting it to `str', for example, would
     make option names case sensitive:

         cfgparser = ConfigParser()
         ...
         cfgparser.optionxform = str

     Note that when reading configuration files, whitespace around the
     option names are stripped before *note optionxform(): 1027. is
     called.


File: python.info,  Node: ConfigParser Objects,  Next: SafeConfigParser Objects,  Prev: RawConfigParser Objects,  Up: ConfigParser --- Configuration file parser

5.13.2.2 ConfigParser Objects
.............................

The *note ConfigParser: 6d. class extends some methods of the *note
RawConfigParser: 1026. interface, adding some optional arguments.

 -- Method: ConfigParser.get (section, option[, raw[, vars]])
     Get an _option_ value for the named _section_.  If _vars_ is
     provided, it must be a dictionary.  The _option_ is looked up in
     _vars_ (if provided), _section_, and in _defaults_ in that order.

     All the `'%'' interpolations are expanded in the return values,
     unless the _raw_ argument is true.  Values for interpolation keys
     are looked up in the same manner as the option.

 -- Method: ConfigParser.items (section[, raw[, vars]])
     Return a list of `(name, value)' pairs for each option in the
     given _section_.  Optional arguments have the same meaning as for
     the *note get(): 1029. method.

     New in version 2.3.


File: python.info,  Node: SafeConfigParser Objects,  Next: Examples<5>,  Prev: ConfigParser Objects,  Up: ConfigParser --- Configuration file parser

5.13.2.3 SafeConfigParser Objects
.................................

The *note SafeConfigParser: 1025. class implements the same extended
interface as *note ConfigParser: 6d, with the following addition:

 -- Method: SafeConfigParser.set (section, option, value)
     If the given section exists, set the given option to the specified
     value; otherwise raise *note NoSectionError: 102c.  _value_ must
     be a string (*note str: 1e7.  or *note unicode: 1f2.); if not,
     *note TypeError: 215. is raised.

     New in version 2.4.


File: python.info,  Node: Examples<5>,  Prev: SafeConfigParser Objects,  Up: ConfigParser --- Configuration file parser

5.13.2.4 Examples
.................

An example of writing to a configuration file:

    import ConfigParser

    config = ConfigParser.RawConfigParser()

    # When adding sections or items, add them in the reverse order of
    # how you want them to be displayed in the actual file.
    # In addition, please note that using RawConfigParser's and the raw
    # mode of ConfigParser's respective set functions, you can assign
    # non-string values to keys internally, but will receive an error
    # when attempting to write to a file or when you get it in non-raw
    # mode. SafeConfigParser does not allow such assignments to take place.
    config.add_section('Section1')
    config.set('Section1', 'an_int', '15')
    config.set('Section1', 'a_bool', 'true')
    config.set('Section1', 'a_float', '3.1415')
    config.set('Section1', 'baz', 'fun')
    config.set('Section1', 'bar', 'Python')
    config.set('Section1', 'foo', '%(bar)s is %(baz)s!')

    # Writing our configuration file to 'example.cfg'
    with open('example.cfg', 'wb') as configfile:
        config.write(configfile)

An example of reading the configuration file again:

    import ConfigParser

    config = ConfigParser.RawConfigParser()
    config.read('example.cfg')

    # getfloat() raises an exception if the value is not a float
    # getint() and getboolean() also do this for their respective types
    a_float = config.getfloat('Section1', 'a_float')
    an_int = config.getint('Section1', 'an_int')
    print a_float + an_int

    # Notice that the next output does not interpolate '%(bar)s' or '%(baz)s'.
    # This is because we are using a RawConfigParser().
    if config.getboolean('Section1', 'a_bool'):
        print config.get('Section1', 'foo')

To get interpolation, you will need to use a *note ConfigParser: 6d. or
*note SafeConfigParser: 1025.:

    import ConfigParser

    config = ConfigParser.ConfigParser()
    config.read('example.cfg')

    # Set the third, optional argument of get to 1 if you wish to use raw mode.
    print config.get('Section1', 'foo', 0) # -> "Python is fun!"
    print config.get('Section1', 'foo', 1) # -> "%(bar)s is %(baz)s!"

    # The optional fourth argument is a dict with members that will take
    # precedence in interpolation.
    print config.get('Section1', 'foo', 0, {'bar': 'Documentation',
                                            'baz': 'evil'})

Defaults are available in all three types of ConfigParsers. They are
used in interpolation if an option used is not defined elsewhere.

    import ConfigParser

    # New instance with 'bar' and 'baz' defaulting to 'Life' and 'hard' each
    config = ConfigParser.SafeConfigParser({'bar': 'Life', 'baz': 'hard'})
    config.read('example.cfg')

    print config.get('Section1', 'foo') # -> "Python is fun!"
    config.remove_option('Section1', 'bar')
    config.remove_option('Section1', 'baz')
    print config.get('Section1', 'foo') # -> "Life is hard!"

The function `opt_move' below can be used to move options between
sections:

    def opt_move(config, section1, section2, option):
        try:
            config.set(section2, option, config.get(section1, option, 1))
        except ConfigParser.NoSectionError:
            # Create non-existent section
            config.add_section(section2)
            opt_move(config, section1, section2, option)
        else:
            config.remove_option(section1, option)

Some configuration files are known to include settings without values,
but which otherwise conform to the syntax supported by *note
ConfigParser: 6d.  The _allow_no_value_ parameter to the constructor
can be used to indicate that such values should be accepted:

    >>> import ConfigParser
    >>> import io

    >>> sample_config = """
    ... [mysqld]
    ... user = mysql
    ... pid-file = /var/run/mysqld/mysqld.pid
    ... skip-external-locking
    ... old_passwords = 1
    ... skip-bdb
    ... skip-innodb
    ... """
    >>> config = ConfigParser.RawConfigParser(allow_no_value=True)
    >>> config.readfp(io.BytesIO(sample_config))

    >>> # Settings with values are treated as before:
    >>> config.get("mysqld", "user")
    'mysql'

    >>> # Settings without values provide None:
    >>> config.get("mysqld", "skip-bdb")

    >>> # Settings which aren't specified still raise an error:
    >>> config.get("mysqld", "does-not-exist")
    Traceback (most recent call last):
      ...
    ConfigParser.NoOptionError: No option 'does-not-exist' in section: 'mysqld'



File: python.info,  Node: robotparser --- Parser for robots txt,  Next: netrc --- netrc file processing,  Prev: ConfigParser --- Configuration file parser,  Up: File Formats

5.13.3 `robotparser' --  Parser for robots.txt
----------------------------------------------

     Note: The *note robotparser: 14a. module has been renamed
     `urllib.robotparser' in Python 3.  The *note 2to3: bbc. tool will
     automatically adapt imports when converting your sources to Python
     3.

This module provides a single class, *note RobotFileParser: 1051, which
answers questions about whether or not a particular user agent can
fetch a URL on the Web site that published the `robots.txt' file.  For
more details on the structure of `robots.txt' files, see
<http://www.robotstxt.org/orig.html>.

 -- Class: robotparser.RobotFileParser (url='')
     This class provides methods to read, parse and answer questions
     about the `robots.txt' file at _url_.

      -- Method: set_url (url)
          Sets the URL referring to a `robots.txt' file.

      -- Method: read ()
          Reads the `robots.txt' URL and feeds it to the parser.

      -- Method: parse (lines)
          Parses the lines argument.

      -- Method: can_fetch (useragent, url)
          Returns `True' if the _useragent_ is allowed to fetch the
          _url_ according to the rules contained in the parsed
          `robots.txt' file.

      -- Method: mtime ()
          Returns the time the `robots.txt' file was last fetched.
          This is useful for long-running web spiders that need to
          check for new `robots.txt' files periodically.

      -- Method: modified ()
          Sets the time the `robots.txt' file was last fetched to the
          current time.

  The following example demonstrates basic use of the RobotFileParser
class.

    >>> import robotparser
    >>> rp = robotparser.RobotFileParser()
    >>> rp.set_url("http://www.musi-cal.com/robots.txt")
    >>> rp.read()
    >>> rp.can_fetch("*", "http://www.musi-cal.com/cgi-bin/search?city=San+Francisco")
    False
    >>> rp.can_fetch("*", "http://www.musi-cal.com/")
    True



File: python.info,  Node: netrc --- netrc file processing,  Next: xdrlib --- Encode and decode XDR data,  Prev: robotparser --- Parser for robots txt,  Up: File Formats

5.13.4 `netrc' -- netrc file processing
---------------------------------------

New in version 1.5.2.

  *Source code:* Lib/netrc.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note netrc: 121. class parses and encapsulates the netrc file
format used by the Unix *ftp* program and other FTP clients.

 -- Class: netrc.netrc ([file])
     A *note netrc: 121. instance or subclass instance encapsulates
     data from  a netrc file.  The initialization argument, if present,
     specifies the file to parse.  If no argument is given, the file
     `.netrc' in the user's home directory will be read.  Parse errors
     will raise *note NetrcParseError: 105b. with diagnostic
     information including the file name, line number, and terminating
     token.

 -- Exception: netrc.NetrcParseError
     Exception raised by the *note netrc: 121. class when syntactical
     errors are encountered in source text.  Instances of this
     exception provide three interesting attributes:  `msg' is a
     textual explanation of the error, `filename' is the name of the
     source file, and `lineno' gives the line number on which the error
     was found.

* Menu:

* netrc Objects::

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/netrc.py


File: python.info,  Node: netrc Objects,  Up: netrc --- netrc file processing

5.13.4.1 netrc Objects
......................

A *note netrc: 121. instance has the following methods:

 -- Method: netrc.authenticators (host)
     Return a 3-tuple `(login, account, password)' of authenticators
     for _host_.  If the netrc file did not contain an entry for the
     given host, return the tuple associated with the 'default' entry.
     If neither matching host nor default entry is available, return
     `None'.

 -- Method: netrc.__repr__ ()
     Dump the class data as a string in the format of a netrc file.
     (This discards comments and may reorder the entries.)

  Instances of *note netrc: 121. have public instance variables:

 -- Attribute: netrc.hosts
     Dictionary mapping host names to `(login, account, password)'
     tuples.  The 'default' entry, if any, is represented as a
     pseudo-host by that name.

 -- Attribute: netrc.macros
     Dictionary mapping macro names to string lists.

     Note: Passwords are limited to a subset of the ASCII character
     set. Versions of this module prior to 2.3 were extremely limited.
     Starting with 2.3, all ASCII punctuation is allowed in passwords.
     However, note that whitespace and non-printable characters are not
     allowed in passwords.  This is a limitation of the way the .netrc
     file is parsed and may be removed in the future.


File: python.info,  Node: xdrlib --- Encode and decode XDR data,  Next: plistlib --- Generate and parse Mac OS X plist files,  Prev: netrc --- netrc file processing,  Up: File Formats

5.13.5 `xdrlib' -- Encode and decode XDR data
---------------------------------------------

*Source code:* Lib/xdrlib.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  The *note xdrlib: 19f. module supports the External Data
Representation Standard as described in RFC 1014(2), written by Sun
Microsystems, Inc. June 1987.  It supports most of the data types
described in the RFC.

  The *note xdrlib: 19f. module defines two classes, one for packing
variables into XDR representation, and another for unpacking from XDR
representation.  There are also two exception classes.

 -- Class: xdrlib.Packer
     *note Packer: 1064. is the class for packing data into XDR
     representation. The *note Packer: 1064. class is instantiated with
     no arguments.

 -- Class: xdrlib.Unpacker (data)
     `Unpacker' is the complementary class which unpacks XDR data
     values from a string buffer.  The input buffer is given as _data_.

See also
........

RFC 1014(3) - XDR: External Data Representation Standard
     This RFC defined the encoding of data which was XDR at the time
     this module was originally written.  It has apparently been
     obsoleted by RFC 1832(4).

RFC 1832(5) - XDR: External Data Representation Standard
     Newer RFC that provides a revised definition of XDR.

* Menu:

* Packer Objects::
* Unpacker Objects::
* Exceptions: Exceptions<3>.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/xdrlib.py

  (2) http://tools.ietf.org/html/rfc1014.html

  (3) http://tools.ietf.org/html/rfc1014.html

  (4) http://tools.ietf.org/html/rfc1832.html

  (5) http://tools.ietf.org/html/rfc1832.html


File: python.info,  Node: Packer Objects,  Next: Unpacker Objects,  Up: xdrlib --- Encode and decode XDR data

5.13.5.1 Packer Objects
.......................

*note Packer: 1064. instances have the following methods:

 -- Method: Packer.get_buffer ()
     Returns the current pack buffer as a string.

 -- Method: Packer.reset ()
     Resets the pack buffer to the empty string.

  In general, you can pack any of the most common XDR data types by
calling the appropriate `pack_type()' method.  Each method takes a
single argument, the value to pack.  The following simple data type
packing methods are supported: `pack_uint()', `pack_int()',
`pack_enum()', `pack_bool()', `pack_uhyper()', and `pack_hyper()'.

 -- Method: Packer.pack_float (value)
     Packs the single-precision floating point number _value_.

 -- Method: Packer.pack_double (value)
     Packs the double-precision floating point number _value_.

  The following methods support packing strings, bytes, and opaque data:

 -- Method: Packer.pack_fstring (n, s)
     Packs a fixed length string, _s_.  _n_ is the length of the string
     but it is _not_ packed into the data buffer.  The string is padded
     with null bytes if necessary to guaranteed 4 byte alignment.

 -- Method: Packer.pack_fopaque (n, data)
     Packs a fixed length opaque data stream, similarly to *note
     pack_fstring(): 106c.

 -- Method: Packer.pack_string (s)
     Packs a variable length string, _s_.  The length of the string is
     first packed as an unsigned integer, then the string data is
     packed with *note pack_fstring(): 106c.

 -- Method: Packer.pack_opaque (data)
     Packs a variable length opaque data string, similarly to *note
     pack_string(): 106e.

 -- Method: Packer.pack_bytes (bytes)
     Packs a variable length byte stream, similarly to *note
     pack_string(): 106e.

  The following methods support packing arrays and lists:

 -- Method: Packer.pack_list (list, pack_item)
     Packs a _list_ of homogeneous items.  This method is useful for
     lists with an indeterminate size; i.e. the size is not available
     until the entire list has been walked.  For each item in the list,
     an unsigned integer `1' is packed first, followed by the data
     value from the list.  _pack_item_ is the function that is called
     to pack the individual item.  At the end of the list, an unsigned
     integer `0' is packed.

     For example, to pack a list of integers, the code might appear
     like this:

         import xdrlib
         p = xdrlib.Packer()
         p.pack_list([1, 2, 3], p.pack_int)



 -- Method: Packer.pack_farray (n, array, pack_item)
     Packs a fixed length list (_array_) of homogeneous items.  _n_ is
     the length of the list; it is _not_ packed into the buffer, but a
     *note ValueError: 233. exception is raised if `len(array)' is not
     equal to _n_.  As above, _pack_item_ is the function used to pack
     each element.

 -- Method: Packer.pack_array (list, pack_item)
     Packs a variable length _list_ of homogeneous items.  First, the
     length of the list is packed as an unsigned integer, then each
     element is packed as in *note pack_farray(): 1072. above.


File: python.info,  Node: Unpacker Objects,  Next: Exceptions<3>,  Prev: Packer Objects,  Up: xdrlib --- Encode and decode XDR data

5.13.5.2 Unpacker Objects
.........................

The *note Unpacker: 1065. class offers the following methods:

 -- Method: Unpacker.reset (data)
     Resets the string buffer with the given _data_.

 -- Method: Unpacker.get_position ()
     Returns the current unpack position in the data buffer.

 -- Method: Unpacker.set_position (position)
     Sets the data buffer unpack position to _position_.  You should be
     careful about using *note get_position(): 1077. and *note
     set_position(): 1078.

 -- Method: Unpacker.get_buffer ()
     Returns the current unpack data buffer as a string.

 -- Method: Unpacker.done ()
     Indicates unpack completion.  Raises an *note Error: 107b.
     exception if all of the data has not been unpacked.

  In addition, every data type that can be packed with a *note Packer:
1064, can be unpacked with an *note Unpacker: 1065.  Unpacking methods
are of the form `unpack_type()', and take no arguments.  They return
the unpacked object.

 -- Method: Unpacker.unpack_float ()
     Unpacks a single-precision floating point number.

 -- Method: Unpacker.unpack_double ()
     Unpacks a double-precision floating point number, similarly to
     *note unpack_float(): 107c.

  In addition, the following methods unpack strings, bytes, and opaque
data:

 -- Method: Unpacker.unpack_fstring (n)
     Unpacks and returns a fixed length string.  _n_ is the number of
     characters expected.  Padding with null bytes to guaranteed 4 byte
     alignment is assumed.

 -- Method: Unpacker.unpack_fopaque (n)
     Unpacks and returns a fixed length opaque data stream, similarly to
     *note unpack_fstring(): 107e.

 -- Method: Unpacker.unpack_string ()
     Unpacks and returns a variable length string.  The length of the
     string is first unpacked as an unsigned integer, then the string
     data is unpacked with *note unpack_fstring(): 107e.

 -- Method: Unpacker.unpack_opaque ()
     Unpacks and returns a variable length opaque data string,
     similarly to *note unpack_string(): 1080.

 -- Method: Unpacker.unpack_bytes ()
     Unpacks and returns a variable length byte stream, similarly to
     *note unpack_string(): 1080.

  The following methods support unpacking arrays and lists:

 -- Method: Unpacker.unpack_list (unpack_item)
     Unpacks and returns a list of homogeneous items.  The list is
     unpacked one element at a time by first unpacking an unsigned
     integer flag.  If the flag is `1', then the item is unpacked and
     appended to the list.  A flag of `0' indicates the end of the
     list.  _unpack_item_ is the function that is called to unpack the
     items.

 -- Method: Unpacker.unpack_farray (n, unpack_item)
     Unpacks and returns (as a list) a fixed length array of
     homogeneous items.  _n_ is number of list elements to expect in
     the buffer. As above, _unpack_item_ is the function used to unpack
     each element.

 -- Method: Unpacker.unpack_array (unpack_item)
     Unpacks and returns a variable length _list_ of homogeneous items.
     First, the length of the list is unpacked as an unsigned integer,
     then each element is unpacked as in *note unpack_farray(): 1084.
     above.


File: python.info,  Node: Exceptions<3>,  Prev: Unpacker Objects,  Up: xdrlib --- Encode and decode XDR data

5.13.5.3 Exceptions
...................

Exceptions in this module are coded as class instances:

 -- Exception: xdrlib.Error
     The base exception class.  *note Error: 107b. has a single public
     attribute `msg' containing the description of the error.

 -- Exception: xdrlib.ConversionError
     Class derived from *note Error: 107b.  Contains no additional
     instance variables.

  Here is an example of how you would catch one of these exceptions:

    import xdrlib
    p = xdrlib.Packer()
    try:
        p.pack_double(8.01)
    except xdrlib.ConversionError as instance:
        print 'packing the double failed:', instance.msg



File: python.info,  Node: plistlib --- Generate and parse Mac OS X plist files,  Prev: xdrlib --- Encode and decode XDR data,  Up: File Formats

5.13.6 `plistlib' -- Generate and parse Mac OS X `.plist' files
---------------------------------------------------------------

Changed in version 2.6: This module was previously only available in
the Mac-specific library, it is now available for all platforms.

  *Source code:* Lib/plistlib.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module provides an interface for reading and writing the
"property list" XML files used mainly by Mac OS X.

  The property list (`.plist') file format is a simple XML pickle
supporting basic object types, like dictionaries, lists, numbers and
strings.  Usually the top level object is a dictionary.

  Values can be strings, integers, floats, booleans, tuples, lists,
dictionaries (but only with string keys), *note Data: 108b. or *note
datetime.datetime: 2d7.  objects.  String values (including dictionary
keys) may be unicode strings - they will be written out as UTF-8.

  The `<data>' plist type is supported through the *note Data: 108b.
class.  This is a thin wrapper around a Python string.  Use *note Data:
108b. if your strings contain control characters.

See also
........

PList manual page(2)
     Apple's documentation of the file format.

  This module defines the following functions:

 -- Function: plistlib.readPlist (pathOrFile)
     Read a plist file. _pathOrFile_ may either be a file name or a
     (readable) file object.  Return the unpacked root object (which
     usually is a dictionary).

     The XML data is parsed using the Expat parser from *note
     xml.parsers.expat: 1a5.  - see its documentation for possible
     exceptions on ill-formed XML.  Unknown elements will simply be
     ignored by the plist parser.

 -- Function: plistlib.writePlist (rootObject, pathOrFile)
     Write _rootObject_ to a plist file. _pathOrFile_ may either be a
     file name or a (writable) file object.

     A *note TypeError: 215. will be raised if the object is of an
     unsupported type or a container that contains objects of
     unsupported types.

 -- Function: plistlib.readPlistFromString (data)
     Read a plist from a string.  Return the root object.

 -- Function: plistlib.writePlistToString (rootObject)
     Return _rootObject_ as a plist-formatted string.

 -- Function: plistlib.readPlistFromResource (path, restype='plst',
          resid=0)
     Read a plist from the resource with type _restype_ from the
     resource fork of _path_.  Availability: Mac OS X.

          Note: In Python 3.x, this function has been removed.

 -- Function: plistlib.writePlistToResource (rootObject, path,
          restype='plst', resid=0)
     Write _rootObject_ as a resource with type _restype_ to the
     resource fork of _path_.  Availability: Mac OS X.

          Note: In Python 3.x, this function has been removed.

  The following class is available:

 -- Class: plistlib.Data (data)
     Return a "data" wrapper object around the string _data_.  This is
     used in functions converting from/to plists to represent the
     `<data>' type available in plists.

     It has one attribute, `data', that can be used to retrieve the
     Python string stored in it.

* Menu:

* Examples: Examples<6>.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/plistlib.py

  (2)
http://developer.apple.com/documentation/Darwin/Reference/ManPages/man5/plist.5.html


File: python.info,  Node: Examples<6>,  Up: plistlib --- Generate and parse Mac OS X plist files

5.13.6.1 Examples
.................

Generating a plist:

    pl = dict(
        aString="Doodah",
        aList=["A", "B", 12, 32.1, [1, 2, 3]],
        aFloat = 0.1,
        anInt = 728,
        aDict=dict(
            anotherString="<hello & hi there!>",
            aUnicodeValue=u'M\xe4ssig, Ma\xdf',
            aTrueValue=True,
            aFalseValue=False,
        ),
        someData = Data("<binary gunk>"),
        someMoreData = Data("<lots of binary gunk>" * 10),
        aDate = datetime.datetime.fromtimestamp(time.mktime(time.gmtime())),
    )
    # unicode keys are possible, but a little awkward to use:
    pl[u'\xc5benraa'] = "That was a unicode key."
    writePlist(pl, fileName)

Parsing a plist:

    pl = readPlist(pathOrFile)
    print pl["aKey"]



File: python.info,  Node: Cryptographic Services,  Next: Generic Operating System Services,  Prev: File Formats,  Up: The Python Standard Library

5.14 Cryptographic Services
===========================

The modules described in this chapter implement various algorithms of a
cryptographic nature.  They are available at the discretion of the
installation.  Here's an overview:

* Menu:

* hashlib: hashlib --- Secure hashes and message digests. Secure hashes and message digests
* hmac: hmac --- Keyed-Hashing for Message Authentication. Keyed-Hashing for Message Authentication
* md5: md5 --- MD5 message digest algorithm. MD5 message digest algorithm
* sha: sha --- SHA-1 message digest algorithm. SHA-1 message digest algorithm


File: python.info,  Node: hashlib --- Secure hashes and message digests,  Next: hmac --- Keyed-Hashing for Message Authentication,  Up: Cryptographic Services

5.14.1 `hashlib' -- Secure hashes and message digests
-----------------------------------------------------

New in version 2.5.

  *Source code:* Lib/hashlib.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module implements a common interface to many different secure
hash and message digest algorithms.  Included are the FIPS secure hash
algorithms SHA1, SHA224, SHA256, SHA384, and SHA512 (defined in FIPS
180-2) as well as RSA's MD5 algorithm (defined in Internet RFC
1321(2)). The terms secure hash and message digest are interchangeable.
Older algorithms were called message digests.  The modern term is
secure hash.

     Note: If you want the adler32 or crc32 hash functions they are
     available in the *note zlib: 1ad. module.

     Warning: Some algorithms have known hash collision weaknesses, see
     the FAQ at the end.

  There is one constructor method named for each type of _hash_.  All
return a hash object with the same simple interface. For example: use
`sha1()' to create a SHA1 hash object. You can now feed this object
with arbitrary strings using the `update()' method.  At any point you
can ask it for the _digest_ of the concatenation of the strings fed to
it so far using the `digest()' or `hexdigest()' methods.

  Constructors for hash algorithms that are always present in this
module are *note md5(): 10d, `sha1()', `sha224()', `sha256()',
`sha384()', and `sha512()'.  Additional algorithms may also be
available depending upon the OpenSSL library that Python uses on your
platform.

  For example, to obtain the digest of the string `'Nobody inspects the
spammish repetition'':

    >>> import hashlib
    >>> m = hashlib.md5()
    >>> m.update("Nobody inspects")
    >>> m.update(" the spammish repetition")
    >>> m.digest()
    '\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'
    >>> m.digest_size
    16
    >>> m.block_size
    64

More condensed:

    >>> hashlib.sha224("Nobody inspects the spammish repetition").hexdigest()
    'a4337bc45a8fc544c03f52dc550cd6e1e87021bc896588bd79e901e2'

A generic *note new(): 122. constructor that takes the string name of
the desired algorithm as its first parameter also exists to allow
access to the above listed hashes as well as any other algorithms that
your OpenSSL library may offer.  The named constructors are much faster
than *note new(): 122. and should be preferred.

  Using *note new(): 122. with an algorithm provided by OpenSSL:

    >>> h = hashlib.new('ripemd160')
    >>> h.update("Nobody inspects the spammish repetition")
    >>> h.hexdigest()
    'cc4a5ce1b3df48aec5d22d1f16b894a0b894eccc'

This module provides the following constant attribute:

 -- Data: hashlib.algorithms
     A tuple providing the names of the hash algorithms guaranteed to be
     supported by this module.

     New in version 2.7.

  The following values are provided as constant attributes of the hash
objects returned by the constructors:

 -- Data: hash.digest_size
     The size of the resulting hash in bytes.

 -- Data: hash.block_size
     The internal block size of the hash algorithm in bytes.

  A hash object has the following methods:

 -- Method: hash.update (arg)
     Update the hash object with the string _arg_.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to
     `m.update(a+b)'.

     Changed in version 2.7.

 -- Method: hash.digest ()
     Return the digest of the strings passed to the *note update():
     109a. method so far.  This is a string of *note digest_size: 1098.
     bytes which may contain non-ASCII characters, including null bytes.

 -- Method: hash.hexdigest ()
     Like *note digest(): 109b. except the digest is returned as a
     string of double length, containing only hexadecimal digits.  This
     may  be used to exchange the value safely in email or other
     non-binary environments.

 -- Method: hash.copy ()
     Return a copy ("clone") of the hash object.  This can be used to
     efficiently compute the digests of strings that share a common
     initial substring.

See also
........

Module *note hmac: e8.
     A module to generate message authentication codes using hashes.

Module *note base64: 15.
     Another way to encode binary hashes for non-binary environments.

<http://csrc.nist.gov/publications/fips/fips180-2/fips180-2.pdf>
     The FIPS 180-2 publication on Secure Hash Algorithms.

<http://en.wikipedia.org/wiki/Cryptographic_hash_function#Cryptographic_hash_algorithms>
     Wikipedia article with information on which algorithms have known
     issues and what that means regarding their use.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/hashlib.py

  (2) http://tools.ietf.org/html/rfc1321.html


File: python.info,  Node: hmac --- Keyed-Hashing for Message Authentication,  Next: md5 --- MD5 message digest algorithm,  Prev: hashlib --- Secure hashes and message digests,  Up: Cryptographic Services

5.14.2 `hmac' -- Keyed-Hashing for Message Authentication
---------------------------------------------------------

New in version 2.2.

  *Source code:* Lib/hmac.py(1)

      * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 


  This module implements the HMAC algorithm as described by RFC 2104(2).

 -- Function: hmac.new (key[, msg[, digestmod]])
     Return a new hmac object.  If _msg_ is present, the method call
     `update(msg)' is made. _digestmod_ is the digest constructor or
     module for the HMAC object to use. It defaults to  the
     `hashlib.md5()' constructor.

  An HMAC object has the following methods:

 -- Method: HMAC.update (msg)
     Update the hmac object with the string _msg_.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to `m.update(a
     + b)'.

 -- Method: HMAC.digest ()
     Return the digest of the strings passed to the *note update():
     10a1. method so far.  This string will be the same length as the
     _digest_size_ of the digest given to the constructor.  It may
     contain non-ASCII characters, including NUL bytes.

 -- Method: HMAC.hexdigest ()
     Like *note digest(): 10a2. except the digest is returned as a
     string twice the length containing only hexadecimal digits.  This
     may be used to exchange the value safely in email or other
     non-binary environments.

 -- Method: HMAC.copy ()
     Return a copy ("clone") of the hmac object.  This can be used to
     efficiently compute the digests of strings that share a common
     initial substring.

See also
........

Module *note hashlib: e6.
     The Python module providing secure hash functions.

  ---------- Footnotes ----------

  (1) http://hg.python.org/cpython/file/2.7/Lib/hmac.py

  (2) http://tools.ietf.org/html/rfc2104.html


File: python.info,  Node: md5 --- MD5 message digest algorithm,  Next: sha --- SHA-1 message digest algorithm,  Prev: hmac --- Keyed-Hashing for Message Authentication,  Up: Cryptographic Services

5.14.3 `md5' -- MD5 message digest algorithm
--------------------------------------------

Deprecated since version 2.5: Use the *note hashlib: e6. module instead.

  This module implements the interface to RSA's MD5 message digest
algorithm (see also Internet RFC 1321(1)).  Its use is quite
straightforward: use *note new(): 122.  to create an md5 object. You
can now feed this object with arbitrary strings using the `update()'
method, and at any point you can ask it for the _digest_ (a strong kind
of 128-bit checksum, a.k.a. "fingerprint") of the concatenation of the
strings fed to it so far using the `digest()' method.

  For example, to obtain the digest of the string `'Nobody inspects the
spammish repetition'':

    >>> import md5
    >>> m = md5.new()
    >>> m.update("Nobody inspects")
    >>> m.update(" the spammish repetition")
    >>> m.digest()
    '\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

More condensed:

    >>> md5.new("Nobody inspects the spammish repetition").digest()
    '\xbbd\x9c\x83\xdd\x1e\xa5\xc9\xd9\xde\xc9\xa1\x8d\xf0\xff\xe9'

The following values are provided as constants in the module and as
attributes of the md5 objects returned by *note new(): 122.:

 -- Data: md5.digest_size
     The size of the resulting digest in bytes.  This is always `16'.

  The md5 module provides the following functions:

 -- Function: md5.new ([arg])
     Return a new md5 object.  If _arg_ is present, the method call
     `update(arg)' is made.

 -- Function: md5.md5 ([arg])
     For backward compatibility reasons, this is an alternative name
     for the *note new(): 122. function.

  An md5 object has the following methods:

 -- Method: md5.update (arg)
     Update the md5 object with the string _arg_.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to
     `m.update(a+b)'.

 -- Method: md5.digest ()
     Return the digest of the strings passed to the *note update():
     10aa. method so far.  This is a 16-byte string which may contain
     non-ASCII characters, including null bytes.

 -- Method: md5.hexdigest ()
     Like *note digest(): 10ab. except the digest is returned as a
     string of length 32, containing only hexadecimal digits.  This may
     be used to exchange the value safely in email or other non-binary
     environments.

 -- Method: md5.copy ()
     Return a copy ("clone") of the md5 object.  This can be used to
     efficiently compute the digests of strings that share a common
     initial substring.

See also
........

Module *note sha: 151.
     Similar module implementing the Secure Hash Algorithm (SHA).  The
     SHA algorithm is considered a more secure hash.

  ---------- Footnotes ----------

  (1) http://tools.ietf.org/html/rfc1321.html


File: python.info,  Node: sha --- SHA-1 message digest algorithm,  Prev: md5 --- MD5 message digest algorithm,  Up: Cryptographic Services

5.14.4 `sha' -- SHA-1 message digest algorithm
----------------------------------------------

Deprecated since version 2.5: Use the *note hashlib: e6. module instead.

  This module implements the interface to NIST's secure hash
algorithm, known as SHA-1.  SHA-1 is an improved version of the
original SHA hash algorithm.  It is used in the same way as the *note
md5: 10d. module: use *note new(): 122. to create an sha object, then
feed this object with arbitrary strings using the `update()' method,
and at any point you can ask it for the _digest_ of the concatenation
of the strings fed to it so far.  SHA-1 digests are 160 bits instead of
MD5's 128 bits.

 -- Function: sha.new ([string])
     Return a new sha object.  If _string_ is present, the method call
     `update(string)' is made.

  The following values are provided as constants in the module and as
attributes of the sha objects returned by *note new(): 122.:

 -- Data: sha.blocksize
     Size of the blocks fed into the hash function; this is always `1'.
     This size is used to allow an arbitrary string to be hashed.

 -- Data: sha.digest_size
     The size of the resulting digest in bytes.  This is always `20'.

  An sha object has the same methods as md5 objects:

 -- Method: sha.update (arg)
     Update the sha object with the string _arg_.  Repeated calls are
     equivalent to a single call with the concatenation of all the
     arguments: `m.update(a); m.update(b)' is equivalent to
     `m.update(a+b)'.

 -- Method: sha.digest ()
     Return the digest of the strings passed to the *note update():
     10b3. method so far.  This is a 20-byte string which may contain
     non-ASCII characters, including null bytes.

 -- Method: sha.hexdigest ()
     Like *note digest(): 10b4. except the digest is returned as a
     string of length 40, containing only hexadecimal digits.  This may
     be used to exchange the value safely in email or other non-binary
     environments.

 -- Method: sha.copy ()
     Return a copy ("clone") of the sha object.  This can be used to
     efficiently compute the digests of strings that share a common
     initial substring.

See also
........

Secure Hash Standard(1)
     The Secure Hash Algorithm is defined by NIST document FIPS PUB
     180-2: Secure Hash Standard(2), published in August 2002.

Cryptographic Toolkit (Secure Hashing)(3)
     Links from NIST to various information on secure hashing.

  Hardcore cypherpunks will probably find the cryptographic modules
written by A.M. Kuchling of further interest; the package contains
modules for various encryption algorithms, most notably AES.  These
modules are not distributed with Python but available separately.  See
the URL <http://www.pycrypto.org>  for more information.

  ---------- Footnotes ----------

  (1)
http://csrc.nist.gov/publications/fips/fips180-2/fips180-2withchangenotice.pdf

  (2)
http://csrc.nist.gov/publications/fips/fips180-2/fips180-2withchangenotice.pdf

  (3) http://csrc.nist.gov/CryptoToolkit/tkhash.html


File: python.info,  Node: Generic Operating System Services,  Next: Optional Operating System Services,  Prev: Cryptographic Services,  Up: The Python Standard Library

5.15 Generic Operating System Services
======================================

The modules described in this chapter provide interfaces to operating
system features that are available on (almost) all operating systems,
such as files and a clock.  The interfaces are generally modeled after
the Unix or C interfaces, but they are available on most other systems
as well.  Here's an overview:

* Menu:

* os: os --- Miscellaneous operating system interfaces. Miscellaneous operating system interfaces
* io: io --- Core tools for working with streams. Core tools for working with streams
* time: time --- Time access and conversions. Time access and conversions
* argparse: argparse --- Parser for command-line options arguments and sub-commands. Parser for command-line options, arguments and sub-
                        commands
* optparse: optparse --- Parser for command line options. Parser for command line options
* getopt: getopt --- C-style parser for command line options. C-style parser for command line options
* logging: logging --- Logging facility for Python. Logging facility for Python
* logging.config: logging config --- Logging configuration. Logging configuration
* logging.handlers: logging handlers --- Logging handlers. Logging handlers
* getpass: getpass --- Portable password input. Portable password input
* curses: curses --- Terminal handling for character-cell displays. Terminal handling for character-cell displays
* curses.textpad: curses textpad --- Text input widget for curses programs. Text input widget for curses programs
* curses.ascii: curses ascii --- Utilities for ASCII characters. Utilities for ASCII characters
* curses.panel: curses panel --- A panel stack extension for curses. A panel stack extension for curses
* platform: platform --- Access to underlying platform's identifying data. Access to underlying platform's identifying data
* errno: errno --- Standard errno system symbols. Standard errno system symbols
* ctypes: ctypes --- A foreign function library for Python. A foreign function library for Python

os --- Miscellaneous operating system interfaces

* Process Parameters::
* File Object Creation::
* File Descriptor Operations::
* Files and Directories::
* Process Management::
* Miscellaneous System Information::
* Miscellaneous Functions::

File Descriptor Operations

* open() flag constants: open flag constants.

io --- Core tools for working with streams

* Module Interface::
* I/O Base Classes::
* Raw File I/O::
* Buffered Streams::
* Text I/O::
* Advanced topics::

Advanced topics

* Performance::
* Multi-threading: Multi-threading<2>.
* Reentrancy::

Performance

* Binary I/O::
* Text I/O: Text I/O<2>.

argparse --- Parser for command-line options, arguments and sub-commands

* Example: Example<6>.
* ArgumentParser objects::
* The add_argument() method: The add_argument method.
* The parse_args() method: The parse_args method.
* Other utilities::
* Upgrading optparse code::

Example

* Creating a parser::
* Adding arguments::
* Parsing arguments::

ArgumentParser objects

* prog::
* usage::
* description::
* epilog::
* parents::
* formatter_class::
* prefix_chars::
* fromfile_prefix_chars::
* argument_default::
* conflict_handler::
* add_help::

The add_argument() method

* name or flags::
* action::
* nargs::
* const::
* default::
* type::
* choices::
* required::
* help::
* metavar::
* dest::

The parse_args() method

* Option value syntax::
* Invalid arguments::
* Arguments containing -::
* Argument abbreviations::
* Beyond sys.argv: Beyond sys argv.
* The Namespace object::

Other utilities

* Sub-commands::
* FileType objects::
* Argument groups::
* Mutual exclusion::
* Parser defaults::
* Printing help::
* Partial parsing::
* Customizing file parsing::
* Exiting methods::

optparse --- Parser for command line options

* Background::
* Tutorial::
* Reference Guide::
* Option Callbacks::
* Extending optparse::

Background

* Terminology::
* What are options for?::
* What are positional arguments for?::

Tutorial

* Understanding option actions::
* The store action::
* Handling boolean (flag) options: Handling boolean flag options.
* Other actions::
* Default values::
* Generating help::
* Printing a version string::
* How optparse handles errors::
* Putting it all together::

Generating help

* Grouping Options::

Reference Guide

* Creating the parser::
* Populating the parser::
* Defining options::
* Option attributes::
* Standard option actions::
* Standard option types::
* Parsing arguments: Parsing arguments<2>.
* Querying and manipulating your option parser::
* Conflicts between options::
* Cleanup::
* Other methods::

Option Callbacks

* Defining a callback option::
* How callbacks are called::
* Raising errors in a callback::
* Callback example 1; trivial callback: Callback example 1 trivial callback.
* Callback example 2; check option order: Callback example 2 check option order.
* Callback example 3; check option order (generalized): Callback example 3 check option order generalized.
* Callback example 4; check arbitrary condition: Callback example 4 check arbitrary condition.
* Callback example 5; fixed arguments: Callback example 5 fixed arguments.
* Callback example 6; variable arguments: Callback example 6 variable arguments.

Extending optparse

* Adding new types::
* Adding new actions::

logging --- Logging facility for Python

* Logger Objects::
* Handler Objects::
* Formatter Objects::
* Filter Objects::
* LogRecord Objects::
* LogRecord attributes::
* LoggerAdapter Objects::
* Thread Safety::
* Module-Level Functions::
* Integration with the warnings module::

logging.config --- Logging configuration

* Configuration functions::
* Configuration dictionary schema::
* Configuration file format::

Configuration dictionary schema

* Dictionary Schema Details::
* Incremental Configuration::
* Object connections::
* User-defined objects::
* Access to external objects::
* Access to internal objects::
* Import resolution and custom importers::

logging.handlers --- Logging handlers

* StreamHandler::
* FileHandler::
* NullHandler::
* WatchedFileHandler::
* RotatingFileHandler::
* TimedRotatingFileHandler::
* SocketHandler::
* DatagramHandler::
* SysLogHandler::
* NTEventLogHandler::
* SMTPHandler::
* MemoryHandler::
* HTTPHandler::

curses --- Terminal handling for character-cell displays

* Functions: Functions<2>.
* Window Objects::
* Constants: Constants<3>.

curses.textpad --- Text input widget for curses programs

* Textbox objects::

curses.panel --- A panel stack extension for curses

* Functions: Functions<3>.
* Panel Objects::

platform ---  Access to underlying platform's identifying data

* Cross Platform::
* Java Platform::
* Windows Platform::
* Mac OS Platform::
* Unix Platforms::

Windows Platform

* Win95/98 specific::

ctypes --- A foreign function library for Python

* ctypes tutorial::
* ctypes reference::

ctypes tutorial

* Loading dynamic link libraries::
* Accessing functions from loaded dlls::
* Calling functions::
* Fundamental data types::
* Calling functions, continued: Calling functions continued.
* Calling functions with your own custom data types::
* Specifying the required argument types (function prototypes): Specifying the required argument types function prototypes.
* Return types::
* Passing pointers (or; passing parameters by reference): Passing pointers or passing parameters by reference.
* Structures and unions::
* Structure/union alignment and byte order::
* Bit fields in structures and unions::
* Arrays::
* Pointers::
* Type conversions::
* Incomplete Types::
* Callback functions::
* Accessing values exported from dlls::
* Surprises::
* Variable-sized data types::

ctypes reference

* Finding shared libraries::
* Loading shared libraries::
* Foreign functions::
* Function prototypes::
* Utility functions::
* Data types::
* Fundamental data types: Fundamental data types<2>.
* Structured data types::
* Arrays and pointers::


File: python.info,  Node: os --- Miscellaneous operating system interfaces,  Next: io --- Core tools for working with streams,  Up: Generic Operating System Services

5.15.1 `os' -- Miscellaneous operating system interfaces
--------------------------------------------------------

This module provides a portable way of using operating system dependent
functionality.  If you just want to read or write a file see *note
open(): 2d3, if you want to manipulate paths, see the *note os.path:
129. module, and if you want to read all the lines in all the files on
the command line see the *note fileinput: cc.  module.  For creating
temporary files and directories see the *note tempfile: 173.  module,
and for high-level file and directory handling see the *note shutil:
154.  module.

  Notes on the availability of these functions:

   * The design of all built-in operating system dependent modules of
     Python is such that as long as the same functionality is
     available, it uses the same interface; for example, the function
     `os.stat(path)' returns stat information about _path_ in the same
     format (which happens to have originated with the POSIX interface).

   * Extensions peculiar to a particular operating system are also
     available through the *note os: 128. module, but using them is of
     course a threat to portability.

   * An "Availability: Unix" note means that this function is commonly
     found on Unix systems.  It does not make any claims about its
     existence on a specific operating system.

   * If not separately noted, all functions that claim "Availability:
     Unix" are supported on Mac OS X, which builds on a Unix core.

     Note: All functions in this module raise *note OSError: 22e. in
     the case of invalid or inaccessible file names and paths, or other
     arguments that have the correct type, but are not accepted by the
     operating system.

 -- Exception: os.error
     An alias for the built-in *note OSError: 22e. exception.

 -- Data: os.name
     The name of the operating system dependent module imported.  The
     following names have currently been registered: `'posix'', `'nt'',
     `'os2'', `'ce'', `'java'', `'riscos''.

See also
........

     *note sys.platform: 10bd. has a finer granularity.  *note
os.uname(): 10be. gives system-dependent version information.

     The *note platform: 132. module provides detailed checks for the
system's identity.

* Menu:

* Process Parameters::
* File Object Creation::
* File Descriptor Operations::
* Files and Directories::
* Process Management::
* Miscellaneous System Information::
* Miscellaneous Functions::


File: python.info,  Node: Process Parameters,  Next: File Object Creation,  Up: os --- Miscellaneous operating system interfaces

5.15.1.1 Process Parameters
...........................

These functions and data items provide information and operate on the
current process and user.

 -- Data: os.environ
     A *note mapping: 8e0. object representing the string environment.
     For example, `environ['HOME']' is the pathname of your home
     directory (on some platforms), and is equivalent to
     `getenv("HOME")' in C.

     This mapping is captured the first time the *note os: 128. module
     is imported, typically during Python startup as part of processing
     `site.py'.  Changes to the environment made after this time are
     not reflected in `os.environ', except for changes made by
     modifying `os.environ' directly.

     If the platform supports the *note putenv(): 10c1. function, this
     mapping may be used to modify the environment as well as query the
     environment.  *note putenv(): 10c1. will be called automatically
     when the mapping is modified.

          Note: Calling *note putenv(): 10c1. directly does not change
          `os.environ', so it's better to modify `os.environ'.

          Note: On some platforms, including FreeBSD and Mac OS X,
          setting `environ' may cause memory leaks.  Refer to the
          system documentation for `putenv()'.

     If *note putenv(): 10c1. is not provided, a modified copy of this
     mapping  may be passed to the appropriate process-creation
     functions to cause  child processes to use a modified environment.

     If the platform supports the *note unsetenv(): 34b. function, you
     can delete items in this mapping to unset environment variables.
     *note unsetenv(): 34b. will be called automatically when an item
     is deleted from `os.environ', and when one of the `pop()' or
     `clear()' methods is called.

     Changed in version 2.6: Also unset environment variables when
     calling `os.environ.clear()' and `os.environ.pop()'.

 -- Function: os.chdir (path)
 -- Function: os.fchdir (fd)
 -- Function: os.getcwd ()
     These functions are described in *note Files and Directories: 10c2.

 -- Function: os.ctermid ()
     Return the filename corresponding to the controlling terminal of
     the process.

     Availability: Unix.

 -- Function: os.getegid ()
     Return the effective group id of the current process.  This
     corresponds to the "set id" bit on the file being executed in the
     current process.

     Availability: Unix.

 -- Function: os.geteuid ()
     Return the current process's effective user id.

     Availability: Unix.

 -- Function: os.getgid ()
     Return the real group id of the current process.

     Availability: Unix.

 -- Function: os.getgroups ()
     Return list of supplemental group ids associated with the current
     process.

     Availability: Unix.

          Note: On Mac OS X, *note getgroups(): 10c7. behavior differs
          somewhat from other Unix platforms. If the Python interpreter
          was built with a deployment target of `10.5' or earlier,
          *note getgroups(): 10c7. returns the list of effective group
          ids associated with the current user process; this list is
          limited to a system-defined number of entries, typically 16,
          and may be modified by calls to *note setgroups(): 10c8. if
          suitably privileged.  If built with a deployment target
          greater than `10.5', *note getgroups(): 10c7. returns the
          current group access list for the user associated with the
          effective user id of the process; the group access list may
          change over the lifetime of the process, it is not affected by
          calls to *note setgroups(): 10c8, and its length is not
          limited to 16.  The deployment target value,
          `MACOSX_DEPLOYMENT_TARGET', can be obtained with *note
          sysconfig.get_config_var(): 270.

 -- Function: os.initgroups (username, gid)
     Call the system initgroups() to initialize the group access list
     with all of the groups of which the specified username is a
     member, plus the specified group id.

     Availability: Unix.

     New in version 2.7.

 -- Function: os.getlogin ()
     Return the name of the user logged in on the controlling terminal
     of the process.  For most purposes, it is more useful to use the
     environment variable `LOGNAME' to find out who the user is, or
     `pwd.getpwuid(os.getuid())[0]' to get the login name of the
     currently effective user id.

     Availability: Unix.

 -- Function: os.getpgid (pid)
     Return the process group id of the process with process id _pid_.
     If _pid_ is 0, the process group id of the current process is
     returned.

     Availability: Unix.

     New in version 2.3.

 -- Function: os.getpgrp ()
     Return the id of the current process group.

     Availability: Unix.

 -- Function: os.getpid ()
     Return the current process id.

     Availability: Unix, Windows.

 -- Function: os.getppid ()
     Return the parent's process id.

     Availability: Unix.

 -- Function: os.getresuid ()
     Return a tuple (ruid, euid, suid) denoting the current process's
     real, effective, and saved user ids.

     Availability: Unix.

     New in version 2.7.

 -- Function: os.getresgid ()
     Return a tuple (rgid, egid, sgid) denoting the current process's
     real, effective, and saved group ids.

     Availability: Unix.

     New in version 2.7.

 -- Function: os.getuid ()
     Return the current process's user id.

     Availability: Unix.

 -- Function: os.getenv (varname[, value])
     Return the value of the environment variable _varname_ if it
     exists, or _value_ if it doesn't.  _value_ defaults to `None'.

     Availability: most flavors of Unix, Windows.

 -- Function: os.putenv (varname, value)
     Set the environment variable named _varname_ to the string
     _value_.  Such changes to the environment affect subprocesses
     started with *note os.system(): 3f3, *note popen(): 6ed. or *note
     fork(): 241. and *note execv(): 10d0.

     Availability: most flavors of Unix, Windows.

          Note: On some platforms, including FreeBSD and Mac OS X,
          setting `environ' may cause memory leaks. Refer to the system
          documentation for putenv.

     When *note putenv(): 10c1. is supported, assignments to items in
     `os.environ' are automatically translated into corresponding calls
     to *note putenv(): 10c1.; however, calls to *note putenv(): 10c1.
     don't update `os.environ', so it is actually preferable to assign
     to items of `os.environ'.

 -- Function: os.setegid (egid)
     Set the current process's effective group id.

     Availability: Unix.

 -- Function: os.seteuid (euid)
     Set the current process's effective user id.

     Availability: Unix.

 -- Function: os.setgid (gid)
     Set the current process' group id.

     Availability: Unix.

 -- Function: os.setgroups (groups)
     Set the list of supplemental group ids associated with the current
     process to _groups_. _groups_ must be a sequence, and each element
     must be an integer identifying a group. This operation is
     typically available only to the superuser.

     Availability: Unix.

     New in version 2.2.

          Note: On Mac OS X, the length of _groups_ may not exceed the
          system-defined maximum number of effective group ids,
          typically 16.  See the documentation for *note getgroups():
          10c7. for cases where it may not return the same group list
          set by calling setgroups().

 -- Function: os.setpgrp ()
     Call the system call `setpgrp()' or `setpgrp(0, 0)()' depending on
     which version is implemented (if any).  See the Unix manual for
     the semantics.

     Availability: Unix.

 -- Function: os.setpgid (pid, pgrp)
     Call the system call `setpgid()' to set the process group id of the
     process with id _pid_ to the process group with id _pgrp_.  See
     the Unix manual for the semantics.

     Availability: Unix.

 -- Function: os.setregid (rgid, egid)
     Set the current process's real and effective group ids.

     Availability: Unix.

 -- Function: os.setresgid (rgid, egid, sgid)
     Set the current process's real, effective, and saved group ids.

     Availability: Unix.

     New in version 2.7.

 -- Function: os.setresuid (ruid, euid, suid)
     Set the current process's real, effective, and saved user ids.

     Availability: Unix.

     New in version 2.7.

 -- Function: os.setreuid (ruid, euid)
     Set the current process's real and effective user ids.

     Availability: Unix.

 -- Function: os.getsid (pid)
     Call the system call `getsid()'.  See the Unix manual for the
     semantics.

     Availability: Unix.

     New in version 2.4.

 -- Function: os.setsid ()
     Call the system call `setsid()'.  See the Unix manual for the
     semantics.

     Availability: Unix.

 -- Function: os.setuid (uid)
     Set the current process's user id.

     Availability: Unix.

 -- Function: os.strerror (code)
     Return the error message corresponding to the error code in _code_.
     On platforms where `strerror()' returns `NULL' when given an
     unknown error number, *note ValueError: 233. is raised.

     Availability: Unix, Windows.

 -- Function: os.umask (mask)
     Set the current numeric umask and return the previous umask.

     Availability: Unix, Windows.

 -- Function: os.uname ()
     Return a 5-tuple containing information identifying the current
     operating system.  The tuple contains 5 strings: `(sysname,
     nodename, release, version, machine)'.  Some systems truncate the
     nodename to 8 characters or to the leading component; a better way
     to get the hostname is *note socket.gethostname(): 10dd.  or even
     `socket.gethostbyaddr(socket.gethostname())'.

     Availability: recent flavors of Unix.

 -- Function: os.unsetenv (varname)
     Unset (delete) the environment variable named _varname_. Such
     changes to the environment affect subprocesses started with *note
     os.system(): 3f3, *note popen(): 6ed. or *note fork(): 241. and
     *note execv(): 10d0.

     When *note unsetenv(): 34b. is supported, deletion of items in
     `os.environ' is automatically translated into a corresponding call
     to *note unsetenv(): 34b.; however, calls to *note unsetenv():
     34b. don't update `os.environ', so it is actually preferable to
     delete items of `os.environ'.

     Availability: most flavors of Unix, Windows.


File: python.info,  Node: File Object Creation,  Next: File Descriptor Operations,  Prev: Process Parameters,  Up: os --- Miscellaneous operating system interfaces

5.15.1.2 File Object Creation
.............................

These functions create new file objects. (See also *note open(): 2d3.)

 -- Function: os.fdopen (fd[, mode[, bufsize]])
     Return an open file object connected to the file descriptor _fd_.
     The _mode_ and _bufsize_ arguments have the same meaning as the
     corresponding arguments to the built-in *note open(): 2d3.
     function.

     Availability: Unix, Windows.

     Changed in version 2.3: When specified, the _mode_ argument must
     now start with one of the letters `'r'', `'w'', or `'a'',
     otherwise a *note ValueError: 233. is raised.

     Changed in version 2.5: On Unix, when the _mode_ argument starts
     with `'a'', the _O_APPEND_ flag is set on the file descriptor
     (which the `fdopen()' implementation already does on most
     platforms).

 -- Function: os.popen (command[, mode[, bufsize]])
     Open a pipe to or from _command_.  The return value is an open
     file object connected to the pipe, which can be read or written
     depending on whether _mode_ is `'r'' (default) or `'w''. The
     _bufsize_ argument has the same meaning as the corresponding
     argument to the built-in *note open(): 2d3. function.  The exit
     status of the command (encoded in the format specified for *note
     wait(): 10e0.) is available as the return value of the *note
     close(): 8ef. method of the file object, except that when the exit
     status is zero (termination without errors), `None' is returned.

     Availability: Unix, Windows.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *note subprocess: 167. module.  Check especially the *note
     Replacing Older Functions with the subprocess Module: 10e1.
     section.

     Changed in version 2.0: This function worked unreliably under
     Windows in earlier versions of Python.  This was due to the use of
     the `_popen()' function from the libraries provided with Windows.
     Newer versions of Python do not use the broken implementation from
     the Windows libraries.

 -- Function: os.tmpfile ()
     Return a new file object opened in update mode (`w+b').  The file
     has no directory entries associated with it and will be
     automatically deleted once there are no file descriptors for the
     file.

     Availability: Unix, Windows.

  There are a number of different `popen*()' functions that provide
slightly different ways to create subprocesses.

  Deprecated since version 2.6: All of the `popen*()' functions are
obsolete. Use the *note subprocess: 167.  module.

  For each of the `popen*()' variants, if _bufsize_ is specified, it
specifies the buffer size for the I/O pipes. _mode_, if provided,
should be the string `'b'' or `'t''; on Windows this is needed to
determine whether the file objects should be opened in binary or text
mode.  The default value for _mode_ is `'t''.

  Also, for each of these variants, on Unix, _cmd_ may be a sequence,
in which case arguments will be passed directly to the program without
shell intervention (as with *note os.spawnv(): 10e3.). If _cmd_ is a
string it will be passed to the shell (as with *note os.system(): 3f3.).

  These methods do not make it possible to retrieve the exit status
from the child processes.  The only way to control the input and output
streams and also retrieve the return codes is to use the *note
subprocess: 167. module; these are only available on Unix.

  For a discussion of possible deadlock conditions related to the use
of these functions, see *note Flow Control Issues: 10e4.

 -- Function: os.popen2 (cmd[, mode[, bufsize]])
     Execute _cmd_ as a sub-process and return the file objects
     `(child_stdin, child_stdout)'.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *note subprocess: 167. module.  Check especially the *note
     Replacing Older Functions with the subprocess Module: 10e1.
     section.

     Availability: Unix, Windows.

     New in version 2.0.

 -- Function: os.popen3 (cmd[, mode[, bufsize]])
     Execute _cmd_ as a sub-process and return the file objects
     `(child_stdin, child_stdout, child_stderr)'.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *note subprocess: 167. module.  Check especially the *note
     Replacing Older Functions with the subprocess Module: 10e1.
     section.

     Availability: Unix, Windows.

     New in version 2.0.

 -- Function: os.popen4 (cmd[, mode[, bufsize]])
     Execute _cmd_ as a sub-process and return the file objects
     `(child_stdin, child_stdout_and_stderr)'.

     Deprecated since version 2.6: This function is obsolete.  Use the
     *note subprocess: 167. module.  Check especially the *note
     Replacing Older Functions with the subprocess Module: 10e1.
     section.

     Availability: Unix, Windows.

     New in version 2.0.

  (Note that `child_stdin, child_stdout, and child_stderr' are named
from the point of view of the child process, so _child_stdin_ is the
child's standard input.)

  This functionality is also available in the *note popen2: 134. module
using functions of the same names, but the return values of those
functions have a different order.


File: python.info,  Node: File Descriptor Operations,  Next: Files and Directories,  Prev: File Object Creation,  Up: os --- Miscellaneous operating system interfaces

5.15.1.3 File Descriptor Operations
...................................

These functions operate on I/O streams referenced using file
descriptors.

  File descriptors are small integers corresponding to a file that has
been opened by the current process.  For example, standard input is
usually file descriptor 0, standard output is 1, and standard error is
2.  Further files opened by a process will then be assigned 3, 4, 5,
and so forth.  The name "file descriptor" is slightly deceptive; on
Unix platforms, sockets and pipes are also referenced by file
descriptors.

  The *note fileno(): 8f3. method can be used to obtain the file
descriptor associated with a file object when required.  Note that
using the file descriptor directly will bypass the file object methods,
ignoring aspects such as internal buffering of data.

 -- Function: os.close (fd)
     Close file descriptor _fd_.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O and must be
          applied to a file descriptor as returned by *note os.open():
          5d5. or *note pipe(): 10eb.  To close a "file object"
          returned by the built-in function *note open(): 2d3. or by
          *note popen(): 6ed. or *note fdopen(): 6ee, use its *note
          close(): 8ef. method.

 -- Function: os.closerange (fd_low, fd_high)
     Close all file descriptors from _fd_low_ (inclusive) to _fd_high_
     (exclusive), ignoring errors. Equivalent to:

         for fd in xrange(fd_low, fd_high):
             try:
                 os.close(fd)
             except OSError:
                 pass

     Availability: Unix, Windows.

     New in version 2.6.

 -- Function: os.dup (fd)
     Return a duplicate of file descriptor _fd_.

     Availability: Unix, Windows.

 -- Function: os.dup2 (fd, fd2)
     Duplicate file descriptor _fd_ to _fd2_, closing the latter first
     if necessary.

     Availability: Unix, Windows.

 -- Function: os.fchmod (fd, mode)
     Change the mode of the file given by _fd_ to the numeric _mode_.
     See the docs for *note chmod(): e0f. for possible values of _mode_.

     Availability: Unix.

     New in version 2.6.

 -- Function: os.fchown (fd, uid, gid)
     Change the owner and group id of the file given by _fd_ to the
     numeric _uid_ and _gid_.  To leave one of the ids unchanged, set
     it to -1.

     Availability: Unix.

     New in version 2.6.

 -- Function: os.fdatasync (fd)
     Force write of file with filedescriptor _fd_ to disk. Does not
     force update of metadata.

     Availability: Unix.

          Note: This function is not available on MacOS.

 -- Function: os.fpathconf (fd, name)
     Return system configuration information relevant to an open file.
     _name_ specifies the configuration value to retrieve; it may be a
     string which is the name of a defined system value; these names
     are specified in a number of standards (POSIX.1, Unix 95, Unix 98,
     and others).  Some platforms define additional names as well.  The
     names known to the host operating system are given in the
     `pathconf_names' dictionary.  For configuration variables not
     included in that mapping, passing an integer for _name_ is also
     accepted.

     If _name_ is a string and is not known, *note ValueError: 233. is
     raised.  If a specific value for _name_ is not supported by the
     host system, even if it is included in `pathconf_names', an *note
     OSError: 22e. is raised with *note errno.EINVAL: 10f3. for the
     error number.

     Availability: Unix.

 -- Function: os.fstat (fd)
     Return status for file descriptor _fd_, like *note stat(): 3bd.

     Availability: Unix, Windows.

 -- Function: os.fstatvfs (fd)
     Return information about the filesystem containing the file
     associated with file descriptor _fd_, like *note statvfs(): 162.

     Availability: Unix.

 -- Function: os.fsync (fd)
     Force write of file with filedescriptor _fd_ to disk.  On Unix,
     this calls the native `fsync()' function; on Windows, the MS
     `_commit()' function.

     If you're starting with a Python file object _f_, first do
     `f.flush()', and then do `os.fsync(f.fileno())', to ensure that
     all internal buffers associated with _f_ are written to disk.

     Availability: Unix, and Windows starting in 2.2.3.

 -- Function: os.ftruncate (fd, length)
     Truncate the file corresponding to file descriptor _fd_, so that
     it is at most _length_ bytes in size.

     Availability: Unix.

 -- Function: os.isatty (fd)
     Return `True' if the file descriptor _fd_ is open and connected to
     a tty(-like) device, else `False'.

     Availability: Unix.

 -- Function: os.lseek (fd, pos, how)
     Set the current position of file descriptor _fd_ to position
     _pos_, modified by _how_: *note SEEK_SET: 3be. or `0' to set the
     position relative to the beginning of the file; *note SEEK_CUR:
     3bf. or `1' to set it relative to the current position; *note
     os.SEEK_END: 3c0. or `2' to set it relative to the end of the file.

     Availability: Unix, Windows.

 -- Data: os.SEEK_SET
 -- Data: os.SEEK_CUR
 -- Data: os.SEEK_END
     Parameters to the *note lseek(): 3c1. function. Their values are
     0, 1, and 2, respectively.

     Availability: Windows, Unix.

     New in version 2.5.

 -- Function: os.open (file, flags[, mode])
     Open the file _file_ and set various flags according to _flags_
     and possibly its mode according to _mode_. The default _mode_ is
     `0777' (octal), and the current umask value is first masked out.
     Return the file descriptor for the newly opened file.

     For a description of the flag and mode values, see the C run-time
     documentation; flag constants (like *note O_RDONLY: 10f7. and
     *note O_WRONLY: 10f8.) are defined in this module too (see *note
     open() flag constants: 10f9.).  In particular, on Windows adding
     *note O_BINARY: 10fa. is needed to open files in binary mode.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O.  For
          normal usage, use the built-in function *note open(): 2d3,
          which returns a "file object" with *note read(): 8f7. and
          *note write(): 8fa. methods (and many more).  To wrap a file
          descriptor in a "file object", use *note fdopen(): 6ee.

 -- Function: os.openpty ()
     Open a new pseudo-terminal pair. Return a pair of file descriptors
     `(master, slave)' for the pty and the tty, respectively. For a
     (slightly) more portable approach, use the *note pty: 13b. module.

     Availability: some flavors of Unix.

 -- Function: os.pipe ()
     Create a pipe.  Return a pair of file descriptors `(r, w)' usable
     for reading and writing, respectively.

     Availability: Unix, Windows.

 -- Function: os.read (fd, n)
     Read at most _n_ bytes from file descriptor _fd_. Return a string
     containing the bytes read.  If the end of the file referred to by
     _fd_ has been reached, an empty string is returned.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O and must be
          applied to a file descriptor as returned by *note os.open():
          5d5. or *note pipe(): 10eb.  To read a "file object" returned
          by the built-in function *note open(): 2d3. or by *note
          popen(): 6ed. or *note fdopen(): 6ee, or *note sys.stdin:
          623, use its *note read(): 8f7. or *note readline(): 631.
          methods.

 -- Function: os.tcgetpgrp (fd)
     Return the process group associated with the terminal given by
     _fd_ (an open file descriptor as returned by *note os.open():
     5d5.).

     Availability: Unix.

 -- Function: os.tcsetpgrp (fd, pg)
     Set the process group associated with the terminal given by _fd_
     (an open file descriptor as returned by *note os.open(): 5d5.) to
     _pg_.

     Availability: Unix.

 -- Function: os.ttyname (fd)
     Return a string which specifies the terminal device associated with
     file descriptor _fd_.  If _fd_ is not associated with a terminal
     device, an exception is raised.

     Availability: Unix.

 -- Function: os.write (fd, str)
     Write the string _str_ to file descriptor _fd_. Return the number
     of bytes actually written.

     Availability: Unix, Windows.

          Note: This function is intended for low-level I/O and must be
          applied to a file descriptor as returned by *note os.open():
          5d5. or *note pipe(): 10eb.  To write a "file object"
          returned by the built-in function *note open(): 2d3. or by
          *note popen(): 6ed. or *note fdopen(): 6ee, or *note
          sys.stdout: 873. or *note sys.stderr: 634, use its *note
          write(): 8fa. method.

* Menu:

* open() flag constants: open flag constants.


File: python.info,  Node: open flag constants,  Up: File Descriptor Operations

5.15.1.4 `open()' flag constants
................................

The following constants are options for the _flags_ parameter to the
*note open(): 5d5. function.  They can be combined using the bitwise OR
operator `|'.  Some of them are not available on all platforms.  For
descriptions of their availability and use, consult the `open(2)'
manual page on Unix or the MSDN(1) on Windows.

 -- Data: os.O_RDONLY
 -- Data: os.O_WRONLY
 -- Data: os.O_RDWR
 -- Data: os.O_APPEND
 -- Data: os.O_CREAT
 -- Data: os.O_EXCL
 -- Data: os.O_TRUNC
     These constants are available on Unix and Windows.

 -- Data: os.O_DSYNC
 -- Data: os.O_RSYNC
 -- Data: os.O_SYNC
 -- Data: os.O_NDELAY
 -- Data: os.O_NONBLOCK
 -- Data: os.O_NOCTTY
 -- Data: os.O_SHLOCK
 -- Data: os.O_EXLOCK
     These constants are only available on Unix.

 -- Data: os.O_BINARY
 -- Data: os.O_NOINHERIT
 -- Data: os.O_SHORT_LIVED
 -- Data: os.O_TEMPORARY
 -- Data: os.O_RANDOM
 -- Data: os.O_SEQUENTIAL
 -- Data: os.O_TEXT
     These constants are only available on Windows.

 -- Data: os.O_ASYNC
 -- Data: os.O_DIRECT
 -- Data: os.O_DIRECTORY
 -- Data: os.O_NOFOLLOW
 -- Data: os.O_NOATIME
     These constants are GNU extensions and not present if they are not
     defined by the C library.

  ---------- Footnotes ----------

  (1) http://msdn.microsoft.com/en-us/library/z0kc8e3z.aspx


File: python.info,  Node: Files and Directories,  Next: Process Management,  Prev: File Descriptor Operations,  Up: os --- Miscellaneous operating system interfaces

5.15.1.5 Files and Directories
..............................

 -- Function: os.access (path, mode)
     Use the real uid/gid to test for access to _path_.  Note that most
     operations will use the effective uid/gid, therefore this routine
     can be used in a suid/sgid environment to test if the invoking
     user has the specified access to _path_.  _mode_ should be *note
     F_OK: 1118. to test the existence of _path_, or it can be the
     inclusive OR of one or more of *note R_OK: 1119, *note W_OK: 111a,
     and *note X_OK: 111b. to test permissions.  Return *note True:
     3a9. if access is allowed, *note False: 3aa. if not. See the Unix
     man page `access(2)' for more information.

     Availability: Unix, Windows.

          Note: Using *note access(): 1117. to check if a user is
          authorized to e.g. open a file before actually doing so using
          *note open(): 2d3. creates a security hole, because the user
          might exploit the short time interval between checking and
          opening the file to manipulate it. It's preferable to use
          *note EAFP: 111c.  techniques. For example:

              if os.access("myfile", os.R_OK):
                  with open("myfile") as fp:
                      return fp.read()
              return "some default data"

          is better written as:

              try:
                  fp = open("myfile")
              except IOError as e:
                  if e.errno == errno.EACCES:
                      return "some default data"
                  # Not a permission error.
                  raise
              else:
                  with fp:
                      return fp.read()



          Note: I/O operations may fail even when *note access(): 1117.
          indicates that they would succeed, particularly for
          operations on network filesystems which may have permissions
          semantics beyond the usual POSIX permission-bit model.

 -- Data: os.F_OK
     Value to pass as the _mode_ parameter of *note access(): 1117. to
     test the existence of _path_.

 -- Data: os.R_OK
     Value to include in the _mode_ parameter of *note access(): 1117.
     to test the readability of _path_.

 -- Data: os.W_OK
     Value to include in the _mode_ parameter of *note access(): 1117.
     to test the writability of _path_.

 -- Data: os.X_OK
     Value to include in the _mode_ parameter of *note access(): 1117.
     to determine if _path_ can be executed.

 -- Function: os.chdir (path)
     Change the current working directory to _path_.

     Availability: Unix, Windows.

 -- Function: os.fchdir (fd)
     Change the current working directory to the directory represented
     by the file descriptor _fd_.  The descriptor must refer to an
     opened directory, not an open file.

     Availability: Unix.

     New in version 2.3.

 -- Function: os.getcwd ()
     Return a string representing the current working directory.

     Availability: Unix, Windows.

 -- Function: os.getcwdu ()
     Return a Unicode object representing the current working directory.

     Availability: Unix, Windows.

     New in version 2.3.

 -- Function: os.chflags (path, flags)
     Set the flags of _path_ to the numeric _flags_. _flags_ may take a
     combination (bitwise OR) of the following values (as defined in
     the *note stat: 161. module):

        * *note stat.UF_NODUMP: e36.

        * *note stat.UF_IMMUTABLE: e37.

        * *note stat.UF_APPEND: e38.

        * *note stat.UF_OPAQUE: e39.

        * *note stat.UF_NOUNLINK: e3a.

        * *note stat.UF_COMPRESSED: e3b.

        * *note stat.UF_HIDDEN: e3c.

        * *note stat.SF_ARCHIVED: e3d.

        * *note stat.SF_IMMUTABLE: e3e.

        * *note stat.SF_APPEND: e3f.

        * *note stat.SF_NOUNLINK: e40.

        * *note stat.SF_SNAPSHOT: e41.

     Availability: Unix.

     New in version 2.6.

 -- Function: os.chroot (path)
     Change the root directory of the current process to _path_.
     Availability: Unix.

     New in version 2.2.

 -- Function: os.chmod (path, mode)
     Change the mode of _path_ to the numeric _mode_. _mode_ may take
     one of the following values (as defined in the *note stat: 161.
     module) or bitwise ORed combinations of them:

        * *note stat.S_ISUID: e22.

        * *note stat.S_ISGID: e23.

        * *note stat.S_ENFMT: e25.

        * *note stat.S_ISVTX: e26.

        * *note stat.S_IREAD: e32.

        * *note stat.S_IWRITE: e33.

        * *note stat.S_IEXEC: e34.

        * *note stat.S_IRWXU: e27.

        * *note stat.S_IRUSR: e28.

        * *note stat.S_IWUSR: e29.

        * *note stat.S_IXUSR: e2a.

        * *note stat.S_IRWXG: e2b.

        * *note stat.S_IRGRP: e2c.

        * *note stat.S_IWGRP: e2d.

        * *note stat.S_IXGRP: e24.

        * *note stat.S_IRWXO: e2e.

        * *note stat.S_IROTH: e2f.

        * *note stat.S_IWOTH: e30.

        * *note stat.S_IXOTH: e31.

     Availability: Unix, Windows.

          Note: Although Windows supports *note chmod(): e0f, you can
          only  set the file's read-only flag with it (via the
          `stat.S_IWRITE'  and `stat.S_IREAD' constants or a
          corresponding integer value).  All other bits are ignored.

 -- Function: os.chown (path, uid, gid)
     Change the owner and group id of _path_ to the numeric _uid_ and
     _gid_. To leave one of the ids unchanged, set it to -1.

     Availability: Unix.

 -- Function: os.lchflags (path, flags)
     Set the flags of _path_ to the numeric _flags_, like *note
     chflags(): e35, but do not follow symbolic links.

     Availability: Unix.

     New in version 2.6.

 -- Function: os.lchmod (path, mode)
     Change the mode of _path_ to the numeric _mode_. If path is a
     symlink, this affects the symlink rather than the target. See the
     docs for *note chmod(): e0f.  for possible values of _mode_.

     Availability: Unix.

     New in version 2.6.

 -- Function: os.lchown (path, uid, gid)
     Change the owner and group id of _path_ to the numeric _uid_ and
     _gid_. This function will not follow symbolic links.

     Availability: Unix.

     New in version 2.3.

 -- Function: os.link (source, link_name)
     Create a hard link pointing to _source_ named _link_name_.

     Availability: Unix.

 -- Function: os.listdir (path)
     Return a list containing the names of the entries in the directory
     given by _path_.  The list is in arbitrary order.  It does not
     include the special entries `'.'' and `'..'' even if they are
     present in the directory.

     Availability: Unix, Windows.

     Changed in version 2.3: On Windows NT/2k/XP and Unix, if _path_ is
     a Unicode object, the result will be a list of Unicode objects.
     Undecodable filenames will still be returned as string objects.

 -- Function: os.lstat (path)
     Perform the equivalent of an `lstat()' system call on the given
     path.  Similar to *note stat(): 3bd, but does not follow symbolic
     links.  On platforms that do not support symbolic links, this is
     an alias for *note stat(): 3bd.

 -- Function: os.mkfifo (path[, mode])
     Create a FIFO (a named pipe) named _path_ with numeric mode
     _mode_.  The default _mode_ is `0666' (octal).  The current umask
     value is first masked out from the mode.

     Availability: Unix.

     FIFOs are pipes that can be accessed like regular files.  FIFOs
     exist until they are deleted (for example with *note os.unlink():
     1127.). Generally, FIFOs are used as rendezvous between "client"
     and "server" type processes: the server opens the FIFO for
     reading, and the client opens it for writing.  Note that *note
     mkfifo(): 1126.  doesn't open the FIFO -- it just creates the
     rendezvous point.

 -- Function: os.mknod (filename[, mode=0600[, device=0]])
     Create a filesystem node (file, device special file or named pipe)
     named _filename_. _mode_ specifies both the permissions to use and
     the type of node to be created, being combined (bitwise OR) with
     one of `stat.S_IFREG', `stat.S_IFCHR', `stat.S_IFBLK', and
     `stat.S_IFIFO' (those constants are available in *note stat: 161.).
     For `stat.S_IFCHR' and `stat.S_IFBLK', _device_ defines the newly
     created device special file (probably using *note os.makedev():
     1129.), otherwise it is ignored.

     New in version 2.3.

 -- Function: os.major (device)
     Extract the device major number from a raw device number (usually
     the `st_dev' or `st_rdev' field from `stat').

     New in version 2.3.

 -- Function: os.minor (device)
     Extract the device minor number from a raw device number (usually
     the `st_dev' or `st_rdev' field from `stat').

     New in version 2.3.

 -- Function: os.makedev (major, minor)
     Compose a raw device number from the major and minor device
     numbers.

     New in version 2.3.

 -- Function: os.mkdir (path[, mode])
     Create a directory named _path_ with numeric mode _mode_. The
     default _mode_ is `0777' (octal).  On some systems, _mode_ is
     ignored.  Where it is used, the current umask value is first
     masked out.  If the directory already exists, *note OSError: 22e.
     is raised.

     It is also possible to create temporary directories; see the *note
     tempfile: 173. module's *note tempfile.mkdtemp(): e6a. function.

     Availability: Unix, Windows.

 -- Function: os.makedirs (path[, mode])
     Recursive directory creation function.  Like *note mkdir(): 112c,
     but makes all intermediate-level directories needed to contain the
     leaf directory.  Raises an *note error: de3. exception if the leaf
     directory already exists or cannot be created.  The default _mode_
     is `0777' (octal).  On some systems, _mode_ is ignored. Where it
     is used, the current umask value is first masked out.

          Note: *note makedirs(): 112d. will become confused if the
          path elements to create include *note os.pardir: 112e.

     New in version 1.5.2.

     Changed in version 2.3: This function now handles UNC paths
     correctly.

 -- Function: os.pathconf (path, name)
     Return system configuration information relevant to a named file.
     _name_ specifies the configuration value to retrieve; it may be a
     string which is the name of a defined system value; these names
     are specified in a number of standards (POSIX.1, Unix 95, Unix 98,
     and others).  Some platforms define additional names as well.  The
     names known to the host operating system are given in the
     `pathconf_names' dictionary.  For configuration variables not
     included in that mapping, passing an integer for _name_ is also
     accepted.

     If _name_ is a string and is not known, *note ValueError: 233. is
     raised.  If a specific value for _name_ is not supported by the
     host system, even if it is included in `pathconf_names', an *note
     OSError: 22e. is raised with *note errno.EINVAL: 10f3. for the
     error number.

     Availability: Unix.

 -- Data: os.pathconf_names
     Dictionary mapping names accepted by *note pathconf(): 112f. and
     *note fpathconf(): 10f2. to the integer values defined for those
     names by the host operating system.  This can be used to determine
     the set of names known to the system. Availability: Unix.

 -- Function: os.readlink (path)
     Return a string representing the path to which the symbolic link
     points.  The result may be either an absolute or relative
     pathname; if it is relative, it may be converted to an absolute
     pathname using `os.path.join(os.path.dirname(path), result)'.

     Changed in version 2.6: If the _path_ is a Unicode object the
     result will also be a Unicode object.

     Availability: Unix.

 -- Function: os.remove (path)
     Remove (delete) the file _path_.  If _path_ is a directory, *note
     OSError: 22e. is raised; see *note rmdir(): e8e. below to remove a
     directory.  This is identical to the *note unlink(): 1127.
     function documented below.  On Windows, attempting to remove a
     file that is in use causes an exception to be raised; on Unix, the
     directory entry is removed but the storage allocated to the file
     is not made available until the original file is no longer in use.

     Availability: Unix, Windows.

 -- Function: os.removedirs (path)
     Remove directories recursively.  Works like *note rmdir(): e8e.
     except that, if the leaf directory is successfully removed, *note
     removedirs(): 1132.  tries to successively remove every parent
     directory mentioned in  _path_ until an error is raised (which is
     ignored, because it generally means that a parent directory is not
     empty). For example, `os.removedirs('foo/bar/baz')' will first
     remove the directory `'foo/bar/baz'', and then remove `'foo/bar''
     and `'foo'' if they are empty. Raises *note OSError: 22e. if the
     leaf directory could not be successfully removed.

     New in version 1.5.2.

 -- Function: os.rename (src, dst)
     Rename the file or directory _src_ to _dst_.  If _dst_ is a
     directory, *note OSError: 22e. will be raised.  On Unix, if _dst_
     exists and is a file, it will be replaced silently if the user has
     permission.  The operation may fail on some Unix flavors if _src_
     and _dst_ are on different filesystems.  If successful, the
     renaming will be an atomic operation (this is a POSIX
     requirement).  On Windows, if _dst_ already exists, *note OSError:
     22e. will be raised even if it is a file; there may be no way to
     implement an atomic rename when _dst_ names an existing file.

     Availability: Unix, Windows.

 -- Function: os.renames (old, new)
     Recursive directory or file renaming function. Works like *note
     rename(): e90, except creation of any intermediate directories
     needed to make the new pathname good is attempted first. After the
     rename, directories corresponding to rightmost path segments of
     the old name will be pruned away using *note removedirs(): 1132.

     New in version 1.5.2.

          Note: This function can fail with the new directory structure
          made if you lack permissions needed to remove the leaf
          directory or file.

 -- Function: os.rmdir (path)
     Remove (delete) the directory _path_.  Only works when the
     directory is empty, otherwise, *note OSError: 22e. is raised.  In
     order to remove whole directory trees, *note shutil.rmtree(): e8c.
     can be used.

     Availability: Unix, Windows.

 -- Function: os.stat (path)
     Perform the equivalent of a `stat()' system call on the given path.
     (This function follows symlinks; to stat a symlink use *note
     lstat(): de1.)

     The return value is an object whose attributes correspond to the
     members of the `stat' structure, namely:

        * `st_mode' - protection bits,

        * `st_ino' - inode number,

        * `st_dev' - device,

        * `st_nlink' - number of hard links,

        * `st_uid' - user id of owner,

        * `st_gid' - group id of owner,

        * `st_size' - size of file, in bytes,

        * `st_atime' - time of most recent access,

        * `st_mtime' - time of most recent content modification,

        * `st_ctime' - platform dependent; time of most recent metadata
          change on Unix, or the time of creation on Windows)

     Changed in version 2.3: If *note stat_float_times(): 45b. returns
     `True', the time values are floats, measuring seconds. Fractions
     of a second may be reported if the system supports that. On Mac
     OS, the times are always floats. See *note stat_float_times():
     45b. for further discussion.

     On some Unix systems (such as Linux), the following attributes may
     also be available:

        * `st_blocks' - number of blocks allocated for file

        * `st_blksize' - filesystem blocksize

        * `st_rdev' - type of device if an inode device

        * `st_flags' - user defined flags for file

     On other Unix systems (such as FreeBSD), the following attributes
     may be available (but may be only filled out if root tries to use
     them):

        * `st_gen' - file generation number

        * `st_birthtime' - time of file creation

     On Mac OS systems, the following attributes may also be available:

        * `st_rsize'

        * `st_creator'

        * `st_type'

     On RISCOS systems, the following attributes are also available:

        * `st_ftype' (file type)

        * `st_attrs' (attributes)

        * `st_obtype' (object type).

          Note: The exact meaning and resolution of the `st_atime',
          `st_mtime', and `st_ctime' attributes depend on the operating
          system and the file system. For example, on Windows systems
          using the FAT or FAT32 file systems, `st_mtime' has 2-second
          resolution, and `st_atime' has only 1-day resolution.  See
          your operating system documentation for details.

     For backward compatibility, the return value of *note stat(): 3bd.
     is also accessible as a tuple of at least 10 integers giving the
     most important (and portable) members of the `stat' structure, in
     the order `st_mode', `st_ino', `st_dev', `st_nlink', `st_uid',
     `st_gid', `st_size', `st_atime', `st_mtime', `st_ctime'. More
     items may be added at the end by some implementations.

     The standard module *note stat: 161. defines functions and
     constants that are useful for extracting information from a `stat'
     structure. (On Windows, some items are filled with dummy values.)

     Example:

         >>> import os
         >>> statinfo = os.stat('somefile.txt')
         >>> statinfo
         (33188, 422511, 769, 1, 1032, 100, 926, 1105022698,1105022732, 1105022732)
         >>> statinfo.st_size
         926

     Availability: Unix, Windows.

     Changed in version 2.2: Added access to values as attributes of
     the returned object.

     Changed in version 2.5: Added `st_gen' and `st_birthtime'.

 -- Function: os.stat_float_times ([newvalue])
     Determine whether `stat_result' represents time stamps as float
     objects.  If _newvalue_ is `True', future calls to *note stat():
     3bd. return floats, if it is `False', future calls return ints. If
     _newvalue_ is omitted, return the current setting.

     For compatibility with older Python versions, accessing
     `stat_result' as a tuple always returns integers.

     Changed in version 2.5: Python now returns float values by
     default. Applications which do not work correctly with floating
     point time stamps can use this function to restore the old
     behaviour.

     The resolution of the timestamps (that is the smallest possible
     fraction) depends on the system. Some systems only support second
     resolution; on these systems, the fraction will always be zero.

     It is recommended that this setting is only changed at program
     startup time in the ___main___ module; libraries should never
     change this setting. If an application uses a library that works
     incorrectly if floating point time stamps are processed, this
     application should turn the feature off until the library has been
     corrected.

 -- Function: os.statvfs (path)
     Perform a `statvfs()' system call on the given path.  The return
     value is an object whose attributes describe the filesystem on the
     given path, and correspond to the members of the `statvfs'
     structure, namely: `f_bsize', `f_frsize', `f_blocks', `f_bfree',
     `f_bavail', `f_files', `f_ffree', `f_favail', `f_flag',
     `f_namemax'.

     For backward compatibility, the return value is also accessible as
     a tuple whose values correspond to the attributes, in the order
     given above. The standard module *note statvfs: 162. defines
     constants that are useful for extracting information from a
     `statvfs' structure when accessing it as a sequence; this remains
     useful when writing code that needs to work with versions of Python
     that don't support accessing the fields as attributes.

     Availability: Unix.

     Changed in version 2.2: Added access to values as attributes of
     the returned object.

 -- Function: os.symlink (source, link_name)
     Create a symbolic link pointing to _source_ named _link_name_.

     Availability: Unix.

 -- Function: os.tempnam ([dir[, prefix]])
     Return a unique path name that is reasonable for creating a
     temporary file.  This will be an absolute path that names a
     potential directory entry in the directory _dir_ or a common
     location for temporary files if _dir_ is omitted or `None'.  If
     given and not `None', _prefix_ is used to provide a short prefix
     to the filename.  Applications are responsible for properly
     creating and managing files created using paths returned by *note
     tempnam(): 1135.; no automatic cleanup is provided. On Unix, the
     environment variable `TMPDIR' overrides _dir_, while on Windows `TMP'
     is used.  The specific behavior of this function depends on the C
     library implementation; some aspects are underspecified in system
     documentation.

          Warning: Use of *note tempnam(): 1135. is vulnerable to
          symlink attacks; consider using *note tmpfile(): 10e2.
          (section *note File Object Creation: 10df.) instead.

     Availability: Unix, Windows.

 -- Function: os.tmpnam ()
     Return a unique path name that is reasonable for creating a
     temporary file.  This will be an absolute path that names a
     potential directory entry in a common location for temporary
     files.  Applications are responsible for properly creating and
     managing files created using paths returned by *note tmpnam():
     1136.; no automatic cleanup is provided.

          Warning: Use of *note tmpnam(): 1136. is vulnerable to
          symlink attacks; consider using *note tmpfile(): 10e2.
          (section *note File Object Creation: 10df.) instead.

     Availability: Unix, Windows.  This function probably shouldn't be
     used on Windows, though: Microsoft's implementation of *note
     tmpnam(): 1136. always creates a name in the root directory of the
     current drive, and that's generally a poor location for a temp
     file (depending on privileges, you may not even be able to open a
     file using this name).

 -- Data: os.TMP_MAX
     The maximum number of unique names that *note tmpnam(): 1136. will
     generate before reusing names.

 -- Function: os.unlink (path)
     Remove (delete) the file _path_.  This is the same function as
     *note remove(): e8d.; the *note unlink(): 1127. name is its
     traditional Unix name.

     Availability: Unix, Windows.

 -- Function: os.utime (path, times)
     Set the access and modified times of the file specified by _path_.
     If _times_ is `None', then the file's access and modified times
     are set to the current time. (The effect is similar to running the
     Unix program *touch* on the path.)  Otherwise, _times_ must be a
     2-tuple of numbers, of the form `(atime, mtime)' which is used to
     set the access and modified times, respectively. Whether a
     directory can be given for _path_ depends on whether the operating
     system implements directories as files (for example, Windows does
     not).  Note that the exact times you set here may not be returned
     by a subsequent *note stat(): 3bd. call, depending on the
     resolution with which your operating system records access and
     modification times; see *note stat(): 3bd.

     Changed in version 2.0: Added support for `None' for _times_.

     Availability: Unix, Windows.

 -- Function: os.walk (top, topdown=True, onerror=None,
          followlinks=False)
     Generate the file names in a directory tree by walking the tree
     either top-down or bottom-up. For each directory in the tree
     rooted at directory _top_ (including _top_ itself), it yields a
     3-tuple `(dirpath, dirnames, filenames)'.

     _dirpath_ is a string, the path to the directory.  _dirnames_ is a
     list of the names of the subdirectories in _dirpath_ (excluding
     `'.'' and `'..'').  _filenames_ is a list of the names of the
     non-directory files in _dirpath_.  Note that the names in the
     lists contain no path components.  To get a full path (which
     begins with _top_) to a file or directory in _dirpath_, do
     `os.path.join(dirpath, name)'.

     If optional argument _topdown_ is `True' or not specified, the
     triple for a directory is generated before the triples for any of
     its subdirectories (directories are generated top-down).  If
     _topdown_ is `False', the triple for a directory is generated
     after the triples for all of its subdirectories (directories are
     generated bottom-up).

     When _topdown_ is `True', the caller can modify the _dirnames_
     list in-place (perhaps using *note del: 55f. or slice assignment),
     and *note walk(): 34c. will only recurse into the subdirectories
     whose names remain in _dirnames_; this can be used to prune the
     search, impose a specific order of visiting, or even to inform
     *note walk(): 34c. about directories the caller creates or renames
     before it resumes *note walk(): 34c. again.  Modifying _dirnames_
     when _topdown_ is `False' is ineffective, because in bottom-up
     mode the directories in _dirnames_ are generated before _dirpath_
     itself is generated.

     By default, errors from the *note listdir(): 2cf. call are
     ignored.  If optional argument _onerror_ is specified, it should
     be a function; it will be called with one argument, an *note
     OSError: 22e. instance.  It can report the error to continue with
     the walk, or raise the exception to abort the walk.  Note that the
     filename is available as the `filename' attribute of the exception
     object.

     By default, *note walk(): 34c. will not walk down into symbolic
     links that resolve to directories. Set _followlinks_ to `True' to
     visit directories pointed to by symlinks, on systems that support
     them.

     New in version 2.6: The _followlinks_ parameter.

          Note: Be aware that setting _followlinks_ to `True' can lead
          to infinite recursion if a link points to a parent directory
          of itself. *note walk(): 34c. does not keep track of the
          directories it visited already.

          Note: If you pass a relative pathname, don't change the
          current working directory between resumptions of *note
          walk(): 34c.  *note walk(): 34c. never changes the current
          directory, and assumes that its caller doesn't either.

     This example displays the number of bytes taken by non-directory
     files in each directory under the starting directory, except that
     it doesn't look under any CVS subdirectory:

         import os
         from os.path import join, getsize
         for root, dirs, files in os.walk('python/Lib/email'):
             print root, "consumes",
             print sum(getsize(join(root, name)) for name in files),
             print "bytes in", len(files), "non-directory files"
             if 'CVS' in dirs:
                 dirs.remove('CVS')  # don't visit CVS directories

     In the next example, walking the tree bottom-up is essential:
     *note rmdir(): e8e.  doesn't allow deleting a directory before the
     directory is empty:

         # Delete everything reachable from the directory named in "top",
         # assuming there are no symbolic links.
         # CAUTION:  This is dangerous!  For example, if top == '/', it
         # could delete all your disk files.
         import os
         for root, dirs, files in os.walk(top, topdown=False):
             for name in files:
                 os.remove(os.path.join(root, name))
             for name in dirs:
                 os.rmdir(os.path.join(root, name))

     New in version 2.3.



Local Variables:
coding: utf-8
End:
