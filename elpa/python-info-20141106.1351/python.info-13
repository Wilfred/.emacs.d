This is python.info, produced by makeinfo version 5.2 from python.texi.

     Python 2.7.8, November 06, 2014

     Georg Brandl

     Copyright © 1990-2014, Python Software Foundation

INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.1.3.


File: python.info,  Node: Synchronization primitives,  Next: Shared ctypes Objects,  Prev: Connection Objects<2>,  Up: Reference

5.16.6.12 Synchronization primitives
....................................

Generally synchronization primitives are not as necessary in a
multiprocess program as they are in a multithreaded program.  See the
documentation for *note threading: 179. module.

  Note that one can also create synchronization primitives by using a
manager object – see *note Managers: 1639.

 -- Class: multiprocessing.BoundedSemaphore ([value])

     A bounded semaphore object: a clone of *note
     threading.BoundedSemaphore: 15cf.

     (On Mac OS X, this is indistinguishable from *note Semaphore: 1622.
     because ‘sem_getvalue()’ is not implemented on that platform).

 -- Class: multiprocessing.Condition ([lock])

     A condition variable: a clone of *note threading.Condition: 15e9.

     If _lock_ is specified then it should be a *note Lock: 1620. or
     *note RLock: 1621. object from *note multiprocessing: 119.

 -- Class: multiprocessing.Event

     A clone of *note threading.Event: 269.  This method returns the
     state of the internal semaphore on exit, so it will always return
     ‘True’ except if a timeout is given and the operation times out.

     Changed in version 2.7: Previously, the method always returned
     ‘None’.

 -- Class: multiprocessing.Lock

     A non-recursive lock object: a clone of *note threading.Lock: 15ca.

 -- Class: multiprocessing.RLock

     A recursive lock object: a clone of *note threading.RLock: 15cc.

 -- Class: multiprocessing.Semaphore ([value])

     A semaphore object: a clone of *note threading.Semaphore: 15f1.

     Note: The ‘acquire()’ method of *note BoundedSemaphore: 1623, *note
     Lock: 1620, *note RLock: 1621. and *note Semaphore: 1622. has a
     timeout parameter not supported by the equivalents in *note
     threading: 179.  The signature is ‘acquire(block=True,
     timeout=None)’ with keyword parameters being acceptable.  If
     _block_ is ‘True’ and _timeout_ is not ‘None’ then it specifies a
     timeout in seconds.  If _block_ is ‘False’ then _timeout_ is
     ignored.

     On Mac OS X, ‘sem_timedwait’ is unsupported, so calling ‘acquire()’
     with a timeout will emulate that function’s behavior using a
     sleeping loop.

     Note: If the SIGINT signal generated by Ctrl-C arrives while the
     main thread is blocked by a call to ‘BoundedSemaphore.acquire()’,
     ‘Lock.acquire()’, ‘RLock.acquire()’, ‘Semaphore.acquire()’,
     ‘Condition.acquire()’ or ‘Condition.wait()’ then the call will be
     immediately interrupted and *note KeyboardInterrupt: 251. will be
     raised.

     This differs from the behaviour of *note threading: 179. where
     SIGINT will be ignored while the equivalent blocking calls are in
     progress.


File: python.info,  Node: Shared ctypes Objects,  Next: Managers,  Prev: Synchronization primitives,  Up: Reference

5.16.6.13 Shared ‘ctypes’ Objects
.................................

It is possible to create shared objects using shared memory which can be
inherited by child processes.

 -- Function: multiprocessing.Value (typecode_or_type, *args[, lock])

     Return a *note ctypes: 78. object allocated from shared memory.  By
     default the return value is actually a synchronized wrapper for the
     object.

     _typecode_or_type_ determines the type of the returned object: it
     is either a ctypes type or a one character typecode of the kind
     used by the *note array: e. module.  _*args_ is passed on to the
     constructor for the type.

     If _lock_ is ‘True’ (the default) then a new recursive lock object
     is created to synchronize access to the value.  If _lock_ is a
     *note Lock: 1620. or *note RLock: 1621. object then that will be
     used to synchronize access to the value.  If _lock_ is ‘False’ then
     access to the returned object will not be automatically protected
     by a lock, so it will not necessarily be "process-safe".

     Operations like ‘+=’ which involve a read and write are not atomic.
     So if, for instance, you want to atomically increment a shared
     value it is insufficient to just do

          counter.value += 1

     Assuming the associated lock is recursive (which it is by default)
     you can instead do

          with counter.get_lock():
              counter.value += 1

     Note that _lock_ is a keyword-only argument.

 -- Function: multiprocessing.Array (typecode_or_type,
          size_or_initializer, *, lock=True)

     Return a ctypes array allocated from shared memory.  By default the
     return value is actually a synchronized wrapper for the array.

     _typecode_or_type_ determines the type of the elements of the
     returned array: it is either a ctypes type or a one character
     typecode of the kind used by the *note array: e. module.  If
     _size_or_initializer_ is an integer, then it determines the length
     of the array, and the array will be initially zeroed.  Otherwise,
     _size_or_initializer_ is a sequence which is used to initialize the
     array and whose length determines the length of the array.

     If _lock_ is ‘True’ (the default) then a new lock object is created
     to synchronize access to the value.  If _lock_ is a *note Lock:
     1620. or *note RLock: 1621. object then that will be used to
     synchronize access to the value.  If _lock_ is ‘False’ then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be "process-safe".

     Note that _lock_ is a keyword only argument.

     Note that an array of *note ctypes.c_char: 1506. has _value_ and
     _raw_ attributes which allow one to use it to store and retrieve
     strings.

* Menu:

* The multiprocessing.sharedctypes module: The multiprocessing sharedctypes module. 


File: python.info,  Node: The multiprocessing sharedctypes module,  Up: Shared ctypes Objects

5.16.6.14 The ‘multiprocessing.sharedctypes’ module
...................................................

The *note multiprocessing.sharedctypes: 11e. module provides functions
for allocating *note ctypes: 78. objects from shared memory which can be
inherited by child processes.

     Note: Although it is possible to store a pointer in shared memory
     remember that this will refer to a location in the address space of
     a specific process.  However, the pointer is quite likely to be
     invalid in the context of a second process and trying to
     dereference the pointer from the second process may cause a crash.

 -- Function: multiprocessing.sharedctypes.RawArray (typecode_or_type,
          size_or_initializer)

     Return a ctypes array allocated from shared memory.

     _typecode_or_type_ determines the type of the elements of the
     returned array: it is either a ctypes type or a one character
     typecode of the kind used by the *note array: e. module.  If
     _size_or_initializer_ is an integer then it determines the length
     of the array, and the array will be initially zeroed.  Otherwise
     _size_or_initializer_ is a sequence which is used to initialize the
     array and whose length determines the length of the array.

     Note that setting and getting an element is potentially non-atomic
     – use *note Array(): 165c. instead to make sure that access is
     automatically synchronized using a lock.

 -- Function: multiprocessing.sharedctypes.RawValue (typecode_or_type,
          *args)

     Return a ctypes object allocated from shared memory.

     _typecode_or_type_ determines the type of the returned object: it
     is either a ctypes type or a one character typecode of the kind
     used by the *note array: e. module.  _*args_ is passed on to the
     constructor for the type.

     Note that setting and getting the value is potentially non-atomic –
     use *note Value(): 165e. instead to make sure that access is
     automatically synchronized using a lock.

     Note that an array of *note ctypes.c_char: 1506. has ‘value’ and
     ‘raw’ attributes which allow one to use it to store and retrieve
     strings – see documentation for *note ctypes: 78.

 -- Function: multiprocessing.sharedctypes.Array (typecode_or_type,
          size_or_initializer, *args[, lock])

     The same as *note RawArray(): 165b. except that depending on the
     value of _lock_ a process-safe synchronization wrapper may be
     returned instead of a raw ctypes array.

     If _lock_ is ‘True’ (the default) then a new lock object is created
     to synchronize access to the value.  If _lock_ is a *note Lock:
     1620. or *note RLock: 1621. object then that will be used to
     synchronize access to the value.  If _lock_ is ‘False’ then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be "process-safe".

     Note that _lock_ is a keyword-only argument.

 -- Function: multiprocessing.sharedctypes.Value (typecode_or_type,
          *args[, lock])

     The same as *note RawValue(): 165d. except that depending on the
     value of _lock_ a process-safe synchronization wrapper may be
     returned instead of a raw ctypes object.

     If _lock_ is ‘True’ (the default) then a new lock object is created
     to synchronize access to the value.  If _lock_ is a *note Lock:
     1620. or *note RLock: 1621. object then that will be used to
     synchronize access to the value.  If _lock_ is ‘False’ then access
     to the returned object will not be automatically protected by a
     lock, so it will not necessarily be "process-safe".

     Note that _lock_ is a keyword-only argument.

 -- Function: multiprocessing.sharedctypes.copy (obj)

     Return a ctypes object allocated from shared memory which is a copy
     of the ctypes object _obj_.

 -- Function: multiprocessing.sharedctypes.synchronized (obj[, lock])

     Return a process-safe wrapper object for a ctypes object which uses
     _lock_ to synchronize access.  If _lock_ is ‘None’ (the default)
     then a *note multiprocessing.RLock: 1621. object is created
     automatically.

     A synchronized wrapper will have two methods in addition to those
     of the object it wraps: ‘get_obj()’ returns the wrapped object and
     ‘get_lock()’ returns the lock object used for synchronization.

     Note that accessing the ctypes object through the wrapper can be a
     lot slower than accessing the raw ctypes object.

  The table below compares the syntax for creating shared ctypes objects
from shared memory with the normal ctypes syntax.  (In the table
‘MyStruct’ is some subclass of *note ctypes.Structure: 1527.)

ctypes                   sharedctypes using type        sharedctypes using typecode
                                                        
----------------------------------------------------------------------------------------
                                                        
c_double(2.4)            RawValue(c_double, 2.4)        RawValue(’d’, 2.4)
                                                        
                                                        
MyStruct(4, 6)           RawValue(MyStruct, 4, 6)
                         
                                                        
(c_short * 7)()          RawArray(c_short, 7)           RawArray(’h’, 7)
                                                        
                                                        
(c_int * 3)(9, 2, 8)     RawArray(c_int, (9, 2, 8))     RawArray(’i’, (9, 2, 8))
                                                        

  Below is an example where a number of ctypes objects are modified by a
child process:

     from multiprocessing import Process, Lock
     from multiprocessing.sharedctypes import Value, Array
     from ctypes import Structure, c_double

     class Point(Structure):
         _fields_ = [('x', c_double), ('y', c_double)]

     def modify(n, x, s, A):
         n.value **= 2
         x.value **= 2
         s.value = s.value.upper()
         for a in A:
             a.x **= 2
             a.y **= 2

     if __name__ == '__main__':
         lock = Lock()

         n = Value('i', 7)
         x = Value(c_double, 1.0/3.0, lock=False)
         s = Array('c', 'hello world', lock=lock)
         A = Array(Point, [(1.875,-6.25), (-5.75,2.0), (2.375,9.5)], lock=lock)

         p = Process(target=modify, args=(n, x, s, A))
         p.start()
         p.join()

         print n.value
         print x.value
         print s.value
         print [(a.x, a.y) for a in A]

  The results printed are

     49
     0.1111111111111111
     HELLO WORLD
     [(3.515625, 39.0625), (33.0625, 4.0), (5.640625, 90.25)]


File: python.info,  Node: Managers,  Next: Proxy Objects,  Prev: Shared ctypes Objects,  Up: Reference

5.16.6.15 Managers
..................

Managers provide a way to create data which can be shared between
different processes.  A manager object controls a server process which
manages _shared objects_.  Other processes can access the shared objects
by using proxies.

 -- Function: multiprocessing.Manager ()

     Returns a started *note SyncManager: 1663. object which can be used
     for sharing objects between processes.  The returned manager object
     corresponds to a spawned child process and has methods which will
     create shared objects and return corresponding proxies.

  Manager processes will be shutdown as soon as they are garbage
collected or their parent process exits.  The manager classes are
defined in the *note multiprocessing.managers: 11c. module:

 -- Class: multiprocessing.managers.BaseManager ([address[, authkey]])

     Create a BaseManager object.

     Once created one should call *note start(): 1665. or
     ‘get_server().serve_forever()’ to ensure that the manager object
     refers to a started manager process.

     _address_ is the address on which the manager process listens for
     new connections.  If _address_ is ‘None’ then an arbitrary one is
     chosen.

     _authkey_ is the authentication key which will be used to check the
     validity of incoming connections to the server process.  If
     _authkey_ is ‘None’ then ‘current_process().authkey’.  Otherwise
     _authkey_ is used and it must be a string.

      -- Method: start ([initializer[, initargs]])

          Start a subprocess to start the manager.  If _initializer_ is
          not ‘None’ then the subprocess will call
          ‘initializer(*initargs)’ when it starts.

      -- Method: get_server ()

          Returns a ‘Server’ object which represents the actual server
          under the control of the Manager.  The ‘Server’ object
          supports the ‘serve_forever()’ method:

               >>> from multiprocessing.managers import BaseManager
               >>> manager = BaseManager(address=('', 50000), authkey='abc')
               >>> server = manager.get_server()
               >>> server.serve_forever()

          ‘Server’ additionally has an *note address: 1667. attribute.

      -- Method: connect ()

          Connect a local manager object to a remote manager process:

               >>> from multiprocessing.managers import BaseManager
               >>> m = BaseManager(address=('127.0.0.1', 5000), authkey='abc')
               >>> m.connect()

      -- Method: shutdown ()

          Stop the process used by the manager.  This is only available
          if *note start(): 1665. has been used to start the server
          process.

          This can be called multiple times.

      -- Method: register (typeid[, callable[, proxytype[, exposed[,
               method_to_typeid[, create_method]]]]])

          A classmethod which can be used for registering a type or
          callable with the manager class.

          _typeid_ is a "type identifier" which is used to identify a
          particular type of shared object.  This must be a string.

          _callable_ is a callable used for creating objects for this
          type identifier.  If a manager instance will be created using
          the ‘from_address()’ classmethod or if the _create_method_
          argument is ‘False’ then this can be left as ‘None’.

          _proxytype_ is a subclass of *note BaseProxy: 166b. which is
          used to create proxies for shared objects with this _typeid_.
          If ‘None’ then a proxy class is created automatically.

          _exposed_ is used to specify a sequence of method names which
          proxies for this typeid should be allowed to access using
          *note BaseProxy._callmethod(): 166c.  (If _exposed_ is ‘None’
          then ‘proxytype._exposed_’ is used instead if it exists.)  In
          the case where no exposed list is specified, all "public
          methods" of the shared object will be accessible.  (Here a
          "public method" means any attribute which has a *note
          __call__(): 6fa. method and whose name does not begin with
          ‘'_'’.)

          _method_to_typeid_ is a mapping used to specify the return
          type of those exposed methods which should return a proxy.  It
          maps method names to typeid strings.  (If _method_to_typeid_
          is ‘None’ then ‘proxytype._method_to_typeid_’ is used instead
          if it exists.)  If a method’s name is not a key of this
          mapping or if the mapping is ‘None’ then the object returned
          by the method will be copied by value.

          _create_method_ determines whether a method should be created
          with name _typeid_ which can be used to tell the server
          process to create a new shared object and return a proxy for
          it.  By default it is ‘True’.

     *note BaseManager: 1664. instances also have one read-only
     property:

      -- Attribute: address

          The address used by the manager.

 -- Class: multiprocessing.managers.SyncManager

     A subclass of *note BaseManager: 1664. which can be used for the
     synchronization of processes.  Objects of this type are returned by
     ‘multiprocessing.Manager()’.

     It also supports creation of shared lists and dictionaries.

      -- Method: BoundedSemaphore ([value])

          Create a shared *note threading.BoundedSemaphore: 15cf. object
          and return a proxy for it.

      -- Method: Condition ([lock])

          Create a shared *note threading.Condition: 15e9. object and
          return a proxy for it.

          If _lock_ is supplied then it should be a proxy for a *note
          threading.Lock: 15ca. or *note threading.RLock: 15cc. object.

      -- Method: Event ()

          Create a shared *note threading.Event: 269. object and return
          a proxy for it.

      -- Method: Lock ()

          Create a shared *note threading.Lock: 15ca. object and return
          a proxy for it.

      -- Method: Namespace ()

          Create a shared *note Namespace: 1671. object and return a
          proxy for it.

      -- Method: Queue ([maxsize])

          Create a shared *note Queue.Queue: 609. object and return a
          proxy for it.

      -- Method: RLock ()

          Create a shared *note threading.RLock: 15cc. object and return
          a proxy for it.

      -- Method: Semaphore ([value])

          Create a shared *note threading.Semaphore: 15f1. object and
          return a proxy for it.

      -- Method: Array (typecode, sequence)

          Create an array and return a proxy for it.

      -- Method: Value (typecode, value)

          Create an object with a writable ‘value’ attribute and return
          a proxy for it.

      -- Method: dict ()

      -- Method: dict (mapping)

      -- Method: dict (sequence)

          Create a shared ‘dict’ object and return a proxy for it.

      -- Method: list ()

      -- Method: list (sequence)

          Create a shared ‘list’ object and return a proxy for it.

          Note: Modifications to mutable values or items in dict and
          list proxies will not be propagated through the manager,
          because the proxy has no way of knowing when its values or
          items are modified.  To modify such an item, you can re-assign
          the modified object to the container proxy:

               # create a list proxy and append a mutable object (a dictionary)
               lproxy = manager.list()
               lproxy.append({})
               # now mutate the dictionary
               d = lproxy[0]
               d['a'] = 1
               d['b'] = 2
               # at this point, the changes to d are not yet synced, but by
               # reassigning the dictionary, the proxy is notified of the change
               lproxy[0] = d

* Menu:

* Namespace objects:: 
* Customized managers:: 
* Using a remote manager:: 


File: python.info,  Node: Namespace objects,  Next: Customized managers,  Up: Managers

5.16.6.16 Namespace objects
...........................

A namespace object has no public methods, but does have writable
attributes.  Its representation shows the values of its attributes.

  However, when using a proxy for a namespace object, an attribute
beginning with ‘'_'’ will be an attribute of the proxy and not an
attribute of the referent:

     >>> manager = multiprocessing.Manager()
     >>> Global = manager.Namespace()
     >>> Global.x = 10
     >>> Global.y = 'hello'
     >>> Global._z = 12.3    # this is an attribute of the proxy
     >>> print Global
     Namespace(x=10, y='hello')


File: python.info,  Node: Customized managers,  Next: Using a remote manager,  Prev: Namespace objects,  Up: Managers

5.16.6.17 Customized managers
.............................

To create one’s own manager, one creates a subclass of *note
BaseManager: 1664. and uses the *note register(): 166a. classmethod to
register new types or callables with the manager class.  For example:

     from multiprocessing.managers import BaseManager

     class MathsClass(object):
         def add(self, x, y):
             return x + y
         def mul(self, x, y):
             return x * y

     class MyManager(BaseManager):
         pass

     MyManager.register('Maths', MathsClass)

     if __name__ == '__main__':
         manager = MyManager()
         manager.start()
         maths = manager.Maths()
         print maths.add(4, 3)         # prints 7
         print maths.mul(7, 8)         # prints 56


File: python.info,  Node: Using a remote manager,  Prev: Customized managers,  Up: Managers

5.16.6.18 Using a remote manager
................................

It is possible to run a manager server on one machine and have clients
use it from other machines (assuming that the firewalls involved allow
it).

  Running the following commands creates a server for a single shared
queue which remote clients can access:

     >>> from multiprocessing.managers import BaseManager
     >>> import Queue
     >>> queue = Queue.Queue()
     >>> class QueueManager(BaseManager): pass
     >>> QueueManager.register('get_queue', callable=lambda:queue)
     >>> m = QueueManager(address=('', 50000), authkey='abracadabra')
     >>> s = m.get_server()
     >>> s.serve_forever()

  One client can access the server as follows:

     >>> from multiprocessing.managers import BaseManager
     >>> class QueueManager(BaseManager): pass
     >>> QueueManager.register('get_queue')
     >>> m = QueueManager(address=('foo.bar.org', 50000), authkey='abracadabra')
     >>> m.connect()
     >>> queue = m.get_queue()
     >>> queue.put('hello')

  Another client can also use it:

     >>> from multiprocessing.managers import BaseManager
     >>> class QueueManager(BaseManager): pass
     >>> QueueManager.register('get_queue')
     >>> m = QueueManager(address=('foo.bar.org', 50000), authkey='abracadabra')
     >>> m.connect()
     >>> queue = m.get_queue()
     >>> queue.get()
     'hello'

  Local processes can also access that queue, using the code from above
on the client to access it remotely:

     >>> from multiprocessing import Process, Queue
     >>> from multiprocessing.managers import BaseManager
     >>> class Worker(Process):
     ...     def __init__(self, q):
     ...         self.q = q
     ...         super(Worker, self).__init__()
     ...     def run(self):
     ...         self.q.put('local hello')
     ...
     >>> queue = Queue()
     >>> w = Worker(queue)
     >>> w.start()
     >>> class QueueManager(BaseManager): pass
     ...
     >>> QueueManager.register('get_queue', callable=lambda: queue)
     >>> m = QueueManager(address=('', 50000), authkey='abracadabra')
     >>> s = m.get_server()
     >>> s.serve_forever()


File: python.info,  Node: Proxy Objects,  Next: Process Pools,  Prev: Managers,  Up: Reference

5.16.6.19 Proxy Objects
.......................

A proxy is an object which _refers_ to a shared object which lives
(presumably) in a different process.  The shared object is said to be
the _referent_ of the proxy.  Multiple proxy objects may have the same
referent.

  A proxy object has methods which invoke corresponding methods of its
referent (although not every method of the referent will necessarily be
available through the proxy).  A proxy can usually be used in most of
the same ways that its referent can:

     >>> from multiprocessing import Manager
     >>> manager = Manager()
     >>> l = manager.list([i*i for i in range(10)])
     >>> print l
     [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]
     >>> print repr(l)
     <ListProxy object, typeid 'list' at 0x...>
     >>> l[4]
     16
     >>> l[2:5]
     [4, 9, 16]

  Notice that applying *note str(): 1ea. to a proxy will return the
representation of the referent, whereas applying *note repr(): 145. will
return the representation of the proxy.

  An important feature of proxy objects is that they are picklable so
they can be passed between processes.  Note, however, that if a proxy is
sent to the corresponding manager’s process then unpickling it will
produce the referent itself.  This means, for example, that one shared
object can contain a second:

     >>> a = manager.list()
     >>> b = manager.list()
     >>> a.append(b)         # referent of a now contains referent of b
     >>> print a, b
     [[]] []
     >>> b.append('hello')
     >>> print a, b
     [['hello']] ['hello']

     Note: The proxy types in *note multiprocessing: 119. do nothing to
     support comparisons by value.  So, for instance, we have:

          >>> manager.list([1,2,3]) == [1,2,3]
          False

     One should just use a copy of the referent instead when making
     comparisons.

 -- Class: multiprocessing.managers.BaseProxy

     Proxy objects are instances of subclasses of *note BaseProxy: 166b.

      -- Method: _callmethod (methodname[, args[, kwds]])

          Call and return the result of a method of the proxy’s
          referent.

          If ‘proxy’ is a proxy whose referent is ‘obj’ then the
          expression

               proxy._callmethod(methodname, args, kwds)

          will evaluate the expression

               getattr(obj, methodname)(*args, **kwds)

          in the manager’s process.

          The returned value will be a copy of the result of the call or
          a proxy to a new shared object – see documentation for the
          _method_to_typeid_ argument of *note BaseManager.register():
          166a.

          If an exception is raised by the call, then is re-raised by
          *note _callmethod(): 166c.  If some other exception is raised
          in the manager’s process then this is converted into a
          ‘RemoteError’ exception and is raised by *note _callmethod():
          166c.

          Note in particular that an exception will be raised if
          _methodname_ has not been _exposed_

          An example of the usage of *note _callmethod(): 166c.:

               >>> l = manager.list(range(10))
               >>> l._callmethod('__len__')
               10
               >>> l._callmethod('__getslice__', (2, 7))   # equiv to `l[2:7]`
               [2, 3, 4, 5, 6]
               >>> l._callmethod('__getitem__', (20,))     # equiv to `l[20]`
               Traceback (most recent call last):
               ...
               IndexError: list index out of range

      -- Method: _getvalue ()

          Return a copy of the referent.

          If the referent is unpicklable then this will raise an
          exception.

      -- Method: __repr__ ()

          Return a representation of the proxy object.

      -- Method: __str__ ()

          Return the representation of the referent.

* Menu:

* Cleanup: Cleanup<2>. 


File: python.info,  Node: Cleanup<2>,  Up: Proxy Objects

5.16.6.20 Cleanup
.................

A proxy object uses a weakref callback so that when it gets garbage
collected it deregisters itself from the manager which owns its
referent.

  A shared object gets deleted from the manager process when there are
no longer any proxies referring to it.


File: python.info,  Node: Process Pools,  Next: Listeners and Clients,  Prev: Proxy Objects,  Up: Reference

5.16.6.21 Process Pools
.......................

One can create a pool of processes which will carry out tasks submitted
to it with the ‘Pool’ class.

 -- Class: multiprocessing.Pool ([processes[, initializer[, initargs[,
          maxtasksperchild]]]])

     A process pool object which controls a pool of worker processes to
     which jobs can be submitted.  It supports asynchronous results with
     timeouts and callbacks and has a parallel map implementation.

     _processes_ is the number of worker processes to use.  If
     _processes_ is ‘None’ then the number returned by ‘cpu_count()’ is
     used.  If _initializer_ is not ‘None’ then each worker process will
     call ‘initializer(*initargs)’ when it starts.

     Note that the methods of the pool object should only be called by
     the process which created the pool.

     New in version 2.7: _maxtasksperchild_ is the number of tasks a
     worker process can complete before it will exit and be replaced
     with a fresh worker process, to enable unused resources to be
     freed.  The default _maxtasksperchild_ is None, which means worker
     processes will live as long as the pool.

          Note: Worker processes within a ‘Pool’ typically live for the
          complete duration of the Pool’s work queue.  A frequent
          pattern found in other systems (such as Apache, mod_wsgi, etc)
          to free resources held by workers is to allow a worker within
          a pool to complete only a set amount of work before being
          exiting, being cleaned up and a new process spawned to replace
          the old one.  The _maxtasksperchild_ argument to the ‘Pool’
          exposes this ability to the end user.

      -- Method: apply (func[, args[, kwds]])

          Equivalent of the *note apply(): 303. built-in function.  It
          blocks until the result is ready, so *note apply_async():
          1684. is better suited for performing work in parallel.
          Additionally, _func_ is only executed in one of the workers of
          the pool.

      -- Method: apply_async (func[, args[, kwds[, callback]]])

          A variant of the *note apply(): 303. method which returns a
          result object.

          If _callback_ is specified then it should be a callable which
          accepts a single argument.  When the result becomes ready
          _callback_ is applied to it (unless the call failed).
          _callback_ should complete immediately since otherwise the
          thread which handles the results will get blocked.

      -- Method: map (func, iterable[, chunksize])

          A parallel equivalent of the *note map(): 304. built-in
          function (it supports only one _iterable_ argument though).
          It blocks until the result is ready.

          This method chops the iterable into a number of chunks which
          it submits to the process pool as separate tasks.  The
          (approximate) size of these chunks can be specified by setting
          _chunksize_ to a positive integer.

      -- Method: map_async (func, iterable[, chunksize[, callback]])

          A variant of the *note map(): 1685. method which returns a
          result object.

          If _callback_ is specified then it should be a callable which
          accepts a single argument.  When the result becomes ready
          _callback_ is applied to it (unless the call failed).
          _callback_ should complete immediately since otherwise the
          thread which handles the results will get blocked.

      -- Method: imap (func, iterable[, chunksize])

          An equivalent of *note itertools.imap(): d66.

          The _chunksize_ argument is the same as the one used by the
          *note map(): 1685. method.  For very long iterables using a
          large value for _chunksize_ can make the job complete *much*
          faster than using the default value of ‘1’.

          Also if _chunksize_ is ‘1’ then the ‘next()’ method of the
          iterator returned by the *note imap(): 1687. method has an
          optional _timeout_ parameter: ‘next(timeout)’ will raise
          ‘multiprocessing.TimeoutError’ if the result cannot be
          returned within _timeout_ seconds.

      -- Method: imap_unordered (func, iterable[, chunksize])

          The same as *note imap(): 1687. except that the ordering of
          the results from the returned iterator should be considered
          arbitrary.  (Only when there is only one worker process is the
          order guaranteed to be "correct".)

      -- Method: close ()

          Prevents any more tasks from being submitted to the pool.
          Once all the tasks have been completed the worker processes
          will exit.

      -- Method: terminate ()

          Stops the worker processes immediately without completing
          outstanding work.  When the pool object is garbage collected
          *note terminate(): 168a. will be called immediately.

      -- Method: join ()

          Wait for the worker processes to exit.  One must call *note
          close(): 1689. or *note terminate(): 168a. before using *note
          join(): 168b.

 -- Class: multiprocessing.pool.AsyncResult

     The class of the result returned by ‘Pool.apply_async()’ and
     ‘Pool.map_async()’.

      -- Method: get ([timeout])

          Return the result when it arrives.  If _timeout_ is not ‘None’
          and the result does not arrive within _timeout_ seconds then
          ‘multiprocessing.TimeoutError’ is raised.  If the remote call
          raised an exception then that exception will be reraised by
          *note get(): 168d.

      -- Method: wait ([timeout])

          Wait until the result is available or until _timeout_ seconds
          pass.

      -- Method: ready ()

          Return whether the call has completed.

      -- Method: successful ()

          Return whether the call completed without raising an
          exception.  Will raise *note AssertionError: 80c. if the
          result is not ready.

  The following example demonstrates the use of a pool:

     from multiprocessing import Pool

     def f(x):
         return x*x

     if __name__ == '__main__':
         pool = Pool(processes=4)              # start 4 worker processes

         result = pool.apply_async(f, (10,))    # evaluate "f(10)" asynchronously
         print result.get(timeout=1)           # prints "100" unless your computer is *very* slow

         print pool.map(f, range(10))          # prints "[0, 1, 4,..., 81]"

         it = pool.imap(f, range(10))
         print it.next()                       # prints "0"
         print it.next()                       # prints "1"
         print it.next(timeout=1)              # prints "4" unless your computer is *very* slow

         import time
         result = pool.apply_async(time.sleep, (10,))
         print result.get(timeout=1)           # raises TimeoutError


File: python.info,  Node: Listeners and Clients,  Next: Authentication keys,  Prev: Process Pools,  Up: Reference

5.16.6.22 Listeners and Clients
...............................

Usually message passing between processes is done using queues or by
using *note Connection: 163e. objects returned by *note Pipe(): 1619.

  However, the *note multiprocessing.connection: 11a. module allows some
extra flexibility.  It basically gives a high level message oriented API
for dealing with sockets or Windows named pipes, and also has support
for _digest authentication_ using the *note hmac: e8. module.

 -- Function: multiprocessing.connection.deliver_challenge (connection,
          authkey)

     Send a randomly generated message to the other end of the
     connection and wait for a reply.

     If the reply matches the digest of the message using _authkey_ as
     the key then a welcome message is sent to the other end of the
     connection.  Otherwise *note AuthenticationError: 1693. is raised.

 -- Function: multiprocessing.connection.answer_challenge (connection,
          authkey)

     Receive a message, calculate the digest of the message using
     _authkey_ as the key, and then send the digest back.

     If a welcome message is not received, then *note
     AuthenticationError: 1693. is raised.

 -- Function: multiprocessing.connection.Client (address[, family[,
          authenticate[, authkey]]])

     Attempt to set up a connection to the listener which is using
     address _address_, returning a *note Connection: 163e.

     The type of the connection is determined by _family_ argument, but
     this can generally be omitted since it can usually be inferred from
     the format of _address_.  (See *note Address Formats: 1696.)

     If _authenticate_ is ‘True’ or _authkey_ is a string then digest
     authentication is used.  The key used for authentication will be
     either _authkey_ or ‘current_process().authkey)’ if _authkey_ is
     ‘None’.  If authentication fails then *note AuthenticationError:
     1693. is raised.  See *note Authentication keys: 1631.

 -- Class: multiprocessing.connection.Listener ([address[, family[,
          backlog[, authenticate[, authkey]]]]])

     A wrapper for a bound socket or Windows named pipe which is
     ’listening’ for connections.

     _address_ is the address to be used by the bound socket or named
     pipe of the listener object.

          Note: If an address of ’0.0.0.0’ is used, the address will not
          be a connectable end point on Windows.  If you require a
          connectable end-point, you should use ’127.0.0.1’.

     _family_ is the type of socket (or named pipe) to use.  This can be
     one of the strings ‘'AF_INET'’ (for a TCP socket), ‘'AF_UNIX'’ (for
     a Unix domain socket) or ‘'AF_PIPE'’ (for a Windows named pipe).
     Of these only the first is guaranteed to be available.  If _family_
     is ‘None’ then the family is inferred from the format of _address_.
     If _address_ is also ‘None’ then a default is chosen.  This default
     is the family which is assumed to be the fastest available.  See
     *note Address Formats: 1696.  Note that if _family_ is ‘'AF_UNIX'’
     and address is ‘None’ then the socket will be created in a private
     temporary directory created using *note tempfile.mkstemp(): e88.

     If the listener object uses a socket then _backlog_ (1 by default)
     is passed to the *note listen(): 1698. method of the socket once it
     has been bound.

     If _authenticate_ is ‘True’ (‘False’ by default) or _authkey_ is
     not ‘None’ then digest authentication is used.

     If _authkey_ is a string then it will be used as the authentication
     key; otherwise it must be _None_.

     If _authkey_ is ‘None’ and _authenticate_ is ‘True’ then
     ‘current_process().authkey’ is used as the authentication key.  If
     _authkey_ is ‘None’ and _authenticate_ is ‘False’ then no
     authentication is done.  If authentication fails then *note
     AuthenticationError: 1693. is raised.  See *note Authentication
     keys: 1631.

      -- Method: accept ()

          Accept a connection on the bound socket or named pipe of the
          listener object and return a *note Connection: 163e. object.
          If authentication is attempted and fails, then
          ‘AuthenticationError’ is raised.

      -- Method: close ()

          Close the bound socket or named pipe of the listener object.
          This is called automatically when the listener is garbage
          collected.  However it is advisable to call it explicitly.

     Listener objects have the following read-only properties:

      -- Attribute: address

          The address which is being used by the Listener object.

      -- Attribute: last_accepted

          The address from which the last accepted connection came.  If
          this is unavailable then it is ‘None’.

  The module defines two exceptions:

 -- Exception: multiprocessing.connection.AuthenticationError

     Exception raised when there is an authentication error.

  *Examples*

  The following server code creates a listener which uses ‘'secret
password'’ as an authentication key.  It then waits for a connection and
sends some data to the client:

     from multiprocessing.connection import Listener
     from array import array

     address = ('localhost', 6000)     # family is deduced to be 'AF_INET'
     listener = Listener(address, authkey='secret password')

     conn = listener.accept()
     print 'connection accepted from', listener.last_accepted

     conn.send([2.25, None, 'junk', float])

     conn.send_bytes('hello')

     conn.send_bytes(array('i', [42, 1729]))

     conn.close()
     listener.close()

  The following code connects to the server and receives some data from
the server:

     from multiprocessing.connection import Client
     from array import array

     address = ('localhost', 6000)
     conn = Client(address, authkey='secret password')

     print conn.recv()                 # => [2.25, None, 'junk', float]

     print conn.recv_bytes()            # => 'hello'

     arr = array('i', [0, 0, 0, 0, 0])
     print conn.recv_bytes_into(arr)     # => 8
     print arr                         # => array('i', [42, 1729, 0, 0, 0])

     conn.close()

* Menu:

* Address Formats:: 


File: python.info,  Node: Address Formats,  Up: Listeners and Clients

5.16.6.23 Address Formats
.........................

   * An ‘'AF_INET'’ address is a tuple of the form ‘(hostname, port)’
     where _hostname_ is a string and _port_ is an integer.

   * An ‘'AF_UNIX'’ address is a string representing a filename on the
     filesystem.

   * 
     An ‘'AF_PIPE'’ address is a string of the form

          ‘r'\\.\pipe\_PipeName_'’.  To use *note Client(): 1695. to
          connect to a named pipe on a remote computer called
          _ServerName_ one should use an address of the form
          ‘r'\\_ServerName_\pipe\_PipeName_'’ instead.

  Note that any string beginning with two backslashes is assumed by
default to be an ‘'AF_PIPE'’ address rather than an ‘'AF_UNIX'’ address.


File: python.info,  Node: Authentication keys,  Next: Logging<2>,  Prev: Listeners and Clients,  Up: Reference

5.16.6.24 Authentication keys
.............................

When one uses *note Connection.recv: 161b, the data received is
automatically unpickled.  Unfortunately unpickling data from an
untrusted source is a security risk.  Therefore *note Listener: 1697.
and *note Client(): 1695. use the *note hmac: e8. module to provide
digest authentication.

  An authentication key is a string which can be thought of as a
password: once a connection is established both ends will demand proof
that the other knows the authentication key.  (Demonstrating that both
ends are using the same key does *not* involve sending the key over the
connection.)

  If authentication is requested but do authentication key is specified
then the return value of ‘current_process().authkey’ is used (see *note
Process: 1615.).  This value will automatically inherited by any *note
Process: 1615. object that the current process creates.  This means that
(by default) all processes of a multi-process program will share a
single authentication key which can be used when setting up connections
between themselves.

  Suitable authentication keys can also be generated by using *note
os.urandom(): d52.


File: python.info,  Node: Logging<2>,  Next: The multiprocessing dummy module,  Prev: Authentication keys,  Up: Reference

5.16.6.25 Logging
.................

Some support for logging is available.  Note, however, that the *note
logging: 101. package does not use process shared locks so it is
possible (depending on the handler type) for messages from different
processes to get mixed up.

 -- Function: multiprocessing.get_logger ()

     Returns the logger used by *note multiprocessing: 119.  If
     necessary, a new one will be created.

     When first created the logger has level ‘logging.NOTSET’ and no
     default handler.  Messages sent to this logger will not by default
     propagate to the root logger.

     Note that on Windows child processes will only inherit the level of
     the parent process’s logger – any other customization of the logger
     will not be inherited.

 -- Function: multiprocessing.log_to_stderr ()

     This function performs a call to *note get_logger(): 16a0. but in
     addition to returning the logger created by get_logger, it adds a
     handler which sends output to *note sys.stderr: 647. using format
     ‘'[%(levelname)s/%(processName)s] %(message)s'’.

  Below is an example session with logging turned on:

     >>> import multiprocessing, logging
     >>> logger = multiprocessing.log_to_stderr()
     >>> logger.setLevel(logging.INFO)
     >>> logger.warning('doomed')
     [WARNING/MainProcess] doomed
     >>> m = multiprocessing.Manager()
     [INFO/SyncManager-...] child process calling self.run()
     [INFO/SyncManager-...] created temp directory /.../pymp-...
     [INFO/SyncManager-...] manager serving at '/.../listener-...'
     >>> del m
     [INFO/MainProcess] sending shutdown message to manager
     [INFO/SyncManager-...] manager exiting with exitcode 0

  In addition to having these two logging functions, the multiprocessing
also exposes two additional logging level attributes.  These are
‘SUBWARNING’ and ‘SUBDEBUG’.  The table below illustrates where theses
fit in the normal level hierarchy.

Level                Numeric value
                     
------------------------------------------
                     
‘SUBWARNING’         25
                     
                     
‘SUBDEBUG’           5
                     

  For a full table of logging levels, see the *note logging: 101.
module.

  These additional logging levels are used primarily for certain debug
messages within the multiprocessing module.  Below is the same example
as above, except with ‘SUBDEBUG’ enabled:

     >>> import multiprocessing, logging
     >>> logger = multiprocessing.log_to_stderr()
     >>> logger.setLevel(multiprocessing.SUBDEBUG)
     >>> logger.warning('doomed')
     [WARNING/MainProcess] doomed
     >>> m = multiprocessing.Manager()
     [INFO/SyncManager-...] child process calling self.run()
     [INFO/SyncManager-...] created temp directory /.../pymp-...
     [INFO/SyncManager-...] manager serving at '/.../pymp-djGBXN/listener-...'
     >>> del m
     [SUBDEBUG/MainProcess] finalizer calling ...
     [INFO/MainProcess] sending shutdown message to manager
     [DEBUG/SyncManager-...] manager received shutdown message
     [SUBDEBUG/SyncManager-...] calling <Finalize object, callback=unlink, ...
     [SUBDEBUG/SyncManager-...] finalizer calling <built-in function unlink> ...
     [SUBDEBUG/SyncManager-...] calling <Finalize object, dead>
     [SUBDEBUG/SyncManager-...] finalizer calling <function rmtree at 0x5aa730> ...
     [INFO/SyncManager-...] manager exiting with exitcode 0


File: python.info,  Node: The multiprocessing dummy module,  Prev: Logging<2>,  Up: Reference

5.16.6.26 The ‘multiprocessing.dummy’ module
............................................

*note multiprocessing.dummy: 11b. replicates the API of *note
multiprocessing: 119. but is no more than a wrapper around the *note
threading: 179. module.


File: python.info,  Node: Programming guidelines,  Next: Examples<7>,  Prev: Reference,  Up: multiprocessing --- Process-based "threading" interface

5.16.6.27 Programming guidelines
................................

There are certain guidelines and idioms which should be adhered to when
using *note multiprocessing: 119.

* Menu:

* All platforms:: 
* Windows:: 


File: python.info,  Node: All platforms,  Next: Windows,  Up: Programming guidelines

5.16.6.28 All platforms
.......................

Avoid shared state

     As far as possible one should try to avoid shifting large amounts
     of data between processes.

     It is probably best to stick to using queues or pipes for
     communication between processes rather than using the lower level
     synchronization primitives from the *note threading: 179. module.

  Picklability

     Ensure that the arguments to the methods of proxies are picklable.

  Thread safety of proxies

     Do not use a proxy object from more than one thread unless you
     protect it with a lock.

     (There is never a problem with different processes using the _same_
     proxy.)

  Joining zombie processes

     On Unix when a process finishes but has not been joined it becomes
     a zombie.  There should never be very many because each time a new
     process starts (or *note active_children(): 164b. is called) all
     completed processes which have not yet been joined will be joined.
     Also calling a finished process’s *note Process.is_alive: 162c.
     will join the process.  Even so it is probably good practice to
     explicitly join all the processes that you start.

  Better to inherit than pickle/unpickle

     On Windows many types from *note multiprocessing: 119. need to be
     picklable so that child processes can use them.  However, one
     should generally avoid sending shared objects to other processes
     using pipes or queues.  Instead you should arrange the program so
     that a process which needs access to a shared resource created
     elsewhere can inherit it from an ancestor process.

  Avoid terminating processes

     Using the *note Process.terminate: 1632. method to stop a process
     is liable to cause any shared resources (such as locks, semaphores,
     pipes and queues) currently being used by the process to become
     broken or unavailable to other processes.

     Therefore it is probably best to only consider using *note
     Process.terminate: 1632. on processes which never use any shared
     resources.

  Joining processes that use queues

     Bear in mind that a process that has put items in a queue will wait
     before terminating until all the buffered items are fed by the
     "feeder" thread to the underlying pipe.  (The child process can
     call the *note cancel_join_thread(): 163c. method of the queue to
     avoid this behaviour.)

     This means that whenever you use a queue you need to make sure that
     all items which have been put on the queue will eventually be
     removed before the process is joined.  Otherwise you cannot be sure
     that processes which have put items on the queue will terminate.
     Remember also that non-daemonic processes will be automatically be
     joined.

     An example which will deadlock is the following:

          from multiprocessing import Process, Queue

          def f(q):
              q.put('X' * 1000000)

          if __name__ == '__main__':
              queue = Queue()
              p = Process(target=f, args=(queue,))
              p.start()
              p.join()                    # this deadlocks
              obj = queue.get()

     A fix here would be to swap the last two lines round (or simply
     remove the ‘p.join()’ line).

  Explicitly pass resources to child processes

     On Unix a child process can make use of a shared resource created
     in a parent process using a global resource.  However, it is better
     to pass the object as an argument to the constructor for the child
     process.

     Apart from making the code (potentially) compatible with Windows
     this also ensures that as long as the child process is still alive
     the object will not be garbage collected in the parent process.
     This might be important if some resource is freed when the object
     is garbage collected in the parent process.

     So for instance

          from multiprocessing import Process, Lock

          def f():
              ... do something using "lock" ...

          if __name__ == '__main__':
             lock = Lock()
             for i in range(10):
                  Process(target=f).start()

     should be rewritten as

          from multiprocessing import Process, Lock

          def f(l):
              ... do something using "l" ...

          if __name__ == '__main__':
             lock = Lock()
             for i in range(10):
                  Process(target=f, args=(lock,)).start()

  Beware of replacing *note sys.stdin: 636. with a "file like object"

     *note multiprocessing: 119. originally unconditionally called:

          os.close(sys.stdin.fileno())

     in the ‘multiprocessing.Process._bootstrap()’ method — this
     resulted in issues with processes-in-processes.  This has been
     changed to:

          sys.stdin.close()
          sys.stdin = open(os.devnull)

     Which solves the fundamental issue of processes colliding with each
     other resulting in a bad file descriptor error, but introduces a
     potential danger to applications which replace *note sys.stdin():
     636. with a "file-like object" with output buffering.  This danger
     is that if multiple processes call *note close(): 110e. on this
     file-like object, it could result in the same data being flushed to
     the object multiple times, resulting in corruption.

     If you write a file-like object and implement your own caching, you
     can make it fork-safe by storing the pid whenever you append to the
     cache, and discarding the cache when the pid changes.  For example:

          @property
          def cache(self):
              pid = os.getpid()
              if pid != self._pid:
                  self._pid = pid
                  self._cache = []
              return self._cache

     For more information, see issue 5155(1), issue 5313(2) and issue
     5331(3)

   ---------- Footnotes ----------

   (1) http://bugs.python.org/issue5155

   (2) http://bugs.python.org/issue5313

   (3) http://bugs.python.org/issue5331


File: python.info,  Node: Windows,  Prev: All platforms,  Up: Programming guidelines

5.16.6.29 Windows
.................

Since Windows lacks *note os.fork(): 244. it has a few extra
restrictions:

  More picklability

     Ensure that all arguments to ‘Process.__init__()’ are picklable.
     This means, in particular, that bound or unbound methods cannot be
     used directly as the ‘target’ argument on Windows — just define a
     function and use that instead.

     Also, if you subclass *note Process: 1615. then make sure that
     instances will be picklable when the *note Process.start: 1616.
     method is called.

  Global variables

     Bear in mind that if code run in a child process tries to access a
     global variable, then the value it sees (if any) may not be the
     same as the value in the parent process at the time that *note
     Process.start: 1616. was called.

     However, global variables which are just module level constants
     cause no problems.

  Safe importing of main module

     Make sure that the main module can be safely imported by a new
     Python interpreter without causing unintended side effects (such a
     starting a new process).

     For example, under Windows running the following module would fail
     with a *note RuntimeError: 39b.:

          from multiprocessing import Process

          def foo():
              print 'hello'

          p = Process(target=foo)
          p.start()

     Instead one should protect the "entry point" of the program by
     using ‘if __name__ == '__main__':’ as follows:

          from multiprocessing import Process, freeze_support

          def foo():
              print 'hello'

          if __name__ == '__main__':
              freeze_support()
              p = Process(target=foo)
              p.start()

     (The ‘freeze_support()’ line can be omitted if the program will be
     run normally instead of frozen.)

     This allows the newly spawned Python interpreter to safely import
     the module and then run the module’s ‘foo()’ function.

     Similar restrictions apply if a pool or manager is created in the
     main module.


File: python.info,  Node: Examples<7>,  Prev: Programming guidelines,  Up: multiprocessing --- Process-based "threading" interface

5.16.6.30 Examples
..................

Demonstration of how to create and use customized managers and proxies:

     #
     # This module shows how to use arbitrary callables with a subclass of
     # `BaseManager`.
     #
     # Copyright (c) 2006-2008, R Oudkerk
     # All rights reserved.
     #

     from multiprocessing import freeze_support
     from multiprocessing.managers import BaseManager, BaseProxy
     import operator

     ##

     class Foo(object):
         def f(self):
             print 'you called Foo.f()'
         def g(self):
             print 'you called Foo.g()'
         def _h(self):
             print 'you called Foo._h()'

     # A simple generator function
     def baz():
         for i in xrange(10):
             yield i*i

     # Proxy type for generator objects
     class GeneratorProxy(BaseProxy):
         _exposed_ = ('next', '__next__')
         def __iter__(self):
             return self
         def next(self):
             return self._callmethod('next')
         def __next__(self):
             return self._callmethod('__next__')

     # Function to return the operator module
     def get_operator_module():
         return operator

     ##

     class MyManager(BaseManager):
         pass

     # register the Foo class; make `f()` and `g()` accessible via proxy
     MyManager.register('Foo1', Foo)

     # register the Foo class; make `g()` and `_h()` accessible via proxy
     MyManager.register('Foo2', Foo, exposed=('g', '_h'))

     # register the generator function baz; use `GeneratorProxy` to make proxies
     MyManager.register('baz', baz, proxytype=GeneratorProxy)

     # register get_operator_module(); make public functions accessible via proxy
     MyManager.register('operator', get_operator_module)

     ##

     def test():
         manager = MyManager()
         manager.start()

         print '-' * 20

         f1 = manager.Foo1()
         f1.f()
         f1.g()
         assert not hasattr(f1, '_h')
         assert sorted(f1._exposed_) == sorted(['f', 'g'])

         print '-' * 20

         f2 = manager.Foo2()
         f2.g()
         f2._h()
         assert not hasattr(f2, 'f')
         assert sorted(f2._exposed_) == sorted(['g', '_h'])

         print '-' * 20

         it = manager.baz()
         for i in it:
             print '<%d>' % i,
         print

         print '-' * 20

         op = manager.operator()
         print 'op.add(23, 45) =', op.add(23, 45)
         print 'op.pow(2, 94) =', op.pow(2, 94)
         print 'op.getslice(range(10), 2, 6) =', op.getslice(range(10), 2, 6)
         print 'op.repeat(range(5), 3) =', op.repeat(range(5), 3)
         print 'op._exposed_ =', op._exposed_

     ##

     if __name__ == '__main__':
         freeze_support()
         test()


  Using ‘Pool’:

     #
     # A test of `multiprocessing.Pool` class
     #
     # Copyright (c) 2006-2008, R Oudkerk
     # All rights reserved.
     #

     import multiprocessing
     import time
     import random
     import sys

     #
     # Functions used by test code
     #

     def calculate(func, args):
         result = func(*args)
         return '%s says that %s%s = %s' % (
             multiprocessing.current_process().name,
             func.__name__, args, result
             )

     def calculatestar(args):
         return calculate(*args)

     def mul(a, b):
         time.sleep(0.5*random.random())
         return a * b

     def plus(a, b):
         time.sleep(0.5*random.random())
         return a + b

     def f(x):
         return 1.0 / (x-5.0)

     def pow3(x):
         return x**3

     def noop(x):
         pass

     #
     # Test code
     #

     def test():
         print 'cpu_count() = %d\n' % multiprocessing.cpu_count()

         #
         # Create pool
         #

         PROCESSES = 4
         print 'Creating pool with %d processes\n' % PROCESSES
         pool = multiprocessing.Pool(PROCESSES)
         print 'pool = %s' % pool
         print

         #
         # Tests
         #

         TASKS = [(mul, (i, 7)) for i in range(10)] + \
                 [(plus, (i, 8)) for i in range(10)]

         results = [pool.apply_async(calculate, t) for t in TASKS]
         imap_it = pool.imap(calculatestar, TASKS)
         imap_unordered_it = pool.imap_unordered(calculatestar, TASKS)

         print 'Ordered results using pool.apply_async():'
         for r in results:
             print '\t', r.get()
         print

         print 'Ordered results using pool.imap():'
         for x in imap_it:
             print '\t', x
         print

         print 'Unordered results using pool.imap_unordered():'
         for x in imap_unordered_it:
             print '\t', x
         print

         print 'Ordered results using pool.map() --- will block till complete:'
         for x in pool.map(calculatestar, TASKS):
             print '\t', x
         print

         #
         # Simple benchmarks
         #

         N = 100000
         print 'def pow3(x): return x**3'

         t = time.time()
         A = map(pow3, xrange(N))
         print '\tmap(pow3, xrange(%d)):\n\t\t%s seconds' % \
               (N, time.time() - t)

         t = time.time()
         B = pool.map(pow3, xrange(N))
         print '\tpool.map(pow3, xrange(%d)):\n\t\t%s seconds' % \
               (N, time.time() - t)

         t = time.time()
         C = list(pool.imap(pow3, xrange(N), chunksize=N//8))
         print '\tlist(pool.imap(pow3, xrange(%d), chunksize=%d)):\n\t\t%s' \
               ' seconds' % (N, N//8, time.time() - t)

         assert A == B == C, (len(A), len(B), len(C))
         print

         L = [None] * 1000000
         print 'def noop(x): pass'
         print 'L = [None] * 1000000'

         t = time.time()
         A = map(noop, L)
         print '\tmap(noop, L):\n\t\t%s seconds' % \
               (time.time() - t)

         t = time.time()
         B = pool.map(noop, L)
         print '\tpool.map(noop, L):\n\t\t%s seconds' % \
               (time.time() - t)

         t = time.time()
         C = list(pool.imap(noop, L, chunksize=len(L)//8))
         print '\tlist(pool.imap(noop, L, chunksize=%d)):\n\t\t%s seconds' % \
               (len(L)//8, time.time() - t)

         assert A == B == C, (len(A), len(B), len(C))
         print

         del A, B, C, L

         #
         # Test error handling
         #

         print 'Testing error handling:'

         try:
             print pool.apply(f, (5,))
         except ZeroDivisionError:
             print '\tGot ZeroDivisionError as expected from pool.apply()'
         else:
             raise AssertionError('expected ZeroDivisionError')

         try:
             print pool.map(f, range(10))
         except ZeroDivisionError:
             print '\tGot ZeroDivisionError as expected from pool.map()'
         else:
             raise AssertionError('expected ZeroDivisionError')

         try:
             print list(pool.imap(f, range(10)))
         except ZeroDivisionError:
             print '\tGot ZeroDivisionError as expected from list(pool.imap())'
         else:
             raise AssertionError('expected ZeroDivisionError')

         it = pool.imap(f, range(10))
         for i in range(10):
             try:
                 x = it.next()
             except ZeroDivisionError:
                 if i == 5:
                     pass
             except StopIteration:
                 break
             else:
                 if i == 5:
                     raise AssertionError('expected ZeroDivisionError')

         assert i == 9
         print '\tGot ZeroDivisionError as expected from IMapIterator.next()'
         print

         #
         # Testing timeouts
         #

         print 'Testing ApplyResult.get() with timeout:',
         res = pool.apply_async(calculate, TASKS[0])
         while 1:
             sys.stdout.flush()
             try:
                 sys.stdout.write('\n\t%s' % res.get(0.02))
                 break
             except multiprocessing.TimeoutError:
                 sys.stdout.write('.')
         print
         print

         print 'Testing IMapIterator.next() with timeout:',
         it = pool.imap(calculatestar, TASKS)
         while 1:
             sys.stdout.flush()
             try:
                 sys.stdout.write('\n\t%s' % it.next(0.02))
             except StopIteration:
                 break
             except multiprocessing.TimeoutError:
                 sys.stdout.write('.')
         print
         print

         #
         # Testing callback
         #

         print 'Testing callback:'

         A = []
         B = [56, 0, 1, 8, 27, 64, 125, 216, 343, 512, 729]

         r = pool.apply_async(mul, (7, 8), callback=A.append)
         r.wait()

         r = pool.map_async(pow3, range(10), callback=A.extend)
         r.wait()

         if A == B:
             print '\tcallbacks succeeded\n'
         else:
             print '\t*** callbacks failed\n\t\t%s != %s\n' % (A, B)

         #
         # Check there are no outstanding tasks
         #

         assert not pool._cache, 'cache = %r' % pool._cache

         #
         # Check close() methods
         #

         print 'Testing close():'

         for worker in pool._pool:
             assert worker.is_alive()

         result = pool.apply_async(time.sleep, [0.5])
         pool.close()
         pool.join()

         assert result.get() is None

         for worker in pool._pool:
             assert not worker.is_alive()

         print '\tclose() succeeded\n'

         #
         # Check terminate() method
         #

         print 'Testing terminate():'

         pool = multiprocessing.Pool(2)
         DELTA = 0.1
         ignore = pool.apply(pow3, [2])
         results = [pool.apply_async(time.sleep, [DELTA]) for i in range(100)]
         pool.terminate()
         pool.join()

         for worker in pool._pool:
             assert not worker.is_alive()

         print '\tterminate() succeeded\n'

         #
         # Check garbage collection
         #

         print 'Testing garbage collection:'

         pool = multiprocessing.Pool(2)
         DELTA = 0.1
         processes = pool._pool
         ignore = pool.apply(pow3, [2])
         results = [pool.apply_async(time.sleep, [DELTA]) for i in range(100)]

         results = pool = None

         time.sleep(DELTA * 2)

         for worker in processes:
             assert not worker.is_alive()

         print '\tgarbage collection succeeded\n'


     if __name__ == '__main__':
         multiprocessing.freeze_support()

         assert len(sys.argv) in (1, 2)

         if len(sys.argv) == 1 or sys.argv[1] == 'processes':
             print ' Using processes '.center(79, '-')
         elif sys.argv[1] == 'threads':
             print ' Using threads '.center(79, '-')
             import multiprocessing.dummy as multiprocessing
         else:
             print 'Usage:\n\t%s [processes | threads]' % sys.argv[0]
             raise SystemExit(2)

         test()


  Synchronization types like locks, conditions and queues:

     #
     # A test file for the `multiprocessing` package
     #
     # Copyright (c) 2006-2008, R Oudkerk
     # All rights reserved.
     #

     import time, sys, random
     from Queue import Empty

     import multiprocessing               # may get overwritten


     #### TEST_VALUE

     def value_func(running, mutex):
         random.seed()
         time.sleep(random.random()*4)

         mutex.acquire()
         print '\n\t\t\t' + str(multiprocessing.current_process()) + ' has finished'
         running.value -= 1
         mutex.release()

     def test_value():
         TASKS = 10
         running = multiprocessing.Value('i', TASKS)
         mutex = multiprocessing.Lock()

         for i in range(TASKS):
             p = multiprocessing.Process(target=value_func, args=(running, mutex))
             p.start()

         while running.value > 0:
             time.sleep(0.08)
             mutex.acquire()
             print running.value,
             sys.stdout.flush()
             mutex.release()

         print
         print 'No more running processes'


     #### TEST_QUEUE

     def queue_func(queue):
         for i in range(30):
             time.sleep(0.5 * random.random())
             queue.put(i*i)
         queue.put('STOP')

     def test_queue():
         q = multiprocessing.Queue()

         p = multiprocessing.Process(target=queue_func, args=(q,))
         p.start()

         o = None
         while o != 'STOP':
             try:
                 o = q.get(timeout=0.3)
                 print o,
                 sys.stdout.flush()
             except Empty:
                 print 'TIMEOUT'

         print


     #### TEST_CONDITION

     def condition_func(cond):
         cond.acquire()
         print '\t' + str(cond)
         time.sleep(2)
         print '\tchild is notifying'
         print '\t' + str(cond)
         cond.notify()
         cond.release()

     def test_condition():
         cond = multiprocessing.Condition()

         p = multiprocessing.Process(target=condition_func, args=(cond,))
         print cond

         cond.acquire()
         print cond
         cond.acquire()
         print cond

         p.start()

         print 'main is waiting'
         cond.wait()
         print 'main has woken up'

         print cond
         cond.release()
         print cond
         cond.release()

         p.join()
         print cond


     #### TEST_SEMAPHORE

     def semaphore_func(sema, mutex, running):
         sema.acquire()

         mutex.acquire()
         running.value += 1
         print running.value, 'tasks are running'
         mutex.release()

         random.seed()
         time.sleep(random.random()*2)

         mutex.acquire()
         running.value -= 1
         print '%s has finished' % multiprocessing.current_process()
         mutex.release()

         sema.release()

     def test_semaphore():
         sema = multiprocessing.Semaphore(3)
         mutex = multiprocessing.RLock()
         running = multiprocessing.Value('i', 0)

         processes = [
             multiprocessing.Process(target=semaphore_func,
                                     args=(sema, mutex, running))
             for i in range(10)
             ]

         for p in processes:
             p.start()

         for p in processes:
             p.join()


     #### TEST_JOIN_TIMEOUT

     def join_timeout_func():
         print '\tchild sleeping'
         time.sleep(5.5)
         print '\n\tchild terminating'

     def test_join_timeout():
         p = multiprocessing.Process(target=join_timeout_func)
         p.start()

         print 'waiting for process to finish'

         while 1:
             p.join(timeout=1)
             if not p.is_alive():
                 break
             print '.',
             sys.stdout.flush()


     #### TEST_EVENT

     def event_func(event):
         print '\t%r is waiting' % multiprocessing.current_process()
         event.wait()
         print '\t%r has woken up' % multiprocessing.current_process()

     def test_event():
         event = multiprocessing.Event()

         processes = [multiprocessing.Process(target=event_func, args=(event,))
                      for i in range(5)]

         for p in processes:
             p.start()

         print 'main is sleeping'
         time.sleep(2)

         print 'main is setting event'
         event.set()

         for p in processes:
             p.join()


     #### TEST_SHAREDVALUES

     def sharedvalues_func(values, arrays, shared_values, shared_arrays):
         for i in range(len(values)):
             v = values[i][1]
             sv = shared_values[i].value
             assert v == sv

         for i in range(len(values)):
             a = arrays[i][1]
             sa = list(shared_arrays[i][:])
             assert a == sa

         print 'Tests passed'

     def test_sharedvalues():
         values = [
             ('i', 10),
             ('h', -2),
             ('d', 1.25)
             ]
         arrays = [
             ('i', range(100)),
             ('d', [0.25 * i for i in range(100)]),
             ('H', range(1000))
             ]

         shared_values = [multiprocessing.Value(id, v) for id, v in values]
         shared_arrays = [multiprocessing.Array(id, a) for id, a in arrays]

         p = multiprocessing.Process(
             target=sharedvalues_func,
             args=(values, arrays, shared_values, shared_arrays)
             )
         p.start()
         p.join()

         assert p.exitcode == 0


     ####

     def test(namespace=multiprocessing):
         global multiprocessing

         multiprocessing = namespace

         for func in [ test_value, test_queue, test_condition,
                       test_semaphore, test_join_timeout, test_event,
                       test_sharedvalues ]:

             print '\n\t######## %s\n' % func.__name__
             func()

         ignore = multiprocessing.active_children()      # cleanup any old processes
         if hasattr(multiprocessing, '_debug_info'):
             info = multiprocessing._debug_info()
             if info:
                 print info
                 raise ValueError('there should be no positive refcounts left')


     if __name__ == '__main__':
         multiprocessing.freeze_support()

         assert len(sys.argv) in (1, 2)

         if len(sys.argv) == 1 or sys.argv[1] == 'processes':
             print ' Using processes '.center(79, '-')
             namespace = multiprocessing
         elif sys.argv[1] == 'manager':
             print ' Using processes and a manager '.center(79, '-')
             namespace = multiprocessing.Manager()
             namespace.Process = multiprocessing.Process
             namespace.current_process = multiprocessing.current_process
             namespace.active_children = multiprocessing.active_children
         elif sys.argv[1] == 'threads':
             print ' Using threads '.center(79, '-')
             import multiprocessing.dummy as namespace
         else:
             print 'Usage:\n\t%s [processes | manager | threads]' % sys.argv[0]
             raise SystemExit(2)

         test(namespace)


  An example showing how to use queues to feed tasks to a collection of
worker processes and collect the results:

     #
     # Simple example which uses a pool of workers to carry out some tasks.
     #
     # Notice that the results will probably not come out of the output
     # queue in the same in the same order as the corresponding tasks were
     # put on the input queue.  If it is important to get the results back
     # in the original order then consider using `Pool.map()` or
     # `Pool.imap()` (which will save on the amount of code needed anyway).
     #
     # Copyright (c) 2006-2008, R Oudkerk
     # All rights reserved.
     #

     import time
     import random

     from multiprocessing import Process, Queue, current_process, freeze_support

     #
     # Function run by worker processes
     #

     def worker(input, output):
         for func, args in iter(input.get, 'STOP'):
             result = calculate(func, args)
             output.put(result)

     #
     # Function used to calculate result
     #

     def calculate(func, args):
         result = func(*args)
         return '%s says that %s%s = %s' % \
             (current_process().name, func.__name__, args, result)

     #
     # Functions referenced by tasks
     #

     def mul(a, b):
         time.sleep(0.5*random.random())
         return a * b

     def plus(a, b):
         time.sleep(0.5*random.random())
         return a + b

     #
     #
     #

     def test():
         NUMBER_OF_PROCESSES = 4
         TASKS1 = [(mul, (i, 7)) for i in range(20)]
         TASKS2 = [(plus, (i, 8)) for i in range(10)]

         # Create queues
         task_queue = Queue()
         done_queue = Queue()

         # Submit tasks
         for task in TASKS1:
             task_queue.put(task)

         # Start worker processes
         for i in range(NUMBER_OF_PROCESSES):
             Process(target=worker, args=(task_queue, done_queue)).start()

         # Get and print results
         print 'Unordered results:'
         for i in range(len(TASKS1)):
             print '\t', done_queue.get()

         # Add more tasks using `put()`
         for task in TASKS2:
             task_queue.put(task)

         # Get and print some more results
         for i in range(len(TASKS2)):
             print '\t', done_queue.get()

         # Tell child processes to stop
         for i in range(NUMBER_OF_PROCESSES):
             task_queue.put('STOP')


     if __name__ == '__main__':
         freeze_support()
         test()


  An example of how a pool of worker processes can each run a
‘SimpleHTTPServer.HttpServer’ instance while sharing a single listening
socket.

     #
     # Example where a pool of http servers share a single listening socket
     #
     # On Windows this module depends on the ability to pickle a socket
     # object so that the worker processes can inherit a copy of the server
     # object.  (We import `multiprocessing.reduction` to enable this pickling.)
     #
     # Not sure if we should synchronize access to `socket.accept()` method by
     # using a process-shared lock -- does not seem to be necessary.
     #
     # Copyright (c) 2006-2008, R Oudkerk
     # All rights reserved.
     #

     import os
     import sys

     from multiprocessing import Process, current_process, freeze_support
     from BaseHTTPServer import HTTPServer
     from SimpleHTTPServer import SimpleHTTPRequestHandler

     if sys.platform == 'win32':
         import multiprocessing.reduction    # make sockets pickable/inheritable


     def note(format, *args):
         sys.stderr.write('[%s]\t%s\n' % (current_process().name, format%args))


     class RequestHandler(SimpleHTTPRequestHandler):
         # we override log_message() to show which process is handling the request
         def log_message(self, format, *args):
             note(format, *args)

     def serve_forever(server):
         note('starting server')
         try:
             server.serve_forever()
         except KeyboardInterrupt:
             pass


     def runpool(address, number_of_processes):
         # create a single server object -- children will each inherit a copy
         server = HTTPServer(address, RequestHandler)

         # create child processes to act as workers
         for i in range(number_of_processes-1):
             Process(target=serve_forever, args=(server,)).start()

         # main process also acts as a worker
         serve_forever(server)


     def test():
         DIR = os.path.join(os.path.dirname(__file__), '..')
         ADDRESS = ('localhost', 8000)
         NUMBER_OF_PROCESSES = 4

         print 'Serving at http://%s:%d using %d worker processes' % \
               (ADDRESS[0], ADDRESS[1], NUMBER_OF_PROCESSES)
         print 'To exit press Ctrl-' + ['C', 'Break'][sys.platform=='win32']

         os.chdir(DIR)
         runpool(ADDRESS, NUMBER_OF_PROCESSES)


     if __name__ == '__main__':
         freeze_support()
         test()


  Some simple benchmarks comparing *note multiprocessing: 119. with
*note threading: 179.:

     #
     # Simple benchmarks for the multiprocessing package
     #
     # Copyright (c) 2006-2008, R Oudkerk
     # All rights reserved.
     #

     import time, sys, multiprocessing, threading, Queue, gc

     if sys.platform == 'win32':
         _timer = time.clock
     else:
         _timer = time.time

     delta = 1


     #### TEST_QUEUESPEED

     def queuespeed_func(q, c, iterations):
         a = '0' * 256
         c.acquire()
         c.notify()
         c.release()

         for i in xrange(iterations):
             q.put(a)

         q.put('STOP')

     def test_queuespeed(Process, q, c):
         elapsed = 0
         iterations = 1

         while elapsed < delta:
             iterations *= 2

             p = Process(target=queuespeed_func, args=(q, c, iterations))
             c.acquire()
             p.start()
             c.wait()
             c.release()

             result = None
             t = _timer()

             while result != 'STOP':
                 result = q.get()

             elapsed = _timer() - t

             p.join()

         print iterations, 'objects passed through the queue in', elapsed, 'seconds'
         print 'average number/sec:', iterations/elapsed


     #### TEST_PIPESPEED

     def pipe_func(c, cond, iterations):
         a = '0' * 256
         cond.acquire()
         cond.notify()
         cond.release()

         for i in xrange(iterations):
             c.send(a)

         c.send('STOP')

     def test_pipespeed():
         c, d = multiprocessing.Pipe()
         cond = multiprocessing.Condition()
         elapsed = 0
         iterations = 1

         while elapsed < delta:
             iterations *= 2

             p = multiprocessing.Process(target=pipe_func,
                                         args=(d, cond, iterations))
             cond.acquire()
             p.start()
             cond.wait()
             cond.release()

             result = None
             t = _timer()

             while result != 'STOP':
                 result = c.recv()

             elapsed = _timer() - t
             p.join()

         print iterations, 'objects passed through connection in',elapsed,'seconds'
         print 'average number/sec:', iterations/elapsed


     #### TEST_SEQSPEED

     def test_seqspeed(seq):
         elapsed = 0
         iterations = 1

         while elapsed < delta:
             iterations *= 2

             t = _timer()

             for i in xrange(iterations):
                 a = seq[5]

             elapsed = _timer()-t

         print iterations, 'iterations in', elapsed, 'seconds'
         print 'average number/sec:', iterations/elapsed


     #### TEST_LOCK

     def test_lockspeed(l):
         elapsed = 0
         iterations = 1

         while elapsed < delta:
             iterations *= 2

             t = _timer()

             for i in xrange(iterations):
                 l.acquire()
                 l.release()

             elapsed = _timer()-t

         print iterations, 'iterations in', elapsed, 'seconds'
         print 'average number/sec:', iterations/elapsed


     #### TEST_CONDITION

     def conditionspeed_func(c, N):
         c.acquire()
         c.notify()

         for i in xrange(N):
             c.wait()
             c.notify()

         c.release()

     def test_conditionspeed(Process, c):
         elapsed = 0
         iterations = 1

         while elapsed < delta:
             iterations *= 2

             c.acquire()
             p = Process(target=conditionspeed_func, args=(c, iterations))
             p.start()

             c.wait()

             t = _timer()

             for i in xrange(iterations):
                 c.notify()
                 c.wait()

             elapsed = _timer()-t

             c.release()
             p.join()

         print iterations * 2, 'waits in', elapsed, 'seconds'
         print 'average number/sec:', iterations * 2 / elapsed

     ####

     def test():
         manager = multiprocessing.Manager()

         gc.disable()

         print '\n\t######## testing Queue.Queue\n'
         test_queuespeed(threading.Thread, Queue.Queue(),
                         threading.Condition())
         print '\n\t######## testing multiprocessing.Queue\n'
         test_queuespeed(multiprocessing.Process, multiprocessing.Queue(),
                         multiprocessing.Condition())
         print '\n\t######## testing Queue managed by server process\n'
         test_queuespeed(multiprocessing.Process, manager.Queue(),
                         manager.Condition())
         print '\n\t######## testing multiprocessing.Pipe\n'
         test_pipespeed()

         print

         print '\n\t######## testing list\n'
         test_seqspeed(range(10))
         print '\n\t######## testing list managed by server process\n'
         test_seqspeed(manager.list(range(10)))
         print '\n\t######## testing Array("i", ..., lock=False)\n'
         test_seqspeed(multiprocessing.Array('i', range(10), lock=False))
         print '\n\t######## testing Array("i", ..., lock=True)\n'
         test_seqspeed(multiprocessing.Array('i', range(10), lock=True))

         print

         print '\n\t######## testing threading.Lock\n'
         test_lockspeed(threading.Lock())
         print '\n\t######## testing threading.RLock\n'
         test_lockspeed(threading.RLock())
         print '\n\t######## testing multiprocessing.Lock\n'
         test_lockspeed(multiprocessing.Lock())
         print '\n\t######## testing multiprocessing.RLock\n'
         test_lockspeed(multiprocessing.RLock())
         print '\n\t######## testing lock managed by server process\n'
         test_lockspeed(manager.Lock())
         print '\n\t######## testing rlock managed by server process\n'
         test_lockspeed(manager.RLock())

         print

         print '\n\t######## testing threading.Condition\n'
         test_conditionspeed(threading.Thread, threading.Condition())
         print '\n\t######## testing multiprocessing.Condition\n'
         test_conditionspeed(multiprocessing.Process, multiprocessing.Condition())
         print '\n\t######## testing condition managed by a server process\n'
         test_conditionspeed(multiprocessing.Process, manager.Condition())

         gc.enable()

     if __name__ == '__main__':
         multiprocessing.freeze_support()
         test()



File: python.info,  Node: mmap --- Memory-mapped file support,  Next: readline --- GNU readline interface,  Prev: multiprocessing --- Process-based "threading" interface,  Up: Optional Operating System Services

5.16.7 ‘mmap’ — Memory-mapped file support
------------------------------------------

Memory-mapped file objects behave like both strings and like file
objects.  Unlike normal string objects, however, these are mutable.  You
can use mmap objects in most places where strings are expected; for
example, you can use the *note re: 143. module to search through a
memory-mapped file.  Since they’re mutable, you can change a single
character by doing ‘obj[index] = 'a'’, or change a substring by
assigning to a slice: ‘obj[i1:i2] = '...'’.  You can also read and write
data starting at the current file position, and *note seek(): 16a9.
through the file to different positions.

  A memory-mapped file is created by the *note mmap: 114. constructor,
which is different on Unix and on Windows.  In either case you must
provide a file descriptor for a file opened for update.  If you wish to
map an existing Python file object, use its ‘fileno()’ method to obtain
the correct value for the _fileno_ parameter.  Otherwise, you can open
the file using the *note os.open(): 5e4. function, which returns a file
descriptor directly (the file still needs to be closed when done).

     Note: If you want to create a memory-mapping for a writable,
     buffered file, you should *note flush(): 11bc. the file first.
     This is necessary to ensure that local modifications to the buffers
     are actually available to the mapping.

  For both the Unix and Windows versions of the constructor, _access_
may be specified as an optional keyword parameter.  _access_ accepts one
of three values: ‘ACCESS_READ’, ‘ACCESS_WRITE’, or ‘ACCESS_COPY’ to
specify read-only, write-through or copy-on-write memory respectively.
_access_ can be used on both Unix and Windows.  If _access_ is not
specified, Windows mmap returns a write-through mapping.  The initial
memory values for all three access types are taken from the specified
file.  Assignment to an ‘ACCESS_READ’ memory map raises a *note
TypeError: 218. exception.  Assignment to an ‘ACCESS_WRITE’ memory map
affects both memory and the underlying file.  Assignment to an
‘ACCESS_COPY’ memory map affects memory but does not update the
underlying file.

  Changed in version 2.5: To map anonymous memory, -1 should be passed
as the fileno along with the length.

  Changed in version 2.6: mmap.mmap has formerly been a factory function
creating mmap objects.  Now mmap.mmap is the class itself.

 -- Class: mmap.mmap (fileno, length[, tagname[, access[, offset]]])

     *(Windows version)* Maps _length_ bytes from the file specified by
     the file handle _fileno_, and creates a mmap object.  If _length_
     is larger than the current size of the file, the file is extended
     to contain _length_ bytes.  If _length_ is ‘0’, the maximum length
     of the map is the current size of the file, except that if the file
     is empty Windows raises an exception (you cannot create an empty
     mapping on Windows).

     _tagname_, if specified and not ‘None’, is a string giving a tag
     name for the mapping.  Windows allows you to have many different
     mappings against the same file.  If you specify the name of an
     existing tag, that tag is opened, otherwise a new tag of this name
     is created.  If this parameter is omitted or ‘None’, the mapping is
     created without a name.  Avoiding the use of the tag parameter will
     assist in keeping your code portable between Unix and Windows.

     _offset_ may be specified as a non-negative integer offset.  mmap
     references will be relative to the offset from the beginning of the
     file.  _offset_ defaults to 0.  _offset_ must be a multiple of the
     ALLOCATIONGRANULARITY.

 -- Class: mmap.mmap (fileno, length[, flags[, prot[, access[,
          offset]]]])

     *(Unix version)* Maps _length_ bytes from the file specified by the
     file descriptor _fileno_, and returns a mmap object.  If _length_
     is ‘0’, the maximum length of the map will be the current size of
     the file when *note mmap: 114. is called.

     _flags_ specifies the nature of the mapping.  ‘MAP_PRIVATE’ creates
     a private copy-on-write mapping, so changes to the contents of the
     mmap object will be private to this process, and ‘MAP_SHARED’
     creates a mapping that’s shared with all other processes mapping
     the same areas of the file.  The default value is ‘MAP_SHARED’.

     _prot_, if specified, gives the desired memory protection; the two
     most useful values are ‘PROT_READ’ and ‘PROT_WRITE’, to specify
     that the pages may be read or written.  _prot_ defaults to
     ‘PROT_READ | PROT_WRITE’.

     _access_ may be specified in lieu of _flags_ and _prot_ as an
     optional keyword parameter.  It is an error to specify both
     _flags_, _prot_ and _access_.  See the description of _access_
     above for information on how to use this parameter.

     _offset_ may be specified as a non-negative integer offset.  mmap
     references will be relative to the offset from the beginning of the
     file.  _offset_ defaults to 0.  _offset_ must be a multiple of the
     PAGESIZE or ALLOCATIONGRANULARITY.

     To ensure validity of the created memory mapping the file specified
     by the descriptor _fileno_ is internally automatically synchronized
     with physical backing store on Mac OS X and OpenVMS.

     This example shows a simple way of using *note mmap: 114.:

          import mmap

          # write a simple example file
          with open("hello.txt", "wb") as f:
              f.write("Hello Python!\n")

          with open("hello.txt", "r+b") as f:
              # memory-map the file, size 0 means whole file
              mm = mmap.mmap(f.fileno(), 0)
              # read content via standard file methods
              print mm.readline()  # prints "Hello Python!"
              # read content via slice notation
              print mm[:5]  # prints "Hello"
              # update content using slice notation;
              # note that new content must have same size
              mm[6:] = " world!\n"
              # ... and read again using standard file methods
              mm.seek(0)
              print mm.readline()  # prints "Hello  world!"
              # close the map
              mm.close()

     The next example demonstrates how to create an anonymous map and
     exchange data between the parent and child processes:

          import mmap
          import os

          mm = mmap.mmap(-1, 13)
          mm.write("Hello world!")

          pid = os.fork()

          if pid == 0: # In a child process
              mm.seek(0)
              print mm.readline()

              mm.close()

     Memory-mapped file objects support the following methods:

      -- Method: mmap.close ()

          Closes the mmap.  Subsequent calls to other methods of the
          object will result in a ValueError exception being raised.
          This will not close the open file.

      -- Method: mmap.find (string[, start[, end]])

          Returns the lowest index in the object where the substring
          _string_ is found, such that _string_ is contained in the
          range [_start_, _end_].  Optional arguments _start_ and _end_
          are interpreted as in slice notation.  Returns ‘-1’ on
          failure.

      -- Method: mmap.flush ([offset, size])

          Flushes changes made to the in-memory copy of a file back to
          disk.  Without use of this call there is no guarantee that
          changes are written back before the object is destroyed.  If
          _offset_ and _size_ are specified, only changes to the given
          range of bytes will be flushed to disk; otherwise, the whole
          extent of the mapping is flushed.

          *(Windows version)* A nonzero value returned indicates
          success; zero indicates failure.

          *(Unix version)* A zero value is returned to indicate success.
          An exception is raised when the call failed.

      -- Method: mmap.move (dest, src, count)

          Copy the _count_ bytes starting at offset _src_ to the
          destination index _dest_.  If the mmap was created with
          ‘ACCESS_READ’, then calls to move will raise a *note
          TypeError: 218. exception.

      -- Method: mmap.read (num)

          Return a string containing up to _num_ bytes starting from the
          current file position; the file position is updated to point
          after the bytes that were returned.

      -- Method: mmap.read_byte ()

          Returns a string of length 1 containing the character at the
          current file position, and advances the file position by 1.

      -- Method: mmap.readline ()

          Returns a single line, starting at the current file position
          and up to the next newline.

      -- Method: mmap.resize (newsize)

          Resizes the map and the underlying file, if any.  If the mmap
          was created with ‘ACCESS_READ’ or ‘ACCESS_COPY’, resizing the
          map will raise a *note TypeError: 218. exception.

      -- Method: mmap.rfind (string[, start[, end]])

          Returns the highest index in the object where the substring
          _string_ is found, such that _string_ is contained in the
          range [_start_, _end_].  Optional arguments _start_ and _end_
          are interpreted as in slice notation.  Returns ‘-1’ on
          failure.

      -- Method: mmap.seek (pos[, whence])

          Set the file’s current position.  _whence_ argument is
          optional and defaults to ‘os.SEEK_SET’ or ‘0’ (absolute file
          positioning); other values are ‘os.SEEK_CUR’ or ‘1’ (seek
          relative to the current position) and ‘os.SEEK_END’ or ‘2’
          (seek relative to the file’s end).

      -- Method: mmap.size ()

          Return the length of the file, which can be larger than the
          size of the memory-mapped area.

      -- Method: mmap.tell ()

          Returns the current position of the file pointer.

      -- Method: mmap.write (string)

          Write the bytes in _string_ into memory at the current
          position of the file pointer; the file position is updated to
          point after the bytes that were written.  If the mmap was
          created with ‘ACCESS_READ’, then writing to it will raise a
          *note TypeError: 218. exception.

      -- Method: mmap.write_byte (byte)

          Write the single-character string _byte_ into memory at the
          current position of the file pointer; the file position is
          advanced by ‘1’.  If the mmap was created with ‘ACCESS_READ’,
          then writing to it will raise a *note TypeError: 218.
          exception.


File: python.info,  Node: readline --- GNU readline interface,  Next: rlcompleter --- Completion function for GNU readline,  Prev: mmap --- Memory-mapped file support,  Up: Optional Operating System Services

5.16.8 ‘readline’ — GNU readline interface
------------------------------------------

The *note readline: 144. module defines a number of functions to
facilitate completion and reading/writing of history files from the
Python interpreter.  This module can be used directly or via the *note
rlcompleter: 149. module.  Settings made using this module affect the
behaviour of both the interpreter’s interactive prompt and the prompts
offered by the *note raw_input(): 869. and *note input(): 3bf. built-in
functions.

     Note: On MacOS X the *note readline: 144. module can be implemented
     using the ‘libedit’ library instead of GNU readline.

     The configuration file for ‘libedit’ is different from that of GNU
     readline.  If you programmatically load configuration strings you
     can check for the text "libedit" in ‘readline.__doc__’ to
     differentiate between GNU readline and libedit.

  The *note readline: 144. module defines the following functions:

 -- Function: readline.parse_and_bind (string)

     Parse and execute single line of a readline init file.

 -- Function: readline.get_line_buffer ()

     Return the current contents of the line buffer.

 -- Function: readline.insert_text (string)

     Insert text into the command line.

 -- Function: readline.read_init_file ([filename])

     Parse a readline initialization file.  The default filename is the
     last filename used.

 -- Function: readline.read_history_file ([filename])

     Load a readline history file.  The default filename is
     ‘~/.history’.

 -- Function: readline.write_history_file ([filename])

     Save a readline history file.  The default filename is
     ‘~/.history’.

 -- Function: readline.clear_history ()

     Clear the current history.  (Note: this function is not available
     if the installed version of GNU readline doesn’t support it.)

     New in version 2.4.

 -- Function: readline.get_history_length ()

     Return the desired length of the history file.  Negative values
     imply unlimited history file size.

 -- Function: readline.set_history_length (length)

     Set the number of lines to save in the history file.  *note
     write_history_file(): 16bf. uses this value to truncate the history
     file when saving.  Negative values imply unlimited history file
     size.

 -- Function: readline.get_current_history_length ()

     Return the number of lines currently in the history.  (This is
     different from *note get_history_length(): 16c1, which returns the
     maximum number of lines that will be written to a history file.)

     New in version 2.3.

 -- Function: readline.get_history_item (index)

     Return the current contents of history item at _index_.

     New in version 2.3.

 -- Function: readline.remove_history_item (pos)

     Remove history item specified by its position from the history.

     New in version 2.4.

 -- Function: readline.replace_history_item (pos, line)

     Replace history item specified by its position with the given line.

     New in version 2.4.

 -- Function: readline.redisplay ()

     Change what’s displayed on the screen to reflect the current
     contents of the line buffer.

     New in version 2.3.

 -- Function: readline.set_startup_hook ([function])

     Set or remove the startup_hook function.  If _function_ is
     specified, it will be used as the new startup_hook function; if
     omitted or ‘None’, any hook function already installed is removed.
     The startup_hook function is called with no arguments just before
     readline prints the first prompt.

 -- Function: readline.set_pre_input_hook ([function])

     Set or remove the pre_input_hook function.  If _function_ is
     specified, it will be used as the new pre_input_hook function; if
     omitted or ‘None’, any hook function already installed is removed.
     The pre_input_hook function is called with no arguments after the
     first prompt has been printed and just before readline starts
     reading input characters.

 -- Function: readline.set_completer ([function])

     Set or remove the completer function.  If _function_ is specified,
     it will be used as the new completer function; if omitted or
     ‘None’, any completer function already installed is removed.  The
     completer function is called as ‘function(text, state)’, for
     _state_ in ‘0’, ‘1’, ‘2’, ..., until it returns a non-string value.
     It should return the next possible completion starting with _text_.

 -- Function: readline.get_completer ()

     Get the completer function, or ‘None’ if no completer function has
     been set.

     New in version 2.3.

 -- Function: readline.get_completion_type ()

     Get the type of completion being attempted.

     New in version 2.6.

 -- Function: readline.get_begidx ()

     Get the beginning index of the readline tab-completion scope.

 -- Function: readline.get_endidx ()

     Get the ending index of the readline tab-completion scope.

 -- Function: readline.set_completer_delims (string)

     Set the readline word delimiters for tab-completion.

 -- Function: readline.get_completer_delims ()

     Get the readline word delimiters for tab-completion.

 -- Function: readline.set_completion_display_matches_hook ([function])

     Set or remove the completion display function.  If _function_ is
     specified, it will be used as the new completion display function;
     if omitted or ‘None’, any completion display function already
     installed is removed.  The completion display function is called as
     ‘function(substitution, [matches], longest_match_length)’ once each
     time matches need to be displayed.

     New in version 2.6.

 -- Function: readline.add_history (line)

     Append a line to the history buffer, as if it was the last line
     typed.

See also
........

Module *note rlcompleter: 149.

     Completion of Python identifiers at the interactive prompt.

* Menu:

* Example: Example<7>. 


File: python.info,  Node: Example<7>,  Up: readline --- GNU readline interface

5.16.8.1 Example
................

The following example demonstrates how to use the *note readline: 144.
module’s history reading and writing functions to automatically load and
save a history file named ‘.pyhist’ from the user’s home directory.  The
code below would normally be executed automatically during interactive
sessions from the user’s *note PYTHONSTARTUP: 514. file.

     import os
     import readline
     histfile = os.path.join(os.path.expanduser("~"), ".pyhist")
     try:
         readline.read_history_file(histfile)
     except IOError:
         pass
     import atexit
     atexit.register(readline.write_history_file, histfile)
     del os, histfile

  The following example extends the *note code.InteractiveConsole: 16d5.
class to support history save/restore.

     import code
     import readline
     import atexit
     import os

     class HistoryConsole(code.InteractiveConsole):
         def __init__(self, locals=None, filename="<console>",
                      histfile=os.path.expanduser("~/.console-history")):
             code.InteractiveConsole.__init__(self, locals, filename)
             self.init_history(histfile)

         def init_history(self, histfile):
             readline.parse_and_bind("tab: complete")
             if hasattr(readline, "read_history_file"):
                 try:
                     readline.read_history_file(histfile)
                 except IOError:
                     pass
                 atexit.register(self.save_history, histfile)

         def save_history(self, histfile):
             readline.write_history_file(histfile)


File: python.info,  Node: rlcompleter --- Completion function for GNU readline,  Prev: readline --- GNU readline interface,  Up: Optional Operating System Services

5.16.9 ‘rlcompleter’ — Completion function for GNU readline
-----------------------------------------------------------

*Source code:* Lib/rlcompleter.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note rlcompleter: 149. module defines a completion function
suitable for the *note readline: 144. module by completing valid Python
identifiers and keywords.

  When this module is imported on a Unix platform with the *note
readline: 144. module available, an instance of the ‘Completer’ class is
automatically created and its ‘complete()’ method is set as the *note
readline: 144. completer.

  Example:

     >>> import rlcompleter
     >>> import readline
     >>> readline.parse_and_bind("tab: complete")
     >>> readline. <TAB PRESSED>
     readline.__doc__          readline.get_line_buffer(  readline.read_init_file(
     readline.__file__         readline.insert_text(      readline.set_completer(
     readline.__name__         readline.parse_and_bind(
     >>> readline.

  The *note rlcompleter: 149. module is designed for use with Python’s
interactive mode.  A user can add the following lines to his or her
initialization file (identified by the *note PYTHONSTARTUP: 514.
environment variable) to get automatic ‘Tab’ completion:

     try:
         import readline
     except ImportError:
         print "Module readline not available."
     else:
         import rlcompleter
         readline.parse_and_bind("tab: complete")

  On platforms without *note readline: 144, the ‘Completer’ class
defined by this module can still be used for custom purposes.

* Menu:

* Completer Objects:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/rlcompleter.py


File: python.info,  Node: Completer Objects,  Up: rlcompleter --- Completion function for GNU readline

5.16.9.1 Completer Objects
..........................

Completer objects have the following method:

 -- Method: Completer.complete (text, state)

     Return the _state_th completion for _text_.

     If called for _text_ that doesn’t include a period character
     (‘'.'’), it will complete from names currently defined in *note
     __main__: 2, *note __builtin__: 0. and keywords (as defined by the
     *note keyword: fd. module).

     If called for a dotted name, it will try to evaluate anything
     without obvious side-effects (functions will not be evaluated, but
     it can generate calls to *note __getattr__(): 331.) up to the last
     part, and find matches for the rest via the *note dir(): 33a.
     function.  Any exception raised during the evaluation of the
     expression is caught, silenced and *note None: 39a. is returned.


File: python.info,  Node: Interprocess Communication and Networking,  Next: Internet Data Handling,  Prev: Optional Operating System Services,  Up: The Python Standard Library

5.17 Interprocess Communication and Networking
==============================================

The modules described in this chapter provide mechanisms for different
processes to communicate.

  Some modules only work for two processes that are on the same machine,
e.g.  *note signal: 155. and *note subprocess: 167.  Other modules
support networking protocols that two or more processes can used to
communicate across machines.

  The list of modules described in this chapter is:

* Menu:

* subprocess: subprocess --- Subprocess management. Subprocess management
* socket: socket --- Low-level networking interface. Low-level networking interface
* ssl: ssl --- TLS/SSL wrapper for socket objects. TLS/SSL wrapper for socket objects
* signal: signal --- Set handlers for asynchronous events. Set handlers for asynchronous events
* popen2: popen2 --- Subprocesses with accessible I/O streams. Subprocesses with accessible I/O streams
* asyncore: asyncore --- Asynchronous socket handler. Asynchronous socket handler
* asynchat: asynchat --- Asynchronous socket command/response handler. Asynchronous socket command/response handler

subprocess — Subprocess management

* Using the subprocess Module:: 
* Popen Objects:: 
* Windows Popen Helpers:: 
* Replacing Older Functions with the subprocess Module:: 
* Notes:: 

Using the subprocess Module

* Frequently Used Arguments:: 
* Popen Constructor:: 
* Exceptions: Exceptions<4>. 
* Security:: 

Windows Popen Helpers

* Constants: Constants<4>. 

Replacing Older Functions with the subprocess Module

* Replacing /bin/sh shell backquote:: 
* Replacing shell pipeline:: 
* Replacing os.system(): Replacing os system. 
* Replacing the os.spawn family: Replacing the os spawn family. 
* Replacing os.popen(), os.popen2(), os.popen3(): Replacing os popen os popen2 os popen3. 
* Replacing functions from the popen2 module:: 

Notes

* Converting an argument sequence to a string on Windows:: 

socket — Low-level networking interface

* Socket Objects:: 
* Example: Example<8>. 

ssl — TLS/SSL wrapper for socket objects

* Functions, Constants, and Exceptions: Functions Constants and Exceptions. 
* SSLSocket Objects:: 
* Certificates:: 
* Examples: Examples<8>. 

Examples

* Testing for SSL support:: 
* Client-side operation:: 
* Server-side operation:: 

signal — Set handlers for asynchronous events

* Example: Example<9>. 

popen2 — Subprocesses with accessible I/O streams

* Popen3 and Popen4 Objects:: 
* Flow Control Issues:: 

asyncore — Asynchronous socket handler

* asyncore Example basic HTTP client:: 
* asyncore Example basic echo server:: 

asynchat — Asynchronous socket command/response handler

* asynchat - Auxiliary Classes:: 
* asynchat Example:: 


File: python.info,  Node: subprocess --- Subprocess management,  Next: socket --- Low-level networking interface,  Up: Interprocess Communication and Networking

5.17.1 ‘subprocess’ — Subprocess management
-------------------------------------------

New in version 2.4.

  The *note subprocess: 167. module allows you to spawn new processes,
connect to their input/output/error pipes, and obtain their return
codes.  This module intends to replace several older modules and
functions:

     os.system
     os.spawn*
     os.popen*
     popen2.*
     commands.*

  Information about how this module can be used to replace the older
functions can be found in the *note subprocess-replacements: 1103.
section.

See also
........

POSIX users (Linux, BSD, etc.)  are strongly encouraged to install and
use the much more recent subprocess32(1) module instead of the version
included with python 2.7.  It is a drop in replacement with better
behavior in many situations.

  PEP 324(2) – PEP proposing the subprocess module

* Menu:

* Using the subprocess Module:: 
* Popen Objects:: 
* Windows Popen Helpers:: 
* Replacing Older Functions with the subprocess Module:: 
* Notes:: 

Using the subprocess Module

* Frequently Used Arguments:: 
* Popen Constructor:: 
* Exceptions: Exceptions<4>. 
* Security:: 

Windows Popen Helpers

* Constants: Constants<4>. 

Replacing Older Functions with the subprocess Module

* Replacing /bin/sh shell backquote:: 
* Replacing shell pipeline:: 
* Replacing os.system(): Replacing os system. 
* Replacing the os.spawn family: Replacing the os spawn family. 
* Replacing os.popen(), os.popen2(), os.popen3(): Replacing os popen os popen2 os popen3. 
* Replacing functions from the popen2 module:: 

Notes

* Converting an argument sequence to a string on Windows:: 

   ---------- Footnotes ----------

   (1) https://pypi.python.org/pypi/subprocess32/

   (2) http://www.python.org/dev/peps/pep-0324


File: python.info,  Node: Using the subprocess Module,  Next: Popen Objects,  Up: subprocess --- Subprocess management

5.17.1.1 Using the ‘subprocess’ Module
......................................

The recommended way to launch subprocesses is to use the following
convenience functions.  For more advanced use cases when these do not
meet your needs, use the underlying *note Popen: 16e2. interface.

 -- Function: subprocess.call (args, *, stdin=None, stdout=None,
          stderr=None, shell=False)

     Run the command described by _args_.  Wait for command to complete,
     then return the ‘returncode’ attribute.

     The arguments shown above are merely the most common ones,
     described below in *note Frequently Used Arguments: 16e4. (hence
     the slightly odd notation in the abbreviated signature).  The full
     function signature is the same as that of the *note Popen: 16e2.
     constructor - this functions passes all supplied arguments directly
     through to that interface.

     Examples:

          >>> subprocess.call(["ls", "-l"])
          0

          >>> subprocess.call("exit 1", shell=True)
          1

          Warning: Using ‘shell=True’ can be a security hazard.  See the
          warning under *note Frequently Used Arguments: 16e4. for
          details.

          Note: Do not use ‘stdout=PIPE’ or ‘stderr=PIPE’ with this
          function as that can deadlock based on the child process
          output volume.  Use *note Popen: 16e2. with the
          ‘communicate()’ method when you need pipes.

 -- Function: subprocess.check_call (args, *, stdin=None, stdout=None,
          stderr=None, shell=False)

     Run command with arguments.  Wait for command to complete.  If the
     return code was zero then return, otherwise raise *note
     CalledProcessError: 262.  The *note CalledProcessError: 262. object
     will have the return code in the *note returncode: 16e6. attribute.

     The arguments shown above are merely the most common ones,
     described below in *note Frequently Used Arguments: 16e4. (hence
     the slightly odd notation in the abbreviated signature).  The full
     function signature is the same as that of the *note Popen: 16e2.
     constructor - this functions passes all supplied arguments directly
     through to that interface.

     Examples:

          >>> subprocess.check_call(["ls", "-l"])
          0

          >>> subprocess.check_call("exit 1", shell=True)
          Traceback (most recent call last):
             ...
          subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

     New in version 2.5.

          Warning: Using ‘shell=True’ can be a security hazard.  See the
          warning under *note Frequently Used Arguments: 16e4. for
          details.

          Note: Do not use ‘stdout=PIPE’ or ‘stderr=PIPE’ with this
          function as that can deadlock based on the child process
          output volume.  Use *note Popen: 16e2. with the
          ‘communicate()’ method when you need pipes.

 -- Function: subprocess.check_output (args, *, stdin=None, stderr=None,
          shell=False, universal_newlines=False)

     Run command with arguments and return its output as a byte string.

     If the return code was non-zero it raises a *note
     CalledProcessError: 262.  The *note CalledProcessError: 262. object
     will have the return code in the *note returncode: 16e6. attribute
     and any output in the *note output: 16e7. attribute.

     The arguments shown above are merely the most common ones,
     described below in *note Frequently Used Arguments: 16e4. (hence
     the slightly odd notation in the abbreviated signature).  The full
     function signature is largely the same as that of the *note Popen:
     16e2. constructor, except that _stdout_ is not permitted as it is
     used internally.  All other supplied arguments are passed directly
     through to the *note Popen: 16e2. constructor.

     Examples:

          >>> subprocess.check_output(["echo", "Hello World!"])
          'Hello World!\n'

          >>> subprocess.check_output("exit 1", shell=True)
          Traceback (most recent call last):
             ...
          subprocess.CalledProcessError: Command 'exit 1' returned non-zero exit status 1

     To also capture standard error in the result, use
     ‘stderr=subprocess.STDOUT’:

          >>> subprocess.check_output(
          ...     "ls non_existent_file; exit 0",
          ...     stderr=subprocess.STDOUT,
          ...     shell=True)
          'ls: non_existent_file: No such file or directory\n'

     New in version 2.7.

          Warning: Using ‘shell=True’ can be a security hazard.  See the
          warning under *note Frequently Used Arguments: 16e4. for
          details.

          Note: Do not use ‘stderr=PIPE’ with this function as that can
          deadlock based on the child process error volume.  Use *note
          Popen: 16e2. with the ‘communicate()’ method when you need a
          stderr pipe.

 -- Data: subprocess.PIPE

     Special value that can be used as the _stdin_, _stdout_ or _stderr_
     argument to *note Popen: 16e2. and indicates that a pipe to the
     standard stream should be opened.

 -- Data: subprocess.STDOUT

     Special value that can be used as the _stderr_ argument to *note
     Popen: 16e2. and indicates that standard error should go into the
     same handle as standard output.

 -- Exception: subprocess.CalledProcessError

     Exception raised when a process run by *note check_call(): 16e5. or
     *note check_output(): 261. returns a non-zero exit status.

      -- Attribute: returncode

          Exit status of the child process.

      -- Attribute: cmd

          Command that was used to spawn the child process.

      -- Attribute: output

          Output of the child process if this exception is raised by
          *note check_output(): 261.  Otherwise, ‘None’.

* Menu:

* Frequently Used Arguments:: 
* Popen Constructor:: 
* Exceptions: Exceptions<4>. 
* Security:: 


File: python.info,  Node: Frequently Used Arguments,  Next: Popen Constructor,  Up: Using the subprocess Module

5.17.1.2 Frequently Used Arguments
..................................

To support a wide variety of use cases, the *note Popen: 16e2.
constructor (and the convenience functions) accept a large number of
optional arguments.  For most typical use cases, many of these arguments
can be safely left at their default values.  The arguments that are most
commonly needed are:

     _args_ is required for all calls and should be a string, or a
     sequence of program arguments.  Providing a sequence of arguments
     is generally preferred, as it allows the module to take care of any
     required escaping and quoting of arguments (e.g.  to permit spaces
     in file names).  If passing a single string, either _shell_ must be
     *note True: 3b0. (see below) or else the string must simply name
     the program to be executed without specifying any arguments.

     _stdin_, _stdout_ and _stderr_ specify the executed program’s
     standard input, standard output and standard error file handles,
     respectively.  Valid values are *note PIPE: 16e8, an existing file
     descriptor (a positive integer), an existing file object, and
     ‘None’.  *note PIPE: 16e8. indicates that a new pipe to the child
     should be created.  With the default settings of ‘None’, no
     redirection will occur; the child’s file handles will be inherited
     from the parent.  Additionally, _stderr_ can be *note STDOUT: 16e9,
     which indicates that the stderr data from the child process should
     be captured into the same file handle as for stdout.

     When _stdout_ or _stderr_ are pipes and _universal_newlines_ is
     ‘True’ then all line endings will be converted to ‘'\n'’ as
     described for the *note universal newlines: 315. ‘'U'’ mode
     argument to *note open(): 2d6.

     If _shell_ is ‘True’, the specified command will be executed
     through the shell.  This can be useful if you are using Python
     primarily for the enhanced control flow it offers over most system
     shells and still want convenient access to other shell features
     such as shell pipes, filename wildcards, environment variable
     expansion, and expansion of ‘~’ to a user’s home directory.
     However, note that Python itself offers implementations of many
     shell-like features (in particular, *note glob: e3, *note fnmatch:
     d2, *note os.walk(): 353, *note os.path.expandvars(): 354, *note
     os.path.expanduser(): df9, and *note shutil: 154.).

          Warning: Executing shell commands that incorporate unsanitized
          input from an untrusted source makes a program vulnerable to
          shell injection(1), a serious security flaw which can result
          in arbitrary command execution.  For this reason, the use of
          ‘shell=True’ is *strongly discouraged* in cases where the
          command string is constructed from external input:

               >>> from subprocess import call
               >>> filename = input("What file would you like to display?\n")
               What file would you like to display?
               non_existent; rm -rf / #
               >>> call("cat " + filename, shell=True) # Uh-oh. This will end badly...

          ‘shell=False’ disables all shell based features, but does not
          suffer from this vulnerability; see the Note in the *note
          Popen: 16e2. constructor documentation for helpful hints in
          getting ‘shell=False’ to work.

          When using ‘shell=True’, *note pipes.quote(): 16ec. can be
          used to properly escape whitespace and shell metacharacters in
          strings that are going to be used to construct shell commands.

  These options, along with all of the other options, are described in
more detail in the *note Popen: 16e2. constructor documentation.

   ---------- Footnotes ----------

   (1) http://en.wikipedia.org/wiki/Shell_injection#Shell_injection


File: python.info,  Node: Popen Constructor,  Next: Exceptions<4>,  Prev: Frequently Used Arguments,  Up: Using the subprocess Module

5.17.1.3 Popen Constructor
..........................

The underlying process creation and management in this module is handled
by the *note Popen: 16e2. class.  It offers a lot of flexibility so that
developers are able to handle the less common cases not covered by the
convenience functions.

 -- Class: subprocess.Popen (args, bufsize=0, executable=None,
          stdin=None, stdout=None, stderr=None, preexec_fn=None,
          close_fds=False, shell=False, cwd=None, env=None,
          universal_newlines=False, startupinfo=None, creationflags=0)

     Execute a child program in a new process.  On Unix, the class uses
     *note os.execvp(): 1164.-like behavior to execute the child
     program.  On Windows, the class uses the Windows ‘CreateProcess()’
     function.  The arguments to *note Popen: 16e2. are as follows.

     _args_ should be a sequence of program arguments or else a single
     string.  By default, the program to execute is the first item in
     _args_ if _args_ is a sequence.  If _args_ is a string, the
     interpretation is platform-dependent and described below.  See the
     _shell_ and _executable_ arguments for additional differences from
     the default behavior.  Unless otherwise stated, it is recommended
     to pass _args_ as a sequence.

     On Unix, if _args_ is a string, the string is interpreted as the
     name or path of the program to execute.  However, this can only be
     done if not passing arguments to the program.

          Note: *note shlex.split(): 16ee. can be useful when
          determining the correct tokenization for _args_, especially in
          complex cases:

               >>> import shlex, subprocess
               >>> command_line = raw_input()
               /bin/vikings -input eggs.txt -output "spam spam.txt" -cmd "echo '$MONEY'"
               >>> args = shlex.split(command_line)
               >>> print args
               ['/bin/vikings', '-input', 'eggs.txt', '-output', 'spam spam.txt', '-cmd', "echo '$MONEY'"]
               >>> p = subprocess.Popen(args) # Success!

          Note in particular that options (such as _-input_) and
          arguments (such as _eggs.txt_) that are separated by
          whitespace in the shell go in separate list elements, while
          arguments that need quoting or backslash escaping when used in
          the shell (such as filenames containing spaces or the _echo_
          command shown above) are single list elements.

     On Windows, if _args_ is a sequence, it will be converted to a
     string in a manner described in *note Converting an argument
     sequence to a string on Windows: 16ef.  This is because the
     underlying ‘CreateProcess()’ operates on strings.

     The _shell_ argument (which defaults to _False_) specifies whether
     to use the shell as the program to execute.  If _shell_ is _True_,
     it is recommended to pass _args_ as a string rather than as a
     sequence.

     On Unix with ‘shell=True’, the shell defaults to ‘/bin/sh’.  If
     _args_ is a string, the string specifies the command to execute
     through the shell.  This means that the string must be formatted
     exactly as it would be when typed at the shell prompt.  This
     includes, for example, quoting or backslash escaping filenames with
     spaces in them.  If _args_ is a sequence, the first item specifies
     the command string, and any additional items will be treated as
     additional arguments to the shell itself.  That is to say, *note
     Popen: 16e2. does the equivalent of:

          Popen(['/bin/sh', '-c', args[0], args[1], ...])

     On Windows with ‘shell=True’, the ‘COMSPEC’ environment variable
     specifies the default shell.  The only time you need to specify
     ‘shell=True’ on Windows is when the command you wish to execute is
     built into the shell (e.g.  *dir* or *copy*).  You do not need
     ‘shell=True’ to run a batch file or console-based executable.

          Warning: Passing ‘shell=True’ can be a security hazard if
          combined with untrusted input.  See the warning under *note
          Frequently Used Arguments: 16e4. for details.

     _bufsize_, if given, has the same meaning as the corresponding
     argument to the built-in open() function: ‘0’ means unbuffered, ‘1’
     means line buffered, any other positive value means use a buffer of
     (approximately) that size.  A negative _bufsize_ means to use the
     system default, which usually means fully buffered.  The default
     value for _bufsize_ is ‘0’ (unbuffered).

          Note: If you experience performance issues, it is recommended
          that you try to enable buffering by setting _bufsize_ to
          either -1 or a large enough positive value (such as 4096).

     The _executable_ argument specifies a replacement program to
     execute.  It is very seldom needed.  When ‘shell=False’,
     _executable_ replaces the program to execute specified by _args_.
     However, the original _args_ is still passed to the program.  Most
     programs treat the program specified by _args_ as the command name,
     which can then be different from the program actually executed.  On
     Unix, the _args_ name becomes the display name for the executable
     in utilities such as *ps*.  If ‘shell=True’, on Unix the
     _executable_ argument specifies a replacement shell for the default
     ‘/bin/sh’.

     _stdin_, _stdout_ and _stderr_ specify the executed program’s
     standard input, standard output and standard error file handles,
     respectively.  Valid values are *note PIPE: 16e8, an existing file
     descriptor (a positive integer), an existing file object, and
     ‘None’.  *note PIPE: 16e8. indicates that a new pipe to the child
     should be created.  With the default settings of ‘None’, no
     redirection will occur; the child’s file handles will be inherited
     from the parent.  Additionally, _stderr_ can be *note STDOUT: 16e9,
     which indicates that the stderr data from the child process should
     be captured into the same file handle as for stdout.

     If _preexec_fn_ is set to a callable object, this object will be
     called in the child process just before the child is executed.
     (Unix only)

     If _close_fds_ is true, all file descriptors except ‘0’, ‘1’ and
     ‘2’ will be closed before the child process is executed.  (Unix
     only).  Or, on Windows, if _close_fds_ is true then no handles will
     be inherited by the child process.  Note that on Windows, you
     cannot set _close_fds_ to true and also redirect the standard
     handles by setting _stdin_, _stdout_ or _stderr_.

     If _cwd_ is not ‘None’, the child’s current directory will be
     changed to _cwd_ before it is executed.  Note that this directory
     is not considered when searching the executable, so you can’t
     specify the program’s path relative to _cwd_.

     If _env_ is not ‘None’, it must be a mapping that defines the
     environment variables for the new process; these are used instead
     of inheriting the current process’ environment, which is the
     default behavior.

          Note: If specified, _env_ must provide any variables required
          for the program to execute.  On Windows, in order to run a
          side-by-side assembly(1) the specified _env_ *must* include a
          valid ‘SystemRoot’.

     If _universal_newlines_ is ‘True’, the file objects _stdout_ and
     _stderr_ are opened as text files in *note universal newlines: 315.
     mode.  Lines may be terminated by any of ‘'\n'’, the Unix
     end-of-line convention, ‘'\r'’, the old Macintosh convention or
     ‘'\r\n'’, the Windows convention.  All of these external
     representations are seen as ‘'\n'’ by the Python program.

          Note: This feature is only available if Python is built with
          universal newline support (the default).  Also, the newlines
          attribute of the file objects *note stdout: 16f0, *note stdin:
          16f1. and *note stderr: 16f2. are not updated by the
          communicate() method.

     If given, _startupinfo_ will be a *note STARTUPINFO: 16f3. object,
     which is passed to the underlying ‘CreateProcess’ function.
     _creationflags_, if given, can be *note CREATE_NEW_CONSOLE: 16f4.
     or *note CREATE_NEW_PROCESS_GROUP: 16f5.  (Windows only)

   ---------- Footnotes ----------

   (1) http://en.wikipedia.org/wiki/Side-by-Side_Assembly


File: python.info,  Node: Exceptions<4>,  Next: Security,  Prev: Popen Constructor,  Up: Using the subprocess Module

5.17.1.4 Exceptions
...................

Exceptions raised in the child process, before the new program has
started to execute, will be re-raised in the parent.  Additionally, the
exception object will have one extra attribute called ‘child_traceback’,
which is a string containing traceback information from the child’s
point of view.

  The most common exception raised is *note OSError: 231.  This occurs,
for example, when trying to execute a non-existent file.  Applications
should prepare for *note OSError: 231. exceptions.

  A *note ValueError: 236. will be raised if *note Popen: 16e2. is
called with invalid arguments.

  *note check_call(): 16e5. and *note check_output(): 261. will raise
*note CalledProcessError: 262. if the called process returns a non-zero
return code.


File: python.info,  Node: Security,  Prev: Exceptions<4>,  Up: Using the subprocess Module

5.17.1.5 Security
.................

Unlike some other popen functions, this implementation will never call a
system shell implicitly.  This means that all characters, including
shell metacharacters, can safely be passed to child processes.
Obviously, if the shell is invoked explicitly, then it is the
application’s responsibility to ensure that all whitespace and
metacharacters are quoted appropriately.


File: python.info,  Node: Popen Objects,  Next: Windows Popen Helpers,  Prev: Using the subprocess Module,  Up: subprocess --- Subprocess management

5.17.1.6 Popen Objects
......................

Instances of the *note Popen: 16e2. class have the following methods:

 -- Method: Popen.poll ()

     Check if child process has terminated.  Set and return *note
     returncode: 16fa. attribute.

 -- Method: Popen.wait ()

     Wait for child process to terminate.  Set and return *note
     returncode: 16fa. attribute.

          Warning: This will deadlock when using ‘stdout=PIPE’ and/or
          ‘stderr=PIPE’ and the child process generates enough output to
          a pipe such that it blocks waiting for the OS pipe buffer to
          accept more data.  Use *note communicate(): 16fc. to avoid
          that.

 -- Method: Popen.communicate (input=None)

     Interact with process: Send data to stdin.  Read data from stdout
     and stderr, until end-of-file is reached.  Wait for process to
     terminate.  The optional _input_ argument should be a string to be
     sent to the child process, or ‘None’, if no data should be sent to
     the child.

     *note communicate(): 16fc. returns a tuple ‘(stdoutdata,
     stderrdata)’.

     Note that if you want to send data to the process’s stdin, you need
     to create the Popen object with ‘stdin=PIPE’.  Similarly, to get
     anything other than ‘None’ in the result tuple, you need to give
     ‘stdout=PIPE’ and/or ‘stderr=PIPE’ too.

          Note: The data read is buffered in memory, so do not use this
          method if the data size is large or unlimited.

 -- Method: Popen.send_signal (signal)

     Sends the signal _signal_ to the child.

          Note: On Windows, SIGTERM is an alias for *note terminate():
          16fe.  CTRL_C_EVENT and CTRL_BREAK_EVENT can be sent to
          processes started with a _creationflags_ parameter which
          includes ‘CREATE_NEW_PROCESS_GROUP’.

     New in version 2.6.

 -- Method: Popen.terminate ()

     Stop the child.  On Posix OSs the method sends SIGTERM to the
     child.  On Windows the Win32 API function ‘TerminateProcess()’ is
     called to stop the child.

     New in version 2.6.

 -- Method: Popen.kill ()

     Kills the child.  On Posix OSs the function sends SIGKILL to the
     child.  On Windows *note kill(): 16ff. is an alias for *note
     terminate(): 16fe.

     New in version 2.6.

  The following attributes are also available:

     Warning: Use *note communicate(): 16fc. rather than *note
     .stdin.write: 16f1, *note .stdout.read: 16f0. or *note
     .stderr.read: 16f2. to avoid deadlocks due to any of the other OS
     pipe buffers filling up and blocking the child process.

 -- Attribute: Popen.stdin

     If the _stdin_ argument was *note PIPE: 16e8, this attribute is a
     file object that provides input to the child process.  Otherwise,
     it is ‘None’.

 -- Attribute: Popen.stdout

     If the _stdout_ argument was *note PIPE: 16e8, this attribute is a
     file object that provides output from the child process.
     Otherwise, it is ‘None’.

 -- Attribute: Popen.stderr

     If the _stderr_ argument was *note PIPE: 16e8, this attribute is a
     file object that provides error output from the child process.
     Otherwise, it is ‘None’.

 -- Attribute: Popen.pid

     The process ID of the child process.

     Note that if you set the _shell_ argument to ‘True’, this is the
     process ID of the spawned shell.

 -- Attribute: Popen.returncode

     The child return code, set by *note poll(): 16f9. and *note wait():
     16fb. (and indirectly by *note communicate(): 16fc.).  A ‘None’
     value indicates that the process hasn’t terminated yet.

     A negative value ‘-N’ indicates that the child was terminated by
     signal ‘N’ (Unix only).


File: python.info,  Node: Windows Popen Helpers,  Next: Replacing Older Functions with the subprocess Module,  Prev: Popen Objects,  Up: subprocess --- Subprocess management

5.17.1.7 Windows Popen Helpers
..............................

The *note STARTUPINFO: 16f3. class and following constants are only
available on Windows.

 -- Class: subprocess.STARTUPINFO

     Partial support of the Windows STARTUPINFO(1) structure is used for
     *note Popen: 16e2. creation.

      -- Attribute: dwFlags

          A bit field that determines whether certain *note STARTUPINFO:
          16f3. attributes are used when the process creates a window.

               si = subprocess.STARTUPINFO()
               si.dwFlags = subprocess.STARTF_USESTDHANDLES | subprocess.STARTF_USESHOWWINDOW

      -- Attribute: hStdInput

          If *note dwFlags: 1702. specifies *note STARTF_USESTDHANDLES:
          1704, this attribute is the standard input handle for the
          process.  If *note STARTF_USESTDHANDLES: 1704. is not
          specified, the default for standard input is the keyboard
          buffer.

      -- Attribute: hStdOutput

          If *note dwFlags: 1702. specifies *note STARTF_USESTDHANDLES:
          1704, this attribute is the standard output handle for the
          process.  Otherwise, this attribute is ignored and the default
          for standard output is the console window’s buffer.

      -- Attribute: hStdError

          If *note dwFlags: 1702. specifies *note STARTF_USESTDHANDLES:
          1704, this attribute is the standard error handle for the
          process.  Otherwise, this attribute is ignored and the default
          for standard error is the console window’s buffer.

      -- Attribute: wShowWindow

          If *note dwFlags: 1702. specifies *note STARTF_USESHOWWINDOW:
          1708, this attribute can be any of the values that can be
          specified in the ‘nCmdShow’ parameter for the ShowWindow(2)
          function, except for ‘SW_SHOWDEFAULT’.  Otherwise, this
          attribute is ignored.

          *note SW_HIDE: 1709. is provided for this attribute.  It is
          used when *note Popen: 16e2. is called with ‘shell=True’.

* Menu:

* Constants: Constants<4>. 

   ---------- Footnotes ----------

   (1) http://msdn.microsoft.com/en-us/library/ms686331(v=vs.85).aspx

   (2) http://msdn.microsoft.com/en-us/library/ms633548(v=vs.85).aspx


File: python.info,  Node: Constants<4>,  Up: Windows Popen Helpers

5.17.1.8 Constants
..................

The *note subprocess: 167. module exposes the following constants.

 -- Data: subprocess.STD_INPUT_HANDLE

     The standard input device.  Initially, this is the console input
     buffer, ‘CONIN$’.

 -- Data: subprocess.STD_OUTPUT_HANDLE

     The standard output device.  Initially, this is the active console
     screen buffer, ‘CONOUT$’.

 -- Data: subprocess.STD_ERROR_HANDLE

     The standard error device.  Initially, this is the active console
     screen buffer, ‘CONOUT$’.

 -- Data: subprocess.SW_HIDE

     Hides the window.  Another window will be activated.

 -- Data: subprocess.STARTF_USESTDHANDLES

     Specifies that the *note STARTUPINFO.hStdInput: 1703, *note
     STARTUPINFO.hStdOutput: 1705, and *note STARTUPINFO.hStdError:
     1706. attributes contain additional information.

 -- Data: subprocess.STARTF_USESHOWWINDOW

     Specifies that the *note STARTUPINFO.wShowWindow: 1707. attribute
     contains additional information.

 -- Data: subprocess.CREATE_NEW_CONSOLE

     The new process has a new console, instead of inheriting its
     parent’s console (the default).

     This flag is always set when *note Popen: 16e2. is created with
     ‘shell=True’.

 -- Data: subprocess.CREATE_NEW_PROCESS_GROUP

     A *note Popen: 16e2. ‘creationflags’ parameter to specify that a
     new process group will be created.  This flag is necessary for
     using *note os.kill(): 2d1. on the subprocess.

     This flag is ignored if *note CREATE_NEW_CONSOLE: 16f4. is
     specified.


File: python.info,  Node: Replacing Older Functions with the subprocess Module,  Next: Notes,  Prev: Windows Popen Helpers,  Up: subprocess --- Subprocess management

5.17.1.9 Replacing Older Functions with the ‘subprocess’ Module
...............................................................

In this section, "a becomes b" means that b can be used as a replacement
for a.

     Note: All "a" functions in this section fail (more or less)
     silently if the executed program cannot be found; the "b"
     replacements raise *note OSError: 231. instead.

     In addition, the replacements using *note check_output(): 261. will
     fail with a *note CalledProcessError: 262. if the requested
     operation produces a non-zero return code.  The output is still
     available as the *note output: 16e7. attribute of the raised
     exception.

  In the following examples, we assume that the relevant functions have
already been imported from the *note subprocess: 167. module.

* Menu:

* Replacing /bin/sh shell backquote:: 
* Replacing shell pipeline:: 
* Replacing os.system(): Replacing os system. 
* Replacing the os.spawn family: Replacing the os spawn family. 
* Replacing os.popen(), os.popen2(), os.popen3(): Replacing os popen os popen2 os popen3. 
* Replacing functions from the popen2 module:: 


File: python.info,  Node: Replacing /bin/sh shell backquote,  Next: Replacing shell pipeline,  Up: Replacing Older Functions with the subprocess Module

5.17.1.10 Replacing /bin/sh shell backquote
...........................................

     output=`mycmd myarg`
     # becomes
     output = check_output(["mycmd", "myarg"])


File: python.info,  Node: Replacing shell pipeline,  Next: Replacing os system,  Prev: Replacing /bin/sh shell backquote,  Up: Replacing Older Functions with the subprocess Module

5.17.1.11 Replacing shell pipeline
..................................

     output=`dmesg | grep hda`
     # becomes
     p1 = Popen(["dmesg"], stdout=PIPE)
     p2 = Popen(["grep", "hda"], stdin=p1.stdout, stdout=PIPE)
     p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.
     output = p2.communicate()[0]

  The p1.stdout.close() call after starting the p2 is important in order
for p1 to receive a SIGPIPE if p2 exits before p1.

  Alternatively, for trusted input, the shell’s own pipeline support may
still be used directly:

     output=`dmesg | grep hda`
     # becomes
     output=check_output("dmesg | grep hda", shell=True)


File: python.info,  Node: Replacing os system,  Next: Replacing the os spawn family,  Prev: Replacing shell pipeline,  Up: Replacing Older Functions with the subprocess Module

5.17.1.12 Replacing ‘os.system()’
.................................

     status = os.system("mycmd" + " myarg")
     # becomes
     status = subprocess.call("mycmd" + " myarg", shell=True)

  Notes:

   * Calling the program through the shell is usually not required.

  A more realistic example would look like this:

     try:
         retcode = call("mycmd" + " myarg", shell=True)
         if retcode < 0:
             print >>sys.stderr, "Child was terminated by signal", -retcode
         else:
             print >>sys.stderr, "Child returned", retcode
     except OSError as e:
         print >>sys.stderr, "Execution failed:", e


File: python.info,  Node: Replacing the os spawn family,  Next: Replacing os popen os popen2 os popen3,  Prev: Replacing os system,  Up: Replacing Older Functions with the subprocess Module

5.17.1.13 Replacing the ‘os.spawn’ family
.........................................

P_NOWAIT example:

     pid = os.spawnlp(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg")
     ==>
     pid = Popen(["/bin/mycmd", "myarg"]).pid

  P_WAIT example:

     retcode = os.spawnlp(os.P_WAIT, "/bin/mycmd", "mycmd", "myarg")
     ==>
     retcode = call(["/bin/mycmd", "myarg"])

  Vector example:

     os.spawnvp(os.P_NOWAIT, path, args)
     ==>
     Popen([path] + args[1:])

  Environment example:

     os.spawnlpe(os.P_NOWAIT, "/bin/mycmd", "mycmd", "myarg", env)
     ==>
     Popen(["/bin/mycmd", "myarg"], env={"PATH": "/usr/bin"})


File: python.info,  Node: Replacing os popen os popen2 os popen3,  Next: Replacing functions from the popen2 module,  Prev: Replacing the os spawn family,  Up: Replacing Older Functions with the subprocess Module

5.17.1.14 Replacing ‘os.popen()’, ‘os.popen2()’, ‘os.popen3()’
..............................................................

     pipe = os.popen("cmd", 'r', bufsize)
     ==>
     pipe = Popen("cmd", shell=True, bufsize=bufsize, stdout=PIPE).stdout

     pipe = os.popen("cmd", 'w', bufsize)
     ==>
     pipe = Popen("cmd", shell=True, bufsize=bufsize, stdin=PIPE).stdin

     (child_stdin, child_stdout) = os.popen2("cmd", mode, bufsize)
     ==>
     p = Popen("cmd", shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, close_fds=True)
     (child_stdin, child_stdout) = (p.stdin, p.stdout)

     (child_stdin,
      child_stdout,
      child_stderr) = os.popen3("cmd", mode, bufsize)
     ==>
     p = Popen("cmd", shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)
     (child_stdin,
      child_stdout,
      child_stderr) = (p.stdin, p.stdout, p.stderr)

     (child_stdin, child_stdout_and_stderr) = os.popen4("cmd", mode,
                                                        bufsize)
     ==>
     p = Popen("cmd", shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, stderr=STDOUT, close_fds=True)
     (child_stdin, child_stdout_and_stderr) = (p.stdin, p.stdout)

  On Unix, os.popen2, os.popen3 and os.popen4 also accept a sequence as
the command to execute, in which case arguments will be passed directly
to the program without shell intervention.  This usage can be replaced
as follows:

     (child_stdin, child_stdout) = os.popen2(["/bin/ls", "-l"], mode,
                                             bufsize)
     ==>
     p = Popen(["/bin/ls", "-l"], bufsize=bufsize, stdin=PIPE, stdout=PIPE)
     (child_stdin, child_stdout) = (p.stdin, p.stdout)

  Return code handling translates as follows:

     pipe = os.popen("cmd", 'w')
     ...
     rc = pipe.close()
     if rc is not None and rc >> 8:
         print "There were some errors"
     ==>
     process = Popen("cmd", 'w', shell=True, stdin=PIPE)
     ...
     process.stdin.close()
     if process.wait() != 0:
         print "There were some errors"


File: python.info,  Node: Replacing functions from the popen2 module,  Prev: Replacing os popen os popen2 os popen3,  Up: Replacing Older Functions with the subprocess Module

5.17.1.15 Replacing functions from the ‘popen2’ module
......................................................

     (child_stdout, child_stdin) = popen2.popen2("somestring", bufsize, mode)
     ==>
     p = Popen("somestring", shell=True, bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, close_fds=True)
     (child_stdout, child_stdin) = (p.stdout, p.stdin)

  On Unix, popen2 also accepts a sequence as the command to execute, in
which case arguments will be passed directly to the program without
shell intervention.  This usage can be replaced as follows:

     (child_stdout, child_stdin) = popen2.popen2(["mycmd", "myarg"], bufsize,
                                                 mode)
     ==>
     p = Popen(["mycmd", "myarg"], bufsize=bufsize,
               stdin=PIPE, stdout=PIPE, close_fds=True)
     (child_stdout, child_stdin) = (p.stdout, p.stdin)

  *note popen2.Popen3: 1715. and *note popen2.Popen4: 1716. basically
work as *note subprocess.Popen: 16e2, except that:

   * *note Popen: 16e2. raises an exception if the execution fails.

   * the _capturestderr_ argument is replaced with the _stderr_
     argument.

   * ‘stdin=PIPE’ and ‘stdout=PIPE’ must be specified.

   * popen2 closes all file descriptors by default, but you have to
     specify ‘close_fds=True’ with *note Popen: 16e2.


File: python.info,  Node: Notes,  Prev: Replacing Older Functions with the subprocess Module,  Up: subprocess --- Subprocess management

5.17.1.16 Notes
...............

* Menu:

* Converting an argument sequence to a string on Windows:: 


File: python.info,  Node: Converting an argument sequence to a string on Windows,  Up: Notes

5.17.1.17 Converting an argument sequence to a string on Windows
................................................................

On Windows, an _args_ sequence is converted to a string that can be
parsed using the following rules (which correspond to the rules used by
the MS C runtime):

  1. Arguments are delimited by white space, which is either a space or
     a tab.

  2. A string surrounded by double quotation marks is interpreted as a
     single argument, regardless of white space contained within.  A
     quoted string can be embedded in an argument.

  3. A double quotation mark preceded by a backslash is interpreted as a
     literal double quotation mark.

  4. Backslashes are interpreted literally, unless they immediately
     precede a double quotation mark.

  5. If backslashes immediately precede a double quotation mark, every
     pair of backslashes is interpreted as a literal backslash.  If the
     number of backslashes is odd, the last backslash escapes the next
     double quotation mark as described in rule 3.


File: python.info,  Node: socket --- Low-level networking interface,  Next: ssl --- TLS/SSL wrapper for socket objects,  Prev: subprocess --- Subprocess management,  Up: Interprocess Communication and Networking

5.17.2 ‘socket’ — Low-level networking interface
------------------------------------------------

This module provides access to the BSD _socket_ interface.  It is
available on all modern Unix systems, Windows, Mac OS X, BeOS, OS/2, and
probably additional platforms.

     Note: Some behavior may be platform dependent, since calls are made
     to the operating system socket APIs.

  For an introduction to socket programming (in C), see the following
papers: An Introductory 4.3BSD Interprocess Communication Tutorial, by
Stuart Sechrest and An Advanced 4.3BSD Interprocess Communication
Tutorial, by Samuel J. Leffler et al, both in the UNIX Programmer’s
Manual, Supplementary Documents 1 (sections PS1:7 and PS1:8).  The
platform-specific reference material for the various socket-related
system calls are also a valuable source of information on the details of
socket semantics.  For Unix, refer to the manual pages; for Windows, see
the WinSock (or Winsock 2) specification.  For IPv6-ready APIs, readers
may want to refer to RFC 3493(1) titled Basic Socket Interface
Extensions for IPv6.

  The Python interface is a straightforward transliteration of the Unix
system call and library interface for sockets to Python’s
object-oriented style: the *note socket(): 15a4. function returns a
_socket object_ whose methods implement the various socket system calls.
Parameter types are somewhat higher-level than in the C interface: as
with ‘read()’ and ‘write()’ operations on Python files, buffer
allocation on receive operations is automatic, and buffer length is
implicit on send operations.

  Socket addresses are represented as follows: A single string is used
for the *note AF_UNIX: 171b. address family.  A pair ‘(host, port)’ is
used for the *note AF_INET: 171c. address family, where _host_ is a
string representing either a hostname in Internet domain notation like
‘'daring.cwi.nl'’ or an IPv4 address like ‘'100.50.200.5'’, and _port_
is an integer.  For *note AF_INET6: 171d. address family, a four-tuple
‘(host, port, flowinfo, scopeid)’ is used, where _flowinfo_ and
_scopeid_ represents ‘sin6_flowinfo’ and ‘sin6_scope_id’ member in
‘struct sockaddr_in6’ in C. For *note socket: 15c. module methods,
_flowinfo_ and _scopeid_ can be omitted just for backward compatibility.
Note, however, omission of _scopeid_ can cause problems in manipulating
scoped IPv6 addresses.  Other address families are currently not
supported.  The address format required by a particular socket object is
automatically selected based on the address family specified when the
socket object was created.

  For IPv4 addresses, two special forms are accepted instead of a host
address: the empty string represents ‘INADDR_ANY’, and the string
‘'<broadcast>'’ represents ‘INADDR_BROADCAST’.  The behavior is not
available for IPv6 for backward compatibility, therefore, you may want
to avoid these if you intend to support IPv6 with your Python programs.

  If you use a hostname in the _host_ portion of IPv4/v6 socket address,
the program may show a nondeterministic behavior, as Python uses the
first address returned from the DNS resolution.  The socket address will
be resolved differently into an actual IPv4/v6 address, depending on the
results from DNS resolution and/or the host configuration.  For
deterministic behavior use a numeric address in _host_ portion.

  New in version 2.5: AF_NETLINK sockets are represented as pairs ‘pid,
groups’.

  New in version 2.6: Linux-only support for TIPC is also available
using the ‘AF_TIPC’ address family.  TIPC is an open, non-IP based
networked protocol designed for use in clustered computer environments.
Addresses are represented by a tuple, and the fields depend on the
address type.  The general tuple form is ‘(addr_type, v1, v2, v3 [,
scope])’, where:

   - _addr_type_ is one of ‘TIPC_ADDR_NAMESEQ’, ‘TIPC_ADDR_NAME’, or
     ‘TIPC_ADDR_ID’.

   - _scope_ is one of ‘TIPC_ZONE_SCOPE’, ‘TIPC_CLUSTER_SCOPE’, and
     ‘TIPC_NODE_SCOPE’.

   - If _addr_type_ is ‘TIPC_ADDR_NAME’, then _v1_ is the server type,
     _v2_ is the port identifier, and _v3_ should be 0.

     If _addr_type_ is ‘TIPC_ADDR_NAMESEQ’, then _v1_ is the server
     type, _v2_ is the lower port number, and _v3_ is the upper port
     number.

     If _addr_type_ is ‘TIPC_ADDR_ID’, then _v1_ is the node, _v2_ is
     the reference, and _v3_ should be set to 0.

  All errors raise exceptions.  The normal exceptions for invalid
argument types and out-of-memory conditions can be raised; errors
related to socket or address semantics raise the error *note
socket.error: 381.

  Non-blocking mode is supported through *note setblocking(): 171e.  A
generalization of this based on timeouts is supported through *note
settimeout(): 171f.

  The module *note socket: 15c. exports the following constants and
functions:

 -- Exception: socket.error

     This exception is raised for socket-related errors.  The
     accompanying value is either a string telling what went wrong or a
     pair ‘(errno, string)’ representing an error returned by a system
     call, similar to the value accompanying *note os.error: e02.  See
     the module *note errno: c8, which contains names for the error
     codes defined by the underlying operating system.

     Changed in version 2.6: *note socket.error: 381. is now a child
     class of *note IOError: 1fa.

 -- Exception: socket.herror

     This exception is raised for address-related errors, i.e.  for
     functions that use _h_errno_ in the C API, including *note
     gethostbyname_ex(): 1721. and *note gethostbyaddr(): 1722.

     The accompanying value is a pair ‘(h_errno, string)’ representing
     an error returned by a library call.  _string_ represents the
     description of _h_errno_, as returned by the ‘hstrerror()’ C
     function.

 -- Exception: socket.gaierror

     This exception is raised for address-related errors, for *note
     getaddrinfo(): 1724. and *note getnameinfo(): 1725.  The
     accompanying value is a pair ‘(error, string)’ representing an
     error returned by a library call.  _string_ represents the
     description of _error_, as returned by the ‘gai_strerror()’ C
     function.  The _error_ value will match one of the ‘EAI_*’
     constants defined in this module.

 -- Exception: socket.timeout

     This exception is raised when a timeout occurs on a socket which
     has had timeouts enabled via a prior call to ‘settimeout()’.  The
     accompanying value is a string whose value is currently always
     "timed out".

     New in version 2.3.

 -- Data: socket.AF_UNIX
 -- Data: socket.AF_INET
 -- Data: socket.AF_INET6

     These constants represent the address (and protocol) families, used
     for the first argument to *note socket(): 15a4.  If the *note
     AF_UNIX: 171b. constant is not defined then this protocol is
     unsupported.

 -- Data: socket.SOCK_STREAM
 -- Data: socket.SOCK_DGRAM
 -- Data: socket.SOCK_RAW
 -- Data: socket.SOCK_RDM
 -- Data: socket.SOCK_SEQPACKET

     These constants represent the socket types, used for the second
     argument to *note socket(): 15c.  (Only *note SOCK_STREAM: 1dc. and
     *note SOCK_DGRAM: 1db. appear to be generally useful.)

 -- Data: SO_*
 -- Data: socket.SOMAXCONN

 -- Data: MSG_*

 -- Data: SOL_*

 -- Data: IPPROTO_*

 -- Data: IPPORT_*

 -- Data: INADDR_*

 -- Data: IP_*

 -- Data: IPV6_*

 -- Data: EAI_*

 -- Data: AI_*

 -- Data: NI_*

 -- Data: TCP_*

     Many constants of these forms, documented in the Unix documentation
     on sockets and/or the IP protocol, are also defined in the socket
     module.  They are generally used in arguments to the ‘setsockopt()’
     and ‘getsockopt()’ methods of socket objects.  In most cases, only
     those symbols that are defined in the Unix header files are
     defined; for a few symbols, default values are provided.

 -- Data: SIO_*

 -- Data: RCVALL_*

     Constants for Windows’ WSAIoctl().  The constants are used as
     arguments to the *note ioctl(): 172a. method of socket objects.

     New in version 2.6.

 -- Data: TIPC_*

     TIPC related constants, matching the ones exported by the C socket
     API. See the TIPC documentation for more information.

     New in version 2.6.

 -- Data: socket.has_ipv6

     This constant contains a boolean value which indicates if IPv6 is
     supported on this platform.

     New in version 2.3.

 -- Function: socket.create_connection (address[, timeout[,
          source_address]])

     Connect to a TCP service listening on the Internet _address_ (a
     2-tuple ‘(host, port)’), and return the socket object.  This is a
     higher-level function than *note socket.connect(): 172c.: if _host_
     is a non-numeric hostname, it will try to resolve it for both *note
     AF_INET: 171c. and *note AF_INET6: 171d, and then try to connect to
     all possible addresses in turn until a connection succeeds.  This
     makes it easy to write clients that are compatible to both IPv4 and
     IPv6.

     Passing the optional _timeout_ parameter will set the timeout on
     the socket instance before attempting to connect.  If no _timeout_
     is supplied, the global default timeout setting returned by *note
     getdefaulttimeout(): 172d. is used.

     If supplied, _source_address_ must be a 2-tuple ‘(host, port)’ for
     the socket to bind to as its source address before connecting.  If
     host or port are ’’ or 0 respectively the OS default behavior will
     be used.

     New in version 2.6.

     Changed in version 2.7: _source_address_ was added.

 -- Function: socket.getaddrinfo (host, port[, family[, socktype[,
          proto[, flags]]]])

     Translate the _host_/_port_ argument into a sequence of 5-tuples
     that contain all the necessary arguments for creating a socket
     connected to that service.  _host_ is a domain name, a string
     representation of an IPv4/v6 address or ‘None’.  _port_ is a string
     service name such as ‘'http'’, a numeric port number or ‘None’.  By
     passing ‘None’ as the value of _host_ and _port_, you can pass
     ‘NULL’ to the underlying C API.

     The _family_, _socktype_ and _proto_ arguments can be optionally
     specified in order to narrow the list of addresses returned.  By
     default, their value is ‘0’, meaning that the full range of results
     is selected.  The _flags_ argument can be one or several of the
     ‘AI_*’ constants, and will influence how results are computed and
     returned.  Its default value is ‘0’.  For example, ‘AI_NUMERICHOST’
     will disable domain name resolution and will raise an error if
     _host_ is a domain name.

     The function returns a list of 5-tuples with the following
     structure:

     ‘(family, socktype, proto, canonname, sockaddr)’

     In these tuples, _family_, _socktype_, _proto_ are all integers and
     are meant to be passed to the *note socket(): 15a4. function.
     _canonname_ will be a string representing the canonical name of the
     _host_ if ‘AI_CANONNAME’ is part of the _flags_ argument; else
     _canonname_ will be empty.  _sockaddr_ is a tuple describing a
     socket address, whose format depends on the returned _family_ (a
     ‘(address, port)’ 2-tuple for *note AF_INET: 171c, a ‘(address,
     port, flow info, scope id)’ 4-tuple for *note AF_INET6: 171d.), and
     is meant to be passed to the *note socket.connect(): 172c. method.

     The following example fetches address information for a
     hypothetical TCP connection to ‘www.python.org’ on port 80 (results
     may differ on your system if IPv6 isn’t enabled):

          >>> socket.getaddrinfo("www.python.org", 80, 0, 0, socket.SOL_TCP)
          [(2, 1, 6, '', ('82.94.164.162', 80)),
           (10, 1, 6, '', ('2001:888:2000:d::a2', 80, 0, 0))]

     New in version 2.2.

 -- Function: socket.getfqdn ([name])

     Return a fully qualified domain name for _name_.  If _name_ is
     omitted or empty, it is interpreted as the local host.  To find the
     fully qualified name, the hostname returned by *note
     gethostbyaddr(): 1722. is checked, followed by aliases for the
     host, if available.  The first name which includes a period is
     selected.  In case no fully qualified domain name is available, the
     hostname as returned by *note gethostname(): 10ff. is returned.

     New in version 2.0.

 -- Function: socket.gethostbyname (hostname)

     Translate a host name to IPv4 address format.  The IPv4 address is
     returned as a string, such as ‘'100.50.200.5'’.  If the host name
     is an IPv4 address itself it is returned unchanged.  See *note
     gethostbyname_ex(): 1721. for a more complete interface.  *note
     gethostbyname(): 172f. does not support IPv6 name resolution, and
     *note getaddrinfo(): 1724. should be used instead for IPv4/v6 dual
     stack support.

 -- Function: socket.gethostbyname_ex (hostname)

     Translate a host name to IPv4 address format, extended interface.
     Return a triple ‘(hostname, aliaslist, ipaddrlist)’ where
     _hostname_ is the primary host name responding to the given
     _ip_address_, _aliaslist_ is a (possibly empty) list of alternative
     host names for the same address, and _ipaddrlist_ is a list of IPv4
     addresses for the same interface on the same host (often but not
     always a single address).  *note gethostbyname_ex(): 1721. does not
     support IPv6 name resolution, and *note getaddrinfo(): 1724. should
     be used instead for IPv4/v6 dual stack support.

 -- Function: socket.gethostname ()

     Return a string containing the hostname of the machine where the
     Python interpreter is currently executing.

     If you want to know the current machine’s IP address, you may want
     to use ‘gethostbyname(gethostname())’.  This operation assumes that
     there is a valid address-to-host mapping for the host, and the
     assumption does not always hold.

     Note: *note gethostname(): 10ff. doesn’t always return the fully
     qualified domain name; use ‘getfqdn()’ (see above).

 -- Function: socket.gethostbyaddr (ip_address)

     Return a triple ‘(hostname, aliaslist, ipaddrlist)’ where
     _hostname_ is the primary host name responding to the given
     _ip_address_, _aliaslist_ is a (possibly empty) list of alternative
     host names for the same address, and _ipaddrlist_ is a list of
     IPv4/v6 addresses for the same interface on the same host (most
     likely containing only a single address).  To find the fully
     qualified domain name, use the function *note getfqdn(): 172e.
     *note gethostbyaddr(): 1722. supports both IPv4 and IPv6.

 -- Function: socket.getnameinfo (sockaddr, flags)

     Translate a socket address _sockaddr_ into a 2-tuple ‘(host,
     port)’.  Depending on the settings of _flags_, the result can
     contain a fully-qualified domain name or numeric address
     representation in _host_.  Similarly, _port_ can contain a string
     port name or a numeric port number.

     New in version 2.2.

 -- Function: socket.getprotobyname (protocolname)

     Translate an Internet protocol name (for example, ‘'icmp'’) to a
     constant suitable for passing as the (optional) third argument to
     the *note socket(): 15a4. function.  This is usually only needed
     for sockets opened in "raw" mode (*note SOCK_RAW: 1726.); for the
     normal socket modes, the correct protocol is chosen automatically
     if the protocol is omitted or zero.

 -- Function: socket.getservbyname (servicename[, protocolname])

     Translate an Internet service name and protocol name to a port
     number for that service.  The optional protocol name, if given,
     should be ‘'tcp'’ or ‘'udp'’, otherwise any protocol will match.

 -- Function: socket.getservbyport (port[, protocolname])

     Translate an Internet port number and protocol name to a service
     name for that service.  The optional protocol name, if given,
     should be ‘'tcp'’ or ‘'udp'’, otherwise any protocol will match.

 -- Function: socket.socket ([family[, type[, proto]]])

     Create a new socket using the given address family, socket type and
     protocol number.  The address family should be *note AF_INET: 171c.
     (the default), *note AF_INET6: 171d. or *note AF_UNIX: 171b.  The
     socket type should be *note SOCK_STREAM: 1dc. (the default), *note
     SOCK_DGRAM: 1db. or perhaps one of the other ‘SOCK_’ constants.
     The protocol number is usually zero and may be omitted in that
     case.

 -- Function: socket.socketpair ([family[, type[, proto]]])

     Build a pair of connected socket objects using the given address
     family, socket type, and protocol number.  Address family, socket
     type, and protocol number are as for the *note socket(): 15a4.
     function above.  The default family is *note AF_UNIX: 171b. if
     defined on the platform; otherwise, the default is *note AF_INET:
     171c.  Availability: Unix.

     New in version 2.4.

 -- Function: socket.fromfd (fd, family, type[, proto])

     Duplicate the file descriptor _fd_ (an integer as returned by a
     file object’s ‘fileno()’ method) and build a socket object from the
     result.  Address family, socket type and protocol number are as for
     the *note socket(): 15a4. function above.  The file descriptor
     should refer to a socket, but this is not checked — subsequent
     operations on the object may fail if the file descriptor is
     invalid.  This function is rarely needed, but can be used to get or
     set socket options on a socket passed to a program as standard
     input or output (such as a server started by the Unix inet daemon).
     The socket is assumed to be in blocking mode.  Availability: Unix.

 -- Function: socket.ntohl (x)

     Convert 32-bit positive integers from network to host byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 4-byte swap
     operation.

 -- Function: socket.ntohs (x)

     Convert 16-bit positive integers from network to host byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 2-byte swap
     operation.

 -- Function: socket.htonl (x)

     Convert 32-bit positive integers from host to network byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 4-byte swap
     operation.

 -- Function: socket.htons (x)

     Convert 16-bit positive integers from host to network byte order.
     On machines where the host byte order is the same as network byte
     order, this is a no-op; otherwise, it performs a 2-byte swap
     operation.

 -- Function: socket.inet_aton (ip_string)

     Convert an IPv4 address from dotted-quad string format (for
     example, ’123.45.67.89’) to 32-bit packed binary format, as a
     string four characters in length.  This is useful when conversing
     with a program that uses the standard C library and needs objects
     of type ‘struct in_addr’, which is the C type for the 32-bit packed
     binary this function returns.

     *note inet_aton(): 1739. also accepts strings with less than three
     dots; see the Unix manual page ‘inet(3)’ for details.

     If the IPv4 address string passed to this function is invalid,
     *note socket.error: 381. will be raised.  Note that exactly what is
     valid depends on the underlying C implementation of ‘inet_aton()’.

     *note inet_aton(): 1739. does not support IPv6, and *note
     inet_pton(): 173a. should be used instead for IPv4/v6 dual stack
     support.

 -- Function: socket.inet_ntoa (packed_ip)

     Convert a 32-bit packed IPv4 address (a string four characters in
     length) to its standard dotted-quad string representation (for
     example, ’123.45.67.89’).  This is useful when conversing with a
     program that uses the standard C library and needs objects of type
     ‘struct in_addr’, which is the C type for the 32-bit packed binary
     data this function takes as an argument.

     If the string passed to this function is not exactly 4 bytes in
     length, *note socket.error: 381. will be raised.  *note
     inet_ntoa(): 173b. does not support IPv6, and *note inet_ntop():
     173c. should be used instead for IPv4/v6 dual stack support.

 -- Function: socket.inet_pton (address_family, ip_string)

     Convert an IP address from its family-specific string format to a
     packed, binary format.  *note inet_pton(): 173a. is useful when a
     library or network protocol calls for an object of type ‘struct
     in_addr’ (similar to *note inet_aton(): 1739.) or ‘struct
     in6_addr’.

     Supported values for _address_family_ are currently *note AF_INET:
     171c. and *note AF_INET6: 171d.  If the IP address string
     _ip_string_ is invalid, *note socket.error: 381. will be raised.
     Note that exactly what is valid depends on both the value of
     _address_family_ and the underlying implementation of
     ‘inet_pton()’.

     Availability: Unix (maybe not all platforms).

     New in version 2.3.

 -- Function: socket.inet_ntop (address_family, packed_ip)

     Convert a packed IP address (a string of some number of characters)
     to its standard, family-specific string representation (for
     example, ‘'7.10.0.5'’ or ‘'5aef:2b::8'’) *note inet_ntop(): 173c.
     is useful when a library or network protocol returns an object of
     type ‘struct in_addr’ (similar to *note inet_ntoa(): 173b.) or
     ‘struct in6_addr’.

     Supported values for _address_family_ are currently *note AF_INET:
     171c. and *note AF_INET6: 171d.  If the string _packed_ip_ is not
     the correct length for the specified address family, *note
     ValueError: 236. will be raised.  A *note socket.error: 381. is
     raised for errors from the call to *note inet_ntop(): 173c.

     Availability: Unix (maybe not all platforms).

     New in version 2.3.

 -- Function: socket.getdefaulttimeout ()

     Return the default timeout in seconds (float) for new socket
     objects.  A value of ‘None’ indicates that new socket objects have
     no timeout.  When the socket module is first imported, the default
     is ‘None’.

     New in version 2.3.

 -- Function: socket.setdefaulttimeout (timeout)

     Set the default timeout in seconds (float) for new socket objects.
     A value of ‘None’ indicates that new socket objects have no
     timeout.  When the socket module is first imported, the default is
     ‘None’.

     New in version 2.3.

 -- Data: socket.SocketType

     This is a Python type object that represents the socket object
     type.  It is the same as ‘type(socket(...))’.

See also
........

Module *note SocketServer: 15d.

     Classes that simplify writing network servers.

Module *note ssl: 160.

     A TLS/SSL wrapper for socket objects.

* Menu:

* Socket Objects:: 
* Example: Example<8>. 

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc3493.html


File: python.info,  Node: Socket Objects,  Next: Example<8>,  Up: socket --- Low-level networking interface

5.17.2.1 Socket Objects
.......................

Socket objects have the following methods.  Except for ‘makefile()’
these correspond to Unix system calls applicable to sockets.

 -- Method: socket.accept ()

     Accept a connection.  The socket must be bound to an address and
     listening for connections.  The return value is a pair ‘(conn,
     address)’ where _conn_ is a _new_ socket object usable to send and
     receive data on the connection, and _address_ is the address bound
     to the socket on the other end of the connection.

 -- Method: socket.bind (address)

     Bind the socket to _address_.  The socket must not already be
     bound.  (The format of _address_ depends on the address family —
     see above.)

          Note: This method has historically accepted a pair of
          parameters for *note AF_INET: 171c. addresses instead of only
          a tuple.  This was never intentional and is no longer
          available in Python 2.0 and later.

 -- Method: socket.close ()

     Close the socket.  All future operations on the socket object will
     fail.  The remote end will receive no more data (after queued data
     is flushed).  Sockets are automatically closed when they are
     garbage-collected.

          Note: *note close(): 1743. releases the resource associated
          with a connection but does not necessarily close the
          connection immediately.  If you want to close the connection
          in a timely fashion, call *note shutdown(): 1744. before *note
          close(): 1743.

 -- Method: socket.connect (address)

     Connect to a remote socket at _address_.  (The format of _address_
     depends on the address family — see above.)

          Note: This method has historically accepted a pair of
          parameters for *note AF_INET: 171c. addresses instead of only
          a tuple.  This was never intentional and is no longer
          available in Python 2.0 and later.

 -- Method: socket.connect_ex (address)

     Like ‘connect(address)’, but return an error indicator instead of
     raising an exception for errors returned by the C-level ‘connect()’
     call (other problems, such as "host not found," can still raise
     exceptions).  The error indicator is ‘0’ if the operation
     succeeded, otherwise the value of the ‘errno’ variable.  This is
     useful to support, for example, asynchronous connects.

          Note: This method has historically accepted a pair of
          parameters for *note AF_INET: 171c. addresses instead of only
          a tuple.  This was never intentional and is no longer
          available in Python 2.0 and later.

 -- Method: socket.fileno ()

     Return the socket’s file descriptor (a small integer).  This is
     useful with *note select.select(): 15a3.

     Under Windows the small integer returned by this method cannot be
     used where a file descriptor can be used (such as *note
     os.fdopen(): 701.).  Unix does not have this limitation.

 -- Method: socket.getpeername ()

     Return the remote address to which the socket is connected.  This
     is useful to find out the port number of a remote IPv4/v6 socket,
     for instance.  (The format of the address returned depends on the
     address family — see above.)  On some systems this function is not
     supported.

 -- Method: socket.getsockname ()

     Return the socket’s own address.  This is useful to find out the
     port number of an IPv4/v6 socket, for instance.  (The format of the
     address returned depends on the address family — see above.)

 -- Method: socket.getsockopt (level, optname[, buflen])

     Return the value of the given socket option (see the Unix man page
     ‘getsockopt(2)’).  The needed symbolic constants (‘SO_*’ etc.)  are
     defined in this module.  If _buflen_ is absent, an integer option
     is assumed and its integer value is returned by the function.  If
     _buflen_ is present, it specifies the maximum length of the buffer
     used to receive the option in, and this buffer is returned as a
     string.  It is up to the caller to decode the contents of the
     buffer (see the optional built-in module *note struct: 166. for a
     way to decode C structures encoded as strings).

 -- Method: socket.ioctl (control, option)

          Platform : Windows

     The *note ioctl(): 172a. method is a limited interface to the
     WSAIoctl system interface.  Please refer to the Win32
     documentation(1) for more information.

     On other platforms, the generic *note fcntl.fcntl(): 174a. and
     *note fcntl.ioctl(): 421. functions may be used; they accept a
     socket object as their first argument.

     New in version 2.6.

 -- Method: socket.listen (backlog)

     Listen for connections made to the socket.  The _backlog_ argument
     specifies the maximum number of queued connections and should be at
     least 0; the maximum value is system-dependent (usually 5), the
     minimum value is forced to 0.

 -- Method: socket.makefile ([mode[, bufsize]])

     Return a _file object_ associated with the socket.  (File objects
     are described in *note File Objects: 643.)  The file object
     references a ‘dup()’ped version of the socket file descriptor, so
     the file object and socket object may be closed or
     garbage-collected independently.  The socket must be in blocking
     mode (it can not have a timeout).  The optional _mode_ and
     _bufsize_ arguments are interpreted the same way as by the built-in
     *note file(): 1f9. function.

          Note: On Windows, the file-like object created by *note
          makefile(): 174b. cannot be used where a file object with a
          file descriptor is expected, such as the stream arguments of
          *note subprocess.Popen(): 16e2.

 -- Method: socket.recv (bufsize[, flags])

     Receive data from the socket.  The return value is a string
     representing the data received.  The maximum amount of data to be
     received at once is specified by _bufsize_.  See the Unix manual
     page ‘recv(2)’ for the meaning of the optional argument _flags_; it
     defaults to zero.

          Note: For best match with hardware and network realities, the
          value of _bufsize_ should be a relatively small power of 2,
          for example, 4096.

 -- Method: socket.recvfrom (bufsize[, flags])

     Receive data from the socket.  The return value is a pair ‘(string,
     address)’ where _string_ is a string representing the data received
     and _address_ is the address of the socket sending the data.  See
     the Unix manual page ‘recv(2)’ for the meaning of the optional
     argument _flags_; it defaults to zero.  (The format of _address_
     depends on the address family — see above.)

 -- Method: socket.recvfrom_into (buffer[, nbytes[, flags]])

     Receive data from the socket, writing it into _buffer_ instead of
     creating a new string.  The return value is a pair ‘(nbytes,
     address)’ where _nbytes_ is the number of bytes received and
     _address_ is the address of the socket sending the data.  See the
     Unix manual page ‘recv(2)’ for the meaning of the optional argument
     _flags_; it defaults to zero.  (The format of _address_ depends on
     the address family — see above.)

     New in version 2.5.

 -- Method: socket.recv_into (buffer[, nbytes[, flags]])

     Receive up to _nbytes_ bytes from the socket, storing the data into
     a buffer rather than creating a new string.  If _nbytes_ is not
     specified (or 0), receive up to the size available in the given
     buffer.  Returns the number of bytes received.  See the Unix manual
     page ‘recv(2)’ for the meaning of the optional argument _flags_; it
     defaults to zero.

     New in version 2.5.

 -- Method: socket.send (string[, flags])

     Send data to the socket.  The socket must be connected to a remote
     socket.  The optional _flags_ argument has the same meaning as for
     *note recv(): 174c. above.  Returns the number of bytes sent.
     Applications are responsible for checking that all data has been
     sent; if only some of the data was transmitted, the application
     needs to attempt delivery of the remaining data.  For further
     information on this concept, consult the *note Socket Programming
     HOWTO: 174f.

 -- Method: socket.sendall (string[, flags])

     Send data to the socket.  The socket must be connected to a remote
     socket.  The optional _flags_ argument has the same meaning as for
     *note recv(): 174c. above.  Unlike *note send(): 174e, this method
     continues to send data from _string_ until either all data has been
     sent or an error occurs.  ‘None’ is returned on success.  On error,
     an exception is raised, and there is no way to determine how much
     data, if any, was successfully sent.

 -- Method: socket.sendto (string, address)

 -- Method: socket.sendto (string, flags, address)

     Send data to the socket.  The socket should not be connected to a
     remote socket, since the destination socket is specified by
     _address_.  The optional _flags_ argument has the same meaning as
     for *note recv(): 174c. above.  Return the number of bytes sent.
     (The format of _address_ depends on the address family — see
     above.)

 -- Method: socket.setblocking (flag)

     Set blocking or non-blocking mode of the socket: if _flag_ is 0,
     the socket is set to non-blocking, else to blocking mode.
     Initially all sockets are in blocking mode.  In non-blocking mode,
     if a *note recv(): 174c. call doesn’t find any data, or if a *note
     send(): 174e. call can’t immediately dispose of the data, a *note
     error: 381. exception is raised; in blocking mode, the calls block
     until they can proceed.  ‘s.setblocking(0)’ is equivalent to
     ‘s.settimeout(0.0)’; ‘s.setblocking(1)’ is equivalent to
     ‘s.settimeout(None)’.

 -- Method: socket.settimeout (value)

     Set a timeout on blocking socket operations.  The _value_ argument
     can be a nonnegative float expressing seconds, or ‘None’.  If a
     float is given, subsequent socket operations will raise a *note
     timeout: 463. exception if the timeout period _value_ has elapsed
     before the operation has completed.  Setting a timeout of ‘None’
     disables timeouts on socket operations.  ‘s.settimeout(0.0)’ is
     equivalent to ‘s.setblocking(0)’; ‘s.settimeout(None)’ is
     equivalent to ‘s.setblocking(1)’.

     New in version 2.3.

 -- Method: socket.gettimeout ()

     Return the timeout in seconds (float) associated with socket
     operations, or ‘None’ if no timeout is set.  This reflects the last
     call to *note setblocking(): 171e. or *note settimeout(): 171f.

     New in version 2.3.

  Some notes on socket blocking and timeouts: A socket object can be in
one of three modes: blocking, non-blocking, or timeout.  Sockets are
always created in blocking mode.  In blocking mode, operations block
until complete or the system returns an error (such as connection timed
out).  In non-blocking mode, operations fail (with an error that is
unfortunately system-dependent) if they cannot be completed immediately.
In timeout mode, operations fail if they cannot be completed within the
timeout specified for the socket or if the system returns an error.  The
*note setblocking(): 171e. method is simply a shorthand for certain
*note settimeout(): 171f. calls.

  Timeout mode internally sets the socket in non-blocking mode.  The
blocking and timeout modes are shared between file descriptors and
socket objects that refer to the same network endpoint.  A consequence
of this is that file objects returned by the *note makefile(): 174b.
method must only be used when the socket is in blocking mode; in timeout
or non-blocking mode file operations that cannot be completed
immediately will fail.

  Note that the *note connect(): 172c. operation is subject to the
timeout setting, and in general it is recommended to call *note
settimeout(): 171f. before calling *note connect(): 172c. or pass a
timeout parameter to *note create_connection(): 252.  The system network
stack may return a connection timeout error of its own regardless of any
Python socket timeout setting.

 -- Method: socket.setsockopt (level, optname, value)

     Set the value of the given socket option (see the Unix manual page
     ‘setsockopt(2)’).  The needed symbolic constants are defined in the
     *note socket: 15c. module (‘SO_*’ etc.).  The value can be an
     integer or a string representing a buffer.  In the latter case it
     is up to the caller to ensure that the string contains the proper
     bits (see the optional built-in module *note struct: 166. for a way
     to encode C structures as strings).

 -- Method: socket.shutdown (how)

     Shut down one or both halves of the connection.  If _how_ is
     ‘SHUT_RD’, further receives are disallowed.  If _how_ is ‘SHUT_WR’,
     further sends are disallowed.  If _how_ is ‘SHUT_RDWR’, further
     sends and receives are disallowed.  Depending on the platform,
     shutting down one half of the connection can also close the
     opposite half (e.g.  on Mac OS X, ‘shutdown(SHUT_WR)’ does not
     allow further reads on the other end of the connection).

  Note that there are no methods ‘read()’ or ‘write()’; use *note
recv(): 174c. and *note send(): 174e. without _flags_ argument instead.

  Socket objects also have these (read-only) attributes that correspond
to the values given to the *note socket: 15c. constructor.

 -- Attribute: socket.family

     The socket family.

     New in version 2.5.

 -- Attribute: socket.type

     The socket type.

     New in version 2.5.

 -- Attribute: socket.proto

     The socket protocol.

     New in version 2.5.

   ---------- Footnotes ----------

   (1) http://msdn.microsoft.com/en-us/library/ms741621%28VS.85%29.aspx


File: python.info,  Node: Example<8>,  Prev: Socket Objects,  Up: socket --- Low-level networking interface

5.17.2.2 Example
................

Here are four minimal example programs using the TCP/IP protocol: a
server that echoes all data that it receives back (servicing only one
client), and a client using it.  Note that a server must perform the
sequence *note socket(): 15a4, *note bind(): 1742, *note listen(): 1698,
*note accept(): 1741. (possibly repeating the *note accept(): 1741. to
service more than one client), while a client only needs the sequence
*note socket(): 15a4, *note connect(): 172c.  Also note that the server
does not *note sendall(): 1750./*note recv(): 174c. on the socket it is
listening on but on the new socket returned by *note accept(): 1741.

  The first two examples support IPv4 only.

     # Echo server program
     import socket

     HOST = ''                 # Symbolic name meaning all available interfaces
     PORT = 50007              # Arbitrary non-privileged port
     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     s.bind((HOST, PORT))
     s.listen(1)
     conn, addr = s.accept()
     print 'Connected by', addr
     while 1:
         data = conn.recv(1024)
         if not data: break
         conn.sendall(data)
     conn.close()

     # Echo client program
     import socket

     HOST = 'daring.cwi.nl'    # The remote host
     PORT = 50007              # The same port as used by the server
     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     s.connect((HOST, PORT))
     s.sendall('Hello, world')
     data = s.recv(1024)
     s.close()
     print 'Received', repr(data)

  The next two examples are identical to the above two, but support both
IPv4 and IPv6.  The server side will listen to the first address family
available (it should listen to both instead).  On most of IPv6-ready
systems, IPv6 will take precedence and the server may not accept IPv4
traffic.  The client side will try to connect to the all addresses
returned as a result of the name resolution, and sends traffic to the
first one connected successfully.

     # Echo server program
     import socket
     import sys

     HOST = None               # Symbolic name meaning all available interfaces
     PORT = 50007              # Arbitrary non-privileged port
     s = None
     for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC,
                                   socket.SOCK_STREAM, 0, socket.AI_PASSIVE):
         af, socktype, proto, canonname, sa = res
         try:
             s = socket.socket(af, socktype, proto)
         except socket.error as msg:
             s = None
             continue
         try:
             s.bind(sa)
             s.listen(1)
         except socket.error as msg:
             s.close()
             s = None
             continue
         break
     if s is None:
         print 'could not open socket'
         sys.exit(1)
     conn, addr = s.accept()
     print 'Connected by', addr
     while 1:
         data = conn.recv(1024)
         if not data: break
         conn.send(data)
     conn.close()

     # Echo client program
     import socket
     import sys

     HOST = 'daring.cwi.nl'    # The remote host
     PORT = 50007              # The same port as used by the server
     s = None
     for res in socket.getaddrinfo(HOST, PORT, socket.AF_UNSPEC, socket.SOCK_STREAM):
         af, socktype, proto, canonname, sa = res
         try:
             s = socket.socket(af, socktype, proto)
         except socket.error as msg:
             s = None
             continue
         try:
             s.connect(sa)
         except socket.error as msg:
             s.close()
             s = None
             continue
         break
     if s is None:
         print 'could not open socket'
         sys.exit(1)
     s.sendall('Hello, world')
     data = s.recv(1024)
     s.close()
     print 'Received', repr(data)

  The last example shows how to write a very simple network sniffer with
raw sockets on Windows.  The example requires administrator privileges
to modify the interface:

     import socket

     # the public network interface
     HOST = socket.gethostbyname(socket.gethostname())

     # create a raw socket and bind it to the public interface
     s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_IP)
     s.bind((HOST, 0))

     # Include IP headers
     s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1)

     # receive all packages
     s.ioctl(socket.SIO_RCVALL, socket.RCVALL_ON)

     # receive a package
     print s.recvfrom(65565)

     # disabled promiscuous mode
     s.ioctl(socket.SIO_RCVALL, socket.RCVALL_OFF)

  Running an example several times with too small delay between
executions, could lead to this error:

     socket.error: [Errno 98] Address already in use

  This is because the previous execution has left the socket in a
‘TIME_WAIT’ state, and can’t be immediately reused.

  There is a *note socket: 15c. flag to set, in order to prevent this,
‘socket.SO_REUSEADDR’:

     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
     s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)
     s.bind((HOST, PORT))

  the ‘SO_REUSEADDR’ flag tells the kernel to reuse a local socket in
‘TIME_WAIT’ state, without waiting for its natural timeout to expire.


File: python.info,  Node: ssl --- TLS/SSL wrapper for socket objects,  Next: signal --- Set handlers for asynchronous events,  Prev: socket --- Low-level networking interface,  Up: Interprocess Communication and Networking

5.17.3 ‘ssl’ — TLS/SSL wrapper for socket objects
-------------------------------------------------

New in version 2.6.

  *Source code:* Lib/ssl.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module provides access to Transport Layer Security (often known
as "Secure Sockets Layer") encryption and peer authentication facilities
for network sockets, both client-side and server-side.  This module uses
the OpenSSL library.  It is available on all modern Unix systems,
Windows, Mac OS X, and probably additional platforms, as long as OpenSSL
is installed on that platform.

     Note: Some behavior may be platform dependent, since calls are made
     to the operating system socket APIs.  The installed version of
     OpenSSL may also cause variations in behavior.

     Warning: The ssl module won’t validate certificates by default.
     When used in client mode, this means you are vulnerable to
     man-in-the-middle attacks.

     Warning: OpenSSL’s internal random number generator does not
     properly handle fork.  Applications must change the PRNG state of
     the parent process if they use any SSL feature with *note
     os.fork(): 244.  Any successful call of *note RAND_add(): 175b,
     ‘RAND_bytes()’ or ‘RAND_pseudo_bytes()’ is sufficient.

  This section documents the objects and functions in the ‘ssl’ module;
for more general information about TLS, SSL, and certificates, the
reader is referred to the documents in the "See Also" section at the
bottom.

  This module provides a class, ‘ssl.SSLSocket’, which is derived from
the *note socket.socket: 15a4. type, and provides a socket-like wrapper
that also encrypts and decrypts the data going over the socket with SSL.
It supports additional ‘read()’ and ‘write()’ methods, along with a
method, ‘getpeercert()’, to retrieve the certificate of the other side
of the connection, and a method, ‘cipher()’, to retrieve the cipher
being used for the secure connection.

* Menu:

* Functions, Constants, and Exceptions: Functions Constants and Exceptions. 
* SSLSocket Objects:: 
* Certificates:: 
* Examples: Examples<8>. 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/ssl.py


File: python.info,  Node: Functions Constants and Exceptions,  Next: SSLSocket Objects,  Up: ssl --- TLS/SSL wrapper for socket objects

5.17.3.1 Functions, Constants, and Exceptions
.............................................

 -- Exception: ssl.SSLError

     Raised to signal an error from the underlying SSL implementation.
     This signifies some problem in the higher-level encryption and
     authentication layer that’s superimposed on the underlying network
     connection.  This error is a subtype of *note socket.error: 381,
     which in turn is a subtype of *note IOError: 1fa.

 -- Function: ssl.wrap_socket (sock, keyfile=None, certfile=None,
          server_side=False, cert_reqs=CERT_NONE, ssl_version={see
          docs}, ca_certs=None, do_handshake_on_connect=True,
          suppress_ragged_eofs=True, ciphers=None)

     Takes an instance ‘sock’ of *note socket.socket: 15a4, and returns
     an instance of ‘ssl.SSLSocket’, a subtype of *note socket.socket:
     15a4, which wraps the underlying socket in an SSL context.  ‘sock’
     must be a *note SOCK_STREAM: 1dc. socket; other socket types are
     unsupported.

     For client-side sockets, the context construction is lazy; if the
     underlying socket isn’t connected yet, the context construction
     will be performed after ‘connect()’ is called on the socket.  For
     server-side sockets, if the socket has no remote peer, it is
     assumed to be a listening socket, and the server-side SSL wrapping
     is automatically performed on client connections accepted via the
     ‘accept()’ method.  *note wrap_socket(): 259. may raise *note
     SSLError: 175d.

     The ‘keyfile’ and ‘certfile’ parameters specify optional files
     which contain a certificate to be used to identify the local side
     of the connection.  See the discussion of *note Certificates: 175e.
     for more information on how the certificate is stored in the
     ‘certfile’.

     Often the private key is stored in the same file as the
     certificate; in this case, only the ‘certfile’ parameter need be
     passed.  If the private key is stored in a separate file, both
     parameters must be used.  If the private key is stored in the
     ‘certfile’, it should come before the first certificate in the
     certificate chain:

          -----BEGIN RSA PRIVATE KEY-----
          ... (private key in base64 encoding) ...
          -----END RSA PRIVATE KEY-----
          -----BEGIN CERTIFICATE-----
          ... (certificate in base64 PEM encoding) ...
          -----END CERTIFICATE-----

     The parameter ‘server_side’ is a boolean which identifies whether
     server-side or client-side behavior is desired from this socket.

     The parameter ‘cert_reqs’ specifies whether a certificate is
     required from the other side of the connection, and whether it will
     be validated if provided.  It must be one of the three values *note
     CERT_NONE: 175f. (certificates ignored), *note CERT_OPTIONAL: 1760.
     (not required, but validated if provided), or *note CERT_REQUIRED:
     1761. (required and validated).  If the value of this parameter is
     not *note CERT_NONE: 175f, then the ‘ca_certs’ parameter must point
     to a file of CA certificates.

     The ‘ca_certs’ file contains a set of concatenated "certification
     authority" certificates, which are used to validate certificates
     passed from the other end of the connection.  See the discussion of
     *note Certificates: 175e. for more information about how to arrange
     the certificates in this file.

     The parameter ‘ssl_version’ specifies which version of the SSL
     protocol to use.  Typically, the server chooses a particular
     protocol version, and the client must adapt to the server’s choice.
     Most of the versions are not interoperable with the other versions.
     If not specified, the default is *note PROTOCOL_SSLv23: 1762.; it
     provides the most compatibility with other versions.

     Here’s a table showing which versions in a client (down the side)
     can connect to which versions in a server (along the top):

          _client_ / *server*          *SSLv2*       *SSLv3*       *SSLv23*       *TLSv1*
                                                                                  
                                                                                  
          _SSLv2_                      yes           no            yes            no
                                                                                  
                                                                                  
          _SSLv3_                      no            yes           yes            no
                                                                                  
                                                                                  
          _SSLv23_                     yes           no            yes            no
                                                                                  
                                                                                  
          _TLSv1_                      no            no            yes            yes
                                                                                  

          Note: Which connections succeed will vary depending on the
          version of OpenSSL. For instance, in some older versions of
          OpenSSL (such as 0.9.7l on OS X 10.4), an SSLv2 client could
          not connect to an SSLv23 server.  Another example: beginning
          with OpenSSL 1.0.0, an SSLv23 client will not actually attempt
          SSLv2 connections unless you explicitly enable SSLv2 ciphers;
          for example, you might specify ‘"ALL"’ or ‘"SSLv2"’ as the
          _ciphers_ parameter to enable them.

     The _ciphers_ parameter sets the available ciphers for this SSL
     object.  It should be a string in the OpenSSL cipher list
     format(1).

     The parameter ‘do_handshake_on_connect’ specifies whether to do the
     SSL handshake automatically after doing a ‘socket.connect()’, or
     whether the application program will call it explicitly, by
     invoking the *note SSLSocket.do_handshake(): 1763. method.  Calling
     *note SSLSocket.do_handshake(): 1763. explicitly gives the program
     control over the blocking behavior of the socket I/O involved in
     the handshake.

     The parameter ‘suppress_ragged_eofs’ specifies how the
     ‘SSLSocket.read()’ method should signal unexpected EOF from the
     other end of the connection.  If specified as *note True: 3b0. (the
     default), it returns a normal EOF in response to unexpected EOF
     errors raised from the underlying socket; if *note False: 3b1, it
     will raise the exceptions back to the caller.

     Changed in version 2.7: New optional argument _ciphers_.

 -- Function: ssl.RAND_status ()

     Returns ‘True’ if the SSL pseudo-random number generator has been
     seeded with ’enough’ randomness, and False otherwise.  You can use
     *note ssl.RAND_egd(): 1765. and *note ssl.RAND_add(): 175b. to
     increase the randomness of the pseudo-random number generator.

 -- Function: ssl.RAND_egd (path)

     If you are running an entropy-gathering daemon (EGD) somewhere, and
     ‘path’ is the pathname of a socket connection open to it, this will
     read 256 bytes of randomness from the socket, and add it to the SSL
     pseudo-random number generator to increase the security of
     generated secret keys.  This is typically only necessary on systems
     without better sources of randomness.

     See ‘http://egd.sourceforge.net/’ or
     ‘http://prngd.sourceforge.net/’ for sources of entropy-gathering
     daemons.

 -- Function: ssl.RAND_add (bytes, entropy)

     Mixes the given ‘bytes’ into the SSL pseudo-random number
     generator.  The parameter ‘entropy’ (a float) is a lower bound on
     the entropy contained in string (so you can always use ‘0.0’).  See
     RFC 1750(2) for more information on sources of entropy.

 -- Function: ssl.cert_time_to_seconds (timestring)

     Returns a floating-point value containing a normal
     seconds-after-the-epoch time value, given the time-string
     representing the "notBefore" or "notAfter" date from a certificate.

     Here’s an example:

          >>> import ssl
          >>> ssl.cert_time_to_seconds("May  9 00:00:00 2007 GMT")
          1178694000.0
          >>> import time
          >>> time.ctime(ssl.cert_time_to_seconds("May  9 00:00:00 2007 GMT"))
          'Wed May  9 00:00:00 2007'
          >>>

 -- Function: ssl.get_server_certificate (addr,
          ssl_version=PROTOCOL_SSLv3, ca_certs=None)

     Given the address ‘addr’ of an SSL-protected server, as a
     (_hostname_, _port-number_) pair, fetches the server’s certificate,
     and returns it as a PEM-encoded string.  If ‘ssl_version’ is
     specified, uses that version of the SSL protocol to attempt to
     connect to the server.  If ‘ca_certs’ is specified, it should be a
     file containing a list of root certificates, the same format as
     used for the same parameter in *note wrap_socket(): 259.  The call
     will attempt to validate the server certificate against that set of
     root certificates, and will fail if the validation attempt fails.

 -- Function: ssl.DER_cert_to_PEM_cert (DER_cert_bytes)

     Given a certificate as a DER-encoded blob of bytes, returns a
     PEM-encoded string version of the same certificate.

 -- Function: ssl.PEM_cert_to_DER_cert (PEM_cert_string)

     Given a certificate as an ASCII PEM string, returns a DER-encoded
     sequence of bytes for that same certificate.

 -- Data: ssl.CERT_NONE

     Value to pass to the ‘cert_reqs’ parameter to ‘sslobject()’ when no
     certificates will be required or validated from the other side of
     the socket connection.

 -- Data: ssl.CERT_OPTIONAL

     Value to pass to the ‘cert_reqs’ parameter to ‘sslobject()’ when no
     certificates will be required from the other side of the socket
     connection, but if they are provided, will be validated.  Note that
     use of this setting requires a valid certificate validation file
     also be passed as a value of the ‘ca_certs’ parameter.

 -- Data: ssl.CERT_REQUIRED

     Value to pass to the ‘cert_reqs’ parameter to ‘sslobject()’ when
     certificates will be required from the other side of the socket
     connection.  Note that use of this setting requires a valid
     certificate validation file also be passed as a value of the
     ‘ca_certs’ parameter.

 -- Data: ssl.PROTOCOL_SSLv2

     Selects SSL version 2 as the channel encryption protocol.

     This protocol is not available if OpenSSL is compiled with
     OPENSSL_NO_SSL2 flag.

          Warning: SSL version 2 is insecure.  Its use is highly
          discouraged.

 -- Data: ssl.PROTOCOL_SSLv23

     Selects SSL version 2 or 3 as the channel encryption protocol.
     This is a setting to use with servers for maximum compatibility
     with the other end of an SSL connection, but it may cause the
     specific ciphers chosen for the encryption to be of fairly low
     quality.

 -- Data: ssl.PROTOCOL_SSLv3

     Selects SSL version 3 as the channel encryption protocol.  For
     clients, this is the maximally compatible SSL variant.

 -- Data: ssl.PROTOCOL_TLSv1

     Selects TLS version 1 as the channel encryption protocol.  This is
     the most modern version, and probably the best choice for maximum
     protection, if both sides can speak it.

 -- Data: ssl.OPENSSL_VERSION

     The version string of the OpenSSL library loaded by the
     interpreter:

          >>> ssl.OPENSSL_VERSION
          'OpenSSL 0.9.8k 25 Mar 2009'

     New in version 2.7.

 -- Data: ssl.OPENSSL_VERSION_INFO

     A tuple of five integers representing version information about the
     OpenSSL library:

          >>> ssl.OPENSSL_VERSION_INFO
          (0, 9, 8, 11, 15)

     New in version 2.7.

 -- Data: ssl.OPENSSL_VERSION_NUMBER

     The raw version number of the OpenSSL library, as a single integer:

          >>> ssl.OPENSSL_VERSION_NUMBER
          9470143L
          >>> hex(ssl.OPENSSL_VERSION_NUMBER)
          '0x9080bfL'

     New in version 2.7.

   ---------- Footnotes ----------

   (1) http://www.openssl.org/docs/apps/ciphers.html#CIPHER_LIST_FORMAT

   (2) http://tools.ietf.org/html/rfc1750.html


File: python.info,  Node: SSLSocket Objects,  Next: Certificates,  Prev: Functions Constants and Exceptions,  Up: ssl --- TLS/SSL wrapper for socket objects

5.17.3.2 SSLSocket Objects
..........................

SSL sockets provide the following methods of *note Socket Objects:
173f.:

   - *note accept(): 1741.

   - *note bind(): 1742.

   - *note close(): 1743.

   - *note connect(): 172c.

   - *note fileno(): 1746.

   - *note getpeername(): 1747, *note getsockname(): 1748.

   - *note getsockopt(): 1749, *note setsockopt(): 1753.

   - *note gettimeout(): 1752, *note settimeout(): 171f, *note
     setblocking(): 171e.

   - *note listen(): 1698.

   - *note makefile(): 174b.

   - *note recv(): 174c, *note recv_into(): 253. (but passing a non-zero
     ‘flags’ argument is not allowed)

   - *note send(): 174e, *note sendall(): 1750. (with the same
     limitation)

   - *note shutdown(): 1744.

  However, since the SSL (and TLS) protocol has its own framing atop of
TCP, the SSL sockets abstraction can, in certain respects, diverge from
the specification of normal, OS-level sockets.

  SSL sockets also have the following additional methods and attributes:

 -- Method: SSLSocket.getpeercert (binary_form=False)

     If there is no certificate for the peer on the other end of the
     connection, returns ‘None’.

     If the ‘binary_form’ parameter is *note False: 3b1, and a
     certificate was received from the peer, this method returns a *note
     dict: 305. instance.  If the certificate was not validated, the
     dict is empty.  If the certificate was validated, it returns a dict
     with the keys ‘subject’ (the principal for which the certificate
     was issued), and ‘notAfter’ (the time after which the certificate
     should not be trusted).  The certificate was already validated, so
     the ‘notBefore’ and ‘issuer’ fields are not returned.  If a
     certificate contains an instance of the _Subject Alternative Name_
     extension (see RFC 3280(1)), there will also be a ‘subjectAltName’
     key in the dictionary.

     The "subject" field is a tuple containing the sequence of relative
     distinguished names (RDNs) given in the certificate’s data
     structure for the principal, and each RDN is a sequence of
     name-value pairs:

          {'notAfter': 'Feb 16 16:54:50 2013 GMT',
           'subject': ((('countryName', u'US'),),
                       (('stateOrProvinceName', u'Delaware'),),
                       (('localityName', u'Wilmington'),),
                       (('organizationName', u'Python Software Foundation'),),
                       (('organizationalUnitName', u'SSL'),),
                       (('commonName', u'somemachine.python.org'),))}

     If the ‘binary_form’ parameter is *note True: 3b0, and a
     certificate was provided, this method returns the DER-encoded form
     of the entire certificate as a sequence of bytes, or *note None:
     39a. if the peer did not provide a certificate.  Whether the peer
     provides a certificate depends on the SSL socket’s role:

        * for a client SSL socket, the server will always provide a
          certificate, regardless of whether validation was required;

        * for a server SSL socket, the client will only provide a
          certificate when requested by the server; therefore *note
          getpeercert(): 176e. will return *note None: 39a. if you used
          *note CERT_NONE: 175f. (rather than *note CERT_OPTIONAL: 1760.
          or *note CERT_REQUIRED: 1761.).

 -- Method: SSLSocket.cipher ()

     Returns a three-value tuple containing the name of the cipher being
     used, the version of the SSL protocol that defines its use, and the
     number of secret bits being used.  If no connection has been
     established, returns ‘None’.

 -- Method: SSLSocket.do_handshake ()

     Perform a TLS/SSL handshake.  If this is used with a non-blocking
     socket, it may raise *note SSLError: 175d. with an ‘arg[0]’ of
     ‘SSL_ERROR_WANT_READ’ or ‘SSL_ERROR_WANT_WRITE’, in which case it
     must be called again until it completes successfully.  For example,
     to simulate the behavior of a blocking socket, one might write:

          while True:
              try:
                  s.do_handshake()
                  break
              except ssl.SSLError as err:
                  if err.args[0] == ssl.SSL_ERROR_WANT_READ:
                      select.select([s], [], [])
                  elif err.args[0] == ssl.SSL_ERROR_WANT_WRITE:
                      select.select([], [s], [])
                  else:
                      raise

 -- Method: SSLSocket.unwrap ()

     Performs the SSL shutdown handshake, which removes the TLS layer
     from the underlying socket, and returns the underlying socket
     object.  This can be used to go from encrypted operation over a
     connection to unencrypted.  The socket instance returned should
     always be used for further communication with the other side of the
     connection, rather than the original socket instance (which may not
     function properly after the unwrap).

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc3280.html


File: python.info,  Node: Certificates,  Next: Examples<8>,  Prev: SSLSocket Objects,  Up: ssl --- TLS/SSL wrapper for socket objects

5.17.3.3 Certificates
.....................

Certificates in general are part of a public-key / private-key system.
In this system, each _principal_, (which may be a machine, or a person,
or an organization) is assigned a unique two-part encryption key.  One
part of the key is public, and is called the _public key_; the other
part is kept secret, and is called the _private key_.  The two parts are
related, in that if you encrypt a message with one of the parts, you can
decrypt it with the other part, and *only* with the other part.

  A certificate contains information about two principals.  It contains
the name of a _subject_, and the subject’s public key.  It also contains
a statement by a second principal, the _issuer_, that the subject is who
he claims to be, and that this is indeed the subject’s public key.  The
issuer’s statement is signed with the issuer’s private key, which only
the issuer knows.  However, anyone can verify the issuer’s statement by
finding the issuer’s public key, decrypting the statement with it, and
comparing it to the other information in the certificate.  The
certificate also contains information about the time period over which
it is valid.  This is expressed as two fields, called "notBefore" and
"notAfter".

  In the Python use of certificates, a client or server can use a
certificate to prove who they are.  The other side of a network
connection can also be required to produce a certificate, and that
certificate can be validated to the satisfaction of the client or server
that requires such validation.  The connection attempt can be set to
raise an exception if the validation fails.  Validation is done
automatically, by the underlying OpenSSL framework; the application need
not concern itself with its mechanics.  But the application does usually
need to provide sets of certificates to allow this process to take
place.

  Python uses files to contain certificates.  They should be formatted
as "PEM" (see RFC 1422(1)), which is a base-64 encoded form wrapped with
a header line and a footer line:

     -----BEGIN CERTIFICATE-----
     ... (certificate in base64 PEM encoding) ...
     -----END CERTIFICATE-----

  The Python files which contain certificates can contain a sequence of
certificates, sometimes called a _certificate chain_.  This chain should
start with the specific certificate for the principal who "is" the
client or server, and then the certificate for the issuer of that
certificate, and then the certificate for the issuer of _that_
certificate, and so on up the chain till you get to a certificate which
is _self-signed_, that is, a certificate which has the same subject and
issuer, sometimes called a _root certificate_.  The certificates should
just be concatenated together in the certificate file.  For example,
suppose we had a three certificate chain, from our server certificate to
the certificate of the certification authority that signed our server
certificate, to the root certificate of the agency which issued the
certification authority’s certificate:

     -----BEGIN CERTIFICATE-----
     ... (certificate for your server)...
     -----END CERTIFICATE-----
     -----BEGIN CERTIFICATE-----
     ... (the certificate for the CA)...
     -----END CERTIFICATE-----
     -----BEGIN CERTIFICATE-----
     ... (the root certificate for the CA's issuer)...
     -----END CERTIFICATE-----

  If you are going to require validation of the other side of the
connection’s certificate, you need to provide a "CA certs" file, filled
with the certificate chains for each issuer you are willing to trust.
Again, this file just contains these chains concatenated together.  For
validation, Python will use the first chain it finds in the file which
matches.

  Some "standard" root certificates are available from various
certification authorities: Thawte(2), Verisign(3), Positive SSL(4) (used
by python.org), Equifax and GeoTrust(5).

  In general, if you are using SSL3 or TLS1, you don’t need to put the
full chain in your "CA certs" file; you only need the root certificates,
and the remote peer is supposed to furnish the other certificates
necessary to chain from its certificate to a root certificate.  See RFC
4158(6) for more discussion of the way in which certification chains can
be built.

  If you are going to create a server that provides SSL-encrypted
connection services, you will need to acquire a certificate for that
service.  There are many ways of acquiring appropriate certificates,
such as buying one from a certification authority.  Another common
practice is to generate a self-signed certificate.  The simplest way to
do this is with the OpenSSL package, using something like the following:

     % openssl req -new -x509 -days 365 -nodes -out cert.pem -keyout cert.pem
     Generating a 1024 bit RSA private key
     .......++++++
     .............................++++++
     writing new private key to 'cert.pem'
     -----
     You are about to be asked to enter information that will be incorporated
     into your certificate request.
     What you are about to enter is what is called a Distinguished Name or a DN.
     There are quite a few fields but you can leave some blank
     For some fields there will be a default value,
     If you enter '.', the field will be left blank.
     -----
     Country Name (2 letter code) [AU]:US
     State or Province Name (full name) [Some-State]:MyState
     Locality Name (eg, city) []:Some City
     Organization Name (eg, company) [Internet Widgits Pty Ltd]:My Organization, Inc.
     Organizational Unit Name (eg, section) []:My Group
     Common Name (eg, YOUR name) []:myserver.mygroup.myorganization.com
     Email Address []:ops@myserver.mygroup.myorganization.com
     %

  The disadvantage of a self-signed certificate is that it is its own
root certificate, and no one else will have it in their cache of known
(and trusted) root certificates.

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc1422.html

   (2) http://www.thawte.com/roots/

   (3) http://www.verisign.com/support/roots.html

   (4) 
http://www.PositiveSSL.com/ssl-certificate-support/cert_installation/UTN-USERFirst-Hardware.crt

   (5) http://www.geotrust.com/resources/root_certificates/index.asp

   (6) http://tools.ietf.org/html/rfc4158.html


File: python.info,  Node: Examples<8>,  Prev: Certificates,  Up: ssl --- TLS/SSL wrapper for socket objects

5.17.3.4 Examples
.................

* Menu:

* Testing for SSL support:: 
* Client-side operation:: 
* Server-side operation:: 


File: python.info,  Node: Testing for SSL support,  Next: Client-side operation,  Up: Examples<8>

5.17.3.5 Testing for SSL support
................................

To test for the presence of SSL support in a Python installation, user
code should use the following idiom:

     try:
         import ssl
     except ImportError:
         pass
     else:
         ... # do something that requires SSL support


File: python.info,  Node: Client-side operation,  Next: Server-side operation,  Prev: Testing for SSL support,  Up: Examples<8>

5.17.3.6 Client-side operation
..............................

This example connects to an SSL server, prints the server’s address and
certificate, sends some bytes, and reads part of the response:

     import socket, ssl, pprint

     s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)

     # require a certificate from the server
     ssl_sock = ssl.wrap_socket(s,
                                ca_certs="/etc/ca_certs_file",
                                cert_reqs=ssl.CERT_REQUIRED)

     ssl_sock.connect(('www.verisign.com', 443))

     print repr(ssl_sock.getpeername())
     print ssl_sock.cipher()
     print pprint.pformat(ssl_sock.getpeercert())

     # Set a simple HTTP request -- use httplib in actual code.
     ssl_sock.write("""GET / HTTP/1.0\r
     Host: www.verisign.com\r\n\r\n""")

     # Read a chunk of data.  Will not necessarily
     # read all the data returned by the server.
     data = ssl_sock.read()

     # note that closing the SSLSocket will also close the underlying socket
     ssl_sock.close()

  As of September 6, 2007, the certificate printed by this program
looked like this:

     {'notAfter': 'May  8 23:59:59 2009 GMT',
      'subject': ((('serialNumber', u'2497886'),),
                  (('1.3.6.1.4.1.311.60.2.1.3', u'US'),),
                  (('1.3.6.1.4.1.311.60.2.1.2', u'Delaware'),),
                  (('countryName', u'US'),),
                  (('postalCode', u'94043'),),
                  (('stateOrProvinceName', u'California'),),
                  (('localityName', u'Mountain View'),),
                  (('streetAddress', u'487 East Middlefield Road'),),
                  (('organizationName', u'VeriSign, Inc.'),),
                  (('organizationalUnitName',
                    u'Production Security Services'),),
                  (('organizationalUnitName',
                    u'Terms of use at www.verisign.com/rpa (c)06'),),
                  (('commonName', u'www.verisign.com'),))}

  which is a fairly poorly-formed ‘subject’ field.


File: python.info,  Node: Server-side operation,  Prev: Client-side operation,  Up: Examples<8>

5.17.3.7 Server-side operation
..............................

For server operation, typically you’d need to have a server certificate,
and private key, each in a file.  You’d open a socket, bind it to a
port, call ‘listen()’ on it, then start waiting for clients to connect:

     import socket, ssl

     bindsocket = socket.socket()
     bindsocket.bind(('myaddr.mydomain.com', 10023))
     bindsocket.listen(5)

  When one did, you’d call ‘accept()’ on the socket to get the new
socket from the other end, and use *note wrap_socket(): 259. to create a
server-side SSL context for it:

     while True:
         newsocket, fromaddr = bindsocket.accept()
         connstream = ssl.wrap_socket(newsocket,
                                      server_side=True,
                                      certfile="mycertfile",
                                      keyfile="mykeyfile",
                                      ssl_version=ssl.PROTOCOL_TLSv1)
         try:
             deal_with_client(connstream)
         finally:
             connstream.shutdown(socket.SHUT_RDWR)
             connstream.close()

  Then you’d read data from the ‘connstream’ and do something with it
till you are finished with the client (or the client is finished with
you):

     def deal_with_client(connstream):
         data = connstream.read()
         # null data means the client is finished with us
         while data:
             if not do_something(connstream, data):
                 # we'll assume do_something returns False
                 # when we're finished with client
                 break
             data = connstream.read()
         # finished with client

  And go back to listening for new client connections.

See also
........

Class *note socket.socket: 15a4.

     Documentation of underlying *note socket: 15c. class

SSL/TLS Strong Encryption: An Introduction(1)

     Intro from the Apache webserver documentation

RFC 1422: Privacy Enhancement for Internet Electronic Mail: Part II: Certificate-Based Key Management(2)

     Steve Kent

RFC 1750: Randomness Recommendations for Security(3)

     D. Eastlake et.  al.

RFC 3280: Internet X.509 Public Key Infrastructure Certificate and CRL Profile(4)

     Housley et.  al.

   ---------- Footnotes ----------

   (1) http://httpd.apache.org/docs/trunk/en/ssl/ssl_intro.html

   (2) http://www.ietf.org/rfc/rfc1422

   (3) http://www.ietf.org/rfc/rfc1750

   (4) http://www.ietf.org/rfc/rfc3280


File: python.info,  Node: signal --- Set handlers for asynchronous events,  Next: popen2 --- Subprocesses with accessible I/O streams,  Prev: ssl --- TLS/SSL wrapper for socket objects,  Up: Interprocess Communication and Networking

5.17.4 ‘signal’ — Set handlers for asynchronous events
------------------------------------------------------

This module provides mechanisms to use signal handlers in Python.  Some
general rules for working with signals and their handlers:

   * A handler for a particular signal, once set, remains installed
     until it is explicitly reset (Python emulates the BSD style
     interface regardless of the underlying implementation), with the
     exception of the handler for ‘SIGCHLD’, which follows the
     underlying implementation.

   * There is no way to "block" signals temporarily from critical
     sections (since this is not supported by all Unix flavors).

   * Although Python signal handlers are called asynchronously as far as
     the Python user is concerned, they can only occur between the
     "atomic" instructions of the Python interpreter.  This means that
     signals arriving during long calculations implemented purely in C
     (such as regular expression matches on large bodies of text) may be
     delayed for an arbitrary amount of time.

   * When a signal arrives during an I/O operation, it is possible that
     the I/O operation raises an exception after the signal handler
     returns.  This is dependent on the underlying Unix system’s
     semantics regarding interrupted system calls.

   * Because the C signal handler always returns, it makes little sense
     to catch synchronous errors like ‘SIGFPE’ or ‘SIGSEGV’.

   * Python installs a small number of signal handlers by default:
     ‘SIGPIPE’ is ignored (so write errors on pipes and sockets can be
     reported as ordinary Python exceptions) and ‘SIGINT’ is translated
     into a *note KeyboardInterrupt: 251. exception.  All of these can
     be overridden.

   * Some care must be taken if both signals and threads are used in the
     same program.  The fundamental thing to remember in using signals
     and threads simultaneously is: always perform *note signal(): 155.
     operations in the main thread of execution.  Any thread can perform
     an *note alarm(): 1778, *note getsignal(): 1779, *note pause():
     177a, *note setitimer(): 177b. or *note getitimer(): 177c.; only
     the main thread can set a new signal handler, and the main thread
     will be the only one to receive signals (this is enforced by the
     Python *note signal: 155. module, even if the underlying thread
     implementation supports sending signals to individual threads).
     This means that signals can’t be used as a means of inter-thread
     communication.  Use locks instead.

  The variables defined in the *note signal: 155. module are:

 -- Data: signal.SIG_DFL

     This is one of two standard signal handling options; it will simply
     perform the default function for the signal.  For example, on most
     systems the default action for ‘SIGQUIT’ is to dump core and exit,
     while the default action for ‘SIGCHLD’ is to simply ignore it.

 -- Data: signal.SIG_IGN

     This is another standard signal handler, which will simply ignore
     the given signal.

 -- Data: SIG*

     All the signal numbers are defined symbolically.  For example, the
     hangup signal is defined as ‘signal.SIGHUP’; the variable names are
     identical to the names used in C programs, as found in
     ‘<signal.h>’.  The Unix man page for ’‘signal()’’ lists the
     existing signals (on some systems this is ‘signal(2)’, on others
     the list is in ‘signal(7)’).  Note that not all systems define the
     same set of signal names; only those names defined by the system
     are defined by this module.

 -- Data: signal.CTRL_C_EVENT

     The signal corresponding to the CTRL+C keystroke event.  This
     signal can only be used with *note os.kill(): 2d1.

     Availability: Windows.

     New in version 2.7.

 -- Data: signal.CTRL_BREAK_EVENT

     The signal corresponding to the CTRL+BREAK keystroke event.  This
     signal can only be used with *note os.kill(): 2d1.

     Availability: Windows.

     New in version 2.7.

 -- Data: signal.NSIG

     One more than the number of the highest signal number.

 -- Data: signal.ITIMER_REAL

     Decrements interval timer in real time, and delivers ‘SIGALRM’ upon
     expiration.

 -- Data: signal.ITIMER_VIRTUAL

     Decrements interval timer only when the process is executing, and
     delivers SIGVTALRM upon expiration.

 -- Data: signal.ITIMER_PROF

     Decrements interval timer both when the process executes and when
     the system is executing on behalf of the process.  Coupled with
     ITIMER_VIRTUAL, this timer is usually used to profile the time
     spent by the application in user and kernel space.  SIGPROF is
     delivered upon expiration.

  The *note signal: 155. module defines one exception:

 -- Exception: signal.ItimerError

     Raised to signal an error from the underlying *note setitimer():
     177b. or *note getitimer(): 177c. implementation.  Expect this
     error if an invalid interval timer or a negative time is passed to
     *note setitimer(): 177b.  This error is a subtype of *note IOError:
     1fa.

  The *note signal: 155. module defines the following functions:

 -- Function: signal.alarm (time)

     If _time_ is non-zero, this function requests that a ‘SIGALRM’
     signal be sent to the process in _time_ seconds.  Any previously
     scheduled alarm is canceled (only one alarm can be scheduled at any
     time).  The returned value is then the number of seconds before any
     previously set alarm was to have been delivered.  If _time_ is
     zero, no alarm is scheduled, and any scheduled alarm is canceled.
     If the return value is zero, no alarm is currently scheduled.  (See
     the Unix man page ‘alarm(2)’.)  Availability: Unix.

 -- Function: signal.getsignal (signalnum)

     Return the current signal handler for the signal _signalnum_.  The
     returned value may be a callable Python object, or one of the
     special values *note signal.SIG_IGN: 177e, *note signal.SIG_DFL:
     177d. or *note None: 39a.  Here, *note signal.SIG_IGN: 177e. means
     that the signal was previously ignored, *note signal.SIG_DFL: 177d.
     means that the default way of handling the signal was previously in
     use, and ‘None’ means that the previous signal handler was not
     installed from Python.

 -- Function: signal.pause ()

     Cause the process to sleep until a signal is received; the
     appropriate handler will then be called.  Returns nothing.  Not on
     Windows.  (See the Unix man page ‘signal(2)’.)

 -- Function: signal.setitimer (which, seconds[, interval])

     Sets given interval timer (one of *note signal.ITIMER_REAL: 1780,
     *note signal.ITIMER_VIRTUAL: 1781. or *note signal.ITIMER_PROF:
     1782.) specified by _which_ to fire after _seconds_ (float is
     accepted, different from *note alarm(): 1778.) and after that every
     _interval_ seconds.  The interval timer specified by _which_ can be
     cleared by setting seconds to zero.

     When an interval timer fires, a signal is sent to the process.  The
     signal sent is dependent on the timer being used; *note
     signal.ITIMER_REAL: 1780. will deliver ‘SIGALRM’, *note
     signal.ITIMER_VIRTUAL: 1781. sends ‘SIGVTALRM’, and *note
     signal.ITIMER_PROF: 1782. will deliver ‘SIGPROF’.

     The old values are returned as a tuple: (delay, interval).

     Attempting to pass an invalid interval timer will cause an *note
     ItimerError: 1783.  Availability: Unix.

     New in version 2.6.

 -- Function: signal.getitimer (which)

     Returns current value of a given interval timer specified by
     _which_.  Availability: Unix.

     New in version 2.6.

 -- Function: signal.set_wakeup_fd (fd)

     Set the wakeup fd to _fd_.  When a signal is received, a ‘'\0'’
     byte is written to the fd.  This can be used by a library to wakeup
     a poll or select call, allowing the signal to be fully processed.

     The old wakeup fd is returned.  _fd_ must be non-blocking.  It is
     up to the library to remove any bytes before calling poll or select
     again.

     When threads are enabled, this function can only be called from the
     main thread; attempting to call it from other threads will cause a
     *note ValueError: 236. exception to be raised.

     New in version 2.6.

 -- Function: signal.siginterrupt (signalnum, flag)

     Change system call restart behaviour: if _flag_ is *note False:
     3b1, system calls will be restarted when interrupted by signal
     _signalnum_, otherwise system calls will be interrupted.  Returns
     nothing.  Availability: Unix (see the man page ‘siginterrupt(3)’
     for further information).

     Note that installing a signal handler with *note signal(): 155.
     will reset the restart behaviour to interruptible by implicitly
     calling ‘siginterrupt()’ with a true _flag_ value for the given
     signal.

     New in version 2.6.

 -- Function: signal.signal (signalnum, handler)

     Set the handler for signal _signalnum_ to the function _handler_.
     _handler_ can be a callable Python object taking two arguments (see
     below), or one of the special values *note signal.SIG_IGN: 177e. or
     *note signal.SIG_DFL: 177d.  The previous signal handler will be
     returned (see the description of *note getsignal(): 1779. above).
     (See the Unix man page ‘signal(2)’.)

     When threads are enabled, this function can only be called from the
     main thread; attempting to call it from other threads will cause a
     *note ValueError: 236. exception to be raised.

     The _handler_ is called with two arguments: the signal number and
     the current stack frame (‘None’ or a frame object; for a
     description of frame objects, see the *note description in the type
     hierarchy: 702. or see the attribute descriptions in the *note
     inspect: f8. module).

     On Windows, *note signal(): 155. can only be called with ‘SIGABRT’,
     ‘SIGFPE’, ‘SIGILL’, ‘SIGINT’, ‘SIGSEGV’, or ‘SIGTERM’.  A *note
     ValueError: 236. will be raised in any other case.

* Menu:

* Example: Example<9>. 


File: python.info,  Node: Example<9>,  Up: signal --- Set handlers for asynchronous events

5.17.4.1 Example
................

Here is a minimal example program.  It uses the *note alarm(): 1778.
function to limit the time spent waiting to open a file; this is useful
if the file is for a serial device that may not be turned on, which
would normally cause the *note os.open(): 5e4. to hang indefinitely.
The solution is to set a 5-second alarm before opening the file; if the
operation takes too long, the alarm signal will be sent, and the handler
raises an exception.

     import signal, os

     def handler(signum, frame):
         print 'Signal handler called with signal', signum
         raise IOError("Couldn't open device!")

     # Set the signal handler and a 5-second alarm
     signal.signal(signal.SIGALRM, handler)
     signal.alarm(5)

     # This open() may hang indefinitely
     fd = os.open('/dev/ttyS0', os.O_RDWR)

     signal.alarm(0)          # Disable the alarm


File: python.info,  Node: popen2 --- Subprocesses with accessible I/O streams,  Next: asyncore --- Asynchronous socket handler,  Prev: signal --- Set handlers for asynchronous events,  Up: Interprocess Communication and Networking

5.17.5 ‘popen2’ — Subprocesses with accessible I/O streams
----------------------------------------------------------

Deprecated since version 2.6: This module is obsolete.  Use the *note
subprocess: 167. module.  Check especially the *note Replacing Older
Functions with the subprocess Module: 1103. section.

  This module allows you to spawn processes and connect to their
input/output/error pipes and obtain their return codes under Unix and
Windows.

  The *note subprocess: 167. module provides more powerful facilities
for spawning new processes and retrieving their results.  Using the
*note subprocess: 167. module is preferable to using the *note popen2:
134. module.

  The primary interface offered by this module is a trio of factory
functions.  For each of these, if _bufsize_ is specified, it specifies
the buffer size for the I/O pipes.  _mode_, if provided, should be the
string ‘'b'’ or ‘'t'’; on Windows this is needed to determine whether
the file objects should be opened in binary or text mode.  The default
value for _mode_ is ‘'t'’.

  On Unix, _cmd_ may be a sequence, in which case arguments will be
passed directly to the program without shell intervention (as with *note
os.spawnv(): 1105.).  If _cmd_ is a string it will be passed to the
shell (as with *note os.system(): 3fa.).

  The only way to retrieve the return codes for the child processes is
by using the ‘poll()’ or ‘wait()’ methods on the *note Popen3: 1715. and
*note Popen4: 1716. classes; these are only available on Unix.  This
information is not available when using the *note popen2(): 134, *note
popen3(): 178a, and *note popen4(): 178b. functions, or the equivalent
functions in the *note os: 128. module.  (Note that the tuples returned
by the *note os: 128. module’s functions are in a different order from
the ones returned by the *note popen2: 134. module.)

 -- Function: popen2.popen2 (cmd[, bufsize[, mode]])

     Executes _cmd_ as a sub-process.  Returns the file objects
     ‘(child_stdout, child_stdin)’.

 -- Function: popen2.popen3 (cmd[, bufsize[, mode]])

     Executes _cmd_ as a sub-process.  Returns the file objects
     ‘(child_stdout, child_stdin, child_stderr)’.

 -- Function: popen2.popen4 (cmd[, bufsize[, mode]])

     Executes _cmd_ as a sub-process.  Returns the file objects
     ‘(child_stdout_and_stderr, child_stdin)’.

     New in version 2.0.

  On Unix, a class defining the objects returned by the factory
functions is also available.  These are not used for the Windows
implementation, and are not available on that platform.

 -- Class: popen2.Popen3 (cmd[, capturestderr[, bufsize]])

     This class represents a child process.  Normally, *note Popen3:
     1715. instances are created using the *note popen2(): 134. and
     *note popen3(): 178a. factory functions described above.

     If not using one of the helper functions to create *note Popen3:
     1715. objects, the parameter _cmd_ is the shell command to execute
     in a sub-process.  The _capturestderr_ flag, if true, specifies
     that the object should capture standard error output of the child
     process.  The default is false.  If the _bufsize_ parameter is
     specified, it specifies the size of the I/O buffers to/from the
     child process.

 -- Class: popen2.Popen4 (cmd[, bufsize])

     Similar to *note Popen3: 1715, but always captures standard error
     into the same file object as standard output.  These are typically
     created using *note popen4(): 178b.

     New in version 2.0.

* Menu:

* Popen3 and Popen4 Objects:: 
* Flow Control Issues:: 


File: python.info,  Node: Popen3 and Popen4 Objects,  Next: Flow Control Issues,  Up: popen2 --- Subprocesses with accessible I/O streams

5.17.5.1 Popen3 and Popen4 Objects
..................................

Instances of the *note Popen3: 1715. and *note Popen4: 1716. classes
have the following methods:

 -- Method: Popen3.poll ()

     Returns ‘-1’ if child process hasn’t completed yet, or its status
     code (see *note wait(): 1790.) otherwise.

 -- Method: Popen3.wait ()

     Waits for and returns the status code of the child process.  The
     status code encodes both the return code of the process and
     information about whether it exited using the ‘exit()’ system call
     or died due to a signal.  Functions to help interpret the status
     code are defined in the *note os: 128. module; see section *note
     Process Management: 115d. for the ‘W*()’ family of functions.

  The following attributes are also available:

 -- Attribute: Popen3.fromchild

     A file object that provides output from the child process.  For
     *note Popen4: 1716. instances, this will provide both the standard
     output and standard error streams.

 -- Attribute: Popen3.tochild

     A file object that provides input to the child process.

 -- Attribute: Popen3.childerr

     A file object that provides error output from the child process, if
     _capturestderr_ was true for the constructor, otherwise ‘None’.
     This will always be ‘None’ for *note Popen4: 1716. instances.

 -- Attribute: Popen3.pid

     The process ID of the child process.


File: python.info,  Node: Flow Control Issues,  Prev: Popen3 and Popen4 Objects,  Up: popen2 --- Subprocesses with accessible I/O streams

5.17.5.2 Flow Control Issues
............................

Any time you are working with any form of inter-process communication,
control flow needs to be carefully thought out.  This remains the case
with the file objects provided by this module (or the *note os: 128.
module equivalents).

  When reading output from a child process that writes a lot of data to
standard error while the parent is reading from the child’s standard
output, a deadlock can occur.  A similar situation can occur with other
combinations of reads and writes.  The essential factors are that more
than ‘_PC_PIPE_BUF’ bytes are being written by one process in a blocking
fashion, while the other process is reading from the first process, also
in a blocking fashion.

  There are several ways to deal with this situation.

  The simplest application change, in many cases, will be to follow this
model in the parent process:

     import popen2

     r, w, e = popen2.popen3('python slave.py')
     e.readlines()
     r.readlines()
     r.close()
     e.close()
     w.close()

  with code like this in the child:

     import os
     import sys

     # note that each of these print statements
     # writes a single long string

     print >>sys.stderr, 400 * 'this is a test\n'
     os.close(sys.stderr.fileno())
     print >>sys.stdout, 400 * 'this is another test\n'

  In particular, note that ‘sys.stderr’ must be closed after writing all
data, or ‘readlines()’ won’t return.  Also note that *note os.close():
110c. must be used, as ‘sys.stderr.close()’ won’t close ‘stderr’
(otherwise assigning to ‘sys.stderr’ will silently close it, so no
further errors can be printed).

  Applications which need to support a more general approach should
integrate I/O over pipes with their *note select(): 14e. loops, or use
separate threads to read each of the individual files provided by
whichever ‘popen*()’ function or ‘Popen*’ class was used.

See also
........

Module *note subprocess: 167.

     Module for spawning and managing subprocesses.


File: python.info,  Node: asyncore --- Asynchronous socket handler,  Next: asynchat --- Asynchronous socket command/response handler,  Prev: popen2 --- Subprocesses with accessible I/O streams,  Up: Interprocess Communication and Networking

5.17.6 ‘asyncore’ — Asynchronous socket handler
-----------------------------------------------

*Source code:* Lib/asyncore.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module provides the basic infrastructure for writing asynchronous
socket service clients and servers.

  There are only two ways to have a program on a single processor do
"more than one thing at a time."  Multi-threaded programming is the
simplest and most popular way to do it, but there is another very
different technique, that lets you have nearly all the advantages of
multi-threading, without actually using multiple threads.  It’s really
only practical if your program is largely I/O bound.  If your program is
processor bound, then pre-emptive scheduled threads are probably what
you really need.  Network servers are rarely processor bound, however.

  If your operating system supports the ‘select()’ system call in its
I/O library (and nearly all do), then you can use it to juggle multiple
communication channels at once; doing other work while your I/O is
taking place in the "background."  Although this strategy can seem
strange and complex, especially at first, it is in many ways easier to
understand and control than multi-threaded programming.  The *note
asyncore: 11. module solves many of the difficult problems for you,
making the task of building sophisticated high-performance network
servers and clients a snap.  For "conversational" applications and
protocols the companion *note asynchat: 10. module is invaluable.

  The basic idea behind both modules is to create one or more network
_channels_, instances of class *note asyncore.dispatcher: 1798. and
*note asynchat.async_chat: 1799.  Creating the channels adds them to a
global map, used by the *note loop(): 179a. function if you do not
provide it with your own _map_.

  Once the initial channel(s) is(are) created, calling the *note loop():
179a. function activates channel service, which continues until the last
channel (including any that have been added to the map during
asynchronous service) is closed.

 -- Function: asyncore.loop ([timeout[, use_poll[, map[, count]]]])

     Enter a polling loop that terminates after count passes or all open
     channels have been closed.  All arguments are optional.  The
     _count_ parameter defaults to None, resulting in the loop
     terminating only when all channels have been closed.  The _timeout_
     argument sets the timeout parameter for the appropriate *note
     select(): 15a3. or *note poll(): 159d. call, measured in seconds;
     the default is 30 seconds.  The _use_poll_ parameter, if true,
     indicates that *note poll(): 159d. should be used in preference to
     *note select(): 15a3. (the default is ‘False’).

     The _map_ parameter is a dictionary whose items are the channels to
     watch.  As channels are closed they are deleted from their map.  If
     _map_ is omitted, a global map is used.  Channels (instances of
     *note asyncore.dispatcher: 1798, *note asynchat.async_chat: 1799.
     and subclasses thereof) can freely be mixed in the map.

 -- Class: asyncore.dispatcher

     The *note dispatcher: 1798. class is a thin wrapper around a
     low-level socket object.  To make it more useful, it has a few
     methods for event-handling which are called from the asynchronous
     loop.  Otherwise, it can be treated as a normal non-blocking socket
     object.

     The firing of low-level events at certain times or in certain
     connection states tells the asynchronous loop that certain
     higher-level events have taken place.  For example, if we have
     asked for a socket to connect to another host, we know that the
     connection has been made when the socket becomes writable for the
     first time (at this point you know that you may write to it with
     the expectation of success).  The implied higher-level events are:

     Event                      Description
                                
     ------------------------------------------------------------------------
                                
     ‘handle_connect()’         Implied by the first read or write event
                                
                                
     ‘handle_close()’           Implied by a read event with no data
                                available
                                
                                
     ‘handle_accept()’          Implied by a read event on a listening
                                socket
                                

     During asynchronous processing, each mapped channel’s *note
     readable(): 179b. and *note writable(): 179c. methods are used to
     determine whether the channel’s socket should be added to the list
     of channels ‘select()’ed or ‘poll()’ed for read and write events.

     Thus, the set of channel events is larger than the basic socket
     events.  The full set of methods that can be overridden in your
     subclass follows:

      -- Method: handle_read ()

          Called when the asynchronous loop detects that a ‘read()’ call
          on the channel’s socket will succeed.

      -- Method: handle_write ()

          Called when the asynchronous loop detects that a writable
          socket can be written.  Often this method will implement the
          necessary buffering for performance.  For example:

               def handle_write(self):
                   sent = self.send(self.buffer)
                   self.buffer = self.buffer[sent:]

      -- Method: handle_expt ()

          Called when there is out of band (OOB) data for a socket
          connection.  This will almost never happen, as OOB is
          tenuously supported and rarely used.

      -- Method: handle_connect ()

          Called when the active opener’s socket actually makes a
          connection.  Might send a "welcome" banner, or initiate a
          protocol negotiation with the remote endpoint, for example.

      -- Method: handle_close ()

          Called when the socket is closed.

      -- Method: handle_error ()

          Called when an exception is raised and not otherwise handled.
          The default version prints a condensed traceback.

      -- Method: handle_accept ()

          Called on listening channels (passive openers) when a
          connection can be established with a new remote endpoint that
          has issued a *note connect(): 17a4. call for the local
          endpoint.

      -- Method: readable ()

          Called each time around the asynchronous loop to determine
          whether a channel’s socket should be added to the list on
          which read events can occur.  The default method simply
          returns ‘True’, indicating that by default, all channels will
          be interested in read events.

      -- Method: writable ()

          Called each time around the asynchronous loop to determine
          whether a channel’s socket should be added to the list on
          which write events can occur.  The default method simply
          returns ‘True’, indicating that by default, all channels will
          be interested in write events.

     In addition, each channel delegates or extends many of the socket
     methods.  Most of these are nearly identical to their socket
     partners.

      -- Method: create_socket (family, type)

          This is identical to the creation of a normal socket, and will
          use the same options for creation.  Refer to the *note socket:
          15c. documentation for information on creating sockets.

      -- Method: connect (address)

          As with the normal socket object, _address_ is a tuple with
          the first element the host to connect to, and the second the
          port number.

      -- Method: send (data)

          Send _data_ to the remote end-point of the socket.

      -- Method: recv (buffer_size)

          Read at most _buffer_size_ bytes from the socket’s remote
          end-point.  An empty string implies that the channel has been
          closed from the other end.

      -- Method: listen (backlog)

          Listen for connections made to the socket.  The _backlog_
          argument specifies the maximum number of queued connections
          and should be at least 1; the maximum value is
          system-dependent (usually 5).

      -- Method: bind (address)

          Bind the socket to _address_.  The socket must not already be
          bound.  (The format of _address_ depends on the address family
          — refer to the *note socket: 15c. documentation for more
          information.)  To mark the socket as re-usable (setting the
          ‘SO_REUSEADDR’ option), call the *note dispatcher: 1798.
          object’s ‘set_reuse_addr()’ method.

      -- Method: accept ()

          Accept a connection.  The socket must be bound to an address
          and listening for connections.  The return value can be either
          ‘None’ or a pair ‘(conn, address)’ where _conn_ is a _new_
          socket object usable to send and receive data on the
          connection, and _address_ is the address bound to the socket
          on the other end of the connection.  When ‘None’ is returned
          it means the connection didn’t take place, in which case the
          server should just ignore this event and keep listening for
          further incoming connections.

      -- Method: close ()

          Close the socket.  All future operations on the socket object
          will fail.  The remote end-point will receive no more data
          (after queued data is flushed).  Sockets are automatically
          closed when they are garbage-collected.

 -- Class: asyncore.dispatcher_with_send

     A *note dispatcher: 1798. subclass which adds simple buffered
     output capability, useful for simple clients.  For more
     sophisticated usage use *note asynchat.async_chat: 1799.

 -- Class: asyncore.file_dispatcher

     A file_dispatcher takes a file descriptor or file object along with
     an optional map argument and wraps it for use with the ‘poll()’ or
     ‘loop()’ functions.  If provided a file object or anything with a
     ‘fileno()’ method, that method will be called and passed to the
     *note file_wrapper: 17ae. constructor.  Availability: UNIX.

 -- Class: asyncore.file_wrapper

     A file_wrapper takes an integer file descriptor and calls *note
     os.dup(): 1110. to duplicate the handle so that the original handle
     may be closed independently of the file_wrapper.  This class
     implements sufficient methods to emulate a socket for use by the
     *note file_dispatcher: 17ad. class.  Availability: UNIX.

* Menu:

* asyncore Example basic HTTP client:: 
* asyncore Example basic echo server:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/asyncore.py


File: python.info,  Node: asyncore Example basic HTTP client,  Next: asyncore Example basic echo server,  Up: asyncore --- Asynchronous socket handler

5.17.6.1 asyncore Example basic HTTP client
...........................................

Here is a very basic HTTP client that uses the *note dispatcher: 1798.
class to implement its socket handling:

     import asyncore, socket

     class HTTPClient(asyncore.dispatcher):

         def __init__(self, host, path):
             asyncore.dispatcher.__init__(self)
             self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
             self.connect( (host, 80) )
             self.buffer = 'GET %s HTTP/1.0\r\n\r\n' % path

         def handle_connect(self):
             pass

         def handle_close(self):
             self.close()

         def handle_read(self):
             print self.recv(8192)

         def writable(self):
             return (len(self.buffer) > 0)

         def handle_write(self):
             sent = self.send(self.buffer)
             self.buffer = self.buffer[sent:]


     client = HTTPClient('www.python.org', '/')
     asyncore.loop()


File: python.info,  Node: asyncore Example basic echo server,  Prev: asyncore Example basic HTTP client,  Up: asyncore --- Asynchronous socket handler

5.17.6.2 asyncore Example basic echo server
...........................................

Here is a basic echo server that uses the *note dispatcher: 1798. class
to accept connections and dispatches the incoming connections to a
handler:

     import asyncore
     import socket

     class EchoHandler(asyncore.dispatcher_with_send):

         def handle_read(self):
             data = self.recv(8192)
             if data:
                 self.send(data)

     class EchoServer(asyncore.dispatcher):

         def __init__(self, host, port):
             asyncore.dispatcher.__init__(self)
             self.create_socket(socket.AF_INET, socket.SOCK_STREAM)
             self.set_reuse_addr()
             self.bind((host, port))
             self.listen(5)

         def handle_accept(self):
             pair = self.accept()
             if pair is not None:
                 sock, addr = pair
                 print 'Incoming connection from %s' % repr(addr)
                 handler = EchoHandler(sock)

     server = EchoServer('localhost', 8080)
     asyncore.loop()


File: python.info,  Node: asynchat --- Asynchronous socket command/response handler,  Prev: asyncore --- Asynchronous socket handler,  Up: Interprocess Communication and Networking

5.17.7 ‘asynchat’ — Asynchronous socket command/response handler
----------------------------------------------------------------

*Source code:* Lib/asynchat.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module builds on the *note asyncore: 11. infrastructure,
simplifying asynchronous clients and servers and making it easier to
handle protocols whose elements are terminated by arbitrary strings, or
are of variable length.  *note asynchat: 10. defines the abstract class
*note async_chat: 1799. that you subclass, providing implementations of
the ‘collect_incoming_data()’ and ‘found_terminator()’ methods.  It uses
the same asynchronous loop as *note asyncore: 11, and the two types of
channel, *note asyncore.dispatcher: 1798. and *note asynchat.async_chat:
1799, can freely be mixed in the channel map.  Typically an *note
asyncore.dispatcher: 1798. server channel generates new *note
asynchat.async_chat: 1799. channel objects as it receives incoming
connection requests.

 -- Class: asynchat.async_chat

     This class is an abstract subclass of *note asyncore.dispatcher:
     1798.  To make practical use of the code you must subclass *note
     async_chat: 1799, providing meaningful *note
     collect_incoming_data(): 17b5. and *note found_terminator(): 17b6.
     methods.  The *note asyncore.dispatcher: 1798. methods can be used,
     although not all make sense in a message/response context.

     Like *note asyncore.dispatcher: 1798, *note async_chat: 1799.
     defines a set of events that are generated by an analysis of socket
     conditions after a ‘select()’ call.  Once the polling loop has been
     started the *note async_chat: 1799. object’s methods are called by
     the event-processing framework with no action on the part of the
     programmer.

     Two class attributes can be modified, to improve performance, or
     possibly even to conserve memory.

      -- Data: ac_in_buffer_size

          The asynchronous input buffer size (default ‘4096’).

      -- Data: ac_out_buffer_size

          The asynchronous output buffer size (default ‘4096’).

     Unlike *note asyncore.dispatcher: 1798, *note async_chat: 1799.
     allows you to define a first-in-first-out queue (fifo) of
     _producers_.  A producer need have only one method, ‘more()’, which
     should return data to be transmitted on the channel.  The producer
     indicates exhaustion (_i.e._  that it contains no more data) by
     having its ‘more()’ method return the empty string.  At this point
     the *note async_chat: 1799. object removes the producer from the
     fifo and starts using the next producer, if any.  When the producer
     fifo is empty the ‘handle_write()’ method does nothing.  You use
     the channel object’s *note set_terminator(): 17b9. method to
     describe how to recognize the end of, or an important breakpoint
     in, an incoming transmission from the remote endpoint.

     To build a functioning *note async_chat: 1799. subclass your input
     methods *note collect_incoming_data(): 17b5. and *note
     found_terminator(): 17b6. must handle the data that the channel
     receives asynchronously.  The methods are described below.

 -- Method: async_chat.close_when_done ()

     Pushes a ‘None’ on to the producer fifo.  When this producer is
     popped off the fifo it causes the channel to be closed.

 -- Method: async_chat.collect_incoming_data (data)

     Called with _data_ holding an arbitrary amount of received data.
     The default method, which must be overridden, raises a *note
     NotImplementedError: 94e. exception.

 -- Method: async_chat.discard_buffers ()

     In emergencies this method will discard any data held in the input
     and/or output buffers and the producer fifo.

 -- Method: async_chat.found_terminator ()

     Called when the incoming data stream matches the termination
     condition set by *note set_terminator(): 17b9.  The default method,
     which must be overridden, raises a *note NotImplementedError: 94e.
     exception.  The buffered input data should be available via an
     instance attribute.

 -- Method: async_chat.get_terminator ()

     Returns the current terminator for the channel.

 -- Method: async_chat.push (data)

     Pushes data on to the channel’s fifo to ensure its transmission.
     This is all you need to do to have the channel write the data out
     to the network, although it is possible to use your own producers
     in more complex schemes to implement encryption and chunking, for
     example.

 -- Method: async_chat.push_with_producer (producer)

     Takes a producer object and adds it to the producer fifo associated
     with the channel.  When all currently-pushed producers have been
     exhausted the channel will consume this producer’s data by calling
     its ‘more()’ method and send the data to the remote endpoint.

 -- Method: async_chat.set_terminator (term)

     Sets the terminating condition to be recognized on the channel.
     ‘term’ may be any of three types of value, corresponding to three
     different ways to handle incoming protocol data.

     term            Description
                     
     ------------------------------------------------------------------
                     
     _string_        Will call *note found_terminator(): 17b6. when
                     the string is found in the input stream
                     
                     
     _integer_       Will call *note found_terminator(): 17b6. when
                     the indicated number of characters have been
                     received
                     
                     
     ‘None’          The channel continues to collect data forever
                     

     Note that any data following the terminator will be available for
     reading by the channel after *note found_terminator(): 17b6. is
     called.

* Menu:

* asynchat - Auxiliary Classes:: 
* asynchat Example:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/asynchat.py


File: python.info,  Node: asynchat - Auxiliary Classes,  Next: asynchat Example,  Up: asynchat --- Asynchronous socket command/response handler

5.17.7.1 asynchat - Auxiliary Classes
.....................................

 -- Class: asynchat.fifo ([list=None])

     A *note fifo: 17c0. holding data which has been pushed by the
     application but not yet popped for writing to the channel.  A *note
     fifo: 17c0. is a list used to hold data and/or producers until they
     are required.  If the _list_ argument is provided then it should
     contain producers or data items to be written to the channel.

      -- Method: is_empty ()

          Returns ‘True’ if and only if the fifo is empty.

      -- Method: first ()

          Returns the least-recently *note push(): 17c3.ed item from the
          fifo.

      -- Method: push (data)

          Adds the given data (which may be a string or a producer
          object) to the producer fifo.

      -- Method: pop ()

          If the fifo is not empty, returns ‘True, first()’, deleting
          the popped item.  Returns ‘False, None’ for an empty fifo.


File: python.info,  Node: asynchat Example,  Prev: asynchat - Auxiliary Classes,  Up: asynchat --- Asynchronous socket command/response handler

5.17.7.2 asynchat Example
.........................

The following partial example shows how HTTP requests can be read with
*note async_chat: 1799.  A web server might create an
‘http_request_handler’ object for each incoming client connection.
Notice that initially the channel terminator is set to match the blank
line at the end of the HTTP headers, and a flag indicates that the
headers are being read.

  Once the headers have been read, if the request is of type POST
(indicating that further data are present in the input stream) then the
‘Content-Length:’ header is used to set a numeric terminator to read the
right amount of data from the channel.

  The ‘handle_request()’ method is called once all relevant input has
been marshalled, after setting the channel terminator to ‘None’ to
ensure that any extraneous data sent by the web client are ignored.

     class http_request_handler(asynchat.async_chat):

         def __init__(self, sock, addr, sessions, log):
             asynchat.async_chat.__init__(self, sock=sock)
             self.addr = addr
             self.sessions = sessions
             self.ibuffer = []
             self.obuffer = ""
             self.set_terminator("\r\n\r\n")
             self.reading_headers = True
             self.handling = False
             self.cgi_data = None
             self.log = log

         def collect_incoming_data(self, data):
             """Buffer the data"""
             self.ibuffer.append(data)

         def found_terminator(self):
             if self.reading_headers:
                 self.reading_headers = False
                 self.parse_headers("".join(self.ibuffer))
                 self.ibuffer = []
                 if self.op.upper() == "POST":
                     clen = self.headers.getheader("content-length")
                     self.set_terminator(int(clen))
                 else:
                     self.handling = True
                     self.set_terminator(None)
                     self.handle_request()
             elif not self.handling:
                 self.set_terminator(None) # browsers sometimes over-send
                 self.cgi_data = parse(self.headers, "".join(self.ibuffer))
                 self.handling = True
                 self.ibuffer = []
                 self.handle_request()


File: python.info,  Node: Internet Data Handling,  Next: Structured Markup Processing Tools,  Prev: Interprocess Communication and Networking,  Up: The Python Standard Library

5.18 Internet Data Handling
===========================

This chapter describes modules which support handling data formats
commonly used on the Internet.

* Menu:

* email: email --- An email and MIME handling package. An email and MIME handling package
* json: json --- JSON encoder and decoder. JSON encoder and decoder
* mailcap: mailcap --- Mailcap file handling. Mailcap file handling
* mailbox: mailbox --- Manipulate mailboxes in various formats. Manipulate mailboxes in various formats
* mhlib: mhlib --- Access to MH mailboxes. Access to MH mailboxes
* mimetools: mimetools --- Tools for parsing MIME messages. Tools for parsing MIME messages
* mimetypes: mimetypes --- Map filenames to MIME types. Map filenames to MIME types
* MimeWriter: MimeWriter --- Generic MIME file writer. Generic MIME file writer
* mimify: mimify --- MIME processing of mail messages. MIME processing of mail messages
* multifile: multifile --- Support for files containing distinct parts. Support for files containing distinct parts
* rfc822: rfc822 --- Parse RFC 2822 mail headers. Parse RFC 2822 mail headers
* base64: base64 --- RFC 3548 Base16 Base32 Base64 Data Encodings. RFC 3548: Base16, Base32, Base64 Data Encodings
* binhex: binhex --- Encode and decode binhex4 files. Encode and decode binhex4 files
* binascii: binascii --- Convert between binary and ASCII. Convert between binary and ASCII
* quopri: quopri --- Encode and decode MIME quoted-printable data. Encode and decode MIME quoted-printable data
* uu: uu --- Encode and decode uuencode files. Encode and decode uuencode files

email — An email and MIME handling package

* email.message; Representing an email message: email message Representing an email message. 
* email.parser; Parsing email messages: email parser Parsing email messages. 
* email.generator; Generating MIME documents: email generator Generating MIME documents. 
* email.mime; Creating email and MIME objects from scratch: email mime Creating email and MIME objects from scratch. 
* email.header; Internationalized headers: email header Internationalized headers. 
* email.charset; Representing character sets: email charset Representing character sets. 
* email.encoders; Encoders: email encoders Encoders. 
* email.errors; Exception and Defect classes: email errors Exception and Defect classes. 
* email.utils; Miscellaneous utilities: email utils Miscellaneous utilities. 
* email.iterators; Iterators: email iterators Iterators. 
* email; Examples: email Examples. 
* Package History:: 
* Differences from mimelib:: 

email.parser: Parsing email messages

* FeedParser API:: 
* Parser class API:: 
* Additional notes:: 

json — JSON encoder and decoder

* Basic Usage:: 
* Encoders and Decoders:: 
* Standard Compliance:: 

Standard Compliance

* Character Encodings:: 
* Top-level Non-Object, Non-Array Values: Top-level Non-Object Non-Array Values. 
* Infinite and NaN Number Values:: 
* Repeated Names Within an Object:: 

mailbox — Manipulate mailboxes in various formats

* Mailbox objects:: 
* Message objects:: 
* Exceptions: Exceptions<5>. 
* Deprecated classes and methods:: 
* Examples: Examples<9>. 

Mailbox objects

* Maildir:: 
* mbox:: 
* MH:: 
* Babyl:: 
* MMDF:: 

Message objects

* MaildirMessage:: 
* mboxMessage:: 
* MHMessage:: 
* BabylMessage:: 
* MMDFMessage:: 

mhlib — Access to MH mailboxes

* MH Objects:: 
* Folder Objects:: 
* Message Objects:: 

mimetools — Tools for parsing MIME messages

* Additional Methods of Message Objects:: 

mimetypes — Map filenames to MIME types

* MimeTypes Objects:: 

MimeWriter — Generic MIME file writer

* MimeWriter Objects:: 

multifile — Support for files containing distinct parts

* MultiFile Objects:: 
* MultiFile Example:: 

rfc822 — Parse RFC 2822 mail headers

* Message Objects: Message Objects<2>. 
* AddressList Objects:: 

binhex — Encode and decode binhex4 files

* Notes: Notes<2>. 


File: python.info,  Node: email --- An email and MIME handling package,  Next: json --- JSON encoder and decoder,  Up: Internet Data Handling

5.18.1 ‘email’ — An email and MIME handling package
---------------------------------------------------

New in version 2.2.

  The *note email: bb. package is a library for managing email messages,
including MIME and other RFC 2822(1)-based message documents.  It
subsumes most of the functionality in several older standard modules
such as *note rfc822: 148, *note mimetools: 10f, *note multifile: 118,
and other non-standard packages such as ‘mimecntl’.  It is specifically
_not_ designed to do any sending of email messages to SMTP ( RFC
2821(2)), NNTP, or other servers; those are functions of modules such as
*note smtplib: 15a. and *note nntplib: 124.  The *note email: bb.
package attempts to be as RFC-compliant as possible, supporting in
addition to RFC 2822(3), such MIME-related RFCs as RFC 2045(4), RFC
2046(5), RFC 2047(6), and RFC 2231(7).

  The primary distinguishing feature of the *note email: bb. package is
that it splits the parsing and generating of email messages from the
internal _object model_ representation of email.  Applications using the
*note email: bb. package deal primarily with objects; you can add
sub-objects to messages, remove sub-objects from messages, completely
re-arrange the contents, etc.  There is a separate parser and a separate
generator which handles the transformation from flat text to the object
model, and then back to flat text again.  There are also handy
subclasses for some common MIME object types, and a few miscellaneous
utilities that help with such common tasks as extracting and parsing
message field values, creating RFC-compliant dates, etc.

  The following sections describe the functionality of the *note email:
bb. package.  The ordering follows a progression that should be common
in applications: an email message is read as flat text from a file or
other source, the text is parsed to produce the object structure of the
email message, this structure is manipulated, and finally, the object
tree is rendered back into flat text.

  It is perfectly feasible to create the object structure out of whole
cloth — i.e.  completely from scratch.  From there, a similar
progression can be taken as above.

  Also included are detailed specifications of all the classes and
modules that the *note email: bb. package provides, the exception
classes you might encounter while using the *note email: bb. package,
some auxiliary utilities, and a few examples.  For users of the older
‘mimelib’ package, or previous versions of the *note email: bb. package,
a section on differences and porting is provided.

  Contents of the *note email: bb. package documentation:

* Menu:

* email.message; Representing an email message: email message Representing an email message. 
* email.parser; Parsing email messages: email parser Parsing email messages. 
* email.generator; Generating MIME documents: email generator Generating MIME documents. 
* email.mime; Creating email and MIME objects from scratch: email mime Creating email and MIME objects from scratch. 
* email.header; Internationalized headers: email header Internationalized headers. 
* email.charset; Representing character sets: email charset Representing character sets. 
* email.encoders; Encoders: email encoders Encoders. 
* email.errors; Exception and Defect classes: email errors Exception and Defect classes. 
* email.utils; Miscellaneous utilities: email utils Miscellaneous utilities. 
* email.iterators; Iterators: email iterators Iterators. 
* email; Examples: email Examples. 
* Package History:: 
* Differences from mimelib:: 

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc2822.html

   (2) http://tools.ietf.org/html/rfc2821.html

   (3) http://tools.ietf.org/html/rfc2822.html

   (4) http://tools.ietf.org/html/rfc2045.html

   (5) http://tools.ietf.org/html/rfc2046.html

   (6) http://tools.ietf.org/html/rfc2047.html

   (7) http://tools.ietf.org/html/rfc2231.html


File: python.info,  Node: email message Representing an email message,  Next: email parser Parsing email messages,  Up: email --- An email and MIME handling package

5.18.1.1 ‘email.message’: Representing an email message
.......................................................

The central class in the *note email: bb. package is the *note Message:
216. class, imported from the *note email.message: c2. module.  It is
the base class for the *note email: bb. object model.  *note Message:
216. provides the core functionality for setting and querying header
fields, and for accessing message bodies.

  Conceptually, a *note Message: 216. object consists of _headers_ and
_payloads_.  Headers are RFC 2822(1) style field names and values where
the field name and value are separated by a colon.  The colon is not
part of either the field name or the field value.

  Headers are stored and returned in case-preserving form but are
matched case-insensitively.  There may also be a single envelope header,
also known as the _Unix-From_ header or the ‘From_’ header.  The payload
is either a string in the case of simple message objects or a list of
*note Message: 216. objects for MIME container documents (e.g.
‘multipart/*’ and ‘message/rfc822’).

  *note Message: 216. objects provide a mapping style interface for
accessing the message headers, and an explicit interface for accessing
both the headers and the payload.  It provides convenience methods for
generating a flat text representation of the message object tree, for
accessing commonly used header parameters, and for recursively walking
over the object tree.

  Here are the methods of the *note Message: 216. class:

 -- Class: email.message.Message

     The constructor takes no arguments.

      -- Method: as_string ([unixfrom])

          Return the entire message flattened as a string.  When
          optional _unixfrom_ is ‘True’, the envelope header is included
          in the returned string.  _unixfrom_ defaults to ‘False’.
          Flattening the message may trigger changes to the *note
          Message: 216. if defaults need to be filled in to complete the
          transformation to a string (for example, MIME boundaries may
          be generated or modified).

          Note that this method is provided as a convenience and may not
          always format the message the way you want.  For example, by
          default it mangles lines that begin with ‘From’.  For more
          flexibility, instantiate a *note Generator: 17cf. instance and
          use its *note flatten(): 17d0. method directly.  For example:

               from cStringIO import StringIO
               from email.generator import Generator
               fp = StringIO()
               g = Generator(fp, mangle_from_=False, maxheaderlen=60)
               g.flatten(msg)
               text = fp.getvalue()

      -- Method: __str__ ()

          Equivalent to ‘as_string(unixfrom=True)’.

      -- Method: is_multipart ()

          Return ‘True’ if the message’s payload is a list of sub-*note
          Message: 216. objects, otherwise return ‘False’.  When *note
          is_multipart(): 17d2. returns ‘False’, the payload should be a
          string object.

      -- Method: set_unixfrom (unixfrom)

          Set the message’s envelope header to _unixfrom_, which should
          be a string.

      -- Method: get_unixfrom ()

          Return the message’s envelope header.  Defaults to ‘None’ if
          the envelope header was never set.

      -- Method: attach (payload)

          Add the given _payload_ to the current payload, which must be
          ‘None’ or a list of *note Message: 216. objects before the
          call.  After the call, the payload will always be a list of
          *note Message: 216. objects.  If you want to set the payload
          to a scalar object (e.g.  a string), use *note set_payload():
          17d6. instead.

      -- Method: get_payload ([i[, decode]])

          Return the current payload, which will be a list of *note
          Message: 216. objects when *note is_multipart(): 17d2. is
          ‘True’, or a string when *note is_multipart(): 17d2. is
          ‘False’.  If the payload is a list and you mutate the list
          object, you modify the message’s payload in place.

          With optional argument _i_, *note get_payload(): 17d7. will
          return the _i_-th element of the payload, counting from zero,
          if *note is_multipart(): 17d2. is ‘True’.  An *note
          IndexError: 4e1. will be raised if _i_ is less than 0 or
          greater than or equal to the number of items in the payload.
          If the payload is a string (i.e.  *note is_multipart(): 17d2.
          is ‘False’) and _i_ is given, a *note TypeError: 218. is
          raised.

          Optional _decode_ is a flag indicating whether the payload
          should be decoded or not, according to the
          ‘Content-Transfer-Encoding’ header.  When ‘True’ and the
          message is not a multipart, the payload will be decoded if
          this header’s value is ‘quoted-printable’ or ‘base64’.  If
          some other encoding is used, or ‘Content-Transfer-Encoding’
          header is missing, or if the payload has bogus base64 data,
          the payload is returned as-is (undecoded).  If the message is
          a multipart and the _decode_ flag is ‘True’, then ‘None’ is
          returned.  The default for _decode_ is ‘False’.

      -- Method: set_payload (payload[, charset])

          Set the entire message object’s payload to _payload_.  It is
          the client’s responsibility to ensure the payload invariants.
          Optional _charset_ sets the message’s default character set;
          see *note set_charset(): 17d8. for details.

          Changed in version 2.2.2: _charset_ argument added.

      -- Method: set_charset (charset)

          Set the character set of the payload to _charset_, which can
          either be a *note Charset: 17d9. instance (see *note
          email.charset: bc.), a string naming a character set, or
          ‘None’.  If it is a string, it will be converted to a *note
          Charset: 17d9. instance.  If _charset_ is ‘None’, the
          ‘charset’ parameter will be removed from the ‘Content-Type’
          header (the message will not be otherwise modified).  Anything
          else will generate a *note TypeError: 218.

          If there is no existing ‘MIME-Version’ header one will be
          added.  If there is no existing ‘Content-Type’ header, one
          will be added with a value of ‘text/plain’.  Whether the
          ‘Content-Type’ header already exists or not, its ‘charset’
          parameter will be set to _charset.output_charset_.  If
          _charset.input_charset_ and _charset.output_charset_ differ,
          the payload will be re-encoded to the _output_charset_.  If
          there is no existing ‘Content-Transfer-Encoding’ header, then
          the payload will be transfer-encoded, if needed, using the
          specified *note Charset: 17d9, and a header with the
          appropriate value will be added.  If a
          ‘Content-Transfer-Encoding’ header already exists, the payload
          is assumed to already be correctly encoded using that
          ‘Content-Transfer-Encoding’ and is not modified.

          The message will be assumed to be of type ‘text/*’, with the
          payload either in unicode or encoded with
          _charset.input_charset_.  It will be encoded or converted to
          _charset.output_charset_ and transfer encoded properly, if
          needed, when generating the plain text representation of the
          message.  MIME headers (‘MIME-Version’, ‘Content-Type’,
          ‘Content-Transfer-Encoding’) will be added as needed.

          New in version 2.2.2.

      -- Method: get_charset ()

          Return the *note Charset: 17d9. instance associated with the
          message’s payload.

          New in version 2.2.2.

     The following methods implement a mapping-like interface for
     accessing the message’s RFC 2822(2) headers.  Note that there are
     some semantic differences between these methods and a normal
     mapping (i.e.  dictionary) interface.  For example, in a dictionary
     there are no duplicate keys, but here there may be duplicate
     message headers.  Also, in dictionaries there is no guaranteed
     order to the keys returned by *note keys(): 17db, but in a *note
     Message: 216. object, headers are always returned in the order they
     appeared in the original message, or were added to the message
     later.  Any header deleted and then re-added are always appended to
     the end of the header list.

     These semantic differences are intentional and are biased toward
     maximal convenience.

     Note that in all cases, any envelope header present in the message
     is not included in the mapping interface.

      -- Method: __len__ ()

          Return the total number of headers, including duplicates.

      -- Method: __contains__ (name)

          Return true if the message object has a field named _name_.
          Matching is done case-insensitively and _name_ should not
          include the trailing colon.  Used for the ‘in’ operator, e.g.:

               if 'message-id' in myMessage:
                   print 'Message-ID:', myMessage['message-id']

      -- Method: __getitem__ (name)

          Return the value of the named header field.  _name_ should not
          include the colon field separator.  If the header is missing,
          ‘None’ is returned; a *note KeyError: 205. is never raised.

          Note that if the named field appears more than once in the
          message’s headers, exactly which of those field values will be
          returned is undefined.  Use the *note get_all(): 17df. method
          to get the values of all the extant named headers.

      -- Method: __setitem__ (name, val)

          Add a header to the message with field name _name_ and value
          _val_.  The field is appended to the end of the message’s
          existing fields.

          Note that this does _not_ overwrite or delete any existing
          header with the same name.  If you want to ensure that the new
          header is the only one present in the message with field name
          _name_, delete the field first, e.g.:

               del msg['subject']
               msg['subject'] = 'Python roolz!'

      -- Method: __delitem__ (name)

          Delete all occurrences of the field with name _name_ from the
          message’s headers.  No exception is raised if the named field
          isn’t present in the headers.

      -- Method: has_key (name)

          Return true if the message contains a header field named
          _name_, otherwise return false.

      -- Method: keys ()

          Return a list of all the message’s header field names.

      -- Method: values ()

          Return a list of all the message’s field values.

      -- Method: items ()

          Return a list of 2-tuples containing all the message’s field
          headers and values.

      -- Method: get (name[, failobj])

          Return the value of the named header field.  This is identical
          to *note __getitem__(): 17de. except that optional _failobj_
          is returned if the named header is missing (defaults to
          ‘None’).

     Here are some additional useful methods:

      -- Method: get_all (name[, failobj])

          Return a list of all the values for the field named _name_.
          If there are no such named headers in the message, _failobj_
          is returned (defaults to ‘None’).

      -- Method: add_header (_name, _value, **_params)

          Extended header setting.  This method is similar to *note
          __setitem__(): 17e0. except that additional header parameters
          can be provided as keyword arguments.  __name_ is the header
          field to add and __value_ is the _primary_ value for the
          header.

          For each item in the keyword argument dictionary __params_,
          the key is taken as the parameter name, with underscores
          converted to dashes (since dashes are illegal in Python
          identifiers).  Normally, the parameter will be added as
          ‘key="value"’ unless the value is ‘None’, in which case only
          the key will be added.  If the value contains non-ASCII
          characters, it must be specified as a three tuple in the
          format ‘(CHARSET, LANGUAGE, VALUE)’, where ‘CHARSET’ is a
          string naming the charset to be used to encode the value,
          ‘LANGUAGE’ can usually be set to ‘None’ or the empty string
          (see RFC 2231(3) for other possibilities), and ‘VALUE’ is the
          string value containing non-ASCII code points.

          Here’s an example:

               msg.add_header('Content-Disposition', 'attachment', filename='bud.gif')

          This will add a header that looks like

               Content-Disposition: attachment; filename="bud.gif"

          An example with non-ASCII characters:

               msg.add_header('Content-Disposition', 'attachment',
                              filename=('iso-8859-1', '', 'Fußballer.ppt'))

          Which produces

               Content-Disposition: attachment; filename*="iso-8859-1''Fu%DFballer.ppt"

      -- Method: replace_header (_name, _value)

          Replace a header.  Replace the first header found in the
          message that matches __name_, retaining header order and field
          name case.  If no matching header was found, a *note KeyError:
          205. is raised.

          New in version 2.2.2.

      -- Method: get_content_type ()

          Return the message’s content type.  The returned string is
          coerced to lower case of the form ‘maintype/subtype’.  If
          there was no ‘Content-Type’ header in the message the default
          type as given by *note get_default_type(): 17e9. will be
          returned.  Since according to RFC 2045(4), messages always
          have a default type, *note get_content_type(): 17e8. will
          always return a value.

          RFC 2045(5) defines a message’s default type to be
          ‘text/plain’ unless it appears inside a ‘multipart/digest’
          container, in which case it would be ‘message/rfc822’.  If the
          ‘Content-Type’ header has an invalid type specification, RFC
          2045(6) mandates that the default type be ‘text/plain’.

          New in version 2.2.2.

      -- Method: get_content_maintype ()

          Return the message’s main content type.  This is the
          ‘maintype’ part of the string returned by *note
          get_content_type(): 17e8.

          New in version 2.2.2.

      -- Method: get_content_subtype ()

          Return the message’s sub-content type.  This is the ‘subtype’
          part of the string returned by *note get_content_type(): 17e8.

          New in version 2.2.2.

      -- Method: get_default_type ()

          Return the default content type.  Most messages have a default
          content type of ‘text/plain’, except for messages that are
          subparts of ‘multipart/digest’ containers.  Such subparts have
          a default content type of ‘message/rfc822’.

          New in version 2.2.2.

      -- Method: set_default_type (ctype)

          Set the default content type.  _ctype_ should either be
          ‘text/plain’ or ‘message/rfc822’, although this is not
          enforced.  The default content type is not stored in the
          ‘Content-Type’ header.

          New in version 2.2.2.

      -- Method: get_params ([failobj[, header[, unquote]]])

          Return the message’s ‘Content-Type’ parameters, as a list.
          The elements of the returned list are 2-tuples of key/value
          pairs, as split on the ‘'='’ sign.  The left hand side of the
          ‘'='’ is the key, while the right hand side is the value.  If
          there is no ‘'='’ sign in the parameter the value is the empty
          string, otherwise the value is as described in *note
          get_param(): 17ee. and is unquoted if optional _unquote_ is
          ‘True’ (the default).

          Optional _failobj_ is the object to return if there is no
          ‘Content-Type’ header.  Optional _header_ is the header to
          search instead of ‘Content-Type’.

          Changed in version 2.2.2: _unquote_ argument added.

      -- Method: get_param (param[, failobj[, header[, unquote]]])

          Return the value of the ‘Content-Type’ header’s parameter
          _param_ as a string.  If the message has no ‘Content-Type’
          header or if there is no such parameter, then _failobj_ is
          returned (defaults to ‘None’).

          Optional _header_ if given, specifies the message header to
          use instead of ‘Content-Type’.

          Parameter keys are always compared case insensitively.  The
          return value can either be a string, or a 3-tuple if the
          parameter was RFC 2231(7) encoded.  When it’s a 3-tuple, the
          elements of the value are of the form ‘(CHARSET, LANGUAGE,
          VALUE)’.  Note that both ‘CHARSET’ and ‘LANGUAGE’ can be
          ‘None’, in which case you should consider ‘VALUE’ to be
          encoded in the ‘us-ascii’ charset.  You can usually ignore
          ‘LANGUAGE’.

          If your application doesn’t care whether the parameter was
          encoded as in RFC 2231(8), you can collapse the parameter
          value by calling *note email.utils.collapse_rfc2231_value():
          17ef, passing in the return value from *note get_param():
          17ee.  This will return a suitably decoded Unicode string when
          the value is a tuple, or the original string unquoted if it
          isn’t.  For example:

               rawparam = msg.get_param('foo')
               param = email.utils.collapse_rfc2231_value(rawparam)

          In any case, the parameter value (either the returned string,
          or the ‘VALUE’ item in the 3-tuple) is always unquoted, unless
          _unquote_ is set to ‘False’.

          Changed in version 2.2.2: _unquote_ argument added, and
          3-tuple return value possible.

      -- Method: set_param (param, value[, header[, requote[, charset[,
               language]]]])

          Set a parameter in the ‘Content-Type’ header.  If the
          parameter already exists in the header, its value will be
          replaced with _value_.  If the ‘Content-Type’ header as not
          yet been defined for this message, it will be set to
          ‘text/plain’ and the new parameter value will be appended as
          per RFC 2045(9).

          Optional _header_ specifies an alternative header to
          ‘Content-Type’, and all parameters will be quoted as necessary
          unless optional _requote_ is ‘False’ (the default is ‘True’).

          If optional _charset_ is specified, the parameter will be
          encoded according to RFC 2231(10).  Optional _language_
          specifies the RFC 2231 language, defaulting to the empty
          string.  Both _charset_ and _language_ should be strings.

          New in version 2.2.2.

      -- Method: del_param (param[, header[, requote]])

          Remove the given parameter completely from the ‘Content-Type’
          header.  The header will be re-written in place without the
          parameter or its value.  All values will be quoted as
          necessary unless _requote_ is ‘False’ (the default is ‘True’).
          Optional _header_ specifies an alternative to ‘Content-Type’.

          New in version 2.2.2.

      -- Method: set_type (type[, header][, requote])

          Set the main type and subtype for the ‘Content-Type’ header.
          _type_ must be a string in the form ‘maintype/subtype’,
          otherwise a *note ValueError: 236. is raised.

          This method replaces the ‘Content-Type’ header, keeping all
          the parameters in place.  If _requote_ is ‘False’, this leaves
          the existing header’s quoting as is, otherwise the parameters
          will be quoted (the default).

          An alternative header can be specified in the _header_
          argument.  When the ‘Content-Type’ header is set a
          ‘MIME-Version’ header is also added.

          New in version 2.2.2.

      -- Method: get_filename ([failobj])

          Return the value of the ‘filename’ parameter of the
          ‘Content-Disposition’ header of the message.  If the header
          does not have a ‘filename’ parameter, this method falls back
          to looking for the ‘name’ parameter on the ‘Content-Type’
          header.  If neither is found, or the header is missing, then
          _failobj_ is returned.  The returned string will always be
          unquoted as per *note email.utils.unquote(): 17f4.

      -- Method: get_boundary ([failobj])

          Return the value of the ‘boundary’ parameter of the
          ‘Content-Type’ header of the message, or _failobj_ if either
          the header is missing, or has no ‘boundary’ parameter.  The
          returned string will always be unquoted as per *note
          email.utils.unquote(): 17f4.

      -- Method: set_boundary (boundary)

          Set the ‘boundary’ parameter of the ‘Content-Type’ header to
          _boundary_.  *note set_boundary(): 17f6. will always quote
          _boundary_ if necessary.  A *note HeaderParseError: 17f7. is
          raised if the message object has no ‘Content-Type’ header.

          Note that using this method is subtly different than deleting
          the old ‘Content-Type’ header and adding a new one with the
          new boundary via *note add_header(): 17e6, because *note
          set_boundary(): 17f6. preserves the order of the
          ‘Content-Type’ header in the list of headers.  However, it
          does _not_ preserve any continuation lines which may have been
          present in the original ‘Content-Type’ header.

      -- Method: get_content_charset ([failobj])

          Return the ‘charset’ parameter of the ‘Content-Type’ header,
          coerced to lower case.  If there is no ‘Content-Type’ header,
          or if that header has no ‘charset’ parameter, _failobj_ is
          returned.

          Note that this method differs from *note get_charset(): 17da.
          which returns the *note Charset: 17d9. instance for the
          default encoding of the message body.

          New in version 2.2.2.

      -- Method: get_charsets ([failobj])

          Return a list containing the character set names in the
          message.  If the message is a ‘multipart’, then the list will
          contain one element for each subpart in the payload,
          otherwise, it will be a list of length 1.

          Each item in the list will be a string which is the value of
          the ‘charset’ parameter in the ‘Content-Type’ header for the
          represented subpart.  However, if the subpart has no
          ‘Content-Type’ header, no ‘charset’ parameter, or is not of
          the ‘text’ main MIME type, then that item in the returned list
          will be _failobj_.

      -- Method: walk ()

          The *note walk(): 17fa. method is an all-purpose generator
          which can be used to iterate over all the parts and subparts
          of a message object tree, in depth-first traversal order.  You
          will typically use *note walk(): 17fa. as the iterator in a
          ‘for’ loop; each iteration returns the next subpart.

          Here’s an example that prints the MIME type of every part of a
          multipart message structure:

               >>> for part in msg.walk():
               ...     print part.get_content_type()
               multipart/report
               text/plain
               message/delivery-status
               text/plain
               text/plain
               message/rfc822

     Changed in version 2.5: The previously deprecated methods
     ‘get_type()’, ‘get_main_type()’, and ‘get_subtype()’ were removed.

     *note Message: 216. objects can also optionally contain two
     instance attributes, which can be used when generating the plain
     text of a MIME message.

      -- Attribute: preamble

          The format of a MIME document allows for some text between the
          blank line following the headers, and the first multipart
          boundary string.  Normally, this text is never visible in a
          MIME-aware mail reader because it falls outside the standard
          MIME armor.  However, when viewing the raw text of the
          message, or when viewing the message in a non-MIME aware
          reader, this text can become visible.

          The _preamble_ attribute contains this leading extra-armor
          text for MIME documents.  When the *note Parser: 17fc.
          discovers some text after the headers but before the first
          boundary string, it assigns this text to the message’s
          _preamble_ attribute.  When the *note Generator: 17cf. is
          writing out the plain text representation of a MIME message,
          and it finds the message has a _preamble_ attribute, it will
          write this text in the area between the headers and the first
          boundary.  See *note email.parser: c4. and *note
          email.generator: bf. for details.

          Note that if the message object has no preamble, the
          _preamble_ attribute will be ‘None’.

      -- Attribute: epilogue

          The _epilogue_ attribute acts the same way as the _preamble_
          attribute, except that it contains text that appears between
          the last boundary and the end of the message.

          Changed in version 2.5: You do not need to set the epilogue to
          the empty string in order for the *note Generator: 17cf. to
          print a newline at the end of the file.

      -- Attribute: defects

          The _defects_ attribute contains a list of all the problems
          found when parsing this message.  See *note email.errors: be.
          for a detailed description of the possible parsing defects.

          New in version 2.4.

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc2822.html

   (2) http://tools.ietf.org/html/rfc2822.html

   (3) http://tools.ietf.org/html/rfc2231.html

   (4) http://tools.ietf.org/html/rfc2045.html

   (5) http://tools.ietf.org/html/rfc2045.html

   (6) http://tools.ietf.org/html/rfc2045.html

   (7) http://tools.ietf.org/html/rfc2231.html

   (8) http://tools.ietf.org/html/rfc2231.html

   (9) http://tools.ietf.org/html/rfc2045.html

   (10) http://tools.ietf.org/html/rfc2231.html

