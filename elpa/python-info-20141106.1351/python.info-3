This is python.info, produced by makeinfo version 5.2 from python.texi.

     Python 2.7.8, November 06, 2014

     Georg Brandl

     Copyright © 1990-2014, Python Software Foundation

INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.1.3.


File: python.info,  Node: Build and C API Changes<4>,  Next: Porting to Python 2 4,  Prev: New Improved and Deprecated Modules,  Up: What's New in Python 2 4

1.4.13 Build and C API Changes
------------------------------

Some of the changes to Python’s build process and to the C API are:

   * Three new convenience macros were added for common return values
     from extension functions: *note Py_RETURN_NONE: 417, *note
     Py_RETURN_TRUE: 418, and *note Py_RETURN_FALSE: 419.  (Contributed
     by Brett Cannon.)

   * Another new macro, ‘Py_CLEAR(obj)’, decreases the reference count
     of _obj_ and sets _obj_ to the null pointer.  (Contributed by Jim
     Fulton.)

   * A new function, ‘PyTuple_Pack(N, obj1, obj2, ..., objN)()’,
     constructs tuples from a variable length argument list of Python
     objects.  (Contributed by Raymond Hettinger.)

   * A new function, ‘PyDict_Contains(d, k)()’, implements fast
     dictionary lookups without masking exceptions raised during the
     look-up process.  (Contributed by Raymond Hettinger.)

   * The ‘Py_IS_NAN(X)’ macro returns 1 if its float or double argument
     _X_ is a NaN. (Contributed by Tim Peters.)

   * C code can avoid unnecessary locking by using the new *note
     PyEval_ThreadsInitialized(): 41a. function to tell if any thread
     operations have been performed.  If this function returns false, no
     lock operations are needed.  (Contributed by Nick Coghlan.)

   * A new function, *note PyArg_VaParseTupleAndKeywords(): 41b, is the
     same as *note PyArg_ParseTupleAndKeywords(): 41c. but takes a
     ‘va_list’ instead of a number of arguments.  (Contributed by Greg
     Chapman.)

   * A new method flag, ‘METH_COEXISTS’, allows a function defined in
     slots to co-exist with a *note PyCFunction: 41d. having the same
     name.  This can halve the access time for a method such as
     ‘set.__contains__()’.  (Contributed by Raymond Hettinger.)

   * Python can now be built with additional profiling for the
     interpreter itself, intended as an aid to people developing the
     Python core.  Providing ‘----enable-profiling’ to the *configure*
     script will let you profile the interpreter with *gprof*, and
     providing the ‘----with-tsc’ switch enables profiling using the
     Pentium’s Time-Stamp- Counter register.  Note that the
     ‘----with-tsc’ switch is slightly misnamed, because the profiling
     feature also works on the PowerPC platform, though that processor
     architecture doesn’t call that register "the TSC register".
     (Contributed by Jeremy Hylton.)

   * The ‘tracebackobject’ type has been renamed to ‘PyTracebackObject’.

* Menu:

* Port-Specific Changes: Port-Specific Changes<2>. 


File: python.info,  Node: Port-Specific Changes<2>,  Up: Build and C API Changes<4>

1.4.13.1 Port-Specific Changes
..............................

   * The Windows port now builds under MSVC++ 7.1 as well as version 6.
     (Contributed by Martin von Löwis.)


File: python.info,  Node: Porting to Python 2 4,  Next: Acknowledgements<4>,  Prev: Build and C API Changes<4>,  Up: What's New in Python 2 4

1.4.14 Porting to Python 2.4
----------------------------

This section lists previously described changes that may require changes
to your code:

   * Left shifts and hexadecimal/octal constants that are too large no
     longer trigger a *note FutureWarning: 2b4. and return a value
     limited to 32 or 64 bits; instead they return a long integer.

   * Integer operations will no longer trigger an ‘OverflowWarning’.
     The ‘OverflowWarning’ warning will disappear in Python 2.5.

   * The *note zip(): 405. built-in function and *note itertools.izip():
     406. now return an empty list instead of raising a *note TypeError:
     218. exception if called with no arguments.

   * You can no longer compare the ‘date’ and *note datetime: 7d.
     instances provided by the *note datetime: 7d. module.  Two
     instances of different classes will now always be unequal, and
     relative comparisons (‘<’, ‘>’) will raise a *note TypeError: 218.

   * *note dircache.listdir(): 420. now passes exceptions to the caller
     instead of returning empty lists.

   * ‘LexicalHandler.startDTD()’ used to receive the public and system
     IDs in the wrong order.  This has been corrected; applications
     relying on the wrong order need to be fixed.

   * *note fcntl.ioctl(): 421. now warns if the _mutate_ argument is
     omitted and relevant.

   * The *note tarfile: 171. module now generates GNU-format tar files
     by default.

   * Encountering a failure while importing a module no longer leaves a
     partially- initialized module object in ‘sys.modules’.

   * *note None: 39a. is now a constant; code that binds a new value to
     the name ‘None’ is now a syntax error.

   * The ‘signals.signal()’ function now raises a *note RuntimeError:
     39b. exception for certain illegal values; previously these errors
     would pass silently.  For example, you can no longer set a handler
     on the ‘SIGKILL’ signal.


File: python.info,  Node: Acknowledgements<4>,  Prev: Porting to Python 2 4,  Up: What's New in Python 2 4

1.4.15 Acknowledgements
-----------------------

The author would like to thank the following people for offering
suggestions, corrections and assistance with various drafts of this
article: Koray Can, Hye-Shik Chang, Michael Dyck, Raymond Hettinger,
Brian Hurt, Hamish Lawson, Fredrik Lundh, Sean Reifschneider, Sadruddin
Rejeb.


File: python.info,  Node: What's New in Python 2 3,  Next: What's New in Python 2 2,  Prev: What's New in Python 2 4,  Up: What's New in Python

1.5 What’s New in Python 2.3
============================

     Author: A.M. Kuchling

  This article explains the new features in Python 2.3.  Python 2.3 was
released on July 29, 2003.

  The main themes for Python 2.3 are polishing some of the features
added in 2.2, adding various small but useful enhancements to the core
language, and expanding the standard library.  The new object model
introduced in the previous version has benefited from 18 months of
bugfixes and from optimization efforts that have improved the
performance of new-style classes.  A few new built-in functions have
been added such as *note sum(): 426. and *note enumerate(): 427.  The
*note in: 428. operator can now be used for substring searches (e.g.
‘"ab" in "abc"’ returns *note True: 3b0.).

  Some of the many new library features include Boolean, set, heap, and
date/time data types, the ability to import modules from ZIP-format
archives, metadata support for the long-awaited Python catalog, an
updated version of IDLE, and modules for logging messages, wrapping
text, parsing CSV files, processing command-line options, using
BerkeleyDB databases...  the list of new and enhanced modules is
lengthy.

  This article doesn’t attempt to provide a complete specification of
the new features, but instead provides a convenient overview.  For full
details, you should refer to the documentation for Python 2.3, such as
the Python Library Reference and the Python Reference Manual.  If you
want to understand the complete implementation and design rationale,
refer to the PEP for a particular new feature.

* Menu:

* PEP 218; A Standard Set Datatype: PEP 218 A Standard Set Datatype. 
* PEP 255; Simple Generators: PEP 255 Simple Generators. 
* PEP 263; Source Code Encodings: PEP 263 Source Code Encodings. 
* PEP 273; Importing Modules from ZIP Archives: PEP 273 Importing Modules from ZIP Archives. 
* PEP 277; Unicode file name support for Windows NT: PEP 277 Unicode file name support for Windows NT. 
* PEP 278; Universal Newline Support: PEP 278 Universal Newline Support. 
* PEP 279; enumerate(): PEP 279 enumerate. 
* PEP 282; The logging Package: PEP 282 The logging Package. 
* PEP 285; A Boolean Type: PEP 285 A Boolean Type. 
* PEP 293; Codec Error Handling Callbacks: PEP 293 Codec Error Handling Callbacks. 
* PEP 301; Package Index and Metadata for Distutils: PEP 301 Package Index and Metadata for Distutils. 
* PEP 302; New Import Hooks: PEP 302 New Import Hooks. 
* PEP 305; Comma-separated Files: PEP 305 Comma-separated Files. 
* PEP 307; Pickle Enhancements: PEP 307 Pickle Enhancements. 
* Extended Slices:: 
* Other Language Changes: Other Language Changes<5>. 
* New, Improved, and Deprecated Modules: New Improved and Deprecated Modules<2>. 
* Pymalloc; A Specialized Object Allocator: Pymalloc A Specialized Object Allocator. 
* Build and C API Changes: Build and C API Changes<5>. 
* Other Changes and Fixes: Other Changes and Fixes<2>. 
* Porting to Python 2.3: Porting to Python 2 3. 
* Acknowledgements: Acknowledgements<5>. 


File: python.info,  Node: PEP 218 A Standard Set Datatype,  Next: PEP 255 Simple Generators,  Up: What's New in Python 2 3

1.5.1 PEP 218: A Standard Set Datatype
--------------------------------------

The new *note sets: 14f. module contains an implementation of a set
datatype.  The ‘Set’ class is for mutable sets, sets that can have
members added and removed.  The ‘ImmutableSet’ class is for sets that
can’t be modified, and instances of ‘ImmutableSet’ can therefore be used
as dictionary keys.  Sets are built on top of dictionaries, so the
elements within a set must be hashable.

  Here’s a simple example:

     >>> import sets
     >>> S = sets.Set([1,2,3])
     >>> S
     Set([1, 2, 3])
     >>> 1 in S
     True
     >>> 0 in S
     False
     >>> S.add(5)
     >>> S.remove(3)
     >>> S
     Set([1, 2, 5])
     >>>

  The union and intersection of sets can be computed with the ‘union()’
and ‘intersection()’ methods; an alternative notation uses the bitwise
operators ‘&’ and ‘|’.  Mutable sets also have in-place versions of
these methods, ‘union_update()’ and ‘intersection_update()’.

     >>> S1 = sets.Set([1,2,3])
     >>> S2 = sets.Set([4,5,6])
     >>> S1.union(S2)
     Set([1, 2, 3, 4, 5, 6])
     >>> S1 | S2                  # Alternative notation
     Set([1, 2, 3, 4, 5, 6])
     >>> S1.intersection(S2)
     Set([])
     >>> S1 & S2                  # Alternative notation
     Set([])
     >>> S1.union_update(S2)
     >>> S1
     Set([1, 2, 3, 4, 5, 6])
     >>>

  It’s also possible to take the symmetric difference of two sets.  This
is the set of all elements in the union that aren’t in the intersection.
Another way of putting it is that the symmetric difference contains all
elements that are in exactly one set.  Again, there’s an alternative
notation (‘^’), and an in- place version with the ungainly name
‘symmetric_difference_update()’.

     >>> S1 = sets.Set([1,2,3,4])
     >>> S2 = sets.Set([3,4,5,6])
     >>> S1.symmetric_difference(S2)
     Set([1, 2, 5, 6])
     >>> S1 ^ S2
     Set([1, 2, 5, 6])
     >>>

  There are also ‘issubset()’ and ‘issuperset()’ methods for checking
whether one set is a subset or superset of another:

     >>> S1 = sets.Set([1,2,3])
     >>> S2 = sets.Set([2,3])
     >>> S2.issubset(S1)
     True
     >>> S1.issubset(S2)
     False
     >>> S1.issuperset(S2)
     True
     >>>

See also
........

PEP 218(1) - Adding a Built-In Set Object Type

     PEP written by Greg V. Wilson.  Implemented by Greg V. Wilson, Alex
     Martelli, and GvR.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0218


File: python.info,  Node: PEP 255 Simple Generators,  Next: PEP 263 Source Code Encodings,  Prev: PEP 218 A Standard Set Datatype,  Up: What's New in Python 2 3

1.5.2 PEP 255: Simple Generators
--------------------------------

In Python 2.2, generators were added as an optional feature, to be
enabled by a ‘from __future__ import generators’ directive.  In 2.3
generators no longer need to be specially enabled, and are now always
present; this means that *note yield: 2f7. is now always a keyword.  The
rest of this section is a copy of the description of generators from the
"What’s New in Python 2.2" document; if you read it back when Python 2.2
came out, you can skip the rest of this section.

  You’re doubtless familiar with how function calls work in Python or C.
When you call a function, it gets a private namespace where its local
variables are created.  When the function reaches a *note return: 2f4.
statement, the local variables are destroyed and the resulting value is
returned to the caller.  A later call to the same function will get a
fresh new set of local variables.  But, what if the local variables
weren’t thrown away on exiting a function?  What if you could later
resume the function where it left off?  This is what generators provide;
they can be thought of as resumable functions.

  Here’s the simplest example of a generator function:

     def generate_ints(N):
         for i in range(N):
             yield i

  A new keyword, *note yield: 2f7, was introduced for generators.  Any
function containing a *note yield: 2f7. statement is a generator
function; this is detected by Python’s bytecode compiler which compiles
the function specially as a result.

  When you call a generator function, it doesn’t return a single value;
instead it returns a generator object that supports the iterator
protocol.  On executing the *note yield: 2f7. statement, the generator
outputs the value of ‘i’, similar to a *note return: 2f4. statement.
The big difference between *note yield: 2f7. and a *note return: 2f4.
statement is that on reaching a *note yield: 2f7. the generator’s state
of execution is suspended and local variables are preserved.  On the
next call to the generator’s ‘.next()’ method, the function will resume
executing immediately after the *note yield: 2f7. statement.  (For
complicated reasons, the *note yield: 2f7. statement isn’t allowed
inside the *note try: 395. block of a *note try: 395...*note finally:
396. statement; read PEP 255(1) for a full explanation of the
interaction between *note yield: 2f7. and exceptions.)

  Here’s a sample usage of the ‘generate_ints()’ generator:

     >>> gen = generate_ints(3)
     >>> gen
     <generator object at 0x8117f90>
     >>> gen.next()
     0
     >>> gen.next()
     1
     >>> gen.next()
     2
     >>> gen.next()
     Traceback (most recent call last):
       File "stdin", line 1, in ?
       File "stdin", line 2, in generate_ints
     StopIteration

  You could equally write ‘for i in generate_ints(5)’, or ‘a,b,c =
generate_ints(3)’.

  Inside a generator function, the *note return: 2f4. statement can only
be used without a value, and signals the end of the procession of
values; afterwards the generator cannot return any further values.
*note return: 2f4. with a value, such as ‘return 5’, is a syntax error
inside a generator function.  The end of the generator’s results can
also be indicated by raising *note StopIteration: 333. manually, or by
just letting the flow of execution fall off the bottom of the function.

  You could achieve the effect of generators manually by writing your
own class and storing all the local variables of the generator as
instance variables.  For example, returning a list of integers could be
done by setting ‘self.count’ to 0, and having the *note next(): 399.
method increment ‘self.count’ and return it.  However, for a moderately
complicated generator, writing a corresponding class would be much
messier.  ‘Lib/test/test_generators.py’ contains a number of more
interesting examples.  The simplest one implements an in-order traversal
of a tree using generators recursively.

     # A recursive generator that generates Tree leaves in in-order.
     def inorder(t):
         if t:
             for x in inorder(t.left):
                 yield x
             yield t.label
             for x in inorder(t.right):
                 yield x

  Two other examples in ‘Lib/test/test_generators.py’ produce solutions
for the N-Queens problem (placing $N$ queens on an $NxN$ chess board so
that no queen threatens another) and the Knight’s Tour (a route that
takes a knight to every square of an $NxN$ chessboard without visiting
any square twice).

  The idea of generators comes from other programming languages,
especially Icon (‘http://www.cs.arizona.edu/icon/’), where the idea of
generators is central.  In Icon, every expression and function call
behaves like a generator.  One example from "An Overview of the Icon
Programming Language" at
‘http://www.cs.arizona.edu/icon/docs/ipd266.htm’ gives an idea of what
this looks like:

     sentence := "Store it in the neighboring harbor"
     if (i := find("or", sentence)) > 5 then write(i)

  In Icon the ‘find()’ function returns the indexes at which the
substring "or" is found: 3, 23, 33.  In the *note if: 42c. statement,
‘i’ is first assigned a value of 3, but 3 is less than 5, so the
comparison fails, and Icon retries it with the second value of 23.  23
is greater than 5, so the comparison now succeeds, and the code prints
the value 23 to the screen.

  Python doesn’t go nearly as far as Icon in adopting generators as a
central concept.  Generators are considered part of the core Python
language, but learning or using them isn’t compulsory; if they don’t
solve any problems that you have, feel free to ignore them.  One novel
feature of Python’s interface as compared to Icon’s is that a
generator’s state is represented as a concrete object (the iterator)
that can be passed around to other functions or stored in a data
structure.

See also
........

PEP 255(2) - Simple Generators

     Written by Neil Schemenauer, Tim Peters, Magnus Lie Hetland.
     Implemented mostly by Neil Schemenauer and Tim Peters, with other
     fixes from the Python Labs crew.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0255

   (2) http://www.python.org/dev/peps/pep-0255


File: python.info,  Node: PEP 263 Source Code Encodings,  Next: PEP 273 Importing Modules from ZIP Archives,  Prev: PEP 255 Simple Generators,  Up: What's New in Python 2 3

1.5.3 PEP 263: Source Code Encodings
------------------------------------

Python source files can now be declared as being in different character
set encodings.  Encodings are declared by including a specially
formatted comment in the first or second line of the source file.  For
example, a UTF-8 file can be declared with:

     #!/usr/bin/env python
     # -*- coding: UTF-8 -*-

  Without such an encoding declaration, the default encoding used is
7-bit ASCII. Executing or importing modules that contain string literals
with 8-bit characters and have no encoding declaration will result in a
*note DeprecationWarning: 1bc. being signalled by Python 2.3; in 2.4
this will be a syntax error.

  The encoding declaration only affects Unicode string literals, which
will be converted to Unicode using the specified encoding.  Note that
Python identifiers are still restricted to ASCII characters, so you
can’t have variable names that use characters outside of the usual
alphanumerics.

See also
........

PEP 263(1) - Defining Python Source Code Encodings

     Written by Marc-André Lemburg and Martin von Löwis; implemented by
     Suzuki Hisao and Martin von Löwis.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0263


File: python.info,  Node: PEP 273 Importing Modules from ZIP Archives,  Next: PEP 277 Unicode file name support for Windows NT,  Prev: PEP 263 Source Code Encodings,  Up: What's New in Python 2 3

1.5.4 PEP 273: Importing Modules from ZIP Archives
--------------------------------------------------

The new *note zipimport: 1ac. module adds support for importing modules
from a ZIP- format archive.  You don’t need to import the module
explicitly; it will be automatically imported if a ZIP archive’s
filename is added to ‘sys.path’.  For example:

     amk@nyman:~/src/python$ unzip -l /tmp/example.zip
     Archive:  /tmp/example.zip
       Length     Date   Time    Name
      --------    ----   ----    ----
          8467  11-26-02 22:30   jwzthreading.py
      --------                   -------
          8467                   1 file
     amk@nyman:~/src/python$ ./python
     Python 2.3 (#1, Aug 1 2003, 19:54:32)
     >>> import sys
     >>> sys.path.insert(0, '/tmp/example.zip')  # Add .zip file to front of path
     >>> import jwzthreading
     >>> jwzthreading.__file__
     '/tmp/example.zip/jwzthreading.py'
     >>>

  An entry in ‘sys.path’ can now be the filename of a ZIP archive.  The
ZIP archive can contain any kind of files, but only files named ‘*.py’,
‘*.pyc’, or ‘*.pyo’ can be imported.  If an archive only contains ‘*.py’
files, Python will not attempt to modify the archive by adding the
corresponding ‘*.pyc’ file, meaning that if a ZIP archive doesn’t
contain ‘*.pyc’ files, importing may be rather slow.

  A path within the archive can also be specified to only import from a
subdirectory; for example, the path ‘/tmp/example.zip/lib/’ would only
import from the ‘lib/’ subdirectory within the archive.

See also
........

PEP 273(1) - Import Modules from Zip Archives

     Written by James C. Ahlstrom, who also provided an implementation.
     Python 2.3 follows the specification in PEP 273(2), but uses an
     implementation written by Just van Rossum that uses the import
     hooks described in PEP 302(3).  See section *note PEP 302; New
     Import Hooks: 430. for a description of the new import hooks.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0273

   (2) http://www.python.org/dev/peps/pep-0273

   (3) http://www.python.org/dev/peps/pep-0302


File: python.info,  Node: PEP 277 Unicode file name support for Windows NT,  Next: PEP 278 Universal Newline Support,  Prev: PEP 273 Importing Modules from ZIP Archives,  Up: What's New in Python 2 3

1.5.5 PEP 277: Unicode file name support for Windows NT
-------------------------------------------------------

On Windows NT, 2000, and XP, the system stores file names as Unicode
strings.  Traditionally, Python has represented file names as byte
strings, which is inadequate because it renders some file names
inaccessible.

  Python now allows using arbitrary Unicode strings (within the
limitations of the file system) for all functions that expect file
names, most notably the *note open(): 2d6. built-in function.  If a
Unicode string is passed to *note os.listdir(): 2d2, Python now returns
a list of Unicode strings.  A new function, *note os.getcwdu(): 432,
returns the current directory as a Unicode string.

  Byte strings still work as file names, and on Windows Python will
transparently convert them to Unicode using the ‘mbcs’ encoding.

  Other systems also allow Unicode strings as file names but convert
them to byte strings before passing them to the system, which can cause
a *note UnicodeError: 433. to be raised.  Applications can test whether
arbitrary Unicode strings are supported as file names by checking *note
os.path.supports_unicode_filenames: 434, a Boolean value.

  Under MacOS, *note os.listdir(): 2d2. may now return Unicode
filenames.

See also
........

PEP 277(1) - Unicode file name support for Windows NT

     Written by Neil Hodgson; implemented by Neil Hodgson, Martin von
     Löwis, and Mark Hammond.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0277


File: python.info,  Node: PEP 278 Universal Newline Support,  Next: PEP 279 enumerate,  Prev: PEP 277 Unicode file name support for Windows NT,  Up: What's New in Python 2 3

1.5.6 PEP 278: Universal Newline Support
----------------------------------------

The three major operating systems used today are Microsoft Windows,
Apple’s Macintosh OS, and the various Unix derivatives.  A minor
irritation of cross- platform work is that these three platforms all use
different characters to mark the ends of lines in text files.  Unix uses
the linefeed (ASCII character 10), MacOS uses the carriage return (ASCII
character 13), and Windows uses a two-character sequence of a carriage
return plus a newline.

  Python’s file objects can now support end of line conventions other
than the one followed by the platform on which Python is running.
Opening a file with the mode ‘'U'’ or ‘'rU'’ will open a file for
reading in *note universal newlines: 315. mode.  All three line ending
conventions will be translated to a ‘'\n'’ in the strings returned by
the various file methods such as ‘read()’ and *note readline(): 144.

  Universal newline support is also used when importing modules and when
executing a file with the *note execfile(): 436. function.  This means
that Python modules can be shared between all three operating systems
without needing to convert the line-endings.

  This feature can be disabled when compiling Python by specifying the
‘--without-universal-newlines’ switch when running Python’s *configure*
script.

See also
........

PEP 278(1) - Universal Newline Support

     Written and implemented by Jack Jansen.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0278


File: python.info,  Node: PEP 279 enumerate,  Next: PEP 282 The logging Package,  Prev: PEP 278 Universal Newline Support,  Up: What's New in Python 2 3

1.5.7 PEP 279: enumerate()
--------------------------

A new built-in function, *note enumerate(): 427, will make certain loops
a bit clearer.  ‘enumerate(thing)’, where _thing_ is either an iterator
or a sequence, returns a iterator that will return ‘(0, thing[0])’, ‘(1,
thing[1])’, ‘(2, thing[2])’, and so forth.

  A common idiom to change every element of a list looks like this:

     for i in range(len(L)):
         item = L[i]
         # ... compute some result based on item ...
         L[i] = result

  This can be rewritten using *note enumerate(): 427. as:

     for i, item in enumerate(L):
         # ... compute some result based on item ...
         L[i] = result

See also
........

PEP 279(1) - The enumerate() built-in function

     Written and implemented by Raymond D. Hettinger.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0279


File: python.info,  Node: PEP 282 The logging Package,  Next: PEP 285 A Boolean Type,  Prev: PEP 279 enumerate,  Up: What's New in Python 2 3

1.5.8 PEP 282: The logging Package
----------------------------------

A standard package for writing logs, *note logging: 101, has been added
to Python 2.3.  It provides a powerful and flexible mechanism for
generating logging output which can then be filtered and processed in
various ways.  A configuration file written in a standard format can be
used to control the logging behavior of a program.  Python includes
handlers that will write log records to standard error or to a file or
socket, send them to the system log, or even e-mail them to a particular
address; of course, it’s also possible to write your own handler
classes.

  The ‘Logger’ class is the primary class.  Most application code will
deal with one or more ‘Logger’ objects, each one used by a particular
subsystem of the application.  Each ‘Logger’ is identified by a name,
and names are organized into a hierarchy using ‘.’ as the component
separator.  For example, you might have ‘Logger’ instances named
‘server’, ‘server.auth’ and ‘server.network’.  The latter two instances
are below ‘server’ in the hierarchy.  This means that if you turn up the
verbosity for ‘server’ or direct ‘server’ messages to a different
handler, the changes will also apply to records logged to ‘server.auth’
and ‘server.network’.  There’s also a root ‘Logger’ that’s the parent of
all other loggers.

  For simple uses, the *note logging: 101. package contains some
convenience functions that always use the root log:

     import logging

     logging.debug('Debugging information')
     logging.info('Informational message')
     logging.warning('Warning:config file %s not found', 'server.conf')
     logging.error('Error occurred')
     logging.critical('Critical error -- shutting down')

  This produces the following output:

     WARNING:root:Warning:config file server.conf not found
     ERROR:root:Error occurred
     CRITICAL:root:Critical error -- shutting down

  In the default configuration, informational and debugging messages are
suppressed and the output is sent to standard error.  You can enable the
display of informational and debugging messages by calling the
‘setLevel()’ method on the root logger.

  Notice the ‘warning()’ call’s use of string formatting operators; all
of the functions for logging messages take the arguments ‘(msg, arg1,
arg2, ...)’ and log the string resulting from ‘msg % (arg1, arg2, ...)’.

  There’s also an ‘exception()’ function that records the most recent
traceback.  Any of the other functions will also record the traceback if
you specify a true value for the keyword argument _exc_info_.

     def f():
         try:    1/0
         except: logging.exception('Problem recorded')

     f()

  This produces the following output:

     ERROR:root:Problem recorded
     Traceback (most recent call last):
       File "t.py", line 6, in f
         1/0
     ZeroDivisionError: integer division or modulo by zero

  Slightly more advanced programs will use a logger other than the root
logger.  The ‘getLogger(name)()’ function is used to get a particular
log, creating it if it doesn’t exist yet.  ‘getLogger(None)()’ returns
the root logger.

     log = logging.getLogger('server')
      ...
     log.info('Listening on port %i', port)
      ...
     log.critical('Disk full')
      ...

  Log records are usually propagated up the hierarchy, so a message
logged to ‘server.auth’ is also seen by ‘server’ and ‘root’, but a
‘Logger’ can prevent this by setting its ‘propagate’ attribute to *note
False: 3b1.

  There are more classes provided by the *note logging: 101. package
that can be customized.  When a ‘Logger’ instance is told to log a
message, it creates a ‘LogRecord’ instance that is sent to any number of
different ‘Handler’ instances.  Loggers and handlers can also have an
attached list of filters, and each filter can cause the ‘LogRecord’ to
be ignored or can modify the record before passing it along.  When
they’re finally output, ‘LogRecord’ instances are converted to text by a
‘Formatter’ class.  All of these classes can be replaced by your own
specially-written classes.

  With all of these features the *note logging: 101. package should
provide enough flexibility for even the most complicated applications.
This is only an incomplete overview of its features, so please see the
package’s reference documentation for all of the details.  Reading PEP
282(1) will also be helpful.

See also
........

PEP 282(2) - A Logging System

     Written by Vinay Sajip and Trent Mick; implemented by Vinay Sajip.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0282

   (2) http://www.python.org/dev/peps/pep-0282


File: python.info,  Node: PEP 285 A Boolean Type,  Next: PEP 293 Codec Error Handling Callbacks,  Prev: PEP 282 The logging Package,  Up: What's New in Python 2 3

1.5.9 PEP 285: A Boolean Type
-----------------------------

A Boolean type was added to Python 2.3.  Two new constants were added to
the *note __builtin__: 0. module, *note True: 3b0. and *note False: 3b1.
(*note True: 3b0. and *note False: 3b1. constants were added to the
built-ins in Python 2.2.1, but the 2.2.1 versions are simply set to
integer values of 1 and 0 and aren’t a different type.)

  The type object for this new type is named *note bool: 43c.; the
constructor for it takes any Python value and converts it to *note True:
3b0. or *note False: 3b1.

     >>> bool(1)
     True
     >>> bool(0)
     False
     >>> bool([])
     False
     >>> bool( (1,) )
     True

  Most of the standard library modules and built-in functions have been
changed to return Booleans.

     >>> obj = []
     >>> hasattr(obj, 'append')
     True
     >>> isinstance(obj, list)
     True
     >>> isinstance(obj, tuple)
     False

  Python’s Booleans were added with the primary goal of making code
clearer.  For example, if you’re reading a function and encounter the
statement ‘return 1’, you might wonder whether the ‘1’ represents a
Boolean truth value, an index, or a coefficient that multiplies some
other quantity.  If the statement is ‘return True’, however, the meaning
of the return value is quite clear.

  Python’s Booleans were _not_ added for the sake of strict
type-checking.  A very strict language such as Pascal would also prevent
you performing arithmetic with Booleans, and would require that the
expression in an *note if: 42c. statement always evaluate to a Boolean
result.  Python is not this strict and never will be, as PEP 285(1)
explicitly says.  This means you can still use any expression in an
*note if: 42c. statement, even ones that evaluate to a list or tuple or
some random object.  The Boolean type is a subclass of the *note int:
1f2. class so that arithmetic using a Boolean still works.

     >>> True + 1
     2
     >>> False + 1
     1
     >>> False * 75
     0
     >>> True * 75
     75

  To sum up *note True: 3b0. and *note False: 3b1. in a sentence:
they’re alternative ways to spell the integer values 1 and 0, with the
single difference that *note str(): 1ea. and *note repr(): 145. return
the strings ‘'True'’ and ‘'False'’ instead of ‘'1'’ and ‘'0'’.

See also
........

PEP 285(2) - Adding a bool type

     Written and implemented by GvR.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0285

   (2) http://www.python.org/dev/peps/pep-0285


File: python.info,  Node: PEP 293 Codec Error Handling Callbacks,  Next: PEP 301 Package Index and Metadata for Distutils,  Prev: PEP 285 A Boolean Type,  Up: What's New in Python 2 3

1.5.10 PEP 293: Codec Error Handling Callbacks
----------------------------------------------

When encoding a Unicode string into a byte string, unencodable
characters may be encountered.  So far, Python has allowed specifying
the error processing as either "strict" (raising *note UnicodeError:
433.), "ignore" (skipping the character), or "replace" (using a question
mark in the output string), with "strict" being the default behavior.
It may be desirable to specify alternative processing of such errors,
such as inserting an XML character reference or HTML entity reference
into the converted string.

  Python now has a flexible framework to add different processing
strategies.  New error handlers can be added with *note
codecs.register_error(): 43e, and codecs then can access the error
handler with *note codecs.lookup_error(): 43f.  An equivalent C API has
been added for codecs written in C. The error handler gets the necessary
state information such as the string being converted, the position in
the string where the error was detected, and the target encoding.  The
handler can then either raise an exception or return a replacement
string.

  Two additional error handlers have been implemented using this
framework: "backslashreplace" uses Python backslash quoting to represent
unencodable characters and "xmlcharrefreplace" emits XML character
references.

See also
........

PEP 293(1) - Codec Error Handling Callbacks

     Written and implemented by Walter Dörwald.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0293


File: python.info,  Node: PEP 301 Package Index and Metadata for Distutils,  Next: PEP 302 New Import Hooks,  Prev: PEP 293 Codec Error Handling Callbacks,  Up: What's New in Python 2 3

1.5.11 PEP 301: Package Index and Metadata for Distutils
--------------------------------------------------------

Support for the long-requested Python catalog makes its first appearance
in 2.3.

  The heart of the catalog is the new Distutils *register* command.
Running ‘python setup.py register’ will collect the metadata describing
a package, such as its name, version, maintainer, description, &c., and
send it to a central catalog server.  The resulting catalog is available
from ‘http://www.python.org/pypi’.

  To make the catalog a bit more useful, a new optional _classifiers_
keyword argument has been added to the Distutils ‘setup()’ function.  A
list of Trove(1)-style strings can be supplied to help classify the
software.

  Here’s an example ‘setup.py’ with classifiers, written to be
compatible with older versions of the Distutils:

     from distutils import core
     kw = {'name': "Quixote",
           'version': "0.5.1",
           'description': "A highly Pythonic Web application framework",
           # ...
           }

     if (hasattr(core, 'setup_keywords') and
         'classifiers' in core.setup_keywords):
         kw['classifiers'] = \
             ['Topic :: Internet :: WWW/HTTP :: Dynamic Content',
              'Environment :: No Input/Output (Daemon)',
              'Intended Audience :: Developers'],

     core.setup(**kw)

  The full list of classifiers can be obtained by running ‘python
setup.py register --list-classifiers’.

See also
........

PEP 301(2) - Package Index and Metadata for Distutils

     Written and implemented by Richard Jones.

   ---------- Footnotes ----------

   (1) http://catb.org/~esr/trove/

   (2) http://www.python.org/dev/peps/pep-0301


File: python.info,  Node: PEP 302 New Import Hooks,  Next: PEP 305 Comma-separated Files,  Prev: PEP 301 Package Index and Metadata for Distutils,  Up: What's New in Python 2 3

1.5.12 PEP 302: New Import Hooks
--------------------------------

While it’s been possible to write custom import hooks ever since the
‘ihooks’ module was introduced in Python 1.3, no one has ever been
really happy with it because writing new import hooks is difficult and
messy.  There have been various proposed alternatives such as the *note
imputil: f7. and ‘iu’ modules, but none of them has ever gained much
acceptance, and none of them were easily usable from C code.

  PEP 302(1) borrows ideas from its predecessors, especially from Gordon
McMillan’s ‘iu’ module.  Three new items are added to the *note sys:
16d. module:

   * ‘sys.path_hooks’ is a list of callable objects; most often they’ll
     be classes.  Each callable takes a string containing a path and
     either returns an importer object that will handle imports from
     this path or raises an *note ImportError: 370. exception if it
     can’t handle this path.

   * ‘sys.path_importer_cache’ caches importer objects for each path, so
     ‘sys.path_hooks’ will only need to be traversed once for each path.

   * ‘sys.meta_path’ is a list of importer objects that will be
     traversed before ‘sys.path’ is checked.  This list is initially
     empty, but user code can add objects to it.  Additional built-in
     and frozen modules can be imported by an object added to this list.

  Importer objects must have a single method, ‘find_module(fullname,
path=None)()’.  _fullname_ will be a module or package name, e.g.
‘string’ or ‘distutils.core’.  ‘find_module()’ must return a loader
object that has a single method, ‘load_module(fullname)()’, that creates
and returns the corresponding module object.

  Pseudo-code for Python’s new import logic, therefore, looks something
like this (simplified a bit; see PEP 302(2) for the full details):

     for mp in sys.meta_path:
         loader = mp(fullname)
         if loader is not None:
             <module> = loader.load_module(fullname)

     for path in sys.path:
         for hook in sys.path_hooks:
             try:
                 importer = hook(path)
             except ImportError:
                 # ImportError, so try the other path hooks
                 pass
             else:
                 loader = importer.find_module(fullname)
                 <module> = loader.load_module(fullname)

     # Not found!
     raise ImportError

See also
........

PEP 302(3) - New Import Hooks

     Written by Just van Rossum and Paul Moore.  Implemented by Just van
     Rossum.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0302

   (2) http://www.python.org/dev/peps/pep-0302

   (3) http://www.python.org/dev/peps/pep-0302


File: python.info,  Node: PEP 305 Comma-separated Files,  Next: PEP 307 Pickle Enhancements,  Prev: PEP 302 New Import Hooks,  Up: What's New in Python 2 3

1.5.13 PEP 305: Comma-separated Files
-------------------------------------

Comma-separated files are a format frequently used for exporting data
from databases and spreadsheets.  Python 2.3 adds a parser for
comma-separated files.

  Comma-separated format is deceptively simple at first glance:

     Costs,150,200,3.95

  Read a line and call ‘line.split(',')’: what could be simpler?  But
toss in string data that can contain commas, and things get more
complicated:

     "Costs",150,200,3.95,"Includes taxes, shipping, and sundry items"

  A big ugly regular expression can parse this, but using the new *note
csv: 77. package is much simpler:

     import csv

     input = open('datafile', 'rb')
     reader = csv.reader(input)
     for line in reader:
         print line

  The ‘reader()’ function takes a number of different options.  The
field separator isn’t limited to the comma and can be changed to any
character, and so can the quoting and line-ending characters.

  Different dialects of comma-separated files can be defined and
registered; currently there are two dialects, both used by Microsoft
Excel.  A separate *note csv.writer: 445. class will generate
comma-separated files from a succession of tuples or lists, quoting
strings that contain the delimiter.

See also
........

PEP 305(1) - CSV File API

     Written and implemented by Kevin Altis, Dave Cole, Andrew McNamara,
     Skip Montanaro, Cliff Wells.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0305


File: python.info,  Node: PEP 307 Pickle Enhancements,  Next: Extended Slices,  Prev: PEP 305 Comma-separated Files,  Up: What's New in Python 2 3

1.5.14 PEP 307: Pickle Enhancements
-----------------------------------

The *note pickle: 12d. and *note cPickle: 73. modules received some
attention during the 2.3 development cycle.  In 2.2, new-style classes
could be pickled without difficulty, but they weren’t pickled very
compactly; PEP 307(1) quotes a trivial example where a new-style class
results in a pickled string three times longer than that for a classic
class.

  The solution was to invent a new pickle protocol.  The *note
pickle.dumps(): 448. function has supported a text-or-binary flag for a
long time.  In 2.3, this flag is redefined from a Boolean to an integer:
0 is the old text-mode pickle format, 1 is the old binary format, and
now 2 is a new 2.3-specific format.  A new constant, *note
pickle.HIGHEST_PROTOCOL: 449, can be used to select the fanciest
protocol available.

  Unpickling is no longer considered a safe operation.  2.2’s *note
pickle: 12d. provided hooks for trying to prevent unsafe classes from
being unpickled (specifically, a ‘__safe_for_unpickling__’ attribute),
but none of this code was ever audited and therefore it’s all been
ripped out in 2.3.  You should not unpickle untrusted data in any
version of Python.

  To reduce the pickling overhead for new-style classes, a new interface
for customizing pickling was added using three special methods: *note
__getstate__(): 44a, *note __setstate__(): 44b, and *note
__getnewargs__(): 44c.  Consult PEP 307(2) for the full semantics of
these methods.

  As a way to compress pickles yet further, it’s now possible to use
integer codes instead of long strings to identify pickled classes.  The
Python Software Foundation will maintain a list of standardized codes;
there’s also a range of codes for private use.  Currently no codes have
been specified.

See also
........

PEP 307(3) - Extensions to the pickle protocol

     Written and implemented by Guido van Rossum and Tim Peters.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0307

   (2) http://www.python.org/dev/peps/pep-0307

   (3) http://www.python.org/dev/peps/pep-0307


File: python.info,  Node: Extended Slices,  Next: Other Language Changes<5>,  Prev: PEP 307 Pickle Enhancements,  Up: What's New in Python 2 3

1.5.15 Extended Slices
----------------------

Ever since Python 1.4, the slicing syntax has supported an optional
third "step" or "stride" argument.  For example, these are all legal
Python syntax: ‘L[1:10:2]’, ‘L[:-1:1]’, ‘L[::-1]’.  This was added to
Python at the request of the developers of Numerical Python, which uses
the third argument extensively.  However, Python’s built-in list, tuple,
and string sequence types have never supported this feature, raising a
*note TypeError: 218. if you tried it.  Michael Hudson contributed a
patch to fix this shortcoming.

  For example, you can now easily extract the elements of a list that
have even indexes:

     >>> L = range(10)
     >>> L[::2]
     [0, 2, 4, 6, 8]

  Negative values also work to make a copy of the same list in reverse
order:

     >>> L[::-1]
     [9, 8, 7, 6, 5, 4, 3, 2, 1, 0]

  This also works for tuples, arrays, and strings:

     >>> s='abcd'
     >>> s[::2]
     'ac'
     >>> s[::-1]
     'dcba'

  If you have a mutable sequence such as a list or an array you can
assign to or delete an extended slice, but there are some differences
between assignment to extended and regular slices.  Assignment to a
regular slice can be used to change the length of the sequence:

     >>> a = range(3)
     >>> a
     [0, 1, 2]
     >>> a[1:3] = [4, 5, 6]
     >>> a
     [0, 4, 5, 6]

  Extended slices aren’t this flexible.  When assigning to an extended
slice, the list on the right hand side of the statement must contain the
same number of items as the slice it is replacing:

     >>> a = range(4)
     >>> a
     [0, 1, 2, 3]
     >>> a[::2]
     [0, 2]
     >>> a[::2] = [0, -1]
     >>> a
     [0, 1, -1, 3]
     >>> a[::2] = [0,1,2]
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     ValueError: attempt to assign sequence of size 3 to extended slice of size 2

  Deletion is more straightforward:

     >>> a = range(4)
     >>> a
     [0, 1, 2, 3]
     >>> a[::2]
     [0, 2]
     >>> del a[::2]
     >>> a
     [1, 3]

  One can also now pass slice objects to the *note __getitem__(): 44f.
methods of the built-in sequences:

     >>> range(10).__getitem__(slice(0, 5, 2))
     [0, 2, 4]

  Or use slice objects directly in subscripts:

     >>> range(10)[slice(0, 5, 2)]
     [0, 2, 4]

  To simplify implementing sequences that support extended slicing,
slice objects now have a method ‘indices(length)()’ which, given the
length of a sequence, returns a ‘(start, stop, step)’ tuple that can be
passed directly to *note range(): 2d9.  ‘indices()’ handles omitted and
out-of-bounds indices in a manner consistent with regular slices (and
this innocuous phrase hides a welter of confusing details!).  The method
is intended to be used like this:

     class FakeSeq:
         ...
         def calc_item(self, i):
             ...
         def __getitem__(self, item):
             if isinstance(item, slice):
                 indices = item.indices(len(self))
                 return FakeSeq([self.calc_item(i) for i in range(*indices)])
             else:
                 return self.calc_item(i)

  From this example you can also see that the built-in *note slice: 450.
object is now the type object for the slice type, and is no longer a
function.  This is consistent with Python 2.2, where *note int: 1f2,
*note str: 1ea, etc., underwent the same change.


File: python.info,  Node: Other Language Changes<5>,  Next: New Improved and Deprecated Modules<2>,  Prev: Extended Slices,  Up: What's New in Python 2 3

1.5.16 Other Language Changes
-----------------------------

Here are all of the changes that Python 2.3 makes to the core Python
language.

   * The *note yield: 2f7. statement is now always a keyword, as
     described in section *note PEP 255; Simple Generators: 42a. of this
     document.

   * A new built-in function *note enumerate(): 427. was added, as
     described in section *note PEP 279; enumerate(): 438. of this
     document.

   * Two new constants, *note True: 3b0. and *note False: 3b1. were
     added along with the built-in *note bool: 43c. type, as described
     in section *note PEP 285; A Boolean Type: 43b. of this document.

   * The *note int(): 1f2. type constructor will now return a long
     integer instead of raising an *note OverflowError: 2db. when a
     string or floating-point number is too large to fit into an
     integer.  This can lead to the paradoxical result that
     ‘isinstance(int(expression), int)’ is false, but that seems
     unlikely to cause problems in practice.

   * Built-in types now support the extended slicing syntax, as
     described in section *note Extended Slices: 44d. of this document.

   * A new built-in function, ‘sum(iterable, start=0)()’, adds up the
     numeric items in the iterable object and returns their sum.  *note
     sum(): 426. only accepts numbers, meaning that you can’t use it to
     concatenate a bunch of strings.  (Contributed by Alex Martelli.)

   * ‘list.insert(pos, value)’ used to insert _value_ at the front of
     the list when _pos_ was negative.  The behaviour has now been
     changed to be consistent with slice indexing, so when _pos_ is -1
     the value will be inserted before the last element, and so forth.

   * ‘list.index(value)’, which searches for _value_ within the list and
     returns its index, now takes optional _start_ and _stop_ arguments
     to limit the search to only part of the list.

   * Dictionaries have a new method, ‘pop(key[, *default*])()’, that
     returns the value corresponding to _key_ and removes that key/value
     pair from the dictionary.  If the requested key isn’t present in
     the dictionary, _default_ is returned if it’s specified and *note
     KeyError: 205. raised if it isn’t.

          >>> d = {1:2}
          >>> d
          {1: 2}
          >>> d.pop(4)
          Traceback (most recent call last):
            File "stdin", line 1, in ?
          KeyError: 4
          >>> d.pop(1)
          2
          >>> d.pop(1)
          Traceback (most recent call last):
            File "stdin", line 1, in ?
          KeyError: 'pop(): dictionary is empty'
          >>> d
          {}
          >>>

     There’s also a new class method, ‘dict.fromkeys(iterable,
     value)()’, that creates a dictionary with keys taken from the
     supplied iterator _iterable_ and all values set to _value_,
     defaulting to ‘None’.

     (Patches contributed by Raymond Hettinger.)

     Also, the *note dict(): 305. constructor now accepts keyword
     arguments to simplify creating small dictionaries:

          >>> dict(red=1, blue=2, green=3, black=4)
          {'blue': 2, 'black': 4, 'green': 3, 'red': 1}

     (Contributed by Just van Rossum.)

   * The *note assert: 452. statement no longer checks the ‘__debug__’
     flag, so you can no longer disable assertions by assigning to
     ‘__debug__’.  Running Python with the *note -O: 453. switch will
     still generate code that doesn’t execute any assertions.

   * Most type objects are now callable, so you can use them to create
     new objects such as functions, classes, and modules.  (This means
     that the *note new: 122. module can be deprecated in a future
     Python version, because you can now use the type objects available
     in the *note types: 185. module.)  For example, you can create a
     new module object with the following code:

          >>> import types
          >>> m = types.ModuleType('abc','docstring')
          >>> m
          <module 'abc' (built-in)>
          >>> m.__doc__
          'docstring'

   * A new warning, *note PendingDeprecationWarning: 1f0. was added to
     indicate features which are in the process of being deprecated.
     The warning will _not_ be printed by default.  To check for use of
     features that will be deprecated in the future, supply
     ‘-Walways::PendingDeprecationWarning::’ on the command line or use
     *note warnings.filterwarnings(): 454.

   * The process of deprecating string-based exceptions, as in ‘raise
     "Error occurred"’, has begun.  Raising a string will now trigger
     *note PendingDeprecationWarning: 1f0.

   * Using ‘None’ as a variable name will now result in a *note
     SyntaxWarning: 455. warning.  In a future version of Python, ‘None’
     may finally become a keyword.

   * The ‘xreadlines()’ method of file objects, introduced in Python
     2.1, is no longer necessary because files now behave as their own
     iterator.  ‘xreadlines()’ was originally introduced as a faster way
     to loop over all the lines in a file, but now you can simply write
     ‘for line in file_obj’.  File objects also have a new read-only
     ‘encoding’ attribute that gives the encoding used by the file;
     Unicode strings written to the file will be automatically converted
     to bytes using the given encoding.

   * The method resolution order used by new-style classes has changed,
     though you’ll only notice the difference if you have a really
     complicated inheritance hierarchy.  Classic classes are unaffected
     by this change.  Python 2.2 originally used a topological sort of a
     class’s ancestors, but 2.3 now uses the C3 algorithm as described
     in the paper "A Monotonic Superclass Linearization for Dylan"(1).
     To understand the motivation for this change, read Michele
     Simionato’s article "Python 2.3 Method Resolution Order"(2), or
     read the thread on python-dev starting with the message at
     ‘http://mail.python.org/pipermail/python-dev/2002-October/029035.html’.
     Samuele Pedroni first pointed out the problem and also implemented
     the fix by coding the C3 algorithm.

   * Python runs multithreaded programs by switching between threads
     after executing N bytecodes.  The default value for N has been
     increased from 10 to 100 bytecodes, speeding up single-threaded
     applications by reducing the switching overhead.  Some
     multithreaded applications may suffer slower response time, but
     that’s easily fixed by setting the limit back to a lower number
     using ‘sys.setcheckinterval(N)()’.  The limit can be retrieved with
     the new *note sys.getcheckinterval(): 456. function.

   * One minor but far-reaching change is that the names of extension
     types defined by the modules included with Python now contain the
     module and a ‘'.'’ in front of the type name.  For example, in
     Python 2.2, if you created a socket and printed its ‘__class__’,
     you’d get this output:

          >>> s = socket.socket()
          >>> s.__class__
          <type 'socket'>

     In 2.3, you get this:

          >>> s.__class__
          <type '_socket.socket'>

   * One of the noted incompatibilities between old- and new-style
     classes has been removed: you can now assign to the ‘__name__’ and
     ‘__bases__’ attributes of new-style classes.  There are some
     restrictions on what can be assigned to ‘__bases__’ along the lines
     of those relating to assigning to an instance’s ‘__class__’
     attribute.

* Menu:

* String Changes:: 
* Optimizations: Optimizations<5>. 

   ---------- Footnotes ----------

   (1) http://www.webcom.com/haahr/dylan/linearization-oopsla96.html

   (2) http://www.python.org/2.3/mro.html


File: python.info,  Node: String Changes,  Next: Optimizations<5>,  Up: Other Language Changes<5>

1.5.16.1 String Changes
.......................

   * The *note in: 428. operator now works differently for strings.
     Previously, when evaluating ‘X in Y’ where _X_ and _Y_ are strings,
     _X_ could only be a single character.  That’s now changed; _X_ can
     be a string of any length, and ‘X in Y’ will return *note True:
     3b0. if _X_ is a substring of _Y_. If _X_ is the empty string, the
     result is always *note True: 3b0.

          >>> 'ab' in 'abcd'
          True
          >>> 'ad' in 'abcd'
          False
          >>> '' in 'abcd'
          True

     Note that this doesn’t tell you where the substring starts; if you
     need that information, use the ‘find()’ string method.

   * The ‘strip()’, ‘lstrip()’, and ‘rstrip()’ string methods now have
     an optional argument for specifying the characters to strip.  The
     default is still to remove all whitespace characters:

          >>> '   abc '.strip()
          'abc'
          >>> '><><abc<><><>'.strip('<>')
          'abc'
          >>> '><><abc<><><>\n'.strip('<>')
          'abc<><><>\n'
          >>> u'\u4000\u4001abc\u4000'.strip(u'\u4000')
          u'\u4001abc'
          >>>

     (Suggested by Simon Brunning and implemented by Walter Dörwald.)

   * The ‘startswith()’ and ‘endswith()’ string methods now accept
     negative numbers for the _start_ and _end_ parameters.

   * Another new string method is ‘zfill()’, originally a function in
     the *note string: 163. module.  ‘zfill()’ pads a numeric string
     with zeros on the left until it’s the specified width.  Note that
     the ‘%’ operator is still more flexible and powerful than
     ‘zfill()’.

          >>> '45'.zfill(4)
          '0045'
          >>> '12345'.zfill(4)
          '12345'
          >>> 'goofy'.zfill(6)
          '0goofy'

     (Contributed by Walter Dörwald.)

   * A new type object, *note basestring: 458, has been added.  Both
     8-bit strings and Unicode strings inherit from this type, so
     ‘isinstance(obj, basestring)’ will return *note True: 3b0. for
     either kind of string.  It’s a completely abstract type, so you
     can’t create *note basestring: 458. instances.

   * Interned strings are no longer immortal and will now be
     garbage-collected in the usual way when the only reference to them
     is from the internal dictionary of interned strings.  (Implemented
     by Oren Tirosh.)


File: python.info,  Node: Optimizations<5>,  Prev: String Changes,  Up: Other Language Changes<5>

1.5.16.2 Optimizations
......................

   * The creation of new-style class instances has been made much
     faster; they’re now faster than classic classes!

   * The ‘sort()’ method of list objects has been extensively rewritten
     by Tim Peters, and the implementation is significantly faster.

   * Multiplication of large long integers is now much faster thanks to
     an implementation of Karatsuba multiplication, an algorithm that
     scales better than the O(n*n) required for the grade-school
     multiplication algorithm.  (Original patch by Christopher A. Craig,
     and significantly reworked by Tim Peters.)

   * The ‘SET_LINENO’ opcode is now gone.  This may provide a small
     speed increase, depending on your compiler’s idiosyncrasies.  See
     section *note Other Changes and Fixes: 45a. for a longer
     explanation.  (Removed by Michael Hudson.)

   * *note xrange(): 45b. objects now have their own iterator, making
     ‘for i in xrange(n)’ slightly faster than ‘for i in range(n)’.
     (Patch by Raymond Hettinger.)

   * A number of small rearrangements have been made in various hotspots
     to improve performance, such as inlining a function or removing
     some code.  (Implemented mostly by GvR, but lots of people have
     contributed single changes.)

  The net result of the 2.3 optimizations is that Python 2.3 runs the
pystone benchmark around 25% faster than Python 2.2.


File: python.info,  Node: New Improved and Deprecated Modules<2>,  Next: Pymalloc A Specialized Object Allocator,  Prev: Other Language Changes<5>,  Up: What's New in Python 2 3

1.5.17 New, Improved, and Deprecated Modules
--------------------------------------------

As usual, Python’s standard library received a number of enhancements
and bug fixes.  Here’s a partial list of the most notable changes,
sorted alphabetically by module name.  Consult the ‘Misc/NEWS’ file in
the source tree for a more complete list of changes, or look through the
CVS logs for all the details.

   * The *note array: e. module now supports arrays of Unicode
     characters using the ‘'u'’ format character.  Arrays also now
     support using the ‘+=’ assignment operator to add another array’s
     contents, and the ‘*=’ assignment operator to repeat an array.
     (Contributed by Jason Orendorff.)

   * The *note bsddb: 1c. module has been replaced by version 4.1.6 of
     the PyBSDDB(1) package, providing a more complete interface to the
     transactional features of the BerkeleyDB library.

     The old version of the module has been renamed to ‘bsddb185’ and is
     no longer built automatically; you’ll have to edit ‘Modules/Setup’
     to enable it.  Note that the new *note bsddb: 1c. package is
     intended to be compatible with the old module, so be sure to file
     bugs if you discover any incompatibilities.  When upgrading to
     Python 2.3, if the new interpreter is compiled with a new version
     of the underlying BerkeleyDB library, you will almost certainly
     have to convert your database files to the new version.  You can do
     this fairly easily with the new scripts ‘db2pickle.py’ and
     ‘pickle2db.py’ which you will find in the distribution’s
     ‘Tools/scripts’ directory.  If you’ve already been using the
     PyBSDDB package and importing it as ‘bsddb3’, you will have to
     change your ‘import’ statements to import it as *note bsddb: 1c.

   * The new *note bz2: 1e. module is an interface to the bz2 data
     compression library.  bz2-compressed data is usually smaller than
     corresponding *note zlib: 1ad.-compressed data.  (Contributed by
     Gustavo Niemeyer.)

   * A set of standard date/time types has been added in the new *note
     datetime: 7d. module.  See the following section for more details.

   * The Distutils ‘Extension’ class now supports an extra constructor
     argument named _depends_ for listing additional source files that
     an extension depends on.  This lets Distutils recompile the module
     if any of the dependency files are modified.  For example, if
     ‘sampmodule.c’ includes the header file ‘sample.h’, you would
     create the ‘Extension’ object like this:

          ext = Extension("samp",
                          sources=["sampmodule.c"],
                          depends=["sample.h"])

     Modifying ‘sample.h’ would then cause the module to be recompiled.
     (Contributed by Jeremy Hylton.)

   * Other minor changes to Distutils: it now checks for the ‘CC’,
     ‘CFLAGS’, ‘CPP’, ‘LDFLAGS’, and ‘CPPFLAGS’ environment variables,
     using them to override the settings in Python’s configuration
     (contributed by Robert Weber).

   * Previously the *note doctest: b5. module would only search the
     docstrings of public methods and functions for test cases, but it
     now also examines private ones as well.  The ‘DocTestSuite(()’
     function creates a *note unittest.TestSuite: 45d. object from a set
     of *note doctest: b5. tests.

   * The new ‘gc.get_referents(object)()’ function returns a list of all
     the objects referenced by _object_.

   * The *note getopt: de. module gained a new function, ‘gnu_getopt()’,
     that supports the same arguments as the existing *note getopt():
     de. function but uses GNU-style scanning mode.  The existing *note
     getopt(): de. stops processing options as soon as a non-option
     argument is encountered, but in GNU-style mode processing
     continues, meaning that options and arguments can be mixed.  For
     example:

          >>> getopt.getopt(['-f', 'filename', 'output', '-v'], 'f:v')
          ([('-f', 'filename')], ['output', '-v'])
          >>> getopt.gnu_getopt(['-f', 'filename', 'output', '-v'], 'f:v')
          ([('-f', 'filename'), ('-v', '')], ['output'])

     (Contributed by Peter Åstrand.)

   * The *note grp: e4, *note pwd: 13c, and *note resource: 146. modules
     now return enhanced tuples:

          >>> import grp
          >>> g = grp.getgrnam('amk')
          >>> g.gr_name, g.gr_gid
          ('amk', 500)

   * The *note gzip: e5. module can now handle files exceeding 2 GiB.

   * The new *note heapq: e7. module contains an implementation of a
     heap queue algorithm.  A heap is an array-like data structure that
     keeps items in a partially sorted order such that, for every index
     _k_, ‘heap[k] <= heap[2*k+1]’ and ‘heap[k] <= heap[2*k+2]’.  This
     makes it quick to remove the smallest item, and inserting a new
     item while maintaining the heap property is O(lg n).  (See
     ‘http://www.nist.gov/dads/HTML/priorityque.html’ for more
     information about the priority queue data structure.)

     The *note heapq: e7. module provides ‘heappush()’ and ‘heappop()’
     functions for adding and removing items while maintaining the heap
     property on top of some other mutable Python sequence type.  Here’s
     an example that uses a Python list:

          >>> import heapq
          >>> heap = []
          >>> for item in [3, 7, 5, 11, 1]:
          ...    heapq.heappush(heap, item)
          ...
          >>> heap
          [1, 3, 5, 11, 7]
          >>> heapq.heappop(heap)
          1
          >>> heapq.heappop(heap)
          3
          >>> heap
          [5, 7, 11]

     (Contributed by Kevin O’Connor.)

   * The IDLE integrated development environment has been updated using
     the code from the IDLEfork project (‘http://idlefork.sf.net’).  The
     most notable feature is that the code being developed is now
     executed in a subprocess, meaning that there’s no longer any need
     for manual ‘reload()’ operations.  IDLE’s core code has been
     incorporated into the standard library as the ‘idlelib’ package.

   * The *note imaplib: f2. module now supports IMAP over SSL.
     (Contributed by Piers Lauder and Tino Lange.)

   * The *note itertools: fa. contains a number of useful functions for
     use with iterators, inspired by various functions provided by the
     ML and Haskell languages.  For example,
     ‘itertools.ifilter(predicate, iterator)’ returns all elements in
     the iterator for which the function ‘predicate()’ returns *note
     True: 3b0, and ‘itertools.repeat(obj, N)’ returns ‘obj’ _N_ times.
     There are a number of other functions in the module; see the
     package’s reference documentation for details.  (Contributed by
     Raymond Hettinger.)

   * Two new functions in the *note math: 10c. module, ‘degrees(rads)()’
     and ‘radians(degs)()’, convert between radians and degrees.  Other
     functions in the *note math: 10c. module such as *note math.sin():
     45e. and *note math.cos(): 45f. have always required input values
     measured in radians.  Also, an optional _base_ argument was added
     to *note math.log(): 460. to make it easier to compute logarithms
     for bases other than ‘e’ and ‘10’.  (Contributed by Raymond
     Hettinger.)

   * Several new POSIX functions (‘getpgid()’, ‘killpg()’, ‘lchown()’,
     ‘loadavg()’, ‘major()’, ‘makedev()’, ‘minor()’, and ‘mknod()’) were
     added to the *note posix: 136. module that underlies the *note os:
     128. module.  (Contributed by Gustavo Niemeyer, Geert Jansen, and
     Denis S. Otkidach.)

   * In the *note os: 128. module, the ‘*stat()’ family of functions can
     now report fractions of a second in a timestamp.  Such time stamps
     are represented as floats, similar to the value returned by *note
     time.time(): 461.

     During testing, it was found that some applications will break if
     time stamps are floats.  For compatibility, when using the tuple
     interface of the ‘stat_result’ time stamps will be represented as
     integers.  When using named fields (a feature first introduced in
     Python 2.2), time stamps are still represented as integers, unless
     *note os.stat_float_times(): 462. is invoked to enable float return
     values:

          >>> os.stat("/tmp").st_mtime
          1034791200
          >>> os.stat_float_times(True)
          >>> os.stat("/tmp").st_mtime
          1034791200.6335014

     In Python 2.4, the default will change to always returning floats.

     Application developers should enable this feature only if all their
     libraries work properly when confronted with floating point time
     stamps, or if they use the tuple API. If used, the feature should
     be activated on an application level instead of trying to enable it
     on a per-use basis.

   * The *note optparse: 127. module contains a new parser for
     command-line arguments that can convert option values to a
     particular Python type and will automatically generate a usage
     message.  See the following section for more details.

   * The old and never-documented ‘linuxaudiodev’ module has been
     deprecated, and a new version named *note ossaudiodev: 12a. has
     been added.  The module was renamed because the OSS sound drivers
     can be used on platforms other than Linux, and the interface has
     also been tidied and brought up to date in various ways.
     (Contributed by Greg Ward and Nicholas FitzRoy-Dale.)

   * The new *note platform: 132. module contains a number of functions
     that try to determine various properties of the platform you’re
     running on.  There are functions for getting the architecture, CPU
     type, the Windows OS version, and even the Linux distribution
     version.  (Contributed by Marc-André Lemburg.)

   * The parser objects provided by the ‘pyexpat’ module can now
     optionally buffer character data, resulting in fewer calls to your
     character data handler and therefore faster performance.  Setting
     the parser object’s ‘buffer_text’ attribute to *note True: 3b0.
     will enable buffering.

   * The ‘sample(population, k)()’ function was added to the *note
     random: 142. module.  _population_ is a sequence or *note xrange:
     45b. object containing the elements of a population, and ‘sample()’
     chooses _k_ elements from the population without replacing chosen
     elements.  _k_ can be any value up to ‘len(population)’.  For
     example:

          >>> days = ['Mo', 'Tu', 'We', 'Th', 'Fr', 'St', 'Sn']
          >>> random.sample(days, 3)      # Choose 3 elements
          ['St', 'Sn', 'Th']
          >>> random.sample(days, 7)      # Choose 7 elements
          ['Tu', 'Th', 'Mo', 'We', 'St', 'Fr', 'Sn']
          >>> random.sample(days, 7)      # Choose 7 again
          ['We', 'Mo', 'Sn', 'Fr', 'Tu', 'St', 'Th']
          >>> random.sample(days, 8)      # Can't choose eight
          Traceback (most recent call last):
            File "<stdin>", line 1, in ?
            File "random.py", line 414, in sample
                raise ValueError, "sample larger than population"
          ValueError: sample larger than population
          >>> random.sample(xrange(1,10000,2), 10)   # Choose ten odd nos. under 10000
          [3407, 3805, 1505, 7023, 2401, 2267, 9733, 3151, 8083, 9195]

     The *note random: 142. module now uses a new algorithm, the
     Mersenne Twister, implemented in C. It’s faster and more
     extensively studied than the previous algorithm.

     (All changes contributed by Raymond Hettinger.)

   * The *note readline: 144. module also gained a number of new
     functions: ‘get_history_item()’, ‘get_current_history_length()’,
     and ‘redisplay()’.

   * The *note rexec: 147. and *note Bastion: 17. modules have been
     declared dead, and attempts to import them will fail with a *note
     RuntimeError: 39b.  New-style classes provide new ways to break out
     of the restricted execution environment provided by *note rexec:
     147, and no one has interest in fixing them or time to do so.  If
     you have applications using *note rexec: 147, rewrite them to use
     something else.

     (Sticking with Python 2.2 or 2.1 will not make your applications
     any safer because there are known bugs in the *note rexec: 147.
     module in those versions.  To repeat: if you’re using *note rexec:
     147, stop using it immediately.)

   * The ‘rotor’ module has been deprecated because the algorithm it
     uses for encryption is not believed to be secure.  If you need
     encryption, use one of the several AES Python modules that are
     available separately.

   * The *note shutil: 154. module gained a ‘move(src, dest)()’ function
     that recursively moves a file or directory to a new location.

   * Support for more advanced POSIX signal handling was added to the
     *note signal: 155. but then removed again as it proved impossible
     to make it work reliably across platforms.

   * The *note socket: 15c. module now supports timeouts.  You can call
     the ‘settimeout(t)()’ method on a socket object to set a timeout of
     _t_ seconds.  Subsequent socket operations that take longer than
     _t_ seconds to complete will abort and raise a *note
     socket.timeout: 463. exception.

     The original timeout implementation was by Tim O’Malley.  Michael
     Gilfix integrated it into the Python *note socket: 15c. module and
     shepherded it through a lengthy review.  After the code was checked
     in, Guido van Rossum rewrote parts of it.  (This is a good example
     of a collaborative development process in action.)

   * On Windows, the *note socket: 15c. module now ships with Secure
     Sockets Layer (SSL) support.

   * The value of the C ‘PYTHON_API_VERSION’ macro is now exposed at the
     Python level as ‘sys.api_version’.  The current exception can be
     cleared by calling the new *note sys.exc_clear(): 464. function.

   * The new *note tarfile: 171. module allows reading from and writing
     to *tar*-format archive files.  (Contributed by Lars Gustäbel.)

   * The new *note textwrap: 177. module contains functions for wrapping
     strings containing paragraphs of text.  The ‘wrap(text, width)()’
     function takes a string and returns a list containing the text
     split into lines of no more than the chosen width.  The ‘fill(text,
     width)()’ function returns a single string, reformatted to fit into
     lines no longer than the chosen width.  (As you can guess, ‘fill()’
     is built on top of ‘wrap()’.  For example:

          >>> import textwrap
          >>> paragraph = "Not a whit, we defy augury: ... more text ..."
          >>> textwrap.wrap(paragraph, 60)
          ["Not a whit, we defy augury: there's a special providence in",
           "the fall of a sparrow. If it be now, 'tis not to come; if it",
           ...]
          >>> print textwrap.fill(paragraph, 35)
          Not a whit, we defy augury: there's
          a special providence in the fall of
          a sparrow. If it be now, 'tis not
          to come; if it be not to come, it
          will be now; if it be not now, yet
          it will come: the readiness is all.
          >>>

     The module also contains a ‘TextWrapper’ class that actually
     implements the text wrapping strategy.  Both the ‘TextWrapper’
     class and the ‘wrap()’ and ‘fill()’ functions support a number of
     additional keyword arguments for fine-tuning the formatting;
     consult the module’s documentation for details.  (Contributed by
     Greg Ward.)

   * The *note thread: 178. and *note threading: 179. modules now have
     companion modules, *note dummy_thread: b8. and *note
     dummy_threading: b9, that provide a do-nothing implementation of
     the *note thread: 178. module’s interface for platforms where
     threads are not supported.  The intention is to simplify
     thread-aware modules (ones that _don’t_ rely on threads to run) by
     putting the following code at the top:

          try:
              import threading as _threading
          except ImportError:
              import dummy_threading as _threading

     In this example, ‘_threading’ is used as the module name to make it
     clear that the module being used is not necessarily the actual
     *note threading: 179. module.  Code can call functions and use
     classes in ‘_threading’ whether or not threads are supported,
     avoiding an *note if: 42c. statement and making the code slightly
     clearer.  This module will not magically make multithreaded code
     run without threads; code that waits for another thread to return
     or to do something will simply hang forever.

   * The *note time: 17a. module’s ‘strptime()’ function has long been
     an annoyance because it uses the platform C library’s ‘strptime()’
     implementation, and different platforms sometimes have odd bugs.
     Brett Cannon contributed a portable implementation that’s written
     in pure Python and should behave identically on all platforms.

   * The new *note timeit: 17b. module helps measure how long snippets
     of Python code take to execute.  The ‘timeit.py’ file can be run
     directly from the command line, or the module’s ‘Timer’ class can
     be imported and used directly.  Here’s a short example that figures
     out whether it’s faster to convert an 8-bit string to Unicode by
     appending an empty Unicode string to it or by using the *note
     unicode(): 1f5. function:

          import timeit

          timer1 = timeit.Timer('unicode("abc")')
          timer2 = timeit.Timer('"abc" + u""')

          # Run three trials
          print timer1.repeat(repeat=3, number=100000)
          print timer2.repeat(repeat=3, number=100000)

          # On my laptop this outputs:
          # [0.36831796169281006, 0.37441694736480713, 0.35304892063140869]
          # [0.17574405670166016, 0.18193507194519043, 0.17565798759460449]

   * The *note Tix: 17c. module has received various bug fixes and
     updates for the current version of the Tix package.

   * The *note Tkinter: 17d. module now works with a thread-enabled
     version of Tcl.  Tcl’s threading model requires that widgets only
     be accessed from the thread in which they’re created; accesses from
     another thread can cause Tcl to panic.  For certain Tcl interfaces,
     *note Tkinter: 17d. will now automatically avoid this when a widget
     is accessed from a different thread by marshalling a command,
     passing it to the correct thread, and waiting for the results.
     Other interfaces can’t be handled automatically but *note Tkinter:
     17d. will now raise an exception on such an access so that you can
     at least find out about the problem.  See
     ‘http://mail.python.org/pipermail/python-dev/2002-December/031107.html’
     for a more detailed explanation of this change.  (Implemented by
     Martin von Löwis.)

   * Calling Tcl methods through ‘_tkinter’ no longer returns only
     strings.  Instead, if Tcl returns other objects those objects are
     converted to their Python equivalent, if one exists, or wrapped
     with a ‘_tkinter.Tcl_Obj’ object if no Python equivalent exists.
     This behavior can be controlled through the ‘wantobjects()’ method
     of ‘tkapp’ objects.

     When using ‘_tkinter’ through the *note Tkinter: 17d. module (as
     most Tkinter applications will), this feature is always activated.
     It should not cause compatibility problems, since Tkinter would
     always convert string results to Python types where possible.

     If any incompatibilities are found, the old behavior can be
     restored by setting the ‘wantobjects’ variable in the *note
     Tkinter: 17d. module to false before creating the first ‘tkapp’
     object.

          import Tkinter
          Tkinter.wantobjects = 0

     Any breakage caused by this change should be reported as a bug.

   * The *note UserDict: 18c. module has a new ‘DictMixin’ class which
     defines all dictionary methods for classes that already have a
     minimum mapping interface.  This greatly simplifies writing classes
     that need to be substitutable for dictionaries, such as the classes
     in the *note shelve: 152. module.

     Adding the mix-in as a superclass provides the full dictionary
     interface whenever the class defines *note __getitem__(): 44f,
     *note __setitem__(): 465, *note __delitem__(): 466, and ‘keys()’.
     For example:

          >>> import UserDict
          >>> class SeqDict(UserDict.DictMixin):
          ...     """Dictionary lookalike implemented with lists."""
          ...     def __init__(self):
          ...         self.keylist = []
          ...         self.valuelist = []
          ...     def __getitem__(self, key):
          ...         try:
          ...             i = self.keylist.index(key)
          ...         except ValueError:
          ...             raise KeyError
          ...         return self.valuelist[i]
          ...     def __setitem__(self, key, value):
          ...         try:
          ...             i = self.keylist.index(key)
          ...             self.valuelist[i] = value
          ...         except ValueError:
          ...             self.keylist.append(key)
          ...             self.valuelist.append(value)
          ...     def __delitem__(self, key):
          ...         try:
          ...             i = self.keylist.index(key)
          ...         except ValueError:
          ...             raise KeyError
          ...         self.keylist.pop(i)
          ...         self.valuelist.pop(i)
          ...     def keys(self):
          ...         return list(self.keylist)
          ...
          >>> s = SeqDict()
          >>> dir(s)      # See that other dictionary methods are implemented
          ['__cmp__', '__contains__', '__delitem__', '__doc__', '__getitem__',
           '__init__', '__iter__', '__len__', '__module__', '__repr__',
           '__setitem__', 'clear', 'get', 'has_key', 'items', 'iteritems',
           'iterkeys', 'itervalues', 'keylist', 'keys', 'pop', 'popitem',
           'setdefault', 'update', 'valuelist', 'values']

     (Contributed by Raymond Hettinger.)

   * The DOM implementation in *note xml.dom.minidom: 1a2. can now
     generate XML output in a particular encoding by providing an
     optional encoding argument to the ‘toxml()’ and ‘toprettyxml()’
     methods of DOM nodes.

   * The *note xmlrpclib: 1aa. module now supports an XML-RPC extension
     for handling nil data values such as Python’s ‘None’.  Nil values
     are always supported on unmarshalling an XML-RPC response.  To
     generate requests containing ‘None’, you must supply a true value
     for the _allow_none_ parameter when creating a ‘Marshaller’
     instance.

   * The new *note DocXMLRPCServer: b6. module allows writing
     self-documenting XML-RPC servers.  Run it in demo mode (as a
     program) to see it in action.  Pointing the Web browser to the RPC
     server produces pydoc-style documentation; pointing xmlrpclib to
     the server allows invoking the actual methods.  (Contributed by
     Brian Quinlan.)

   * Support for internationalized domain names (RFCs 3454, 3490, 3491,
     and 3492) has been added.  The "idna" encoding can be used to
     convert between a Unicode domain name and the ASCII-compatible
     encoding (ACE) of that name.

          >{}>{}> u"www.Alliancefrançaise.nu".encode("idna")
          'www.xn--alliancefranaise-npb.nu'

     The *note socket: 15c. module has also been extended to
     transparently convert Unicode hostnames to the ACE version before
     passing them to the C library.  Modules that deal with hostnames
     such as *note httplib: ee. and *note ftplib: d8.) also support
     Unicode host names; *note httplib: ee. also sends HTTP ‘Host’
     headers using the ACE version of the domain name.  *note urllib:
     188. supports Unicode URLs with non-ASCII host names as long as the
     ‘path’ part of the URL is ASCII only.

     To implement this change, the *note stringprep: 165. module, the
     ‘mkstringprep’ tool and the ‘punycode’ encoding have been added.

* Menu:

* Date/Time Type:: 
* The optparse Module:: 

   ---------- Footnotes ----------

   (1) http://pybsddb.sourceforge.net


File: python.info,  Node: Date/Time Type,  Next: The optparse Module,  Up: New Improved and Deprecated Modules<2>

1.5.17.1 Date/Time Type
.......................

Date and time types suitable for expressing timestamps were added as the
*note datetime: 7d. module.  The types don’t support different calendars
or many fancy features, and just stick to the basics of representing
time.

  The three primary types are: ‘date’, representing a day, month, and
year; *note time: 17a, consisting of hour, minute, and second; and *note
datetime: 7d, which contains all the attributes of both ‘date’ and *note
time: 17a.  There’s also a ‘timedelta’ class representing differences
between two points in time, and time zone logic is implemented by
classes inheriting from the abstract ‘tzinfo’ class.

  You can create instances of ‘date’ and *note time: 17a. by either
supplying keyword arguments to the appropriate constructor, e.g.
‘datetime.date(year=1972, month=10, day=15)’, or by using one of a
number of class methods.  For example, the ‘date.today()’ class method
returns the current local date.

  Once created, instances of the date/time classes are all immutable.
There are a number of methods for producing formatted strings from
objects:

     >>> import datetime
     >>> now = datetime.datetime.now()
     >>> now.isoformat()
     '2002-12-30T21:27:03.994956'
     >>> now.ctime()  # Only available on date, datetime
     'Mon Dec 30 21:27:03 2002'
     >>> now.strftime('%Y %d %b')
     '2002 30 Dec'

  The ‘replace()’ method allows modifying one or more fields of a ‘date’
or *note datetime: 7d. instance, returning a new instance:

     >>> d = datetime.datetime.now()
     >>> d
     datetime.datetime(2002, 12, 30, 22, 15, 38, 827738)
     >>> d.replace(year=2001, hour = 12)
     datetime.datetime(2001, 12, 30, 12, 15, 38, 827738)
     >>>

  Instances can be compared, hashed, and converted to strings (the
result is the same as that of ‘isoformat()’).  ‘date’ and *note
datetime: 7d. instances can be subtracted from each other, and added to
‘timedelta’ instances.  The largest missing feature is that there’s no
standard library support for parsing strings and getting back a ‘date’
or *note datetime: 7d.

  For more information, refer to the module’s reference documentation.
(Contributed by Tim Peters.)


File: python.info,  Node: The optparse Module,  Prev: Date/Time Type,  Up: New Improved and Deprecated Modules<2>

1.5.17.2 The optparse Module
............................

The *note getopt: de. module provides simple parsing of command-line
arguments.  The new *note optparse: 127. module (originally named Optik)
provides more elaborate command-line parsing that follows the Unix
conventions, automatically creates the output for *note –help: 1d5, and
can perform different actions for different options.

  You start by creating an instance of ‘OptionParser’ and telling it
what your program’s options are.

     import sys
     from optparse import OptionParser

     op = OptionParser()
     op.add_option('-i', '--input',
                   action='store', type='string', dest='input',
                   help='set input filename')
     op.add_option('-l', '--length',
                   action='store', type='int', dest='length',
                   help='set maximum length of output')

  Parsing a command line is then done by calling the ‘parse_args()’
method.

     options, args = op.parse_args(sys.argv[1:])
     print options
     print args

  This returns an object containing all of the option values, and a list
of strings containing the remaining arguments.

  Invoking the script with the various arguments now works as you’d
expect it to.  Note that the length argument is automatically converted
to an integer.

     $ ./python opt.py -i data arg1
     <Values at 0x400cad4c: {'input': 'data', 'length': None}>
     ['arg1']
     $ ./python opt.py --input=data --length=4
     <Values at 0x400cad2c: {'input': 'data', 'length': 4}>
     []
     $

  The help message is automatically generated for you:

     $ ./python opt.py --help
     usage: opt.py [options]

     options:
       -h, --help            show this help message and exit
       -iINPUT, --input=INPUT
                             set input filename
       -lLENGTH, --length=LENGTH
                             set maximum length of output
     $

  See the module’s documentation for more details.

  Optik was written by Greg Ward, with suggestions from the readers of
the Getopt SIG.


File: python.info,  Node: Pymalloc A Specialized Object Allocator,  Next: Build and C API Changes<5>,  Prev: New Improved and Deprecated Modules<2>,  Up: What's New in Python 2 3

1.5.18 Pymalloc: A Specialized Object Allocator
-----------------------------------------------

Pymalloc, a specialized object allocator written by Vladimir Marangozov,
was a feature added to Python 2.1.  Pymalloc is intended to be faster
than the system ‘malloc()’ and to have less memory overhead for
allocation patterns typical of Python programs.  The allocator uses C’s
‘malloc()’ function to get large pools of memory and then fulfills
smaller memory requests from these pools.

  In 2.1 and 2.2, pymalloc was an experimental feature and wasn’t
enabled by default; you had to explicitly enable it when compiling
Python by providing the ‘--with-pymalloc’ option to the *configure*
script.  In 2.3, pymalloc has had further enhancements and is now
enabled by default; you’ll have to supply ‘--without-pymalloc’ to
disable it.

  This change is transparent to code written in Python; however,
pymalloc may expose bugs in C extensions.  Authors of C extension
modules should test their code with pymalloc enabled, because some
incorrect code may cause core dumps at runtime.

  There’s one particularly common error that causes problems.  There are
a number of memory allocation functions in Python’s C API that have
previously just been aliases for the C library’s ‘malloc()’ and
‘free()’, meaning that if you accidentally called mismatched functions
the error wouldn’t be noticeable.  When the object allocator is enabled,
these functions aren’t aliases of ‘malloc()’ and ‘free()’ any more, and
calling the wrong function to free memory may get you a core dump.  For
example, if memory was allocated using ‘PyObject_Malloc()’, it has to be
freed using ‘PyObject_Free()’, not ‘free()’.  A few modules included
with Python fell afoul of this and had to be fixed; doubtless there are
more third-party modules that will have the same problem.

  As part of this change, the confusing multiple interfaces for
allocating memory have been consolidated down into two API families.
Memory allocated with one family must not be manipulated with functions
from the other family.  There is one family for allocating chunks of
memory and another family of functions specifically for allocating
Python objects.

   * To allocate and free an undistinguished chunk of memory use the
     "raw memory" family: *note PyMem_Malloc(): 3dd, *note
     PyMem_Realloc(): 3de, and *note PyMem_Free(): 3df.

   * The "object memory" family is the interface to the pymalloc
     facility described above and is biased towards a large number of
     "small" allocations: ‘PyObject_Malloc()’, ‘PyObject_Realloc()’, and
     ‘PyObject_Free()’.

   * To allocate and free Python objects, use the "object" family *note
     PyObject_New(): 46b, *note PyObject_NewVar(): 46c, and *note
     PyObject_Del(): 46d.

  Thanks to lots of work by Tim Peters, pymalloc in 2.3 also provides
debugging features to catch memory overwrites and doubled frees in both
extension modules and in the interpreter itself.  To enable this
support, compile a debugging version of the Python interpreter by
running *configure* with ‘--with-pydebug’.

  To aid extension writers, a header file ‘Misc/pymemcompat.h’ is
distributed with the source to Python 2.3 that allows Python extensions
to use the 2.3 interfaces to memory allocation while compiling against
any version of Python since 1.5.2.  You would copy the file from
Python’s source distribution and bundle it with the source of your
extension.

See also
........

‘http://svn.python.org/view/python/trunk/Objects/obmalloc.c’

     For the full details of the pymalloc implementation, see the
     comments at the top of the file ‘Objects/obmalloc.c’ in the Python
     source code.  The above link points to the file within the
     python.org SVN browser.


File: python.info,  Node: Build and C API Changes<5>,  Next: Other Changes and Fixes<2>,  Prev: Pymalloc A Specialized Object Allocator,  Up: What's New in Python 2 3

1.5.19 Build and C API Changes
------------------------------

Changes to Python’s build process and to the C API include:

   * The cycle detection implementation used by the garbage collection
     has proven to be stable, so it’s now been made mandatory.  You can
     no longer compile Python without it, and the ‘--with-cycle-gc’
     switch to *configure* has been removed.

   * Python can now optionally be built as a shared library
     (‘libpython2.3.so’) by supplying ‘--enable-shared’ when running
     Python’s *configure* script.  (Contributed by Ondrej Palkovsky.)

   * The ‘DL_EXPORT’ and ‘DL_IMPORT’ macros are now deprecated.
     Initialization functions for Python extension modules should now be
     declared using the new macro ‘PyMODINIT_FUNC’, while the Python
     core will generally use the ‘PyAPI_FUNC’ and ‘PyAPI_DATA’ macros.

   * The interpreter can be compiled without any docstrings for the
     built-in functions and modules by supplying ‘--without-doc-strings’
     to the *configure* script.  This makes the Python executable about
     10% smaller, but will also mean that you can’t get help for
     Python’s built-ins.  (Contributed by Gustavo Niemeyer.)

   * The ‘PyArg_NoArgs()’ macro is now deprecated, and code that uses it
     should be changed.  For Python 2.2 and later, the method definition
     table can specify the *note METH_NOARGS: 46f. flag, signalling that
     there are no arguments, and the argument checking can then be
     removed.  If compatibility with pre-2.2 versions of Python is
     important, the code could use ‘PyArg_ParseTuple(args, "")’ instead,
     but this will be slower than using *note METH_NOARGS: 46f.

   * *note PyArg_ParseTuple(): 31b. accepts new format characters for
     various sizes of unsigned integers: ‘B’ for ‘unsigned char’, ‘H’
     for ‘unsigned short int’, ‘I’ for ‘unsigned int’, and ‘K’ for
     ‘unsigned long long’.

   * A new function, ‘PyObject_DelItemString(mapping, char *key)()’ was
     added as shorthand for ‘PyObject_DelItem(mapping,
     PyString_New(key))’.

   * File objects now manage their internal string buffer differently,
     increasing it exponentially when needed.  This results in the
     benchmark tests in ‘Lib/test/test_bufio.py’ speeding up
     considerably (from 57 seconds to 1.7 seconds, according to one
     measurement).

   * It’s now possible to define class and static methods for a C
     extension type by setting either the *note METH_CLASS: 470. or
     *note METH_STATIC: 471. flags in a method’s *note PyMethodDef: 472.
     structure.

   * Python now includes a copy of the Expat XML parser’s source code,
     removing any dependence on a system version or local installation
     of Expat.

   * If you dynamically allocate type objects in your extension, you
     should be aware of a change in the rules relating to the
     ‘__module__’ and ‘__name__’ attributes.  In summary, you will want
     to ensure the type’s dictionary contains a ‘'__module__'’ key;
     making the module name the part of the type name leading up to the
     final period will no longer have the desired effect.  For more
     detail, read the API reference documentation or the source.

* Menu:

* Port-Specific Changes: Port-Specific Changes<3>. 


File: python.info,  Node: Port-Specific Changes<3>,  Up: Build and C API Changes<5>

1.5.19.1 Port-Specific Changes
..............................

Support for a port to IBM’s OS/2 using the EMX runtime environment was
merged into the main Python source tree.  EMX is a POSIX emulation layer
over the OS/2 system APIs.  The Python port for EMX tries to support all
the POSIX-like capability exposed by the EMX runtime, and mostly
succeeds; ‘fork()’ and *note fcntl(): ca. are restricted by the
limitations of the underlying emulation layer.  The standard OS/2 port,
which uses IBM’s Visual Age compiler, also gained support for
case-sensitive import semantics as part of the integration of the EMX
port into CVS. (Contributed by Andrew MacIntyre.)

  On MacOS, most toolbox modules have been weaklinked to improve
backward compatibility.  This means that modules will no longer fail to
load if a single routine is missing on the current OS version.  Instead
calling the missing routine will raise an exception.  (Contributed by
Jack Jansen.)

  The RPM spec files, found in the ‘Misc/RPM/’ directory in the Python
source distribution, were updated for 2.3.  (Contributed by Sean
Reifschneider.)

  Other new platforms now supported by Python include AtheOS
(‘http://www.atheos.cx/’), GNU/Hurd, and OpenVMS.


File: python.info,  Node: Other Changes and Fixes<2>,  Next: Porting to Python 2 3,  Prev: Build and C API Changes<5>,  Up: What's New in Python 2 3

1.5.20 Other Changes and Fixes
------------------------------

As usual, there were a bunch of other improvements and bugfixes
scattered throughout the source tree.  A search through the CVS change
logs finds there were 523 patches applied and 514 bugs fixed between
Python 2.2 and 2.3.  Both figures are likely to be underestimates.

  Some of the more notable changes are:

   * If the *note PYTHONINSPECT: 475. environment variable is set, the
     Python interpreter will enter the interactive prompt after running
     a Python program, as if Python had been invoked with the *note -i:
     476. option.  The environment variable can be set before running
     the Python interpreter, or it can be set by the Python program as
     part of its execution.

   * The ‘regrtest.py’ script now provides a way to allow "all resources
     except _foo_."  A resource name passed to the *note -u: 477. option
     can now be prefixed with a hyphen (‘'-'’) to mean "remove this
     resource."  For example, the option ’‘-uall,-bsddb’’ could be used
     to enable the use of all resources except ‘bsddb’.

   * The tools used to build the documentation now work under Cygwin as
     well as Unix.

   * The ‘SET_LINENO’ opcode has been removed.  Back in the mists of
     time, this opcode was needed to produce line numbers in tracebacks
     and support trace functions (for, e.g., *note pdb: 12c.).  Since
     Python 1.5, the line numbers in tracebacks have been computed using
     a different mechanism that works with "python -O". For Python 2.3
     Michael Hudson implemented a similar scheme to determine when to
     call the trace function, removing the need for ‘SET_LINENO’
     entirely.

     It would be difficult to detect any resulting difference from
     Python code, apart from a slight speed up when Python is run
     without *note -O: 453.

     C extensions that access the ‘f_lineno’ field of frame objects
     should instead call ‘PyCode_Addr2Line(f->f_code, f->f_lasti)’.
     This will have the added effect of making the code work as desired
     under "python -O" in earlier versions of Python.

     A nifty new feature is that trace functions can now assign to the
     ‘f_lineno’ attribute of frame objects, changing the line that will
     be executed next.  A ‘jump’ command has been added to the *note
     pdb: 12c. debugger taking advantage of this new feature.
     (Implemented by Richie Hindle.)


File: python.info,  Node: Porting to Python 2 3,  Next: Acknowledgements<5>,  Prev: Other Changes and Fixes<2>,  Up: What's New in Python 2 3

1.5.21 Porting to Python 2.3
----------------------------

This section lists previously described changes that may require changes
to your code:

   * *note yield: 2f7. is now always a keyword; if it’s used as a
     variable name in your code, a different name must be chosen.

   * For strings _X_ and _Y_, ‘X in Y’ now works if _X_ is more than one
     character long.

   * The *note int(): 1f2. type constructor will now return a long
     integer instead of raising an *note OverflowError: 2db. when a
     string or floating-point number is too large to fit into an
     integer.

   * If you have Unicode strings that contain 8-bit characters, you must
     declare the file’s encoding (UTF-8, Latin-1, or whatever) by adding
     a comment to the top of the file.  See section *note PEP 263;
     Source Code Encodings: 42d. for more information.

   * Calling Tcl methods through ‘_tkinter’ no longer returns only
     strings.  Instead, if Tcl returns other objects those objects are
     converted to their Python equivalent, if one exists, or wrapped
     with a ‘_tkinter.Tcl_Obj’ object if no Python equivalent exists.

   * Large octal and hex literals such as ‘0xffffffff’ now trigger a
     *note FutureWarning: 2b4.  Currently they’re stored as 32-bit
     numbers and result in a negative value, but in Python 2.4 they’ll
     become positive long integers.

     There are a few ways to fix this warning.  If you really need a
     positive number, just add an ‘L’ to the end of the literal.  If
     you’re trying to get a 32-bit integer with low bits set and have
     previously used an expression such as ‘~(1 << 31)’, it’s probably
     clearest to start with all bits set and clear the desired upper
     bits.  For example, to clear just the top bit (bit 31), you could
     write ‘0xffffffffL &~(1L<<31)’.

   * You can no longer disable assertions by assigning to ‘__debug__’.

   * The Distutils ‘setup()’ function has gained various new keyword
     arguments such as _depends_.  Old versions of the Distutils will
     abort if passed unknown keywords.  A solution is to check for the
     presence of the new ‘get_distutil_options()’ function in your
     ‘setup.py’ and only uses the new keywords with a version of the
     Distutils that supports them:

          from distutils import core

          kw = {'sources': 'foo.c', ...}
          if hasattr(core, 'get_distutil_options'):
              kw['depends'] = ['foo.h']
          ext = Extension(**kw)

   * Using ‘None’ as a variable name will now result in a *note
     SyntaxWarning: 455. warning.

   * Names of extension types defined by the modules included with
     Python now contain the module and a ‘'.'’ in front of the type
     name.


File: python.info,  Node: Acknowledgements<5>,  Prev: Porting to Python 2 3,  Up: What's New in Python 2 3

1.5.22 Acknowledgements
-----------------------

The author would like to thank the following people for offering
suggestions, corrections and assistance with various drafts of this
article: Jeff Bauer, Simon Brunning, Brett Cannon, Michael Chermside,
Andrew Dalke, Scott David Daniels, Fred L. Drake, Jr., David Fraser,
Kelly Gerber, Raymond Hettinger, Michael Hudson, Chris Lambert, Detlef
Lannert, Martin von Löwis, Andrew MacIntyre, Lalo Martins, Chad Netzer,
Gustavo Niemeyer, Neal Norwitz, Hans Nowak, Chris Reedy, Francesco
Ricciardi, Vinay Sajip, Neil Schemenauer, Roman Suzi, Jason Tishler,
Just van Rossum.


File: python.info,  Node: What's New in Python 2 2,  Next: What's New in Python 2 1,  Prev: What's New in Python 2 3,  Up: What's New in Python

1.6 What’s New in Python 2.2
============================

     Author: A.M. Kuchling

* Menu:

* Introduction:: 
* PEPs 252 and 253; Type and Class Changes: PEPs 252 and 253 Type and Class Changes. 
* PEP 234; Iterators: PEP 234 Iterators. 
* PEP 255; Simple Generators: PEP 255 Simple Generators<2>. 
* PEP 237; Unifying Long Integers and Integers: PEP 237 Unifying Long Integers and Integers<2>. 
* PEP 238; Changing the Division Operator: PEP 238 Changing the Division Operator. 
* Unicode Changes:: 
* PEP 227; Nested Scopes: PEP 227 Nested Scopes. 
* New and Improved Modules: New and Improved Modules<3>. 
* Interpreter Changes and Fixes:: 
* Other Changes and Fixes: Other Changes and Fixes<3>. 
* Acknowledgements: Acknowledgements<6>. 


File: python.info,  Node: Introduction,  Next: PEPs 252 and 253 Type and Class Changes,  Up: What's New in Python 2 2

1.6.1 Introduction
------------------

This article explains the new features in Python 2.2.2, released on
October 14, 2002.  Python 2.2.2 is a bugfix release of Python 2.2,
originally released on December 21, 2001.

  Python 2.2 can be thought of as the "cleanup release".  There are some
features such as generators and iterators that are completely new, but
most of the changes, significant and far-reaching though they may be,
are aimed at cleaning up irregularities and dark corners of the language
design.

  This article doesn’t attempt to provide a complete specification of
the new features, but instead provides a convenient overview.  For full
details, you should refer to the documentation for Python 2.2, such as
the Python Library Reference(1) and the Python Reference Manual(2).  If
you want to understand the complete implementation and design rationale
for a change, refer to the PEP for a particular new feature.

   ---------- Footnotes ----------

   (1) http://www.python.org/doc/2.2/lib/lib.html

   (2) http://www.python.org/doc/2.2/ref/ref.html


File: python.info,  Node: PEPs 252 and 253 Type and Class Changes,  Next: PEP 234 Iterators,  Prev: Introduction,  Up: What's New in Python 2 2

1.6.2 PEPs 252 and 253: Type and Class Changes
----------------------------------------------

The largest and most far-reaching changes in Python 2.2 are to Python’s
model of objects and classes.  The changes should be backward
compatible, so it’s likely that your code will continue to run
unchanged, but the changes provide some amazing new capabilities.
Before beginning this, the longest and most complicated section of this
article, I’ll provide an overview of the changes and offer some
comments.

  A long time ago I wrote a Web page listing flaws in Python’s design.
One of the most significant flaws was that it’s impossible to subclass
Python types implemented in C. In particular, it’s not possible to
subclass built-in types, so you can’t just subclass, say, lists in order
to add a single useful method to them.  The *note UserList: 18d. module
provides a class that supports all of the methods of lists and that can
be subclassed further, but there’s lots of C code that expects a regular
Python list and won’t accept a *note UserList: 18d. instance.

  Python 2.2 fixes this, and in the process adds some exciting new
capabilities.  A brief summary:

   * You can subclass built-in types such as lists and even integers,
     and your subclasses should work in every place that requires the
     original type.

   * It’s now possible to define static and class methods, in addition
     to the instance methods available in previous versions of Python.

   * It’s also possible to automatically call methods on accessing or
     setting an instance attribute by using a new mechanism called
     _properties_.  Many uses of *note __getattr__(): 331. can be
     rewritten to use properties instead, making the resulting code
     simpler and faster.  As a small side benefit, attributes can now
     have docstrings, too.

   * The list of legal attributes for an instance can be limited to a
     particular set using _slots_, making it possible to safeguard
     against typos and perhaps make more optimizations possible in
     future versions of Python.

  Some users have voiced concern about all these changes.  Sure, they
say, the new features are neat and lend themselves to all sorts of
tricks that weren’t possible in previous versions of Python, but they
also make the language more complicated.  Some people have said that
they’ve always recommended Python for its simplicity, and feel that its
simplicity is being lost.

  Personally, I think there’s no need to worry.  Many of the new
features are quite esoteric, and you can write a lot of Python code
without ever needed to be aware of them.  Writing a simple class is no
more difficult than it ever was, so you don’t need to bother learning or
teaching them unless they’re actually needed.  Some very complicated
tasks that were previously only possible from C will now be possible in
pure Python, and to my mind that’s all for the better.

  I’m not going to attempt to cover every single corner case and small
change that were required to make the new features work.  Instead this
section will paint only the broad strokes.  See section *note Related
Links: 47f, "Related Links", for further sources of information about
Python 2.2’s new object model.

* Menu:

* Old and New Classes:: 
* Descriptors:: 
* Multiple Inheritance; The Diamond Rule: Multiple Inheritance The Diamond Rule. 
* Attribute Access:: 
* Related Links:: 


File: python.info,  Node: Old and New Classes,  Next: Descriptors,  Up: PEPs 252 and 253 Type and Class Changes

1.6.2.1 Old and New Classes
...........................

First, you should know that Python 2.2 really has two kinds of classes:
classic or old-style classes, and new-style classes.  The old-style
class model is exactly the same as the class model in earlier versions
of Python.  All the new features described in this section apply only to
new-style classes.  This divergence isn’t intended to last forever;
eventually old-style classes will be dropped, possibly in Python 3.0.

  So how do you define a new-style class?  You do it by subclassing an
existing new-style class.  Most of Python’s built-in types, such as
integers, lists, dictionaries, and even files, are new-style classes
now.  A new-style class named *note object: 1f1, the base class for all
built-in types, has also been added so if no built-in type is suitable,
you can just subclass *note object: 1f1.:

     class C(object):
         def __init__ (self):
             ...
         ...

  This means that *note class: 33d. statements that don’t have any base
classes are always classic classes in Python 2.2.  (Actually you can
also change this by setting a module-level variable named *note
__metaclass__: 481. — see PEP 253(1) for the details — but it’s easier
to just subclass *note object: 482.)

  The type objects for the built-in types are available as built-ins,
named using a clever trick.  Python has always had built-in functions
named *note int(): 1f2, *note float(): 1eb, and *note str(): 1ea.  In
2.2, they aren’t functions any more, but type objects that behave as
factories when called.

     >>> int
     <type 'int'>
     >>> int('123')
     123

  To make the set of types complete, new type objects such as *note
dict(): 305. and *note file(): 1f9. have been added.  Here’s a more
interesting example, adding a ‘lock()’ method to file objects:

     class LockableFile(file):
         def lock (self, operation, length=0, start=0, whence=0):
             import fcntl
             return fcntl.lockf(self.fileno(), operation,
                                length, start, whence)

  The now-obsolete *note posixfile: 137. module contained a class that
emulated all of a file object’s methods and also added a ‘lock()’
method, but this class couldn’t be passed to internal functions that
expected a built-in file, something which is possible with our new
‘LockableFile’.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0253


File: python.info,  Node: Descriptors,  Next: Multiple Inheritance The Diamond Rule,  Prev: Old and New Classes,  Up: PEPs 252 and 253 Type and Class Changes

1.6.2.2 Descriptors
...................

In previous versions of Python, there was no consistent way to discover
what attributes and methods were supported by an object.  There were
some informal conventions, such as defining ‘__members__’ and
‘__methods__’ attributes that were lists of names, but often the author
of an extension type or a class wouldn’t bother to define them.  You
could fall back on inspecting the ‘__dict__’ of an object, but when
class inheritance or an arbitrary *note __getattr__(): 331. hook were in
use this could still be inaccurate.

  The one big idea underlying the new class model is that an API for
describing the attributes of an object using _descriptors_ has been
formalized.  Descriptors specify the value of an attribute, stating
whether it’s a method or a field.  With the descriptor API, static
methods and class methods become possible, as well as more exotic
constructs.

  Attribute descriptors are objects that live inside class objects, and
have a few attributes of their own:

   * ‘__name__’ is the attribute’s name.

   * ‘__doc__’ is the attribute’s docstring.

   * ‘__get__(object)()’ is a method that retrieves the attribute value
     from _object_.

   * ‘__set__(object, value)()’ sets the attribute on _object_ to
     _value_.

   * ‘__delete__(object, value)()’ deletes the _value_ attribute of
     _object_.

  For example, when you write ‘obj.x’, the steps that Python actually
performs are:

     descriptor = obj.__class__.x
     descriptor.__get__(obj)

  For methods, ‘descriptor.__get__()’ returns a temporary object that’s
callable, and wraps up the instance and the method to be called on it.
This is also why static methods and class methods are now possible; they
have descriptors that wrap up just the method, or the method and the
class.  As a brief explanation of these new kinds of methods, static
methods aren’t passed the instance, and therefore resemble regular
functions.  Class methods are passed the class of the object, but not
the object itself.  Static and class methods are defined like this:

     class C(object):
         def f(arg1, arg2):
             ...
         f = staticmethod(f)

         def g(cls, arg1, arg2):
             ...
         g = classmethod(g)

  The *note staticmethod(): 3f5. function takes the function ‘f()’, and
returns it wrapped up in a descriptor so it can be stored in the class
object.  You might expect there to be special syntax for creating such
methods (‘def static f’, ‘defstatic f()’, or something like that) but no
such syntax has been defined yet; that’s been left for future versions
of Python.

  More new features, such as slots and properties, are also implemented
as new kinds of descriptors, and it’s not difficult to write a
descriptor class that does something novel.  For example, it would be
possible to write a descriptor class that made it possible to write
Eiffel-style preconditions and postconditions for a method.  A class
that used this feature might be defined like this:

     from eiffel import eiffelmethod

     class C(object):
         def f(self, arg1, arg2):
             # The actual function
             ...
         def pre_f(self):
             # Check preconditions
             ...
         def post_f(self):
             # Check postconditions
             ...

         f = eiffelmethod(f, pre_f, post_f)

  Note that a person using the new ‘eiffelmethod()’ doesn’t have to
understand anything about descriptors.  This is why I think the new
features don’t increase the basic complexity of the language.  There
will be a few wizards who need to know about it in order to write
‘eiffelmethod()’ or the ZODB or whatever, but most users will just write
code on top of the resulting libraries and ignore the implementation
details.


File: python.info,  Node: Multiple Inheritance The Diamond Rule,  Next: Attribute Access,  Prev: Descriptors,  Up: PEPs 252 and 253 Type and Class Changes

1.6.2.3 Multiple Inheritance: The Diamond Rule
..............................................

Multiple inheritance has also been made more useful through changing the
rules under which names are resolved.  Consider this set of classes
(diagram taken from PEP 253(1) by Guido van Rossum):

           class A:
             ^ ^  def save(self): ...
            /   \
           /     \
          /       \
         /         \
     class B     class C:
         ^         ^  def save(self): ...
          \       /
           \     /
            \   /
             \ /
           class D

  The lookup rule for classic classes is simple but not very smart; the
base classes are searched depth-first, going from left to right.  A
reference to ‘D.save()’ will search the classes ‘D’, ‘B’, and then ‘A’,
where ‘save()’ would be found and returned.  ‘C.save()’ would never be
found at all.  This is bad, because if ‘C’’s ‘save()’ method is saving
some internal state specific to ‘C’, not calling it will result in that
state never getting saved.

  New-style classes follow a different algorithm that’s a bit more
complicated to explain, but does the right thing in this situation.
(Note that Python 2.3 changes this algorithm to one that produces the
same results in most cases, but produces more useful results for really
complicated inheritance graphs.)

  1. List all the base classes, following the classic lookup rule and
     include a class multiple times if it’s visited repeatedly.  In the
     above example, the list of visited classes is [‘D’, ‘B’, ‘A’, ‘C’,
     ‘A’].

  2. Scan the list for duplicated classes.  If any are found, remove all
     but one occurrence, leaving the _last_ one in the list.  In the
     above example, the list becomes [‘D’, ‘B’, ‘C’, ‘A’] after dropping
     duplicates.

  Following this rule, referring to ‘D.save()’ will return ‘C.save()’,
which is the behaviour we’re after.  This lookup rule is the same as the
one followed by Common Lisp.  A new built-in function, *note super():
37d, provides a way to get at a class’s superclasses without having to
reimplement Python’s algorithm.  The most commonly used form will be
‘super(class, obj)()’, which returns a bound superclass object (not the
actual class object).  This form will be used in methods to call a
method in the superclass; for example, ‘D’’s ‘save()’ method would look
like this:

     class D (B,C):
         def save (self):
             # Call superclass .save()
             super(D, self).save()
             # Save D's private information here
             ...

  *note super(): 37d. can also return unbound superclass objects when
called as ‘super(class)()’ or ‘super(class1, class2)()’, but this
probably won’t often be useful.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0253


File: python.info,  Node: Attribute Access,  Next: Related Links,  Prev: Multiple Inheritance The Diamond Rule,  Up: PEPs 252 and 253 Type and Class Changes

1.6.2.4 Attribute Access
........................

A fair number of sophisticated Python classes define hooks for attribute
access using *note __getattr__(): 331.; most commonly this is done for
convenience, to make code more readable by automatically mapping an
attribute access such as ‘obj.parent’ into a method call such as
‘obj.get_parent’.  Python 2.2 adds some new ways of controlling
attribute access.

  First, ‘__getattr__(attr_name)()’ is still supported by new-style
classes, and nothing about it has changed.  As before, it will be called
when an attempt is made to access ‘obj.foo’ and no attribute named ‘foo’
is found in the instance’s dictionary.

  New-style classes also support a new method,
‘__getattribute__(attr_name)()’.  The difference between the two methods
is that *note __getattribute__(): 33b. is _always_ called whenever any
attribute is accessed, while the old *note __getattr__(): 331. is only
called if ‘foo’ isn’t found in the instance’s dictionary.

  However, Python 2.2’s support for _properties_ will often be a simpler
way to trap attribute references.  Writing a *note __getattr__(): 331.
method is complicated because to avoid recursion you can’t use regular
attribute accesses inside them, and instead have to mess around with the
contents of ‘__dict__’.  *note __getattr__(): 331. methods also end up
being called by Python when it checks for other methods such as *note
__repr__(): 486. or *note __coerce__(): 1ee, and so have to be written
with this in mind.  Finally, calling a function on every attribute
access results in a sizable performance loss.

  *note property: 487. is a new built-in type that packages up three
functions that get, set, or delete an attribute, and a docstring.  For
example, if you want to define a ‘size’ attribute that’s computed, but
also settable, you could write:

     class C(object):
         def get_size (self):
             result = ... computation ...
             return result
         def set_size (self, size):
             ... compute something based on the size
             and set internal state appropriately ...

         # Define a property.  The 'delete this attribute'
         # method is defined as None, so the attribute
         # can't be deleted.
         size = property(get_size, set_size,
                         None,
                         "Storage size of this instance")

  That is certainly clearer and easier to write than a pair of *note
__getattr__(): 331./*note __setattr__(): 488. methods that check for the
‘size’ attribute and handle it specially while retrieving all other
attributes from the instance’s ‘__dict__’.  Accesses to ‘size’ are also
the only ones which have to perform the work of calling a function, so
references to other attributes run at their usual speed.

  Finally, it’s possible to constrain the list of attributes that can be
referenced on an object using the new *note __slots__: 489. class
attribute.  Python objects are usually very dynamic; at any time it’s
possible to define a new attribute on an instance by just doing
‘obj.new_attr=1’.  A new-style class can define a class attribute named
*note __slots__: 489. to limit the legal attributes to a particular set
of names.  An example will make this clear:

     >>> class C(object):
     ...     __slots__ = ('template', 'name')
     ...
     >>> obj = C()
     >>> print obj.template
     None
     >>> obj.template = 'Test'
     >>> print obj.template
     Test
     >>> obj.newattr = None
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     AttributeError: 'C' object has no attribute 'newattr'

  Note how you get an *note AttributeError: 1f8. on the attempt to
assign to an attribute not listed in *note __slots__: 489.


File: python.info,  Node: Related Links,  Prev: Attribute Access,  Up: PEPs 252 and 253 Type and Class Changes

1.6.2.5 Related Links
.....................

This section has just been a quick overview of the new features, giving
enough of an explanation to start you programming, but many details have
been simplified or ignored.  Where should you go to get a more complete
picture?

  ‘http://www.python.org/2.2/descrintro.html’ is a lengthy tutorial
introduction to the descriptor features, written by Guido van Rossum.
If my description has whetted your appetite, go read this tutorial next,
because it goes into much more detail about the new features while still
remaining quite easy to read.

  Next, there are two relevant PEPs, PEP 252(1) and PEP 253(2).  PEP
252(3) is titled "Making Types Look More Like Classes", and covers the
descriptor API. PEP 253(4) is titled "Subtyping Built-in Types", and
describes the changes to type objects that make it possible to subtype
built-in objects.  PEP 253(5) is the more complicated PEP of the two,
and at a few points the necessary explanations of types and meta-types
may cause your head to explode.  Both PEPs were written and implemented
by Guido van Rossum, with substantial assistance from the rest of the
Zope Corp.  team.

  Finally, there’s the ultimate authority: the source code.  Most of the
machinery for the type handling is in ‘Objects/typeobject.c’, but you
should only resort to it after all other avenues have been exhausted,
including posting a question to python-list or python-dev.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0252

   (2) http://www.python.org/dev/peps/pep-0253

   (3) http://www.python.org/dev/peps/pep-0252

   (4) http://www.python.org/dev/peps/pep-0253

   (5) http://www.python.org/dev/peps/pep-0253


File: python.info,  Node: PEP 234 Iterators,  Next: PEP 255 Simple Generators<2>,  Prev: PEPs 252 and 253 Type and Class Changes,  Up: What's New in Python 2 2

1.6.3 PEP 234: Iterators
------------------------

Another significant addition to 2.2 is an iteration interface at both
the C and Python levels.  Objects can define how they can be looped over
by callers.

  In Python versions up to 2.1, the usual way to make ‘for item in obj’
work is to define a *note __getitem__(): 44f. method that looks
something like this:

     def __getitem__(self, index):
         return <next item>

  *note __getitem__(): 44f. is more properly used to define an indexing
operation on an object so that you can write ‘obj[5]’ to retrieve the
sixth element.  It’s a bit misleading when you’re using this only to
support *note for: 2f0. loops.  Consider some file-like object that
wants to be looped over; the _index_ parameter is essentially
meaningless, as the class probably assumes that a series of *note
__getitem__(): 44f. calls will be made with _index_ incrementing by one
each time.  In other words, the presence of the *note __getitem__():
44f. method doesn’t mean that using ‘file[5]’ to randomly access the
sixth element will work, though it really should.

  In Python 2.2, iteration can be implemented separately, and *note
__getitem__(): 44f. methods can be limited to classes that really do
support random access.  The basic idea of iterators is simple.  A new
built-in function, ‘iter(obj)()’ or ‘iter(C, sentinel)’, is used to get
an iterator.  ‘iter(obj)()’ returns an iterator for the object _obj_,
while ‘iter(C, sentinel)’ returns an iterator that will invoke the
callable object _C_ until it returns _sentinel_ to signal that the
iterator is done.

  Python classes can define an *note __iter__(): 321. method, which
should create and return a new iterator for the object; if the object is
its own iterator, this method can just return ‘self’.  In particular,
iterators will usually be their own iterators.  Extension types
implemented in C can implement a *note tp_iter: 48c. function in order
to return an iterator, and extension types that want to behave as
iterators can define a *note tp_iternext: 48d. function.

  So, after all this, what do iterators actually do?  They have one
required method, *note next(): 399, which takes no arguments and returns
the next value.  When there are no more values to be returned, calling
*note next(): 399. should raise the *note StopIteration: 333. exception.

     >>> L = [1,2,3]
     >>> i = iter(L)
     >>> print i
     <iterator object at 0x8116870>
     >>> i.next()
     1
     >>> i.next()
     2
     >>> i.next()
     3
     >>> i.next()
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     StopIteration
     >>>

  In 2.2, Python’s *note for: 2f0. statement no longer expects a
sequence; it expects something for which *note iter(): 320. will return
an iterator.  For backward compatibility and convenience, an iterator is
automatically constructed for sequences that don’t implement *note
__iter__(): 321. or a *note tp_iter: 48c. slot, so ‘for i in [1,2,3]’
will still work.  Wherever the Python interpreter loops over a sequence,
it’s been changed to use the iterator protocol.  This means you can do
things like this:

     >>> L = [1,2,3]
     >>> i = iter(L)
     >>> a,b,c = i
     >>> a,b,c
     (1, 2, 3)

  Iterator support has been added to some of Python’s basic types.
Calling *note iter(): 320. on a dictionary will return an iterator which
loops over its keys:

     >>> m = {'Jan': 1, 'Feb': 2, 'Mar': 3, 'Apr': 4, 'May': 5, 'Jun': 6,
     ...      'Jul': 7, 'Aug': 8, 'Sep': 9, 'Oct': 10, 'Nov': 11, 'Dec': 12}
     >>> for key in m: print key, m[key]
     ...
     Mar 3
     Feb 2
     Aug 8
     Sep 9
     May 5
     Jun 6
     Jul 7
     Jan 1
     Apr 4
     Nov 11
     Dec 12
     Oct 10

  That’s just the default behaviour.  If you want to iterate over keys,
values, or key/value pairs, you can explicitly call the ‘iterkeys()’,
‘itervalues()’, or ‘iteritems()’ methods to get an appropriate iterator.
In a minor related change, the *note in: 428. operator now works on
dictionaries, so ‘key in dict’ is now equivalent to ‘dict.has_key(key)’.

  Files also provide an iterator, which calls the *note readline(): 144.
method until there are no more lines in the file.  This means you can
now read each line of a file using code like this:

     for line in file:
         # do something for each line
         ...

  Note that you can only go forward in an iterator; there’s no way to
get the previous element, reset the iterator, or make a copy of it.  An
iterator object could provide such additional capabilities, but the
iterator protocol only requires a *note next(): 399. method.

See also
........

PEP 234(1) - Iterators

     Written by Ka-Ping Yee and GvR; implemented by the Python Labs
     crew, mostly by GvR and Tim Peters.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0234


File: python.info,  Node: PEP 255 Simple Generators<2>,  Next: PEP 237 Unifying Long Integers and Integers<2>,  Prev: PEP 234 Iterators,  Up: What's New in Python 2 2

1.6.4 PEP 255: Simple Generators
--------------------------------

Generators are another new feature, one that interacts with the
introduction of iterators.

  You’re doubtless familiar with how function calls work in Python or C.
When you call a function, it gets a private namespace where its local
variables are created.  When the function reaches a *note return: 2f4.
statement, the local variables are destroyed and the resulting value is
returned to the caller.  A later call to the same function will get a
fresh new set of local variables.  But, what if the local variables
weren’t thrown away on exiting a function?  What if you could later
resume the function where it left off?  This is what generators provide;
they can be thought of as resumable functions.

  Here’s the simplest example of a generator function:

     def generate_ints(N):
         for i in range(N):
             yield i

  A new keyword, *note yield: 2f7, was introduced for generators.  Any
function containing a *note yield: 2f7. statement is a generator
function; this is detected by Python’s bytecode compiler which compiles
the function specially as a result.  Because a new keyword was
introduced, generators must be explicitly enabled in a module by
including a ‘from __future__ import generators’ statement near the top
of the module’s source code.  In Python 2.3 this statement will become
unnecessary.

  When you call a generator function, it doesn’t return a single value;
instead it returns a generator object that supports the iterator
protocol.  On executing the *note yield: 2f7. statement, the generator
outputs the value of ‘i’, similar to a *note return: 2f4. statement.
The big difference between *note yield: 2f7. and a *note return: 2f4.
statement is that on reaching a *note yield: 2f7. the generator’s state
of execution is suspended and local variables are preserved.  On the
next call to the generator’s ‘next()’ method, the function will resume
executing immediately after the *note yield: 2f7. statement.  (For
complicated reasons, the *note yield: 2f7. statement isn’t allowed
inside the *note try: 395. block of a *note try: 395...*note finally:
396. statement; read PEP 255(1) for a full explanation of the
interaction between *note yield: 2f7. and exceptions.)

  Here’s a sample usage of the ‘generate_ints()’ generator:

     >>> gen = generate_ints(3)
     >>> gen
     <generator object at 0x8117f90>
     >>> gen.next()
     0
     >>> gen.next()
     1
     >>> gen.next()
     2
     >>> gen.next()
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
       File "<stdin>", line 2, in generate_ints
     StopIteration

  You could equally write ‘for i in generate_ints(5)’, or ‘a,b,c =
generate_ints(3)’.

  Inside a generator function, the *note return: 2f4. statement can only
be used without a value, and signals the end of the procession of
values; afterwards the generator cannot return any further values.
*note return: 2f4. with a value, such as ‘return 5’, is a syntax error
inside a generator function.  The end of the generator’s results can
also be indicated by raising *note StopIteration: 333. manually, or by
just letting the flow of execution fall off the bottom of the function.

  You could achieve the effect of generators manually by writing your
own class and storing all the local variables of the generator as
instance variables.  For example, returning a list of integers could be
done by setting ‘self.count’ to 0, and having the *note next(): 399.
method increment ‘self.count’ and return it.  However, for a moderately
complicated generator, writing a corresponding class would be much
messier.  ‘Lib/test/test_generators.py’ contains a number of more
interesting examples.  The simplest one implements an in-order traversal
of a tree using generators recursively.

     # A recursive generator that generates Tree leaves in in-order.
     def inorder(t):
         if t:
             for x in inorder(t.left):
                 yield x
             yield t.label
             for x in inorder(t.right):
                 yield x

  Two other examples in ‘Lib/test/test_generators.py’ produce solutions
for the N-Queens problem (placing $N$ queens on an $NxN$ chess board so
that no queen threatens another) and the Knight’s Tour (a route that
takes a knight to every square of an $NxN$ chessboard without visiting
any square twice).

  The idea of generators comes from other programming languages,
especially Icon (‘http://www.cs.arizona.edu/icon/’), where the idea of
generators is central.  In Icon, every expression and function call
behaves like a generator.  One example from "An Overview of the Icon
Programming Language" at
‘http://www.cs.arizona.edu/icon/docs/ipd266.htm’ gives an idea of what
this looks like:

     sentence := "Store it in the neighboring harbor"
     if (i := find("or", sentence)) > 5 then write(i)

  In Icon the ‘find()’ function returns the indexes at which the
substring "or" is found: 3, 23, 33.  In the *note if: 42c. statement,
‘i’ is first assigned a value of 3, but 3 is less than 5, so the
comparison fails, and Icon retries it with the second value of 23.  23
is greater than 5, so the comparison now succeeds, and the code prints
the value 23 to the screen.

  Python doesn’t go nearly as far as Icon in adopting generators as a
central concept.  Generators are considered a new part of the core
Python language, but learning or using them isn’t compulsory; if they
don’t solve any problems that you have, feel free to ignore them.  One
novel feature of Python’s interface as compared to Icon’s is that a
generator’s state is represented as a concrete object (the iterator)
that can be passed around to other functions or stored in a data
structure.

See also
........

PEP 255(2) - Simple Generators

     Written by Neil Schemenauer, Tim Peters, Magnus Lie Hetland.
     Implemented mostly by Neil Schemenauer and Tim Peters, with other
     fixes from the Python Labs crew.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0255

   (2) http://www.python.org/dev/peps/pep-0255


File: python.info,  Node: PEP 237 Unifying Long Integers and Integers<2>,  Next: PEP 238 Changing the Division Operator,  Prev: PEP 255 Simple Generators<2>,  Up: What's New in Python 2 2

1.6.5 PEP 237: Unifying Long Integers and Integers
--------------------------------------------------

In recent versions, the distinction between regular integers, which are
32-bit values on most machines, and long integers, which can be of
arbitrary size, was becoming an annoyance.  For example, on platforms
that support files larger than ‘2**32’ bytes, the ‘tell()’ method of
file objects has to return a long integer.  However, there were various
bits of Python that expected plain integers and would raise an error if
a long integer was provided instead.  For example, in Python 1.5, only
regular integers could be used as a slice index, and ‘'abc'[1L:]’ would
raise a *note TypeError: 218. exception with the message ’slice index
must be int’.

  Python 2.2 will shift values from short to long integers as required.
The ’L’ suffix is no longer needed to indicate a long integer literal,
as now the compiler will choose the appropriate type.  (Using the ’L’
suffix will be discouraged in future 2.x versions of Python, triggering
a warning in Python 2.4, and probably dropped in Python 3.0.)  Many
operations that used to raise an *note OverflowError: 2db. will now
return a long integer as their result.  For example:

     >>> 1234567890123
     1234567890123L
     >>> 2 ** 64
     18446744073709551616L

  In most cases, integers and long integers will now be treated
identically.  You can still distinguish them with the *note type(): 490.
built-in function, but that’s rarely needed.

See also
........

PEP 237(1) - Unifying Long Integers and Integers

     Written by Moshe Zadka and Guido van Rossum.  Implemented mostly by
     Guido van Rossum.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0237


File: python.info,  Node: PEP 238 Changing the Division Operator,  Next: Unicode Changes,  Prev: PEP 237 Unifying Long Integers and Integers<2>,  Up: What's New in Python 2 2

1.6.6 PEP 238: Changing the Division Operator
---------------------------------------------

The most controversial change in Python 2.2 heralds the start of an
effort to fix an old design flaw that’s been in Python from the
beginning.  Currently Python’s division operator, ‘/’, behaves like C’s
division operator when presented with two integer arguments: it returns
an integer result that’s truncated down when there would be a fractional
part.  For example, ‘3/2’ is 1, not 1.5, and ‘(-1)/2’ is -1, not -0.5.
This means that the results of division can vary unexpectedly depending
on the type of the two operands and because Python is dynamically typed,
it can be difficult to determine the possible types of the operands.

  (The controversy is over whether this is _really_ a design flaw, and
whether it’s worth breaking existing code to fix this.  It’s caused
endless discussions on python-dev, and in July 2001 erupted into an
storm of acidly sarcastic postings on ‘comp.lang.python’.  I won’t argue
for either side here and will stick to describing what’s implemented in
2.2.  Read PEP 238(1) for a summary of arguments and counter-arguments.)

  Because this change might break code, it’s being introduced very
gradually.  Python 2.2 begins the transition, but the switch won’t be
complete until Python 3.0.

  First, I’ll borrow some terminology from PEP 238(2).  "True division"
is the division that most non-programmers are familiar with: 3/2 is 1.5,
1/4 is 0.25, and so forth.  "Floor division" is what Python’s ‘/’
operator currently does when given integer operands; the result is the
floor of the value returned by true division.  "Classic division" is the
current mixed behaviour of ‘/’; it returns the result of floor division
when the operands are integers, and returns the result of true division
when one of the operands is a floating-point number.

  Here are the changes 2.2 introduces:

   * A new operator, ‘//’, is the floor division operator.  (Yes, we
     know it looks like C++’s comment symbol.)  ‘//’ _always_ performs
     floor division no matter what the types of its operands are, so ‘1
     // 2’ is 0 and ‘1.0 // 2.0’ is also 0.0.

     ‘//’ is always available in Python 2.2; you don’t need to enable it
     using a ‘__future__’ statement.

   * By including a ‘from __future__ import division’ in a module, the
     ‘/’ operator will be changed to return the result of true division,
     so ‘1/2’ is 0.5.  Without the ‘__future__’ statement, ‘/’ still
     means classic division.  The default meaning of ‘/’ will not change
     until Python 3.0.

   * Classes can define methods called *note __truediv__(): 492. and
     *note __floordiv__(): 493. to overload the two division operators.
     At the C level, there are also slots in the *note PyNumberMethods:
     3ab. structure so extension types can define the two operators.

   * Python 2.2 supports some command-line arguments for testing whether
     code will works with the changed division semantics.  Running
     python with ‘-Q warn’ will cause a warning to be issued whenever
     division is applied to two integers.  You can use this to find code
     that’s affected by the change and fix it.  By default, Python 2.2
     will simply perform classic division without a warning; the warning
     will be turned on by default in Python 2.3.

See also
........

PEP 238(3) - Changing the Division Operator

     Written by Moshe Zadka and Guido van Rossum.  Implemented by Guido
     van Rossum..

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0238

   (2) http://www.python.org/dev/peps/pep-0238

   (3) http://www.python.org/dev/peps/pep-0238


File: python.info,  Node: Unicode Changes,  Next: PEP 227 Nested Scopes,  Prev: PEP 238 Changing the Division Operator,  Up: What's New in Python 2 2

1.6.7 Unicode Changes
---------------------

Python’s Unicode support has been enhanced a bit in 2.2.  Unicode
strings are usually stored as UCS-2, as 16-bit unsigned integers.
Python 2.2 can also be compiled to use UCS-4, 32-bit unsigned integers,
as its internal encoding by supplying ‘--enable-unicode=ucs4’ to the
configure script.  (It’s also possible to specify ‘--disable-unicode’ to
completely disable Unicode support.)

  When built to use UCS-4 (a "wide Python"), the interpreter can
natively handle Unicode characters from U+000000 to U+110000, so the
range of legal values for the *note unichr(): 495. function is expanded
accordingly.  Using an interpreter compiled to use UCS-2 (a "narrow
Python"), values greater than 65535 will still cause *note unichr():
495. to raise a *note ValueError: 236. exception.  This is all described
in PEP 261(1), "Support for ’wide’ Unicode characters"; consult it for
further details.

  Another change is simpler to explain.  Since their introduction,
Unicode strings have supported an ‘encode()’ method to convert the
string to a selected encoding such as UTF-8 or Latin-1.  A symmetric
‘decode([*encoding*])()’ method has been added to 8-bit strings (though
not to Unicode strings) in 2.2.  ‘decode()’ assumes that the string is
in the specified encoding and decodes it, returning whatever is returned
by the codec.

  Using this new feature, codecs have been added for tasks not directly
related to Unicode.  For example, codecs have been added for
uu-encoding, MIME’s base64 encoding, and compression with the *note
zlib: 1ad. module:

     >>> s = """Here is a lengthy piece of redundant, overly verbose,
     ... and repetitive text.
     ... """
     >>> data = s.encode('zlib')
     >>> data
     'x\x9c\r\xc9\xc1\r\x80 \x10\x04\xc0?Ul...'
     >>> data.decode('zlib')
     'Here is a lengthy piece of redundant, overly verbose,\nand repetitive text.\n'
     >>> print s.encode('uu')
     begin 666 <data>
     M2&5R92!I<R!A(&QE;F=T:'D@<&EE8V4@;V8@<F5D=6YD86YT+"!O=F5R;'D@
     >=F5R8F]S92P*86YD(')E<&5T:71I=F4@=&5X="X*

     end
     >>> "sheesh".encode('rot-13')
     'furrfu'

  To convert a class instance to Unicode, a *note __unicode__(): 1f6.
method can be defined by a class, analogous to *note __str__(): 496.

  ‘encode()’, ‘decode()’, and *note __unicode__(): 1f6. were implemented
by Marc-André Lemburg.  The changes to support using UCS-4 internally
were implemented by Fredrik Lundh and Martin von Löwis.

See also
........

PEP 261(2) - Support for ’wide’ Unicode characters

     Written by Paul Prescod.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0261

   (2) http://www.python.org/dev/peps/pep-0261


File: python.info,  Node: PEP 227 Nested Scopes,  Next: New and Improved Modules<3>,  Prev: Unicode Changes,  Up: What's New in Python 2 2

1.6.8 PEP 227: Nested Scopes
----------------------------

In Python 2.1, statically nested scopes were added as an optional
feature, to be enabled by a ‘from __future__ import nested_scopes’
directive.  In 2.2 nested scopes no longer need to be specially enabled,
and are now always present.  The rest of this section is a copy of the
description of nested scopes from my "What’s New in Python 2.1"
document; if you read it when 2.1 came out, you can skip the rest of
this section.

  The largest change introduced in Python 2.1, and made complete in 2.2,
is to Python’s scoping rules.  In Python 2.0, at any given time there
are at most three namespaces used to look up variable names: local,
module-level, and the built-in namespace.  This often surprised people
because it didn’t match their intuitive expectations.  For example, a
nested recursive function definition doesn’t work:

     def f():
         ...
         def g(value):
             ...
             return g(value-1) + 1
         ...

  The function ‘g()’ will always raise a *note NameError: 3a3.
exception, because the binding of the name ‘g’ isn’t in either its local
namespace or in the module-level namespace.  This isn’t much of a
problem in practice (how often do you recursively define interior
functions like this?), but this also made using the *note lambda: 403.
statement clumsier, and this was a problem in practice.  In code which
uses *note lambda: 403. you can often find local variables being copied
by passing them as the default values of arguments.

     def find(self, name):
         "Return list of any entries equal to 'name'"
         L = filter(lambda x, name=name: x == name,
                    self.list_attribute)
         return L

  The readability of Python code written in a strongly functional style
suffers greatly as a result.

  The most significant change to Python 2.2 is that static scoping has
been added to the language to fix this problem.  As a first effect, the
‘name=name’ default argument is now unnecessary in the above example.
Put simply, when a given variable name is not assigned a value within a
function (by an assignment, or the *note def: 3f4, *note class: 33d, or
*note import: 1f4. statements), references to the variable will be
looked up in the local namespace of the enclosing scope.  A more
detailed explanation of the rules, and a dissection of the
implementation, can be found in the PEP.

  This change may cause some compatibility problems for code where the
same variable name is used both at the module level and as a local
variable within a function that contains further function definitions.
This seems rather unlikely though, since such code would have been
pretty confusing to read in the first place.

  One side effect of the change is that the ‘from module import *’ and
*note exec: 404. statements have been made illegal inside a function
scope under certain conditions.  The Python reference manual has said
all along that ‘from module import *’ is only legal at the top level of
a module, but the CPython interpreter has never enforced this before.
As part of the implementation of nested scopes, the compiler which turns
Python source into bytecodes has to generate different code to access
variables in a containing scope.  ‘from module import *’ and *note exec:
404. make it impossible for the compiler to figure this out, because
they add names to the local namespace that are unknowable at compile
time.  Therefore, if a function contains function definitions or *note
lambda: 403. expressions with free variables, the compiler will flag
this by raising a *note SyntaxError: 498. exception.

  To make the preceding explanation a bit clearer, here’s an example:

     x = 1
     def f():
         # The next line is a syntax error
         exec 'x=2'
         def g():
             return x

  Line 4 containing the *note exec: 404. statement is a syntax error,
since *note exec: 404. would define a new local variable named ‘x’ whose
value should be accessed by ‘g()’.

  This shouldn’t be much of a limitation, since *note exec: 404. is
rarely used in most Python code (and when it is used, it’s often a sign
of a poor design anyway).

See also
........

PEP 227(1) - Statically Nested Scopes

     Written and implemented by Jeremy Hylton.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0227


File: python.info,  Node: New and Improved Modules<3>,  Next: Interpreter Changes and Fixes,  Prev: PEP 227 Nested Scopes,  Up: What's New in Python 2 2

1.6.9 New and Improved Modules
------------------------------

   * The *note xmlrpclib: 1aa. module was contributed to the standard
     library by Fredrik Lundh, providing support for writing XML-RPC
     clients.  XML-RPC is a simple remote procedure call protocol built
     on top of HTTP and XML. For example, the following snippet
     retrieves a list of RSS channels from the O’Reilly Network, and
     then lists the recent headlines for one channel:

          import xmlrpclib
          s = xmlrpclib.Server(
                'http://www.oreillynet.com/meerkat/xml-rpc/server.php')
          channels = s.meerkat.getChannels()
          # channels is a list of dictionaries, like this:
          # [{'id': 4, 'title': 'Freshmeat Daily News'}
          #  {'id': 190, 'title': '32Bits Online'},
          #  {'id': 4549, 'title': '3DGamers'}, ... ]

          # Get the items for one channel
          items = s.meerkat.getItems( {'channel': 4} )

          # 'items' is another list of dictionaries, like this:
          # [{'link': 'http://freshmeat.net/releases/52719/',
          #   'description': 'A utility which converts HTML to XSL FO.',
          #   'title': 'html2fo 0.3 (Default)'}, ... ]

     The *note SimpleXMLRPCServer: 157. module makes it easy to create
     straightforward XML-RPC servers.  See ‘http://www.xmlrpc.com/’ for
     more information about XML-RPC.

   * The new *note hmac: e8. module implements the HMAC algorithm
     described by RFC 2104(1).  (Contributed by Gerhard Häring.)

   * Several functions that originally returned lengthy tuples now
     return pseudo- sequences that still behave like tuples but also
     have mnemonic attributes such as memberst_mtime or ‘tm_year’.  The
     enhanced functions include *note stat(): 161, ‘fstat()’, *note
     statvfs(): 162, and ‘fstatvfs()’ in the *note os: 128. module, and
     ‘localtime()’, ‘gmtime()’, and ‘strptime()’ in the *note time: 17a.
     module.

     For example, to obtain a file’s size using the old tuples, you’d
     end up writing something like ‘file_size =
     os.stat(filename)[stat.ST_SIZE]’, but now this can be written more
     clearly as ‘file_size = os.stat(filename).st_size’.

     The original patch for this feature was contributed by Nick
     Mathewson.

   * The Python profiler has been extensively reworked and various
     errors in its output have been corrected.  (Contributed by Fred L.
     Drake, Jr.  and Tim Peters.)

   * The *note socket: 15c. module can be compiled to support IPv6;
     specify the ‘--enable-ipv6’ option to Python’s configure script.
     (Contributed by Jun-ichiro "itojun" Hagino.)

   * Two new format characters were added to the *note struct: 166.
     module for 64-bit integers on platforms that support the C ‘long
     long’ type.  ‘q’ is for a signed 64-bit integer, and ‘Q’ is for an
     unsigned one.  The value is returned in Python’s long integer type.
     (Contributed by Tim Peters.)

   * In the interpreter’s interactive mode, there’s a new built-in
     function *note help(): 49a. that uses the *note pydoc: 13f. module
     introduced in Python 2.1 to provide interactive help.
     ‘help(object)’ displays any available help text about _object_.
     *note help(): 49a. with no argument puts you in an online help
     utility, where you can enter the names of functions, classes, or
     modules to read their help text.  (Contributed by Guido van Rossum,
     using Ka-Ping Yee’s *note pydoc: 13f. module.)

   * Various bugfixes and performance improvements have been made to the
     SRE engine underlying the *note re: 143. module.  For example, the
     *note re.sub(): 248. and *note re.split(): 247. functions have been
     rewritten in C. Another contributed patch speeds up certain Unicode
     character ranges by a factor of two, and a new ‘finditer()’ method
     that returns an iterator over all the non-overlapping matches in a
     given string.  (SRE is maintained by Fredrik Lundh.  The BIGCHARSET
     patch was contributed by Martin von Löwis.)

   * The *note smtplib: 15a. module now supports RFC 2487(2), "Secure
     SMTP over TLS", so it’s now possible to encrypt the SMTP traffic
     between a Python program and the mail transport agent being handed
     a message.  *note smtplib: 15a. also supports SMTP authentication.
     (Contributed by Gerhard Häring.)

   * The *note imaplib: f2. module, maintained by Piers Lauder, has
     support for several new extensions: the NAMESPACE extension defined
     in RFC 2342(3), SORT, GETACL and SETACL. (Contributed by Anthony
     Baxter and Michel Pelletier.)

   * The *note rfc822: 148. module’s parsing of email addresses is now
     compliant with RFC 2822(4), an update to RFC 822(5).  (The module’s
     name is _not_ going to be changed to ‘rfc2822’.)  A new package,
     *note email: bb, has also been added for parsing and generating
     e-mail messages.  (Contributed by Barry Warsaw, and arising out of
     his work on Mailman.)

   * The *note difflib: 82. module now contains a new ‘Differ’ class for
     producing human-readable lists of changes (a "delta") between two
     sequences of lines of text.  There are also two generator
     functions, ‘ndiff()’ and ‘restore()’, which respectively return a
     delta from two sequences, or one of the original sequences from a
     delta.  (Grunt work contributed by David Goodger, from ndiff.py
     code by Tim Peters who then did the generatorization.)

   * New constants ‘ascii_letters’, ‘ascii_lowercase’, and
     ‘ascii_uppercase’ were added to the *note string: 163. module.
     There were several modules in the standard library that used *note
     string.letters: 49b. to mean the ranges A-Za-z, but that assumption
     is incorrect when locales are in use, because *note string.letters:
     49b. varies depending on the set of legal characters defined by the
     current locale.  The buggy modules have all been fixed to use
     ‘ascii_letters’ instead.  (Reported by an unknown person; fixed by
     Fred L. Drake, Jr.)

   * The *note mimetypes: 110. module now makes it easier to use
     alternative MIME-type databases by the addition of a ‘MimeTypes’
     class, which takes a list of filenames to be parsed.  (Contributed
     by Fred L. Drake, Jr.)

   * A ‘Timer’ class was added to the *note threading: 179. module that
     allows scheduling an activity to happen at some future time.
     (Contributed by Itamar Shtull-Trauring.)

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc2104.html

   (2) http://tools.ietf.org/html/rfc2487.html

   (3) http://tools.ietf.org/html/rfc2342.html

   (4) http://tools.ietf.org/html/rfc2822.html

   (5) http://tools.ietf.org/html/rfc822.html


File: python.info,  Node: Interpreter Changes and Fixes,  Next: Other Changes and Fixes<3>,  Prev: New and Improved Modules<3>,  Up: What's New in Python 2 2

1.6.10 Interpreter Changes and Fixes
------------------------------------

Some of the changes only affect people who deal with the Python
interpreter at the C level because they’re writing Python extension
modules, embedding the interpreter, or just hacking on the interpreter
itself.  If you only write Python code, none of the changes described
here will affect you very much.

   * Profiling and tracing functions can now be implemented in C, which
     can operate at much higher speeds than Python-based functions and
     should reduce the overhead of profiling and tracing.  This will be
     of interest to authors of development environments for Python.  Two
     new C functions were added to Python’s API, *note
     PyEval_SetProfile(): 49d. and *note PyEval_SetTrace(): 49e.  The
     existing *note sys.setprofile(): 49f. and *note sys.settrace():
     4a0. functions still exist, and have simply been changed to use the
     new C-level interface.  (Contributed by Fred L. Drake, Jr.)

   * Another low-level API, primarily of interest to implementors of
     Python debuggers and development tools, was added.  *note
     PyInterpreterState_Head(): 4a1. and *note
     PyInterpreterState_Next(): 4a2. let a caller walk through all the
     existing interpreter objects; *note
     PyInterpreterState_ThreadHead(): 4a3. and *note
     PyThreadState_Next(): 4a4. allow looping over all the thread states
     for a given interpreter.  (Contributed by David Beazley.)

   * The C-level interface to the garbage collector has been changed to
     make it easier to write extension types that support garbage
     collection and to debug misuses of the functions.  Various
     functions have slightly different semantics, so a bunch of
     functions had to be renamed.  Extensions that use the old API will
     still compile but will _not_ participate in garbage collection, so
     updating them for 2.2 should be considered fairly high priority.

     To upgrade an extension module to the new API, perform the
     following steps:

   * Rename ‘Py_TPFLAGS_GC()’ to ‘PyTPFLAGS_HAVE_GC()’.

   * 
     Use *note PyObject_GC_New(): 4a5. or *note PyObject_GC_NewVar(): 4a6. to allocate

          objects, and *note PyObject_GC_Del(): 4a7. to deallocate them.

   * 
     Rename ‘PyObject_GC_Init()’ to *note PyObject_GC_Track(): 4a8. and

          ‘PyObject_GC_Fini()’ to *note PyObject_GC_UnTrack(): 4a9.

   * Remove ‘PyGC_HEAD_SIZE()’ from object size calculations.

   * Remove calls to ‘PyObject_AS_GC()’ and ‘PyObject_FROM_GC()’.

   * A new ‘et’ format sequence was added to *note PyArg_ParseTuple():
     31b.; ‘et’ takes both a parameter and an encoding name, and
     converts the parameter to the given encoding if the parameter turns
     out to be a Unicode string, or leaves it alone if it’s an 8-bit
     string, assuming it to already be in the desired encoding.  This
     differs from the ‘es’ format character, which assumes that 8-bit
     strings are in Python’s default ASCII encoding and converts them to
     the specified new encoding.  (Contributed by M.-A. Lemburg, and
     used for the MBCS support on Windows described in the following
     section.)

   * A different argument parsing function, *note PyArg_UnpackTuple():
     4aa, has been added that’s simpler and presumably faster.  Instead
     of specifying a format string, the caller simply gives the minimum
     and maximum number of arguments expected, and a set of pointers to
     *note PyObject*: 3a6. variables that will be filled in with
     argument values.

   * Two new flags *note METH_NOARGS: 46f. and *note METH_O: 4ab. are
     available in method definition tables to simplify implementation of
     methods with no arguments or a single untyped argument.  Calling
     such methods is more efficient than calling a corresponding method
     that uses *note METH_VARARGS: 4ac.  Also, the old *note
     METH_OLDARGS: 4ad. style of writing C methods is now officially
     deprecated.

   * Two new wrapper functions, *note PyOS_snprintf(): 4ae. and *note
     PyOS_vsnprintf(): 4af. were added to provide cross-platform
     implementations for the relatively new ‘snprintf()’ and
     ‘vsnprintf()’ C lib APIs.  In contrast to the standard ‘sprintf()’
     and ‘vsprintf()’ functions, the Python versions check the bounds of
     the buffer used to protect against buffer overruns.  (Contributed
     by M.-A. Lemburg.)

   * The *note _PyTuple_Resize(): 4b0. function has lost an unused
     parameter, so now it takes 2 parameters instead of 3.  The third
     argument was never used, and can simply be discarded when porting
     code from earlier versions to Python 2.2.


File: python.info,  Node: Other Changes and Fixes<3>,  Next: Acknowledgements<6>,  Prev: Interpreter Changes and Fixes,  Up: What's New in Python 2 2

1.6.11 Other Changes and Fixes
------------------------------

As usual there were a bunch of other improvements and bugfixes scattered
throughout the source tree.  A search through the CVS change logs finds
there were 527 patches applied and 683 bugs fixed between Python 2.1 and
2.2; 2.2.1 applied 139 patches and fixed 143 bugs; 2.2.2 applied 106
patches and fixed 82 bugs.  These figures are likely to be
underestimates.

  Some of the more notable changes are:

   * The code for the MacOS port for Python, maintained by Jack Jansen,
     is now kept in the main Python CVS tree, and many changes have been
     made to support MacOS X.

     The most significant change is the ability to build Python as a
     framework, enabled by supplying the ‘--enable-framework’ option to
     the configure script when compiling Python.  According to Jack
     Jansen, "This installs a self- contained Python installation plus
     the OS X framework "glue" into
     ‘/Library/Frameworks/Python.framework’ (or another location of
     choice).  For now there is little immediate added benefit to this
     (actually, there is the disadvantage that you have to change your
     PATH to be able to find Python), but it is the basis for creating a
     full-blown Python application, porting the MacPython IDE, possibly
     using Python as a standard OSA scripting language and much more."

     Most of the MacPython toolbox modules, which interface to MacOS
     APIs such as windowing, QuickTime, scripting, etc.  have been
     ported to OS X, but they’ve been left commented out in ‘setup.py’.
     People who want to experiment with these modules can uncomment them
     manually.

   * Keyword arguments passed to built-in functions that don’t take them
     now cause a *note TypeError: 218. exception to be raised, with the
     message "_function_ takes no keyword arguments".

   * Weak references, added in Python 2.1 as an extension module, are
     now part of the core because they’re used in the implementation of
     new-style classes.  The *note ReferenceError: 4b2. exception has
     therefore moved from the *note weakref: 195. module to become a
     built-in exception.

   * A new script, ‘Tools/scripts/cleanfuture.py’ by Tim Peters,
     automatically removes obsolete ‘__future__’ statements from Python
     source code.

   * An additional _flags_ argument has been added to the built-in
     function *note compile(): 1fb, so the behaviour of ‘__future__’
     statements can now be correctly observed in simulated shells, such
     as those presented by IDLE and other development environments.
     This is described in PEP 264(1).  (Contributed by Michael Hudson.)

   * The new license introduced with Python 1.6 wasn’t GPL-compatible.
     This is fixed by some minor textual changes to the 2.2 license, so
     it’s now legal to embed Python inside a GPLed program again.  Note
     that Python itself is not GPLed, but instead is under a license
     that’s essentially equivalent to the BSD license, same as it always
     was.  The license changes were also applied to the Python 2.0.1 and
     2.1.1 releases.

   * When presented with a Unicode filename on Windows, Python will now
     convert it to an MBCS encoded string, as used by the Microsoft file
     APIs.  As MBCS is explicitly used by the file APIs, Python’s choice
     of ASCII as the default encoding turns out to be an annoyance.  On
     Unix, the locale’s character set is used if
     ‘locale.nl_langinfo(CODESET)()’ is available.  (Windows support was
     contributed by Mark Hammond with assistance from Marc-André
     Lemburg.  Unix support was added by Martin von Löwis.)

   * Large file support is now enabled on Windows.  (Contributed by Tim
     Peters.)

   * The ‘Tools/scripts/ftpmirror.py’ script now parses a ‘.netrc’ file,
     if you have one.  (Contributed by Mike Romberg.)

   * Some features of the object returned by the *note xrange(): 45b.
     function are now deprecated, and trigger warnings when they’re
     accessed; they’ll disappear in Python 2.3.  *note xrange: 45b.
     objects tried to pretend they were full sequence types by
     supporting slicing, sequence multiplication, and the *note in: 428.
     operator, but these features were rarely used and therefore buggy.
     The ‘tolist()’ method and the ‘start’, ‘stop’, and ‘step’
     attributes are also being deprecated.  At the C level, the fourth
     argument to the ‘PyRange_New()’ function, ‘repeat’, has also been
     deprecated.

   * There were a bunch of patches to the dictionary implementation,
     mostly to fix potential core dumps if a dictionary contains objects
     that sneakily changed their hash value, or mutated the dictionary
     they were contained in.  For a while python-dev fell into a gentle
     rhythm of Michael Hudson finding a case that dumped core, Tim
     Peters fixing the bug, Michael finding another case, and round and
     round it went.

   * On Windows, Python can now be compiled with Borland C thanks to a
     number of patches contributed by Stephen Hansen, though the result
     isn’t fully functional yet.  (But this _is_ progress...)

   * Another Windows enhancement: Wise Solutions generously offered
     PythonLabs use of their InstallerMaster 8.1 system.  Earlier
     PythonLabs Windows installers used Wise 5.0a, which was beginning
     to show its age.  (Packaged up by Tim Peters.)

   * Files ending in ‘.pyw’ can now be imported on Windows.  ‘.pyw’ is a
     Windows-only thing, used to indicate that a script needs to be run
     using PYTHONW.EXE instead of PYTHON.EXE in order to prevent a DOS
     console from popping up to display the output.  This patch makes it
     possible to import such scripts, in case they’re also usable as
     modules.  (Implemented by David Bolen.)

   * On platforms where Python uses the C ‘dlopen()’ function to load
     extension modules, it’s now possible to set the flags used by
     ‘dlopen()’ using the *note sys.getdlopenflags(): 4b3. and *note
     sys.setdlopenflags(): 4b4. functions.  (Contributed by Bram Stolk.)

   * The *note pow(): 4b5. built-in function no longer supports 3
     arguments when floating-point numbers are supplied.  ‘pow(x, y, z)’
     returns ‘(x**y) % z’, but this is never useful for floating point
     numbers, and the final result varies unpredictably depending on the
     platform.  A call such as ‘pow(2.0, 8.0, 7.0)’ will now raise a
     *note TypeError: 218. exception.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0264


File: python.info,  Node: Acknowledgements<6>,  Prev: Other Changes and Fixes<3>,  Up: What's New in Python 2 2

1.6.12 Acknowledgements
-----------------------

The author would like to thank the following people for offering
suggestions, corrections and assistance with various drafts of this
article: Fred Bremmer, Keith Briggs, Andrew Dalke, Fred L. Drake, Jr.,
Carel Fellinger, David Goodger, Mark Hammond, Stephen Hansen, Michael
Hudson, Jack Jansen, Marc-André Lemburg, Martin von Löwis, Fredrik
Lundh, Michael McLay, Nick Mathewson, Paul Moore, Gustavo Niemeyer, Don
O’Donnell, Joonas Paalasma, Tim Peters, Jens Quade, Tom Reinhardt, Neil
Schemenauer, Guido van Rossum, Greg Ward, Edward Welbourne.


File: python.info,  Node: What's New in Python 2 1,  Next: What's New in Python 2 0,  Prev: What's New in Python 2 2,  Up: What's New in Python

1.7 What’s New in Python 2.1
============================

     Author: A.M. Kuchling

* Menu:

* Introduction: Introduction<2>. 
* PEP 227; Nested Scopes: PEP 227 Nested Scopes<2>. 
* PEP 236; __future__ Directives: PEP 236 __future__ Directives. 
* PEP 207; Rich Comparisons: PEP 207 Rich Comparisons. 
* PEP 230; Warning Framework: PEP 230 Warning Framework. 
* PEP 229; New Build System: PEP 229 New Build System. 
* PEP 205; Weak References: PEP 205 Weak References. 
* PEP 232; Function Attributes: PEP 232 Function Attributes. 
* PEP 235; Importing Modules on Case-Insensitive Platforms: PEP 235 Importing Modules on Case-Insensitive Platforms. 
* PEP 217; Interactive Display Hook: PEP 217 Interactive Display Hook. 
* PEP 208; New Coercion Model: PEP 208 New Coercion Model. 
* PEP 241; Metadata in Python Packages: PEP 241 Metadata in Python Packages. 
* New and Improved Modules: New and Improved Modules<4>. 
* Other Changes and Fixes: Other Changes and Fixes<4>. 
* Acknowledgements: Acknowledgements<7>. 


File: python.info,  Node: Introduction<2>,  Next: PEP 227 Nested Scopes<2>,  Up: What's New in Python 2 1

1.7.1 Introduction
------------------

This article explains the new features in Python 2.1.  While there
aren’t as many changes in 2.1 as there were in Python 2.0, there are
still some pleasant surprises in store.  2.1 is the first release to be
steered through the use of Python Enhancement Proposals, or PEPs, so
most of the sizable changes have accompanying PEPs that provide more
complete documentation and a design rationale for the change.  This
article doesn’t attempt to document the new features completely, but
simply provides an overview of the new features for Python programmers.
Refer to the Python 2.1 documentation, or to the specific PEP, for more
details about any new feature that particularly interests you.

  One recent goal of the Python development team has been to accelerate
the pace of new releases, with a new release coming every 6 to 9 months.
2.1 is the first release to come out at this faster pace, with the first
alpha appearing in January, 3 months after the final version of 2.0 was
released.

  The final release of Python 2.1 was made on April 17, 2001.


File: python.info,  Node: PEP 227 Nested Scopes<2>,  Next: PEP 236 __future__ Directives,  Prev: Introduction<2>,  Up: What's New in Python 2 1

1.7.2 PEP 227: Nested Scopes
----------------------------

The largest change in Python 2.1 is to Python’s scoping rules.  In
Python 2.0, at any given time there are at most three namespaces used to
look up variable names: local, module-level, and the built-in namespace.
This often surprised people because it didn’t match their intuitive
expectations.  For example, a nested recursive function definition
doesn’t work:

     def f():
         ...
         def g(value):
             ...
             return g(value-1) + 1
         ...

  The function ‘g()’ will always raise a *note NameError: 3a3.
exception, because the binding of the name ‘g’ isn’t in either its local
namespace or in the module-level namespace.  This isn’t much of a
problem in practice (how often do you recursively define interior
functions like this?), but this also made using the *note lambda: 403.
statement clumsier, and this was a problem in practice.  In code which
uses *note lambda: 403. you can often find local variables being copied
by passing them as the default values of arguments.

     def find(self, name):
         "Return list of any entries equal to 'name'"
         L = filter(lambda x, name=name: x == name,
                    self.list_attribute)
         return L

  The readability of Python code written in a strongly functional style
suffers greatly as a result.

  The most significant change to Python 2.1 is that static scoping has
been added to the language to fix this problem.  As a first effect, the
‘name=name’ default argument is now unnecessary in the above example.
Put simply, when a given variable name is not assigned a value within a
function (by an assignment, or the *note def: 3f4, *note class: 33d, or
*note import: 1f4. statements), references to the variable will be
looked up in the local namespace of the enclosing scope.  A more
detailed explanation of the rules, and a dissection of the
implementation, can be found in the PEP.

  This change may cause some compatibility problems for code where the
same variable name is used both at the module level and as a local
variable within a function that contains further function definitions.
This seems rather unlikely though, since such code would have been
pretty confusing to read in the first place.

  One side effect of the change is that the ‘from module import *’ and
*note exec: 404. statements have been made illegal inside a function
scope under certain conditions.  The Python reference manual has said
all along that ‘from module import *’ is only legal at the top level of
a module, but the CPython interpreter has never enforced this before.
As part of the implementation of nested scopes, the compiler which turns
Python source into bytecodes has to generate different code to access
variables in a containing scope.  ‘from module import *’ and *note exec:
404. make it impossible for the compiler to figure this out, because
they add names to the local namespace that are unknowable at compile
time.  Therefore, if a function contains function definitions or *note
lambda: 403. expressions with free variables, the compiler will flag
this by raising a *note SyntaxError: 498. exception.

  To make the preceding explanation a bit clearer, here’s an example:

     x = 1
     def f():
         # The next line is a syntax error
         exec 'x=2'
         def g():
             return x

  Line 4 containing the *note exec: 404. statement is a syntax error,
since *note exec: 404. would define a new local variable named ‘x’ whose
value should be accessed by ‘g()’.

  This shouldn’t be much of a limitation, since *note exec: 404. is
rarely used in most Python code (and when it is used, it’s often a sign
of a poor design anyway).

  Compatibility concerns have led to nested scopes being introduced
gradually; in Python 2.1, they aren’t enabled by default, but can be
turned on within a module by using a future statement as described in
PEP 236.  (See the following section for further discussion of PEP 236.)
In Python 2.2, nested scopes will become the default and there will be
no way to turn them off, but users will have had all of 2.1’s lifetime
to fix any breakage resulting from their introduction.

See also
........

PEP 227(1) - Statically Nested Scopes

     Written and implemented by Jeremy Hylton.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0227


File: python.info,  Node: PEP 236 __future__ Directives,  Next: PEP 207 Rich Comparisons,  Prev: PEP 227 Nested Scopes<2>,  Up: What's New in Python 2 1

1.7.3 PEP 236: __future__ Directives
------------------------------------

The reaction to nested scopes was widespread concern about the dangers
of breaking code with the 2.1 release, and it was strong enough to make
the Pythoneers take a more conservative approach.  This approach
consists of introducing a convention for enabling optional functionality
in release N that will become compulsory in release N+1.

  The syntax uses a ‘from...import’ statement using the reserved module
name *note __future__: 1.  Nested scopes can be enabled by the following
statement:

     from __future__ import nested_scopes

  While it looks like a normal *note import: 1f4. statement, it’s not;
there are strict rules on where such a future statement can be put.
They can only be at the top of a module, and must precede any Python
code or regular *note import: 1f4. statements.  This is because such
statements can affect how the Python bytecode compiler parses code and
generates bytecode, so they must precede any statement that will result
in bytecodes being produced.

See also
........

PEP 236(1) - Back to the *note __future__: 1.

     Written by Tim Peters, and primarily implemented by Jeremy Hylton.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0236


File: python.info,  Node: PEP 207 Rich Comparisons,  Next: PEP 230 Warning Framework,  Prev: PEP 236 __future__ Directives,  Up: What's New in Python 2 1

1.7.4 PEP 207: Rich Comparisons
-------------------------------

In earlier versions, Python’s support for implementing comparisons on
user- defined classes and extension types was quite simple.  Classes
could implement a *note __cmp__(): 221. method that was given two
instances of a class, and could only return 0 if they were equal or +1
or -1 if they weren’t; the method couldn’t raise an exception or return
anything other than a Boolean value.  Users of Numeric Python often
found this model too weak and restrictive, because in the
number-crunching programs that numeric Python is used for, it would be
more useful to be able to perform elementwise comparisons of two
matrices, returning a matrix containing the results of a given
comparison for each element.  If the two matrices are of different
sizes, then the compare has to be able to raise an exception to signal
the error.

  In Python 2.1, rich comparisons were added in order to support this
need.  Python classes can now individually overload each of the ‘<’,
‘<=’, ‘>’, ‘>=’, ‘==’, and ‘!=’ operations.  The new magic method names
are:

Operation       Method name
                
-------------------------------------
                
‘<’             *note __lt__():
                21d.
                
                
‘<=’            *note __le__():
                21e.
                
                
‘>’             *note __gt__():
                21f.
                
                
‘>=’            *note __ge__():
                220.
                
                
‘==’            *note __eq__():
                21c.
                
                
‘!=’            *note __ne__():
                4bd.
                

  (The magic methods are named after the corresponding Fortran operators
‘.LT.’.  ‘.LE.’, &c.  Numeric programmers are almost certainly quite
familiar with these names and will find them easy to remember.)

  Each of these magic methods is of the form ‘method(self, other)’,
where ‘self’ will be the object on the left-hand side of the operator,
while ‘other’ will be the object on the right-hand side.  For example,
the expression ‘A < B’ will cause ‘A.__lt__(B)’ to be called.

  Each of these magic methods can return anything at all: a Boolean, a
matrix, a list, or any other Python object.  Alternatively they can
raise an exception if the comparison is impossible, inconsistent, or
otherwise meaningless.

  The built-in ‘cmp(A,B)()’ function can use the rich comparison
machinery, and now accepts an optional argument specifying which
comparison operation to use; this is given as one of the strings ‘"<"’,
‘"<="’, ‘">"’, ‘">="’, ‘"=="’, or ‘"!="’.  If called without the
optional third argument, *note cmp(): 4be. will only return -1, 0, or +1
as in previous versions of Python; otherwise it will call the
appropriate method and can return any Python object.

  There are also corresponding changes of interest to C programmers;
there’s a new slot ‘tp_richcmp’ in type objects and an API for
performing a given rich comparison.  I won’t cover the C API here, but
will refer you to PEP 207, or to 2.1’s C API documentation, for the full
list of related functions.

See also
........

PEP 207(1) - Rich Comparisions

     Written by Guido van Rossum, heavily based on earlier work by David
     Ascher, and implemented by Guido van Rossum.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0207


File: python.info,  Node: PEP 230 Warning Framework,  Next: PEP 229 New Build System,  Prev: PEP 207 Rich Comparisons,  Up: What's New in Python 2 1

1.7.5 PEP 230: Warning Framework
--------------------------------

Over its 10 years of existence, Python has accumulated a certain number
of obsolete modules and features along the way.  It’s difficult to know
when a feature is safe to remove, since there’s no way of knowing how
much code uses it — perhaps no programs depend on the feature, or
perhaps many do.  To enable removing old features in a more structured
way, a warning framework was added.  When the Python developers want to
get rid of a feature, it will first trigger a warning in the next
version of Python.  The following Python version can then drop the
feature, and users will have had a full release cycle to remove uses of
the old feature.

  Python 2.1 adds the warning framework to be used in this scheme.  It
adds a *note warnings: 193. module that provide functions to issue
warnings, and to filter out warnings that you don’t want to be
displayed.  Third-party modules can also use this framework to deprecate
old features that they no longer wish to support.

  For example, in Python 2.1 the ‘regex’ module is deprecated, so
importing it causes a warning to be printed:

     >>> import regex
     __main__:1: DeprecationWarning: the regex module
              is deprecated; please use the re module
     >>>

  Warnings can be issued by calling the *note warnings.warn(): 4c0.
function:

     warnings.warn("feature X no longer supported")

  The first parameter is the warning message; an additional optional
parameters can be used to specify a particular warning category.

  Filters can be added to disable certain warnings; a regular expression
pattern can be applied to the message or to the module name in order to
suppress a warning.  For example, you may have a program that uses the
‘regex’ module and not want to spare the time to convert it to use the
*note re: 143. module right now.  The warning can be suppressed by
calling

     import warnings
     warnings.filterwarnings(action = 'ignore',
                             message='.*regex module is deprecated',
                             category=DeprecationWarning,
                             module = '__main__')

  This adds a filter that will apply only to warnings of the class
‘DeprecationWarning’ triggered in the *note __main__: 2. module, and
applies a regular expression to only match the message about the ‘regex’
module being deprecated, and will cause such warnings to be ignored.
Warnings can also be printed only once, printed every time the offending
code is executed, or turned into exceptions that will cause the program
to stop (unless the exceptions are caught in the usual way, of course).

  Functions were also added to Python’s C API for issuing warnings;
refer to PEP 230 or to Python’s API documentation for the details.

See also
........

PEP 5(1) - Guidelines for Language Evolution

     Written by Paul Prescod, to specify procedures to be followed when
     removing old features from Python.  The policy described in this
     PEP hasn’t been officially adopted, but the eventual policy
     probably won’t be too different from Prescod’s proposal.

PEP 230(2) - Warning Framework

     Written and implemented by Guido van Rossum.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0005

   (2) http://www.python.org/dev/peps/pep-0230


File: python.info,  Node: PEP 229 New Build System,  Next: PEP 205 Weak References,  Prev: PEP 230 Warning Framework,  Up: What's New in Python 2 1

1.7.6 PEP 229: New Build System
-------------------------------

When compiling Python, the user had to go in and edit the
‘Modules/Setup’ file in order to enable various additional modules; the
default set is relatively small and limited to modules that compile on
most Unix platforms.  This means that on Unix platforms with many more
features, most notably Linux, Python installations often don’t contain
all useful modules they could.

  Python 2.0 added the Distutils, a set of modules for distributing and
installing extensions.  In Python 2.1, the Distutils are used to compile
much of the standard library of extension modules, autodetecting which
ones are supported on the current machine.  It’s hoped that this will
make Python installations easier and more featureful.

  Instead of having to edit the ‘Modules/Setup’ file in order to enable
modules, a ‘setup.py’ script in the top directory of the Python source
distribution is run at build time, and attempts to discover which
modules can be enabled by examining the modules and header files on the
system.  If a module is configured in ‘Modules/Setup’, the ‘setup.py’
script won’t attempt to compile that module and will defer to the
‘Modules/Setup’ file’s contents.  This provides a way to specific any
strange command-line flags or libraries that are required for a specific
platform.

  In another far-reaching change to the build mechanism, Neil
Schemenauer restructured things so Python now uses a single makefile
that isn’t recursive, instead of makefiles in the top directory and in
each of the ‘Python/’, ‘Parser/’, ‘Objects/’, and ‘Modules/’
subdirectories.  This makes building Python faster and also makes
hacking the Makefiles clearer and simpler.

See also
........

PEP 229(1) - Using Distutils to Build Python

     Written and implemented by A.M. Kuchling.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0229


File: python.info,  Node: PEP 205 Weak References,  Next: PEP 232 Function Attributes,  Prev: PEP 229 New Build System,  Up: What's New in Python 2 1

1.7.7 PEP 205: Weak References
------------------------------

Weak references, available through the *note weakref: 195. module, are a
minor but useful new data type in the Python programmer’s toolbox.

  Storing a reference to an object (say, in a dictionary or a list) has
the side effect of keeping that object alive forever.  There are a few
specific cases where this behaviour is undesirable, object caches being
the most common one, and another being circular references in data
structures such as trees.

  For example, consider a memoizing function that caches the results of
another function ‘f(x)()’ by storing the function’s argument and its
result in a dictionary:

     _cache = {}
     def memoize(x):
         if _cache.has_key(x):
             return _cache[x]

         retval = f(x)

         # Cache the returned object
         _cache[x] = retval

         return retval

  This version works for simple things such as integers, but it has a
side effect; the ‘_cache’ dictionary holds a reference to the return
values, so they’ll never be deallocated until the Python process exits
and cleans up This isn’t very noticeable for integers, but if ‘f()’
returns an object, or a data structure that takes up a lot of memory,
this can be a problem.

  Weak references provide a way to implement a cache that won’t keep
objects alive beyond their time.  If an object is only accessible
through weak references, the object will be deallocated and the weak
references will now indicate that the object it referred to no longer
exists.  A weak reference to an object _obj_ is created by calling ‘wr =
weakref.ref(obj)’.  The object being referred to is returned by calling
the weak reference as if it were a function: ‘wr()’.  It will return the
referenced object, or ‘None’ if the object no longer exists.

  This makes it possible to write a ‘memoize()’ function whose cache
doesn’t keep objects alive, by storing weak references in the cache.

     _cache = {}
     def memoize(x):
         if _cache.has_key(x):
             obj = _cache[x]()
             # If weak reference object still exists,
             # return it
             if obj is not None: return obj

         retval = f(x)

         # Cache a weak reference
         _cache[x] = weakref.ref(retval)

         return retval

  The *note weakref: 195. module also allows creating proxy objects
which behave like weak references — an object referenced only by proxy
objects is deallocated – but instead of requiring an explicit call to
retrieve the object, the proxy transparently forwards all operations to
the object as long as the object still exists.  If the object is
deallocated, attempting to use a proxy will cause a *note
weakref.ReferenceError: 4c3. exception to be raised.

     proxy = weakref.proxy(obj)
     proxy.attr   # Equivalent to obj.attr
     proxy.meth() # Equivalent to obj.meth()
     del obj
     proxy.attr   # raises weakref.ReferenceError

See also
........

PEP 205(1) - Weak References

     Written and implemented by Fred L. Drake, Jr.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0205


File: python.info,  Node: PEP 232 Function Attributes,  Next: PEP 235 Importing Modules on Case-Insensitive Platforms,  Prev: PEP 205 Weak References,  Up: What's New in Python 2 1

1.7.8 PEP 232: Function Attributes
----------------------------------

In Python 2.1, functions can now have arbitrary information attached to
them.  People were often using docstrings to hold information about
functions and methods, because the ‘__doc__’ attribute was the only way
of attaching any information to a function.  For example, in the Zope
Web application server, functions are marked as safe for public access
by having a docstring, and in John Aycock’s SPARK parsing framework,
docstrings hold parts of the BNF grammar to be parsed.  This overloading
is unfortunate, since docstrings are really intended to hold a
function’s documentation; for example, it means you can’t properly
document functions intended for private use in Zope.

  Arbitrary attributes can now be set and retrieved on functions using
the regular Python syntax:

     def f(): pass

     f.publish = 1
     f.secure = 1
     f.grammar = "A ::= B (C D)*"

  The dictionary containing attributes can be accessed as the function’s
‘__dict__’.  Unlike the ‘__dict__’ attribute of class instances, in
functions you can actually assign a new dictionary to ‘__dict__’, though
the new value is restricted to a regular Python dictionary; you _can’t_
be tricky and set it to a *note UserDict: 18c. instance, or any other
random object that behaves like a mapping.

See also
........

PEP 232(1) - Function Attributes

     Written and implemented by Barry Warsaw.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0232


File: python.info,  Node: PEP 235 Importing Modules on Case-Insensitive Platforms,  Next: PEP 217 Interactive Display Hook,  Prev: PEP 232 Function Attributes,  Up: What's New in Python 2 1

1.7.9 PEP 235: Importing Modules on Case-Insensitive Platforms
--------------------------------------------------------------

Some operating systems have filesystems that are case-insensitive, MacOS
and Windows being the primary examples; on these systems, it’s
impossible to distinguish the filenames ‘FILE.PY’ and ‘file.py’, even
though they do store the file’s name in its original case (they’re
case-preserving, too).

  In Python 2.1, the *note import: 1f4. statement will work to simulate
case- sensitivity on case-insensitive platforms.  Python will now search
for the first case-sensitive match by default, raising an *note
ImportError: 370. if no such file is found, so ‘import file’ will not
import a module named ‘FILE.PY’.  Case- insensitive matching can be
requested by setting the *note PYTHONCASEOK: 4c6. environment variable
before starting the Python interpreter.


File: python.info,  Node: PEP 217 Interactive Display Hook,  Next: PEP 208 New Coercion Model,  Prev: PEP 235 Importing Modules on Case-Insensitive Platforms,  Up: What's New in Python 2 1

1.7.10 PEP 217: Interactive Display Hook
----------------------------------------

When using the Python interpreter interactively, the output of commands
is displayed using the built-in *note repr(): 145. function.  In Python
2.1, the variable *note sys.displayhook(): 4c8. can be set to a callable
object which will be called instead of *note repr(): 145.  For example,
you can set it to a special pretty- printing function:

     >>> # Create a recursive data structure
     ... L = [1,2,3]
     >>> L.append(L)
     >>> L # Show Python's default output
     [1, 2, 3, [...]]
     >>> # Use pprint.pprint() as the display function
     ... import sys, pprint
     >>> sys.displayhook = pprint.pprint
     >>> L
     [1, 2, 3,  <Recursion on list with id=135143996>]
     >>>

See also
........

PEP 217(1) - Display Hook for Interactive Use

     Written and implemented by Moshe Zadka.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0217


File: python.info,  Node: PEP 208 New Coercion Model,  Next: PEP 241 Metadata in Python Packages,  Prev: PEP 217 Interactive Display Hook,  Up: What's New in Python 2 1

1.7.11 PEP 208: New Coercion Model
----------------------------------

How numeric coercion is done at the C level was significantly modified.
This will only affect the authors of C extensions to Python, allowing
them more flexibility in writing extension types that support numeric
operations.

  Extension types can now set the type flag ‘Py_TPFLAGS_CHECKTYPES’ in
their ‘PyTypeObject’ structure to indicate that they support the new
coercion model.  In such extension types, the numeric slot functions can
no longer assume that they’ll be passed two arguments of the same type;
instead they may be passed two arguments of differing types, and can
then perform their own internal coercion.  If the slot function is
passed a type it can’t handle, it can indicate the failure by returning
a reference to the ‘Py_NotImplemented’ singleton value.  The numeric
functions of the other type will then be tried, and perhaps they can
handle the operation; if the other type also returns
‘Py_NotImplemented’, then a *note TypeError: 218. will be raised.
Numeric methods written in Python can also return ‘Py_NotImplemented’,
causing the interpreter to act as if the method did not exist (perhaps
raising a *note TypeError: 218, perhaps trying another object’s numeric
methods).

See also
........

PEP 208(1) - Reworking the Coercion Model

     Written and implemented by Neil Schemenauer, heavily based upon
     earlier work by Marc-André Lemburg.  Read this to understand the
     fine points of how numeric operations will now be processed at the
     C level.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0208


File: python.info,  Node: PEP 241 Metadata in Python Packages,  Next: New and Improved Modules<4>,  Prev: PEP 208 New Coercion Model,  Up: What's New in Python 2 1

1.7.12 PEP 241: Metadata in Python Packages
-------------------------------------------

A common complaint from Python users is that there’s no single catalog
of all the Python modules in existence.  T. Middleton’s Vaults of
Parnassus at ‘http://www.vex.net/parnassus/’ are the largest catalog of
Python modules, but registering software at the Vaults is optional, and
many people don’t bother.

  As a first small step toward fixing the problem, Python software
packaged using the Distutils *sdist* command will include a file named
‘PKG-INFO’ containing information about the package such as its name,
version, and author (metadata, in cataloguing terminology).  PEP 241
contains the full list of fields that can be present in the ‘PKG-INFO’
file.  As people began to package their software using Python 2.1, more
and more packages will include metadata, making it possible to build
automated cataloguing systems and experiment with them.  With the result
experience, perhaps it’ll be possible to design a really good catalog
and then build support for it into Python 2.2.  For example, the
Distutils *sdist* and *bdist_** commands could support a ‘upload’ option
that would automatically upload your package to a catalog server.

  You can start creating packages containing ‘PKG-INFO’ even if you’re
not using Python 2.1, since a new release of the Distutils will be made
for users of earlier Python versions.  Version 1.0.2 of the Distutils
includes the changes described in PEP 241, as well as various bugfixes
and enhancements.  It will be available from the Distutils SIG at
‘http://www.python.org/sigs/distutils-sig/’.

See also
........

PEP 241(1) - Metadata for Python Software Packages

     Written and implemented by A.M. Kuchling.

PEP 243(2) - Module Repository Upload Mechanism

     Written by Sean Reifschneider, this draft PEP describes a proposed
     mechanism for uploading Python packages to a central server.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0241

   (2) http://www.python.org/dev/peps/pep-0243


File: python.info,  Node: New and Improved Modules<4>,  Next: Other Changes and Fixes<4>,  Prev: PEP 241 Metadata in Python Packages,  Up: What's New in Python 2 1

1.7.13 New and Improved Modules
-------------------------------

   * Ka-Ping Yee contributed two new modules: ‘inspect.py’, a module for
     getting information about live Python code, and ‘pydoc.py’, a
     module for interactively converting docstrings to HTML or text.  As
     a bonus, ‘Tools/scripts/pydoc’, which is now automatically
     installed, uses ‘pydoc.py’ to display documentation given a Python
     module, package, or class name.  For example, ‘pydoc xml.dom’
     displays the following:

          Python Library Documentation: package xml.dom in xml

          NAME
              xml.dom - W3C Document Object Model implementation for Python.

          FILE
              /usr/local/lib/python2.1/xml/dom/__init__.pyc

          DESCRIPTION
              The Python mapping of the Document Object Model is documented in the
              Python Library Reference in the section on the xml.dom package.

              This package contains the following modules:
                ...

     ‘pydoc’ also includes a Tk-based interactive help browser.  ‘pydoc’
     quickly becomes addictive; try it out!

   * Two different modules for unit testing were added to the standard
     library.  The *note doctest: b5. module, contributed by Tim Peters,
     provides a testing framework based on running embedded examples in
     docstrings and comparing the results against the expected output.
     PyUnit, contributed by Steve Purcell, is a unit testing framework
     inspired by JUnit, which was in turn an adaptation of Kent Beck’s
     Smalltalk testing framework.  See ‘http://pyunit.sourceforge.net/’
     for more information about PyUnit.

   * The *note difflib: 82. module contains a class, ‘SequenceMatcher’,
     which compares two sequences and computes the changes required to
     transform one sequence into the other.  For example, this module
     can be used to write a tool similar to the Unix *diff* program, and
     in fact the sample program ‘Tools/scripts/ndiff.py’ demonstrates
     how to write such a script.

   * *note curses.panel: 7b, a wrapper for the panel library, part of
     ncurses and of SYSV curses, was contributed by Thomas Gellekum.
     The panel library provides windows with the additional feature of
     depth.  Windows can be moved higher or lower in the depth ordering,
     and the panel library figures out where panels overlap and which
     sections are visible.

   * The PyXML package has gone through a few releases since Python 2.0,
     and Python 2.1 includes an updated version of the *note xml: 1a0.
     package.  Some of the noteworthy changes include support for Expat
     1.2 and later versions, the ability for Expat parsers to handle
     files in any encoding supported by Python, and various bugfixes for
     SAX, DOM, and the ‘minidom’ module.

   * Ping also contributed another hook for handling uncaught
     exceptions.  *note sys.excepthook(): 4cc. can be set to a callable
     object.  When an exception isn’t caught by any *note try:
     395...*note except: 397. blocks, the exception will be passed to
     *note sys.excepthook(): 4cc, which can then do whatever it likes.
     At the Ninth Python Conference, Ping demonstrated an application
     for this hook: printing an extended traceback that not only lists
     the stack frames, but also lists the function arguments and the
     local variables for each frame.

   * Various functions in the *note time: 17a. module, such as
     ‘asctime()’ and ‘localtime()’, require a floating point argument
     containing the time in seconds since the epoch.  The most common
     use of these functions is to work with the current time, so the
     floating point argument has been made optional; when a value isn’t
     provided, the current time will be used.  For example, log file
     entries usually need a string containing the current time; in
     Python 2.1, ‘time.asctime()’ can be used, instead of the lengthier
     ‘time.asctime(time.localtime(time.time()))’ that was previously
     required.

     This change was proposed and implemented by Thomas Wouters.

   * The *note ftplib: d8. module now defaults to retrieving files in
     passive mode, because passive mode is more likely to work from
     behind a firewall.  This request came from the Debian bug tracking
     system, since other Debian packages use *note ftplib: d8. to
     retrieve files and then don’t work from behind a firewall.  It’s
     deemed unlikely that this will cause problems for anyone, because
     Netscape defaults to passive mode and few people complain, but if
     passive mode is unsuitable for your application or network setup,
     call ‘set_pasv(0)()’ on FTP objects to disable passive mode.

   * Support for raw socket access has been added to the *note socket:
     15c. module, contributed by Grant Edwards.

   * The *note pstats: 13a. module now contains a simple interactive
     statistics browser for displaying timing profiles for Python
     programs, invoked when the module is run as a script.  Contributed
     by Eric S. Raymond.

   * A new implementation-dependent function,
     ‘sys._getframe([depth])()’, has been added to return a given frame
     object from the current call stack.  *note sys._getframe(): 4cd.
     returns the frame at the top of the call stack; if the optional
     integer argument _depth_ is supplied, the function returns the
     frame that is _depth_ calls below the top of the stack.  For
     example, ‘sys._getframe(1)’ returns the caller’s frame object.

     This function is only present in CPython, not in Jython or the .NET
     implementation.  Use it for debugging, and resist the temptation to
     put it into production code.


File: python.info,  Node: Other Changes and Fixes<4>,  Next: Acknowledgements<7>,  Prev: New and Improved Modules<4>,  Up: What's New in Python 2 1

1.7.14 Other Changes and Fixes
------------------------------

There were relatively few smaller changes made in Python 2.1 due to the
shorter release cycle.  A search through the CVS change logs turns up
117 patches applied, and 136 bugs fixed; both figures are likely to be
underestimates.  Some of the more notable changes are:

   * A specialized object allocator is now optionally available, that
     should be faster than the system ‘malloc()’ and have less memory
     overhead.  The allocator uses C’s ‘malloc()’ function to get large
     pools of memory, and then fulfills smaller memory requests from
     these pools.  It can be enabled by providing the ‘--with-pymalloc’
     option to the *configure* script; see ‘Objects/obmalloc.c’ for the
     implementation details.

     Authors of C extension modules should test their code with the
     object allocator enabled, because some incorrect code may break,
     causing core dumps at runtime.  There are a bunch of memory
     allocation functions in Python’s C API that have previously been
     just aliases for the C library’s ‘malloc()’ and ‘free()’, meaning
     that if you accidentally called mismatched functions, the error
     wouldn’t be noticeable.  When the object allocator is enabled,
     these functions aren’t aliases of ‘malloc()’ and ‘free()’ any more,
     and calling the wrong function to free memory will get you a core
     dump.  For example, if memory was allocated using ‘PyMem_New()’, it
     has to be freed using ‘PyMem_Del()’, not ‘free()’.  A few modules
     included with Python fell afoul of this and had to be fixed;
     doubtless there are more third-party modules that will have the
     same problem.

     The object allocator was contributed by Vladimir Marangozov.

   * The speed of line-oriented file I/O has been improved because
     people often complain about its lack of speed, and because it’s
     often been used as a naïve benchmark.  The *note readline(): 144.
     method of file objects has therefore been rewritten to be much
     faster.  The exact amount of the speedup will vary from platform to
     platform depending on how slow the C library’s ‘getc()’ was, but is
     around 66%, and potentially much faster on some particular
     operating systems.  Tim Peters did much of the benchmarking and
     coding for this change, motivated by a discussion in
     comp.lang.python.

     A new module and method for file objects was also added,
     contributed by Jeff Epler.  The new method, ‘xreadlines()’, is
     similar to the existing *note xrange(): 45b. built-in.
     ‘xreadlines()’ returns an opaque sequence object that only supports
     being iterated over, reading a line on every iteration but not
     reading the entire file into memory as the existing ‘readlines()’
     method does.  You’d use it like this:

          for line in sys.stdin.xreadlines():
              # ... do something for each line ...
              ...

     For a fuller discussion of the line I/O changes, see the python-dev
     summary for January 1-15, 2001 at
     ‘http://www.python.org/dev/summary/2001-01-1/’.

   * A new method, ‘popitem()’, was added to dictionaries to enable
     destructively iterating through the contents of a dictionary; this
     can be faster for large dictionaries because there’s no need to
     construct a list containing all the keys or values.  ‘D.popitem()’
     removes a random ‘(key, value)’ pair from the dictionary ‘D’ and
     returns it as a 2-tuple.  This was implemented mostly by Tim Peters
     and Guido van Rossum, after a suggestion and preliminary patch by
     Moshe Zadka.

   * Modules can now control which names are imported when ‘from module
     import *’ is used, by defining an ‘__all__’ attribute containing a
     list of names that will be imported.  One common complaint is that
     if the module imports other modules such as *note sys: 16d. or
     *note string: 163, ‘from module import *’ will add them to the
     importing module’s namespace.  To fix this, simply list the public
     names in ‘__all__’:

          # List public names
          __all__ = ['Database', 'open']

     A stricter version of this patch was first suggested and
     implemented by Ben Wolfson, but after some python-dev discussion, a
     weaker final version was checked in.

   * Applying *note repr(): 145. to strings previously used octal
     escapes for non-printable characters; for example, a newline was
     ‘'\012'’.  This was a vestigial trace of Python’s C ancestry, but
     today octal is of very little practical use.  Ka-Ping Yee suggested
     using hex escapes instead of octal ones, and using the ‘\n’, ‘\t’,
     ‘\r’ escapes for the appropriate characters, and implemented this
     new formatting.

   * Syntax errors detected at compile-time can now raise exceptions
     containing the filename and line number of the error, a pleasant
     side effect of the compiler reorganization done by Jeremy Hylton.

   * C extensions which import other modules have been changed to use
     ‘PyImport_ImportModule()’, which means that they will use any
     import hooks that have been installed.  This is also encouraged for
     third-party extensions that need to import some other module from C
     code.

   * The size of the Unicode character database was shrunk by another
     340K thanks to Fredrik Lundh.

   * Some new ports were contributed: MacOS X (by Steven Majewski),
     Cygwin (by Jason Tishler); RISCOS (by Dietmar Schwertberger);
     Unixware 7 (by Billy G. Allie).

  And there’s the usual list of minor bugfixes, minor memory leaks,
docstring edits, and other tweaks, too lengthy to be worth itemizing;
see the CVS logs for the full details if you want them.


File: python.info,  Node: Acknowledgements<7>,  Prev: Other Changes and Fixes<4>,  Up: What's New in Python 2 1

1.7.15 Acknowledgements
-----------------------

The author would like to thank the following people for offering
suggestions on various drafts of this article: Graeme Cross, David
Goodger, Jay Graves, Michael Hudson, Marc-André Lemburg, Fredrik Lundh,
Neil Schemenauer, Thomas Wouters.


File: python.info,  Node: What's New in Python 2 0,  Prev: What's New in Python 2 1,  Up: What's New in Python

1.8 What’s New in Python 2.0
============================

     Author: A.M. Kuchling and Moshe Zadka

* Menu:

* Introduction: Introduction<3>. 
* What About Python 1.6?: What About Python 1 6?. 
* New Development Process:: 
* Unicode:: 
* List Comprehensions:: 
* Augmented Assignment:: 
* String Methods:: 
* Garbage Collection of Cycles:: 
* Other Core Changes:: 
* Porting to 2.0: Porting to 2 0. 
* Extending/Embedding Changes:: 
* Distutils; Making Modules Easy to Install: Distutils Making Modules Easy to Install. 
* XML Modules:: 
* Module changes:: 
* New modules:: 
* IDLE Improvements:: 
* Deleted and Deprecated Modules:: 
* Acknowledgements: Acknowledgements<8>. 


File: python.info,  Node: Introduction<3>,  Next: What About Python 1 6?,  Up: What's New in Python 2 0

1.8.1 Introduction
------------------

A new release of Python, version 2.0, was released on October 16, 2000.
This article covers the exciting new features in 2.0, highlights some
other useful changes, and points out a few incompatible changes that may
require rewriting code.

  Python’s development never completely stops between releases, and a
steady flow of bug fixes and improvements are always being submitted.  A
host of minor fixes, a few optimizations, additional docstrings, and
better error messages went into 2.0; to list them all would be
impossible, but they’re certainly significant.  Consult the
publicly-available CVS logs if you want to see the full list.  This
progress is due to the five developers working for PythonLabs are now
getting paid to spend their days fixing bugs, and also due to the
improved communication resulting from moving to SourceForge.


File: python.info,  Node: What About Python 1 6?,  Next: New Development Process,  Prev: Introduction<3>,  Up: What's New in Python 2 0

1.8.2 What About Python 1.6?
----------------------------

Python 1.6 can be thought of as the Contractual Obligations Python
release.  After the core development team left CNRI in May 2000, CNRI
requested that a 1.6 release be created, containing all the work on
Python that had been performed at CNRI. Python 1.6 therefore represents
the state of the CVS tree as of May 2000, with the most significant new
feature being Unicode support.  Development continued after May, of
course, so the 1.6 tree received a few fixes to ensure that it’s
forward-compatible with Python 2.0.  1.6 is therefore part of Python’s
evolution, and not a side branch.

  So, should you take much interest in Python 1.6?  Probably not.  The
1.6final and 2.0beta1 releases were made on the same day (September 5,
2000), the plan being to finalize Python 2.0 within a month or so.  If
you have applications to maintain, there seems little point in breaking
things by moving to 1.6, fixing them, and then having another round of
breakage within a month by moving to 2.0; you’re better off just going
straight to 2.0.  Most of the really interesting features described in
this document are only in 2.0, because a lot of work was done between
May and September.


File: python.info,  Node: New Development Process,  Next: Unicode,  Prev: What About Python 1 6?,  Up: What's New in Python 2 0

1.8.3 New Development Process
-----------------------------

The most important change in Python 2.0 may not be to the code at all,
but to how Python is developed: in May 2000 the Python developers began
using the tools made available by SourceForge for storing source code,
tracking bug reports, and managing the queue of patch submissions.  To
report bugs or submit patches for Python 2.0, use the bug tracking and
patch manager tools available from Python’s project page, located at
‘http://sourceforge.net/projects/python/’.

  The most important of the services now hosted at SourceForge is the
Python CVS tree, the version-controlled repository containing the source
code for Python.  Previously, there were roughly 7 or so people who had
write access to the CVS tree, and all patches had to be inspected and
checked in by one of the people on this short list.  Obviously, this
wasn’t very scalable.  By moving the CVS tree to SourceForge, it became
possible to grant write access to more people; as of September 2000
there were 27 people able to check in changes, a fourfold increase.
This makes possible large-scale changes that wouldn’t be attempted if
they’d have to be filtered through the small group of core developers.
For example, one day Peter Schneider-Kamp took it into his head to drop
K&R C compatibility and convert the C source for Python to ANSI C. After
getting approval on the python-dev mailing list, he launched into a
flurry of checkins that lasted about a week, other developers joined in
to help, and the job was done.  If there were only 5 people with write
access, probably that task would have been viewed as "nice, but not
worth the time and effort needed" and it would never have gotten done.

  The shift to using SourceForge’s services has resulted in a remarkable
increase in the speed of development.  Patches now get submitted,
commented on, revised by people other than the original submitter, and
bounced back and forth between people until the patch is deemed worth
checking in.  Bugs are tracked in one central location and can be
assigned to a specific person for fixing, and we can count the number of
open bugs to measure progress.  This didn’t come without a cost:
developers now have more e-mail to deal with, more mailing lists to
follow, and special tools had to be written for the new environment.
For example, SourceForge sends default patch and bug notification e-mail
messages that are completely unhelpful, so Ka-Ping Yee wrote an HTML
screen-scraper that sends more useful messages.

  The ease of adding code caused a few initial growing pains, such as
code was checked in before it was ready or without getting clear
agreement from the developer group.  The approval process that has
emerged is somewhat similar to that used by the Apache group.
Developers can vote +1, +0, -0, or -1 on a patch; +1 and -1 denote
acceptance or rejection, while +0 and -0 mean the developer is mostly
indifferent to the change, though with a slight positive or negative
slant.  The most significant change from the Apache model is that the
voting is essentially advisory, letting Guido van Rossum, who has
Benevolent Dictator For Life status, know what the general opinion is.
He can still ignore the result of a vote, and approve or reject a change
even if the community disagrees with him.

  Producing an actual patch is the last step in adding a new feature,
and is usually easy compared to the earlier task of coming up with a
good design.  Discussions of new features can often explode into lengthy
mailing list threads, making the discussion hard to follow, and no one
can read every posting to python-dev.  Therefore, a relatively formal
process has been set up to write Python Enhancement Proposals (PEPs),
modelled on the Internet RFC process.  PEPs are draft documents that
describe a proposed new feature, and are continually revised until the
community reaches a consensus, either accepting or rejecting the
proposal.  Quoting from the introduction to PEP 1, "PEP Purpose and
Guidelines":

     PEP stands for Python Enhancement Proposal.  A PEP is a design
     document providing information to the Python community, or
     describing a new feature for Python.  The PEP should provide a
     concise technical specification of the feature and a rationale for
     the feature.

     We intend PEPs to be the primary mechanisms for proposing new
     features, for collecting community input on an issue, and for
     documenting the design decisions that have gone into Python.  The
     PEP author is responsible for building consensus within the
     community and documenting dissenting opinions.

  Read the rest of PEP 1 for the details of the PEP editorial process,
style, and format.  PEPs are kept in the Python CVS tree on SourceForge,
though they’re not part of the Python 2.0 distribution, and are also
available in HTML form from ‘http://www.python.org/peps/’.  As of
September 2000, there are 25 PEPS, ranging from PEP 201, "Lockstep
Iteration", to PEP 225, "Elementwise/Objectwise Operators".


File: python.info,  Node: Unicode,  Next: List Comprehensions,  Prev: New Development Process,  Up: What's New in Python 2 0

1.8.4 Unicode
-------------

The largest new feature in Python 2.0 is a new fundamental data type:
Unicode strings.  Unicode uses 16-bit numbers to represent characters
instead of the 8-bit number used by ASCII, meaning that 65,536 distinct
characters can be supported.

  The final interface for Unicode support was arrived at through
countless often- stormy discussions on the python-dev mailing list, and
mostly implemented by Marc-André Lemburg, based on a Unicode string type
implementation by Fredrik Lundh.  A detailed explanation of the
interface was written up as PEP 100(1), "Python Unicode Integration".
This article will simply cover the most significant points about the
Unicode interfaces.

  In Python source code, Unicode strings are written as ‘u"string"’.
Arbitrary Unicode characters can be written using a new escape sequence,
‘\uHHHH’, where _HHHH_ is a 4-digit hexadecimal number from 0000 to
FFFF. The existing ‘\xHHHH’ escape sequence can also be used, and octal
escapes can be used for characters up to U+01FF, which is represented by
‘\777’.

  Unicode strings, just like regular strings, are an immutable sequence
type.  They can be indexed and sliced, but not modified in place.
Unicode strings have an ‘encode( [encoding] )’ method that returns an
8-bit string in the desired encoding.  Encodings are named by strings,
such as ‘'ascii'’, ‘'utf-8'’, ‘'iso-8859-1'’, or whatever.  A codec API
is defined for implementing and registering new encodings that are then
available throughout a Python program.  If an encoding isn’t specified,
the default encoding is usually 7-bit ASCII, though it can be changed
for your Python installation by calling the
‘sys.setdefaultencoding(encoding)()’ function in a customised version of
‘site.py’.

  Combining 8-bit and Unicode strings always coerces to Unicode, using
the default ASCII encoding; the result of ‘'a' + u'bc'’ is ‘u'abc'’.

  New built-in functions have been added, and existing built-ins
modified to support Unicode:

   * ‘unichr(ch)’ returns a Unicode string 1 character long, containing
     the character _ch_.

   * ‘ord(u)’, where _u_ is a 1-character regular or Unicode string,
     returns the number of the character as an integer.

   * ‘unicode(string [, encoding] [, errors] )’ creates a Unicode string
     from an 8-bit string.  ‘encoding’ is a string naming the encoding
     to use.  The ‘errors’ parameter specifies the treatment of
     characters that are invalid for the current encoding; passing
     ‘'strict'’ as the value causes an exception to be raised on any
     encoding error, while ‘'ignore'’ causes errors to be silently
     ignored and ‘'replace'’ uses U+FFFD, the official replacement
     character, in case of any problems.

   * The *note exec: 404. statement, and various built-ins such as
     ‘eval()’, ‘getattr()’, and ‘setattr()’ will also accept Unicode
     strings as well as regular strings.  (It’s possible that the
     process of fixing this missed some built-ins; if you find a
     built-in function that accepts strings but doesn’t accept Unicode
     strings at all, please report it as a bug.)

  A new module, *note unicodedata: 186, provides an interface to Unicode
character properties.  For example, ‘unicodedata.category(u'A')’ returns
the 2-character string ’Lu’, the ’L’ denoting it’s a letter, and ’u’
meaning that it’s uppercase.  ‘unicodedata.bidirectional(u'\u0660')’
returns ’AN’, meaning that U+0660 is an Arabic number.

  The *note codecs: 63. module contains functions to look up existing
encodings and register new ones.  Unless you want to implement a new
encoding, you’ll most often use the ‘codecs.lookup(encoding)()’
function, which returns a 4-element tuple: ‘(encode_func, decode_func,
stream_reader, stream_writer)’.

   * _encode_func_ is a function that takes a Unicode string, and
     returns a 2-tuple ‘(string, length)’.  _string_ is an 8-bit string
     containing a portion (perhaps all) of the Unicode string converted
     into the given encoding, and _length_ tells you how much of the
     Unicode string was converted.

   * _decode_func_ is the opposite of _encode_func_, taking an 8-bit
     string and returning a 2-tuple ‘(ustring, length)’, consisting of
     the resulting Unicode string _ustring_ and the integer _length_
     telling how much of the 8-bit string was consumed.

   * _stream_reader_ is a class that supports decoding input from a
     stream.  _stream_reader(file_obj)_ returns an object that supports
     the ‘read()’, *note readline(): 144, and ‘readlines()’ methods.
     These methods will all translate from the given encoding and return
     Unicode strings.

   * _stream_writer_, similarly, is a class that supports encoding
     output to a stream.  _stream_writer(file_obj)_ returns an object
     that supports the ‘write()’ and ‘writelines()’ methods.  These
     methods expect Unicode strings, translating them to the given
     encoding on output.

  For example, the following code writes a Unicode string into a file,
encoding it as UTF-8:

     import codecs

     unistr = u'\u0660\u2000ab ...'

     (UTF8_encode, UTF8_decode,
      UTF8_streamreader, UTF8_streamwriter) = codecs.lookup('UTF-8')

     output = UTF8_streamwriter( open( '/tmp/output', 'wb') )
     output.write( unistr )
     output.close()

  The following code would then read UTF-8 input from the file:

     input = UTF8_streamreader( open( '/tmp/output', 'rb') )
     print repr(input.read())
     input.close()

  Unicode-aware regular expressions are available through the *note re:
143. module, which has a new underlying implementation called SRE
written by Fredrik Lundh of Secret Labs AB.

  A ‘-U’ command line option was added which causes the Python compiler
to interpret all string literals as Unicode string literals.  This is
intended to be used in testing and future-proofing your Python code,
since some future version of Python may drop support for 8-bit strings
and provide only Unicode strings.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0100


File: python.info,  Node: List Comprehensions,  Next: Augmented Assignment,  Prev: Unicode,  Up: What's New in Python 2 0

1.8.5 List Comprehensions
-------------------------

Lists are a workhorse data type in Python, and many programs manipulate
a list at some point.  Two common operations on lists are to loop over
them, and either pick out the elements that meet a certain criterion, or
apply some function to each element.  For example, given a list of
strings, you might want to pull out all the strings containing a given
substring, or strip off trailing whitespace from each line.

  The existing *note map(): 304. and *note filter(): 409. functions can
be used for this purpose, but they require a function as one of their
arguments.  This is fine if there’s an existing built-in function that
can be passed directly, but if there isn’t, you have to create a little
function to do the required work, and Python’s scoping rules make the
result ugly if the little function needs additional information.  Take
the first example in the previous paragraph, finding all the strings in
the list containing a given substring.  You could write the following to
do it:

     # Given the list L, make a list of all strings
     # containing the substring S.
     sublist = filter( lambda s, substring=S:
                          string.find(s, substring) != -1,
                       L)

  Because of Python’s scoping rules, a default argument is used so that
the anonymous function created by the *note lambda: 403. statement knows
what substring is being searched for.  List comprehensions make this
cleaner:

     sublist = [ s for s in L if string.find(s, S) != -1 ]

  List comprehensions have the form:

     [ expression for expr in sequence1
                  for expr2 in sequence2 ...
                  for exprN in sequenceN
                  if condition ]

  The *note for: 2f0...*note in: 428. clauses contain the sequences to
be iterated over.  The sequences do not have to be the same length,
because they are _not_ iterated over in parallel, but from left to
right; this is explained more clearly in the following paragraphs.  The
elements of the generated list will be the successive values of
_expression_.  The final *note if: 42c. clause is optional; if present,
_expression_ is only evaluated and added to the result if _condition_ is
true.

  To make the semantics very clear, a list comprehension is equivalent
to the following Python code:

     for expr1 in sequence1:
         for expr2 in sequence2:
         ...
             for exprN in sequenceN:
                  if (condition):
                       # Append the value of
                       # the expression to the
                       # resulting list.

  This means that when there are multiple *note for: 2f0...*note in:
428. clauses, the resulting list will be equal to the product of the
lengths of all the sequences.  If you have two lists of length 3, the
output list is 9 elements long:

     seq1 = 'abc'
     seq2 = (1,2,3)
     >>> [ (x,y) for x in seq1 for y in seq2]
     [('a', 1), ('a', 2), ('a', 3), ('b', 1), ('b', 2), ('b', 3), ('c', 1),
     ('c', 2), ('c', 3)]

  To avoid introducing an ambiguity into Python’s grammar, if
_expression_ is creating a tuple, it must be surrounded with
parentheses.  The first list comprehension below is a syntax error,
while the second one is correct:

     # Syntax error
     [ x,y for x in seq1 for y in seq2]
     # Correct
     [ (x,y) for x in seq1 for y in seq2]

  The idea of list comprehensions originally comes from the functional
programming language Haskell (‘http://www.haskell.org’).  Greg Ewing
argued most effectively for adding them to Python and wrote the initial
list comprehension patch, which was then discussed for a seemingly
endless time on the python-dev mailing list and kept up-to-date by Skip
Montanaro.


File: python.info,  Node: Augmented Assignment,  Next: String Methods,  Prev: List Comprehensions,  Up: What's New in Python 2 0

1.8.6 Augmented Assignment
--------------------------

Augmented assignment operators, another long-requested feature, have
been added to Python 2.0.  Augmented assignment operators include ‘+=’,
‘-=’, ‘*=’, and so forth.  For example, the statement ‘a += 2’
increments the value of the variable ‘a’ by 2, equivalent to the
slightly lengthier ‘a = a + 2’.

  The full list of supported assignment operators is ‘+=’, ‘-=’, ‘*=’,
‘/=’, ‘%=’, ‘**=’, ‘&=’, ‘|=’, ‘^=’, ‘>>=’, and ‘<<=’.  Python classes
can override the augmented assignment operators by defining methods
named *note __iadd__(): 4d8, *note __isub__(): 4d9, etc.  For example,
the following ‘Number’ class stores a number and supports using += to
create a new instance with an incremented value.

     class Number:
         def __init__(self, value):
             self.value = value
         def __iadd__(self, increment):
             return Number( self.value + increment)

     n = Number(5)
     n += 3
     print n.value

  The *note __iadd__(): 4d8. special method is called with the value of
the increment, and should return a new instance with an appropriately
modified value; this return value is bound as the new value of the
variable on the left-hand side.

  Augmented assignment operators were first introduced in the C
programming language, and most C-derived languages, such as *awk*, C++,
Java, Perl, and PHP also support them.  The augmented assignment patch
was implemented by Thomas Wouters.


File: python.info,  Node: String Methods,  Next: Garbage Collection of Cycles,  Prev: Augmented Assignment,  Up: What's New in Python 2 0

1.8.7 String Methods
--------------------

Until now string-manipulation functionality was in the *note string:
163. module, which was usually a front-end for the ‘strop’ module
written in C. The addition of Unicode posed a difficulty for the ‘strop’
module, because the functions would all need to be rewritten in order to
accept either 8-bit or Unicode strings.  For functions such as *note
string.replace(): 4db, which takes 3 string arguments, that means eight
possible permutations, and correspondingly complicated code.

  Instead, Python 2.0 pushes the problem onto the string type, making
string manipulation functionality available through methods on both
8-bit strings and Unicode strings.

     >>> 'andrew'.capitalize()
     'Andrew'
     >>> 'hostname'.replace('os', 'linux')
     'hlinuxtname'
     >>> 'moshe'.find('sh')
     2

  One thing that hasn’t changed, a noteworthy April Fools’ joke
notwithstanding, is that Python strings are immutable.  Thus, the string
methods return new strings, and do not modify the string on which they
operate.

  The old *note string: 163. module is still around for backwards
compatibility, but it mostly acts as a front-end to the new string
methods.

  Two methods which have no parallel in pre-2.0 versions, although they
did exist in JPython for quite some time, are ‘startswith()’ and
‘endswith()’.  ‘s.startswith(t)’ is equivalent to ‘s[:len(t)] == t’,
while ‘s.endswith(t)’ is equivalent to ‘s[-len(t):] == t’.

  One other method which deserves special mention is ‘join()’.  The
‘join()’ method of a string receives one parameter, a sequence of
strings, and is equivalent to the *note string.join(): 4dc. function
from the old *note string: 163. module, with the arguments reversed.  In
other words, ‘s.join(seq)’ is equivalent to the old ‘string.join(seq,
s)’.


File: python.info,  Node: Garbage Collection of Cycles,  Next: Other Core Changes,  Prev: String Methods,  Up: What's New in Python 2 0

1.8.8 Garbage Collection of Cycles
----------------------------------

The C implementation of Python uses reference counting to implement
garbage collection.  Every Python object maintains a count of the number
of references pointing to itself, and adjusts the count as references
are created or destroyed.  Once the reference count reaches zero, the
object is no longer accessible, since you need to have a reference to an
object to access it, and if the count is zero, no references exist any
longer.

  Reference counting has some pleasant properties: it’s easy to
understand and implement, and the resulting implementation is portable,
fairly fast, and reacts well with other libraries that implement their
own memory handling schemes.  The major problem with reference counting
is that it sometimes doesn’t realise that objects are no longer
accessible, resulting in a memory leak.  This happens when there are
cycles of references.

  Consider the simplest possible cycle, a class instance which has a
reference to itself:

     instance = SomeClass()
     instance.myself = instance

  After the above two lines of code have been executed, the reference
count of ‘instance’ is 2; one reference is from the variable named
‘'instance'’, and the other is from the ‘myself’ attribute of the
instance.

  If the next line of code is ‘del instance’, what happens?  The
reference count of ‘instance’ is decreased by 1, so it has a reference
count of 1; the reference in the ‘myself’ attribute still exists.  Yet
the instance is no longer accessible through Python code, and it could
be deleted.  Several objects can participate in a cycle if they have
references to each other, causing all of the objects to be leaked.

  Python 2.0 fixes this problem by periodically executing a cycle
detection algorithm which looks for inaccessible cycles and deletes the
objects involved.  A new *note gc: db. module provides functions to
perform a garbage collection, obtain debugging statistics, and tuning
the collector’s parameters.

  Running the cycle detection algorithm takes some time, and therefore
will result in some additional overhead.  It is hoped that after we’ve
gotten experience with the cycle collection from using 2.0, Python 2.1
will be able to minimize the overhead with careful tuning.  It’s not yet
obvious how much performance is lost, because benchmarking this is
tricky and depends crucially on how often the program creates and
destroys objects.  The detection of cycles can be disabled when Python
is compiled, if you can’t afford even a tiny speed penalty or suspect
that the cycle collection is buggy, by specifying the
‘--without-cycle-gc’ switch when running the *configure* script.

  Several people tackled this problem and contributed to a solution.  An
early implementation of the cycle detection approach was written by Toby
Kelsey.  The current algorithm was suggested by Eric Tiedemann during a
visit to CNRI, and Guido van Rossum and Neil Schemenauer wrote two
different implementations, which were later integrated by Neil.  Lots of
other people offered suggestions along the way; the March 2000 archives
of the python-dev mailing list contain most of the relevant discussion,
especially in the threads titled "Reference cycle collection for Python"
and "Finalization again".


File: python.info,  Node: Other Core Changes,  Next: Porting to 2 0,  Prev: Garbage Collection of Cycles,  Up: What's New in Python 2 0

1.8.9 Other Core Changes
------------------------

Various minor changes have been made to Python’s syntax and built-in
functions.  None of the changes are very far-reaching, but they’re handy
conveniences.

* Menu:

* Minor Language Changes:: 
* Changes to Built-in Functions:: 


File: python.info,  Node: Minor Language Changes,  Next: Changes to Built-in Functions,  Up: Other Core Changes

1.8.9.1 Minor Language Changes
..............................

A new syntax makes it more convenient to call a given function with a
tuple of arguments and/or a dictionary of keyword arguments.  In Python
1.5 and earlier, you’d use the *note apply(): 303. built-in function:
‘apply(f, args, kw)’ calls the function ‘f()’ with the argument tuple
_args_ and the keyword arguments in the dictionary _kw_.  *note apply():
303. is the same in 2.0, but thanks to a patch from Greg Ewing,
‘f(*args, **kw)’ as a shorter and clearer way to achieve the same
effect.  This syntax is symmetrical with the syntax for defining
functions:

     def f(*args, **kw):
         # args is a tuple of positional args,
         # kw is a dictionary of keyword args
         ...

  The *note print: 4e0. statement can now have its output directed to a
file-like object by following the *note print: 4e0. with ‘>> file’,
similar to the redirection operator in Unix shells.  Previously you’d
either have to use the ‘write()’ method of the file-like object, which
lacks the convenience and simplicity of *note print: 4e0, or you could
assign a new value to ‘sys.stdout’ and then restore the old value.  For
sending output to standard error, it’s much easier to write this:

     print >> sys.stderr, "Warning: action field not supplied"

  Modules can now be renamed on importing them, using the syntax ‘import
module as name’ or ‘from module import name as othername’.  The patch
was submitted by Thomas Wouters.

  A new format style is available when using the ‘%’ operator; ’%r’ will
insert the *note repr(): 145. of its argument.  This was also added from
symmetry considerations, this time for symmetry with the existing ’%s’
format style, which inserts the *note str(): 1ea. of its argument.  For
example, ‘'%r %s' % ('abc', 'abc')’ returns a string containing ‘'abc'
abc’.

  Previously there was no way to implement a class that overrode
Python’s built-in *note in: 428. operator and implemented a custom
version.  ‘obj in seq’ returns true if _obj_ is present in the sequence
_seq_; Python computes this by simply trying every index of the sequence
until either _obj_ is found or an *note IndexError: 4e1. is encountered.
Moshe Zadka contributed a patch which adds a *note __contains__(): 322.
magic method for providing a custom implementation for *note in: 428.
Additionally, new built-in objects written in C can define what *note
in: 428. means for them via a new slot in the sequence protocol.

  Earlier versions of Python used a recursive algorithm for deleting
objects.  Deeply nested data structures could cause the interpreter to
fill up the C stack and crash; Christian Tismer rewrote the deletion
logic to fix this problem.  On a related note, comparing recursive
objects recursed infinitely and crashed; Jeremy Hylton rewrote the code
to no longer crash, producing a useful result instead.  For example,
after this code:

     a = []
     b = []
     a.append(a)
     b.append(b)

  The comparison ‘a==b’ returns true, because the two recursive data
structures are isomorphic.  See the thread "trashcan and PR#7" in the
April 2000 archives of the python-dev mailing list for the discussion
leading up to this implementation, and some useful relevant links.  Note
that comparisons can now also raise exceptions.  In earlier versions of
Python, a comparison operation such as ‘cmp(a,b)’ would always produce
an answer, even if a user-defined *note __cmp__(): 221. method
encountered an error, since the resulting exception would simply be
silently swallowed.

  Work has been done on porting Python to 64-bit Windows on the Itanium
processor, mostly by Trent Mick of ActiveState.  (Confusingly,
‘sys.platform’ is still ‘'win32'’ on Win64 because it seems that for
ease of porting, MS Visual C++ treats code as 32 bit on Itanium.)
PythonWin also supports Windows CE; see the Python CE page at
‘http://pythonce.sourceforge.net/’ for more information.

  Another new platform is Darwin/MacOS X; initial support for it is in
Python 2.0.  Dynamic loading works, if you specify "configure –with-dyld
–with-suffix=.x".  Consult the README in the Python source distribution
for more instructions.

  An attempt has been made to alleviate one of Python’s warts, the
often-confusing *note NameError: 3a3. exception when code refers to a
local variable before the variable has been assigned a value.  For
example, the following code raises an exception on the *note print: 4e0.
statement in both 1.5.2 and 2.0; in 1.5.2 a *note NameError: 3a3.
exception is raised, while 2.0 raises a new *note UnboundLocalError:
4e2. exception.  *note UnboundLocalError: 4e2. is a subclass of *note
NameError: 3a3, so any existing code that expects *note NameError: 3a3.
to be raised should still work.

     def f():
         print "i=",i
         i = i + 1
     f()

  Two new exceptions, *note TabError: 4e3. and *note IndentationError:
4e4, have been introduced.  They’re both subclasses of *note
SyntaxError: 498, and are raised when Python code is found to be
improperly indented.


File: python.info,  Node: Changes to Built-in Functions,  Prev: Minor Language Changes,  Up: Other Core Changes

1.8.9.2 Changes to Built-in Functions
.....................................

A new built-in, ‘zip(seq1, seq2, ...)()’, has been added.  *note zip():
405. returns a list of tuples where each tuple contains the i-th element
from each of the argument sequences.  The difference between *note
zip(): 405. and ‘map(None, seq1, seq2)’ is that *note map(): 304. pads
the sequences with ‘None’ if the sequences aren’t all of the same
length, while *note zip(): 405. truncates the returned list to the
length of the shortest argument sequence.

  The *note int(): 1f2. and *note long(): 1f3. functions now accept an
optional "base" parameter when the first argument is a string.
‘int('123', 10)’ returns 123, while ‘int('123', 16)’ returns 291.
‘int(123, 16)’ raises a *note TypeError: 218. exception with the message
"can’t convert non-string with explicit base".

  A new variable holding more detailed version information has been
added to the *note sys: 16d. module.  ‘sys.version_info’ is a tuple
‘(major, minor, micro, level, serial)’ For example, in a hypothetical
2.0.1beta1, ‘sys.version_info’ would be ‘(2, 0, 1, 'beta', 1)’.  _level_
is a string such as ‘"alpha"’, ‘"beta"’, or ‘"final"’ for a final
release.

  Dictionaries have an odd new method, ‘setdefault(key, default)()’,
which behaves similarly to the existing ‘get()’ method.  However, if the
key is missing, ‘setdefault()’ both returns the value of _default_ as
‘get()’ would do, and also inserts it into the dictionary as the value
for _key_.  Thus, the following lines of code:

     if dict.has_key( key ): return dict[key]
     else:
         dict[key] = []
         return dict[key]

  can be reduced to a single ‘return dict.setdefault(key, [])’
statement.

  The interpreter sets a maximum recursion depth in order to catch
runaway recursion before filling the C stack and causing a core dump or
GPF.. Previously this limit was fixed when you compiled Python, but in
2.0 the maximum recursion depth can be read and modified using *note
sys.getrecursionlimit(): 4e6. and *note sys.setrecursionlimit(): 4e7.
The default value is 1000, and a rough maximum value for a given
platform can be found by running a new script,
‘Misc/find_recursionlimit.py’.


File: python.info,  Node: Porting to 2 0,  Next: Extending/Embedding Changes,  Prev: Other Core Changes,  Up: What's New in Python 2 0

1.8.10 Porting to 2.0
---------------------

New Python releases try hard to be compatible with previous releases,
and the record has been pretty good.  However, some changes are
considered useful enough, usually because they fix initial design
decisions that turned out to be actively mistaken, that breaking
backward compatibility can’t always be avoided.  This section lists the
changes in Python 2.0 that may cause old Python code to break.

  The change which will probably break the most code is tightening up
the arguments accepted by some methods.  Some methods would take
multiple arguments and treat them as a tuple, particularly various list
methods such as ‘append()’ and ‘insert()’.  In earlier versions of
Python, if ‘L’ is a list, ‘L.append( 1,2 )’ appends the tuple ‘(1,2)’ to
the list.  In Python 2.0 this causes a *note TypeError: 218. exception
to be raised, with the message: ’append requires exactly 1 argument; 2
given’.  The fix is to simply add an extra set of parentheses to pass
both values as a tuple: ‘L.append( (1,2) )’.

  The earlier versions of these methods were more forgiving because they
used an old function in Python’s C interface to parse their arguments;
2.0 modernizes them to use ‘PyArg_ParseTuple()’, the current argument
parsing function, which provides more helpful error messages and treats
multi-argument calls as errors.  If you absolutely must use 2.0 but
can’t fix your code, you can edit ‘Objects/listobject.c’ and define the
preprocessor symbol ‘NO_STRICT_LIST_APPEND’ to preserve the old
behaviour; this isn’t recommended.

  Some of the functions in the *note socket: 15c. module are still
forgiving in this way.  For example, ‘socket.connect( ('hostname', 25)
)()’ is the correct form, passing a tuple representing an IP address,
but ‘socket.connect( 'hostname', 25 )()’ also works.
‘socket.connect_ex()’ and ‘socket.bind()’ are similarly easy-going.
2.0alpha1 tightened these functions up, but because the documentation
actually used the erroneous multiple argument form, many people wrote
code which would break with the stricter checking.  GvR backed out the
changes in the face of public reaction, so for the *note socket: 15c.
module, the documentation was fixed and the multiple argument form is
simply marked as deprecated; it _will_ be tightened up again in a future
Python version.

  The ‘\x’ escape in string literals now takes exactly 2 hex digits.
Previously it would consume all the hex digits following the ’x’ and
take the lowest 8 bits of the result, so ‘\x123456’ was equivalent to
‘\x56’.

  The *note AttributeError: 1f8. and *note NameError: 3a3. exceptions
have a more friendly error message, whose text will be something like
‘'Spam' instance has no attribute 'eggs'’ or ‘name 'eggs' is not
defined’.  Previously the error message was just the missing attribute
name ‘eggs’, and code written to take advantage of this fact will break
in 2.0.

  Some work has been done to make integers and long integers a bit more
interchangeable.  In 1.5.2, large-file support was added for Solaris, to
allow reading files larger than 2 GiB; this made the ‘tell()’ method of
file objects return a long integer instead of a regular integer.  Some
code would subtract two file offsets and attempt to use the result to
multiply a sequence or slice a string, but this raised a *note
TypeError: 218.  In 2.0, long integers can be used to multiply or slice
a sequence, and it’ll behave as you’d intuitively expect it to; ‘3L *
'abc'’ produces ’abcabcabc’, and ‘(0,1,2,3)[2L:4L]’ produces (2,3).
Long integers can also be used in various contexts where previously only
integers were accepted, such as in the ‘seek()’ method of file objects,
and in the formats supported by the ‘%’ operator (‘%d’, ‘%i’, ‘%x’,
etc.).  For example, ‘"%d" % 2L**64’ will produce the string
‘18446744073709551616’.

  The subtlest long integer change of all is that the *note str(): 1ea.
of a long integer no longer has a trailing ’L’ character, though *note
repr(): 145. still includes it.  The ’L’ annoyed many people who wanted
to print long integers that looked just like regular integers, since
they had to go out of their way to chop off the character.  This is no
longer a problem in 2.0, but code which does ‘str(longval)[:-1]’ and
assumes the ’L’ is there, will now lose the final digit.

  Taking the *note repr(): 145. of a float now uses a different
formatting precision than *note str(): 1ea.  *note repr(): 145. uses
‘%.17g’ format string for C’s ‘sprintf()’, while *note str(): 1ea. uses
‘%.12g’ as before.  The effect is that *note repr(): 145. may
occasionally show more decimal places than *note str(): 1ea, for certain
numbers.  For example, the number 8.1 can’t be represented exactly in
binary, so ‘repr(8.1)’ is ‘'8.0999999999999996'’, while str(8.1) is
‘'8.1'’.

  The ‘-X’ command-line option, which turned all standard exceptions
into strings instead of classes, has been removed; the standard
exceptions will now always be classes.  The *note exceptions: c9. module
containing the standard exceptions was translated from Python to a
built-in C module, written by Barry Warsaw and Fredrik Lundh.


File: python.info,  Node: Extending/Embedding Changes,  Next: Distutils Making Modules Easy to Install,  Prev: Porting to 2 0,  Up: What's New in Python 2 0

1.8.11 Extending/Embedding Changes
----------------------------------

Some of the changes are under the covers, and will only be apparent to
people writing C extension modules or embedding a Python interpreter in
a larger application.  If you aren’t dealing with Python’s C API, you
can safely skip this section.

  The version number of the Python C API was incremented, so C
extensions compiled for 1.5.2 must be recompiled in order to work with
2.0.  On Windows, it’s not possible for Python 2.0 to import a third
party extension built for Python 1.5.x due to how Windows DLLs work, so
Python will raise an exception and the import will fail.

  Users of Jim Fulton’s ExtensionClass module will be pleased to find
out that hooks have been added so that ExtensionClasses are now
supported by *note isinstance(): 31e. and *note issubclass(): 31f.  This
means you no longer have to remember to write code such as ‘if type(obj)
== myExtensionClass’, but can use the more natural ‘if isinstance(obj,
myExtensionClass)’.

  The ‘Python/importdl.c’ file, which was a mass of #ifdefs to support
dynamic loading on many different platforms, was cleaned up and
reorganised by Greg Stein.  ‘importdl.c’ is now quite small, and
platform-specific code has been moved into a bunch of
‘Python/dynload_*.c’ files.  Another cleanup: there were also a number
of ‘my*.h’ files in the Include/ directory that held various portability
hacks; they’ve been merged into a single file, ‘Include/pyport.h’.

  Vladimir Marangozov’s long-awaited malloc restructuring was completed,
to make it easy to have the Python interpreter use a custom allocator
instead of C’s standard ‘malloc()’.  For documentation, read the
comments in ‘Include/pymem.h’ and ‘Include/objimpl.h’.  For the lengthy
discussions during which the interface was hammered out, see the Web
archives of the ’patches’ and ’python-dev’ lists at python.org.

  Recent versions of the GUSI development environment for MacOS support
POSIX threads.  Therefore, Python’s POSIX threading support now works on
the Macintosh.  Threading support using the user-space GNU ‘pth’ library
was also contributed.

  Threading support on Windows was enhanced, too.  Windows supports
thread locks that use kernel objects only in case of contention; in the
common case when there’s no contention, they use simpler functions which
are an order of magnitude faster.  A threaded version of Python 1.5.2 on
NT is twice as slow as an unthreaded version; with the 2.0 changes, the
difference is only 10%.  These improvements were contributed by Yakov
Markovitch.

  Python 2.0’s source now uses only ANSI C prototypes, so compiling
Python now requires an ANSI C compiler, and can no longer be done using
a compiler that only supports K&R C.

  Previously the Python virtual machine used 16-bit numbers in its
bytecode, limiting the size of source files.  In particular, this
affected the maximum size of literal lists and dictionaries in Python
source; occasionally people who are generating Python code would run
into this limit.  A patch by Charles G. Waldman raises the limit from
‘2^16’ to ‘2^{32}’.

  Three new convenience functions intended for adding constants to a
module’s dictionary at module initialization time were added:
‘PyModule_AddObject()’, ‘PyModule_AddIntConstant()’, and
‘PyModule_AddStringConstant()’.  Each of these functions takes a module
object, a null-terminated C string containing the name to be added, and
a third argument for the value to be assigned to the name.  This third
argument is, respectively, a Python object, a C long, or a C string.

  A wrapper API was added for Unix-style signal handlers.
‘PyOS_getsig()’ gets a signal handler and ‘PyOS_setsig()’ will set a new
handler.


File: python.info,  Node: Distutils Making Modules Easy to Install,  Next: XML Modules,  Prev: Extending/Embedding Changes,  Up: What's New in Python 2 0

1.8.12 Distutils: Making Modules Easy to Install
------------------------------------------------

Before Python 2.0, installing modules was a tedious affair – there was
no way to figure out automatically where Python is installed, or what
compiler options to use for extension modules.  Software authors had to
go through an arduous ritual of editing Makefiles and configuration
files, which only really work on Unix and leave Windows and MacOS
unsupported.  Python users faced wildly differing installation
instructions which varied between different extension packages, which
made administering a Python installation something of a chore.

  The SIG for distribution utilities, shepherded by Greg Ward, has
created the Distutils, a system to make package installation much
easier.  They form the *note distutils: 85. package, a new part of
Python’s standard library.  In the best case, installing a Python module
from source will require the same steps: first you simply mean unpack
the tarball or zip archive, and the run "‘python setup.py install’".
The platform will be automatically detected, the compiler will be
recognized, C extension modules will be compiled, and the distribution
installed into the proper directory.  Optional command-line arguments
provide more control over the installation process, the distutils
package offers many places to override defaults – separating the build
from the install, building or installing in non-default directories, and
more.

  In order to use the Distutils, you need to write a ‘setup.py’ script.
For the simple case, when the software contains only .py files, a
minimal ‘setup.py’ can be just a few lines long:

     from distutils.core import setup
     setup (name = "foo", version = "1.0",
            py_modules = ["module1", "module2"])

  The ‘setup.py’ file isn’t much more complicated if the software
consists of a few packages:

     from distutils.core import setup
     setup (name = "foo", version = "1.0",
            packages = ["package", "package.subpackage"])

  A C extension can be the most complicated case; here’s an example
taken from the PyXML package:

     from distutils.core import setup, Extension

     expat_extension = Extension('xml.parsers.pyexpat',
          define_macros = [('XML_NS', None)],
          include_dirs = [ 'extensions/expat/xmltok',
                           'extensions/expat/xmlparse' ],
          sources = [ 'extensions/pyexpat.c',
                      'extensions/expat/xmltok/xmltok.c',
                      'extensions/expat/xmltok/xmlrole.c', ]
            )
     setup (name = "PyXML", version = "0.5.4",
            ext_modules =[ expat_extension ] )

  The Distutils can also take care of creating source and binary
distributions.  The "sdist" command, run by "‘python setup.py sdist’’,
builds a source distribution such as ‘foo-1.0.tar.gz’.  Adding new
commands isn’t difficult, "bdist_rpm" and "bdist_wininst" commands have
already been contributed to create an RPM distribution and a Windows
installer for the software, respectively.  Commands to create other
distribution formats such as Debian packages and Solaris ‘.pkg’ files
are in various stages of development.

  All this is documented in a new manual, _Distributing Python Modules_,
that joins the basic set of Python documentation.


File: python.info,  Node: XML Modules,  Next: Module changes,  Prev: Distutils Making Modules Easy to Install,  Up: What's New in Python 2 0

1.8.13 XML Modules
------------------

Python 1.5.2 included a simple XML parser in the form of the ‘xmllib’
module, contributed by Sjoerd Mullender.  Since 1.5.2’s release, two
different interfaces for processing XML have become common: SAX2
(version 2 of the Simple API for XML) provides an event-driven interface
with some similarities to ‘xmllib’, and the DOM (Document Object Model)
provides a tree-based interface, transforming an XML document into a
tree of nodes that can be traversed and modified.  Python 2.0 includes a
SAX2 interface and a stripped- down DOM interface as part of the *note
xml: 1a0. package.  Here we will give a brief overview of these new
interfaces; consult the Python documentation or the source code for
complete details.  The Python XML SIG is also working on improved
documentation.

* Menu:

* SAX2 Support:: 
* DOM Support:: 
* Relationship to PyXML:: 


File: python.info,  Node: SAX2 Support,  Next: DOM Support,  Up: XML Modules

1.8.13.1 SAX2 Support
.....................

SAX defines an event-driven interface for parsing XML. To use SAX, you
must write a SAX handler class.  Handler classes inherit from various
classes provided by SAX, and override various methods that will then be
called by the XML parser.  For example, the ‘startElement()’ and
‘endElement()’ methods are called for every starting and end tag
encountered by the parser, the ‘characters()’ method is called for every
chunk of character data, and so forth.

  The advantage of the event-driven approach is that the whole document
doesn’t have to be resident in memory at any one time, which matters if
you are processing really huge documents.  However, writing the SAX
handler class can get very complicated if you’re trying to modify the
document structure in some elaborate way.

  For example, this little example program defines a handler that prints
a message for every starting and ending tag, and then parses the file
‘hamlet.xml’ using it:

     from xml import sax

     class SimpleHandler(sax.ContentHandler):
         def startElement(self, name, attrs):
             print 'Start of element:', name, attrs.keys()

         def endElement(self, name):
             print 'End of element:', name

     # Create a parser object
     parser = sax.make_parser()

     # Tell it what handler to use
     handler = SimpleHandler()
     parser.setContentHandler( handler )

     # Parse a file!
     parser.parse( 'hamlet.xml' )

  For more information, consult the Python documentation, or the XML
HOWTO at ‘http://pyxml.sourceforge.net/topics/howto/xml-howto.html’.


File: python.info,  Node: DOM Support,  Next: Relationship to PyXML,  Prev: SAX2 Support,  Up: XML Modules

1.8.13.2 DOM Support
....................

The Document Object Model is a tree-based representation for an XML
document.  A top-level ‘Document’ instance is the root of the tree, and
has a single child which is the top-level ‘Element’ instance.  This
‘Element’ has children nodes representing character data and any
sub-elements, which may have further children of their own, and so
forth.  Using the DOM you can traverse the resulting tree any way you
like, access element and attribute values, insert and delete nodes, and
convert the tree back into XML.

  The DOM is useful for modifying XML documents, because you can create
a DOM tree, modify it by adding new nodes or rearranging subtrees, and
then produce a new XML document as output.  You can also construct a DOM
tree manually and convert it to XML, which can be a more flexible way of
producing XML output than simply writing ‘<tag1>’...‘</tag1>’ to a file.

  The DOM implementation included with Python lives in the *note
xml.dom.minidom: 1a2. module.  It’s a lightweight implementation of the
Level 1 DOM with support for XML namespaces.  The ‘parse()’ and
‘parseString()’ convenience functions are provided for generating a DOM
tree:

     from xml.dom import minidom
     doc = minidom.parse('hamlet.xml')

  ‘doc’ is a ‘Document’ instance.  ‘Document’, like all the other DOM
classes such as ‘Element’ and ‘Text’, is a subclass of the ‘Node’ base
class.  All the nodes in a DOM tree therefore support certain common
methods, such as ‘toxml()’ which returns a string containing the XML
representation of the node and its children.  Each class also has
special methods of its own; for example, ‘Element’ and ‘Document’
instances have a method to find all child elements with a given tag
name.  Continuing from the previous 2-line example:

     perslist = doc.getElementsByTagName( 'PERSONA' )
     print perslist[0].toxml()
     print perslist[1].toxml()

  For the _Hamlet_ XML file, the above few lines output:

     <PERSONA>CLAUDIUS, king of Denmark. </PERSONA>
     <PERSONA>HAMLET, son to the late, and nephew to the present king.</PERSONA>

  The root element of the document is available as
‘doc.documentElement’, and its children can be easily modified by
deleting, adding, or removing nodes:

     root = doc.documentElement

     # Remove the first child
     root.removeChild( root.childNodes[0] )

     # Move the new first child to the end
     root.appendChild( root.childNodes[0] )

     # Insert the new first child (originally,
     # the third child) before the 20th child.
     root.insertBefore( root.childNodes[0], root.childNodes[20] )

  Again, I will refer you to the Python documentation for a complete
listing of the different ‘Node’ classes and their various methods.


File: python.info,  Node: Relationship to PyXML,  Prev: DOM Support,  Up: XML Modules

1.8.13.3 Relationship to PyXML
..............................

The XML Special Interest Group has been working on XML-related Python
code for a while.  Its code distribution, called PyXML, is available
from the SIG’s Web pages at ‘http://www.python.org/sigs/xml-sig/’.  The
PyXML distribution also used the package name ‘xml’.  If you’ve written
programs that used PyXML, you’re probably wondering about its
compatibility with the 2.0 *note xml: 1a0. package.

  The answer is that Python 2.0’s *note xml: 1a0. package isn’t
compatible with PyXML, but can be made compatible by installing a recent
version PyXML. Many applications can get by with the XML support that is
included with Python 2.0, but more complicated applications will require
that the full PyXML package will be installed.  When installed, PyXML
versions 0.6.0 or greater will replace the *note xml: 1a0. package
shipped with Python, and will be a strict superset of the standard
package, adding a bunch of additional features.  Some of the additional
features in PyXML include:

   * 4DOM, a full DOM implementation from FourThought, Inc.

   * The xmlproc validating parser, written by Lars Marius Garshol.

   * The ‘sgmlop’ parser accelerator module, written by Fredrik Lundh.


File: python.info,  Node: Module changes,  Next: New modules,  Prev: XML Modules,  Up: What's New in Python 2 0

1.8.14 Module changes
---------------------

Lots of improvements and bugfixes were made to Python’s extensive
standard library; some of the affected modules include *note readline:
144, *note ConfigParser: 6d, *note cgi: 5c, *note calendar: 1f, *note
posix: 136, *note readline: 144, ‘xmllib’, *note aifc: 8, ‘chunk, wave’,
*note random: 142, *note shelve: 152, and *note nntplib: 124.  Consult
the CVS logs for the exact patch-by-patch details.

  Brian Gallew contributed OpenSSL support for the *note socket: 15c.
module.  OpenSSL is an implementation of the Secure Socket Layer, which
encrypts the data being sent over a socket.  When compiling Python, you
can edit ‘Modules/Setup’ to include SSL support, which adds an
additional function to the *note socket: 15c. module:
‘socket.ssl(socket, keyfile, certfile)()’, which takes a socket object
and returns an SSL socket.  The *note httplib: ee. and *note urllib:
188. modules were also changed to support ‘https://’ URLs, though no one
has implemented FTP or SMTP over SSL.

  The *note httplib: ee. module has been rewritten by Greg Stein to
support HTTP/1.1.  Backward compatibility with the 1.5 version of *note
httplib: ee. is provided, though using HTTP/1.1 features such as
pipelining will require rewriting code to use a different set of
interfaces.

  The *note Tkinter: 17d. module now supports Tcl/Tk version 8.1, 8.2,
or 8.3, and support for the older 7.x versions has been dropped.  The
Tkinter module now supports displaying Unicode strings in Tk widgets.
Also, Fredrik Lundh contributed an optimization which makes operations
like ‘create_line’ and ‘create_polygon’ much faster, especially when
using lots of coordinates.

  The *note curses: 79. module has been greatly extended, starting from
Oliver Andrich’s enhanced version, to provide many additional functions
from ncurses and SYSV curses, such as colour, alternative character set
support, pads, and mouse support.  This means the module is no longer
compatible with operating systems that only have BSD curses, but there
don’t seem to be any currently maintained OSes that fall into this
category.

  As mentioned in the earlier discussion of 2.0’s Unicode support, the
underlying implementation of the regular expressions provided by the
*note re: 143. module has been changed.  SRE, a new regular expression
engine written by Fredrik Lundh and partially funded by Hewlett Packard,
supports matching against both 8-bit strings and Unicode strings.


File: python.info,  Node: New modules,  Next: IDLE Improvements,  Prev: Module changes,  Up: What's New in Python 2 0

1.8.15 New modules
------------------

A number of new modules were added.  We’ll simply list them with brief
descriptions; consult the 2.0 documentation for the details of a
particular module.

   * *note atexit: 12.: For registering functions to be called before
     the Python interpreter exits.  Code that currently sets
     ‘sys.exitfunc’ directly should be changed to use the *note atexit:
     12. module instead, importing *note atexit: 12. and calling *note
     atexit.register(): 4f1. with the function to be called on exit.
     (Contributed by Skip Montanaro.)

   * *note codecs: 63, ‘encodings’, *note unicodedata: 186.: Added as
     part of the new Unicode support.

   * *note filecmp: cb.: Supersedes the old *note cmp: 4be, ‘cmpcache’
     and ‘dircmp’ modules, which have now become deprecated.
     (Contributed by Gordon MacMillan and Moshe Zadka.)

   * *note gettext: e0.: This module provides internationalization
     (I18N) and localization (L10N) support for Python programs by
     providing an interface to the GNU gettext message catalog library.
     (Integrated by Barry Warsaw, from separate contributions by Martin
     von Löwis, Peter Funk, and James Henstridge.)

   * ‘linuxaudiodev’: Support for the ‘/dev/audio’ device on Linux, a
     twin to the existing *note sunaudiodev: 169. module.  (Contributed
     by Peter Bosch, with fixes by Jeremy Hylton.)

   * *note mmap: 114.: An interface to memory-mapped files on both
     Windows and Unix.  A file’s contents can be mapped directly into
     memory, at which point it behaves like a mutable string, so its
     contents can be read and modified.  They can even be passed to
     functions that expect ordinary strings, such as the *note re: 143.
     module.  (Contributed by Sam Rushing, with some extensions by A.M.
     Kuchling.)

   * ‘pyexpat’: An interface to the Expat XML parser.  (Contributed by
     Paul Prescod.)

   * *note robotparser: 14a.: Parse a ‘robots.txt’ file, which is used
     for writing Web spiders that politely avoid certain areas of a Web
     site.  The parser accepts the contents of a ‘robots.txt’ file,
     builds a set of rules from it, and can then answer questions about
     the fetchability of a given URL. (Contributed by Skip Montanaro.)

   * *note tabnanny: 170.: A module/script to check Python source code
     for ambiguous indentation.  (Contributed by Tim Peters.)

   * *note UserString: 18e.: A base class useful for deriving objects
     that behave like strings.

   * *note webbrowser: 196.: A module that provides a platform
     independent way to launch a web browser on a specific URL. For each
     platform, various browsers are tried in a specific order.  The user
     can alter which browser is launched by setting the _BROWSER_
     environment variable.  (Originally inspired by Eric S. Raymond’s
     patch to *note urllib: 188. which added similar functionality, but
     the final module comes from code originally implemented by Fred
     Drake as ‘Tools/idle/BrowserControl.py’, and adapted for the
     standard library by Fred.)

   * *note _winreg: 3.: An interface to the Windows registry.  *note
     _winreg: 3. is an adaptation of functions that have been part of
     PythonWin since 1995, but has now been added to the core
     distribution, and enhanced to support Unicode.  *note _winreg: 3.
     was written by Bill Tutt and Mark Hammond.

   * *note zipfile: 1ab.: A module for reading and writing ZIP-format
     archives.  These are archives produced by *PKZIP* on DOS/Windows or
     *zip* on Unix, not to be confused with *gzip*-format files (which
     are supported by the *note gzip: e5. module) (Contributed by James
     C. Ahlstrom.)

   * *note imputil: f7.: A module that provides a simpler way for
     writing customised import hooks, in comparison to the existing
     ‘ihooks’ module.  (Implemented by Greg Stein, with much discussion
     on python-dev along the way.)


File: python.info,  Node: IDLE Improvements,  Next: Deleted and Deprecated Modules,  Prev: New modules,  Up: What's New in Python 2 0

1.8.16 IDLE Improvements
------------------------

IDLE is the official Python cross-platform IDE, written using Tkinter.
Python 2.0 includes IDLE 0.6, which adds a number of new features and
improvements.  A partial list:

   * UI improvements and optimizations, especially in the area of syntax
     highlighting and auto-indentation.

   * The class browser now shows more information, such as the top level
     functions in a module.

   * Tab width is now a user settable option.  When opening an existing
     Python file, IDLE automatically detects the indentation
     conventions, and adapts.

   * There is now support for calling browsers on various platforms,
     used to open the Python documentation in a browser.

   * IDLE now has a command line, which is largely similar to the
     vanilla Python interpreter.

   * Call tips were added in many places.

   * IDLE can now be installed as a package.

   * In the editor window, there is now a line/column bar at the bottom.

   * Three new keystroke commands: Check module (Alt-F5), Import module
     (F5) and Run script (Ctrl-F5).


File: python.info,  Node: Deleted and Deprecated Modules,  Next: Acknowledgements<8>,  Prev: IDLE Improvements,  Up: What's New in Python 2 0

1.8.17 Deleted and Deprecated Modules
-------------------------------------

A few modules have been dropped because they’re obsolete, or because
there are now better ways to do the same thing.  The ‘stdwin’ module is
gone; it was for a platform-independent windowing toolkit that’s no
longer developed.

  A number of modules have been moved to the ‘lib-old’ subdirectory:
*note cmp: 4be, ‘cmpcache’, ‘dircmp’, ‘dump’, ‘find’, ‘grep’,
‘packmail’, ‘poly’, ‘util’, ‘whatsound’, ‘zmod’.  If you have code which
relies on a module that’s been moved to ‘lib-old’, you can simply add
that directory to ‘sys.path’ to get them back, but you’re encouraged to
update any code that uses these modules.


File: python.info,  Node: Acknowledgements<8>,  Prev: Deleted and Deprecated Modules,  Up: What's New in Python 2 0

1.8.18 Acknowledgements
-----------------------

The authors would like to thank the following people for offering
suggestions on various drafts of this article: David Bolen, Mark
Hammond, Gregg Hauser, Jeremy Hylton, Fredrik Lundh, Detlef Lannert,
Aahz Maruch, Skip Montanaro, Vladimir Marangozov, Tobias Polzin, Guido
van Rossum, Neil Schemenauer, and Russ Schmidt.


File: python.info,  Node: The Python Tutorial,  Next: Python Setup and Usage,  Prev: What's New in Python,  Up: Top

2 The Python Tutorial
*********************

Python is an easy to learn, powerful programming language.  It has
efficient high-level data structures and a simple but effective approach
to object-oriented programming.  Python’s elegant syntax and dynamic
typing, together with its interpreted nature, make it an ideal language
for scripting and rapid application development in many areas on most
platforms.

  The Python interpreter and the extensive standard library are freely
available in source or binary form for all major platforms from the
Python Web site, ‘http://www.python.org/’, and may be freely
distributed.  The same site also contains distributions of and pointers
to many free third party Python modules, programs and tools, and
additional documentation.

  The Python interpreter is easily extended with new functions and data
types implemented in C or C++ (or other languages callable from C).
Python is also suitable as an extension language for customizable
applications.

  This tutorial introduces the reader informally to the basic concepts
and features of the Python language and system.  It helps to have a
Python interpreter handy for hands-on experience, but all examples are
self-contained, so the tutorial can be read off-line as well.

  For a description of standard objects and modules, see *note The
Python Standard Library: 4f8.  *note The Python Language Reference: 4f9.
gives a more formal definition of the language.  To write extensions in
C or C++, read *note Extending and Embedding the Python Interpreter:
4fa. and *note Python/C API Reference Manual: 4fb.  There are also
several books covering Python in depth.

  This tutorial does not attempt to be comprehensive and cover every
single feature, or even every commonly used feature.  Instead, it
introduces many of Python’s most noteworthy features, and will give you
a good idea of the language’s flavor and style.  After reading it, you
will be able to read and write Python modules and programs, and you will
be ready to learn more about the various Python library modules
described in *note The Python Standard Library: 4f8.

  The *note Glossary: 4fc. is also worth going through.

* Menu:

* Whetting Your Appetite:: 
* Using the Python Interpreter:: 
* An Informal Introduction to Python:: 
* More Control Flow Tools:: 
* Data Structures:: 
* Modules:: 
* Input and Output:: 
* Errors and Exceptions:: 
* Classes:: 
* Brief Tour of the Standard Library:: 
* Brief Tour of the Standard Library: Brief Tour of the Standard Library -- Part II. Part II
* What Now?:: 
* Interactive Input Editing and History Substitution:: 
* Floating Point Arithmetic; Issues and Limitations: Floating Point Arithmetic Issues and Limitations. 


File: python.info,  Node: Whetting Your Appetite,  Next: Using the Python Interpreter,  Up: The Python Tutorial

2.1 Whetting Your Appetite
==========================

If you do much work on computers, eventually you find that there’s some
task you’d like to automate.  For example, you may wish to perform a
search-and-replace over a large number of text files, or rename and
rearrange a bunch of photo files in a complicated way.  Perhaps you’d
like to write a small custom database, or a specialized GUI application,
or a simple game.

  If you’re a professional software developer, you may have to work with
several C/C++/Java libraries but find the usual
write/compile/test/re-compile cycle is too slow.  Perhaps you’re writing
a test suite for such a library and find writing the testing code a
tedious task.  Or maybe you’ve written a program that could use an
extension language, and you don’t want to design and implement a whole
new language for your application.

  Python is just the language for you.

  You could write a Unix shell script or Windows batch files for some of
these tasks, but shell scripts are best at moving around files and
changing text data, not well-suited for GUI applications or games.  You
could write a C/C++/Java program, but it can take a lot of development
time to get even a first-draft program.  Python is simpler to use,
available on Windows, Mac OS X, and Unix operating systems, and will
help you get the job done more quickly.

  Python is simple to use, but it is a real programming language,
offering much more structure and support for large programs than shell
scripts or batch files can offer.  On the other hand, Python also offers
much more error checking than C, and, being a _very-high-level
language_, it has high-level data types built in, such as flexible
arrays and dictionaries.  Because of its more general data types Python
is applicable to a much larger problem domain than Awk or even Perl, yet
many things are at least as easy in Python as in those languages.

  Python allows you to split your program into modules that can be
reused in other Python programs.  It comes with a large collection of
standard modules that you can use as the basis of your programs — or as
examples to start learning to program in Python.  Some of these modules
provide things like file I/O, system calls, sockets, and even interfaces
to graphical user interface toolkits like Tk.

  Python is an interpreted language, which can save you considerable
time during program development because no compilation and linking is
necessary.  The interpreter can be used interactively, which makes it
easy to experiment with features of the language, to write throw-away
programs, or to test functions during bottom-up program development.  It
is also a handy desk calculator.

  Python enables programs to be written compactly and readably.
Programs written in Python are typically much shorter than equivalent C,
C++, or Java programs, for several reasons:

   * the high-level data types allow you to express complex operations
     in a single statement;

   * statement grouping is done by indentation instead of beginning and
     ending brackets;

   * no variable or argument declarations are necessary.

  Python is _extensible_: if you know how to program in C it is easy to
add a new built-in function or module to the interpreter, either to
perform critical operations at maximum speed, or to link Python programs
to libraries that may only be available in binary form (such as a
vendor-specific graphics library).  Once you are really hooked, you can
link the Python interpreter into an application written in C and use it
as an extension or command language for that application.

  By the way, the language is named after the BBC show "Monty Python’s
Flying Circus" and has nothing to do with reptiles.  Making references
to Monty Python skits in documentation is not only allowed, it is
encouraged!

  Now that you are all excited about Python, you’ll want to examine it
in some more detail.  Since the best way to learn a language is to use
it, the tutorial invites you to play with the Python interpreter as you
read.

  In the next chapter, the mechanics of using the interpreter are
explained.  This is rather mundane information, but essential for trying
out the examples shown later.

  The rest of the tutorial introduces various features of the Python
language and system through examples, beginning with simple expressions,
statements and data types, through functions and modules, and finally
touching upon advanced concepts like exceptions and user-defined
classes.


File: python.info,  Node: Using the Python Interpreter,  Next: An Informal Introduction to Python,  Prev: Whetting Your Appetite,  Up: The Python Tutorial

2.2 Using the Python Interpreter
================================

* Menu:

* Invoking the Interpreter:: 
* The Interpreter and Its Environment:: 

Invoking the Interpreter

* Argument Passing:: 
* Interactive Mode:: 

The Interpreter and Its Environment

* Error Handling:: 
* Executable Python Scripts:: 
* Source Code Encoding:: 
* The Interactive Startup File:: 
* The Customization Modules:: 


File: python.info,  Node: Invoking the Interpreter,  Next: The Interpreter and Its Environment,  Up: Using the Python Interpreter

2.2.1 Invoking the Interpreter
------------------------------

The Python interpreter is usually installed as ‘/usr/local/bin/python’
on those machines where it is available; putting ‘/usr/local/bin’ in
your Unix shell’s search path makes it possible to start it by typing
the command

     python

  to the shell.  Since the choice of the directory where the interpreter
lives is an installation option, other places are possible; check with
your local Python guru or system administrator.  (E.g.,
‘/usr/local/python’ is a popular alternative location.)

  On Windows machines, the Python installation is usually placed in
‘C:\Python27’, though you can change this when you’re running the
installer.  To add this directory to your path, you can type the
following command into the command prompt in a DOS box:

     set path=%path%;C:\python27

  Typing an end-of-file character (‘Control-D’ on Unix, ‘Control-Z’ on
Windows) at the primary prompt causes the interpreter to exit with a
zero exit status.  If that doesn’t work, you can exit the interpreter by
typing the following command: ‘quit()’.

  The interpreter’s line-editing features usually aren’t very
sophisticated.  On Unix, whoever installed the interpreter may have
enabled support for the GNU readline library, which adds more elaborate
interactive editing and history features.  Perhaps the quickest check to
see whether command line editing is supported is typing Control-P to the
first Python prompt you get.  If it beeps, you have command line
editing; see Appendix *note Interactive Input Editing and History
Substitution: 505. for an introduction to the keys.  If nothing appears
to happen, or if ‘^P’ is echoed, command line editing isn’t available;
you’ll only be able to use backspace to remove characters from the
current line.

  The interpreter operates somewhat like the Unix shell: when called
with standard input connected to a tty device, it reads and executes
commands interactively; when called with a file name argument or with a
file as standard input, it reads and executes a _script_ from that file.

  A second way of starting the interpreter is ‘python -c command [arg]
...’, which executes the statement(s) in _command_, analogous to the
shell’s *note -c: 27b. option.  Since Python statements often contain
spaces or other characters that are special to the shell, it is usually
advised to quote _command_ in its entirety with single quotes.

  Some Python modules are also useful as scripts.  These can be invoked
using ‘python -m module [arg] ...’, which executes the source file for
_module_ as if you had spelled out its full name on the command line.

  When a script file is used, it is sometimes useful to be able to run
the script and enter interactive mode afterwards.  This can be done by
passing *note -i: 476. before the script.

* Menu:

* Argument Passing:: 
* Interactive Mode:: 


File: python.info,  Node: Argument Passing,  Next: Interactive Mode,  Up: Invoking the Interpreter

2.2.1.1 Argument Passing
........................

When known to the interpreter, the script name and additional arguments
thereafter are turned into a list of strings and assigned to the ‘argv’
variable in the ‘sys’ module.  You can access this list by executing
‘import sys’.  The length of the list is at least one; when no script
and no arguments are given, ‘sys.argv[0]’ is an empty string.  When the
script name is given as ‘'-'’ (meaning standard input), ‘sys.argv[0]’ is
set to ‘'-'’.  When *note -c: 27b. _command_ is used, ‘sys.argv[0]’ is
set to ‘'-c'’.  When *note -m: 2fb. _module_ is used, ‘sys.argv[0]’ is
set to the full name of the located module.  Options found after *note
-c: 27b. _command_ or *note -m: 2fb. _module_ are not consumed by the
Python interpreter’s option processing but left in ‘sys.argv’ for the
command or module to handle.


File: python.info,  Node: Interactive Mode,  Prev: Argument Passing,  Up: Invoking the Interpreter

2.2.1.2 Interactive Mode
........................

When commands are read from a tty, the interpreter is said to be in
_interactive mode_.  In this mode it prompts for the next command with
the _primary prompt_, usually three greater-than signs (‘>>>’); for
continuation lines it prompts with the _secondary prompt_, by default
three dots (‘...’).  The interpreter prints a welcome message stating
its version number and a copyright notice before printing the first
prompt:

     python
     Python 2.7 (#1, Feb 28 2010, 00:02:06)
     Type "help", "copyright", "credits" or "license" for more information.
     >>>

  Continuation lines are needed when entering a multi-line construct.
As an example, take a look at this *note if: 42c. statement:

     >>> the_world_is_flat = 1
     >>> if the_world_is_flat:
     ...     print "Be careful not to fall off!"
     ...
     Be careful not to fall off!


File: python.info,  Node: The Interpreter and Its Environment,  Prev: Invoking the Interpreter,  Up: Using the Python Interpreter

2.2.2 The Interpreter and Its Environment
-----------------------------------------

* Menu:

* Error Handling:: 
* Executable Python Scripts:: 
* Source Code Encoding:: 
* The Interactive Startup File:: 
* The Customization Modules:: 


File: python.info,  Node: Error Handling,  Next: Executable Python Scripts,  Up: The Interpreter and Its Environment

2.2.2.1 Error Handling
......................

When an error occurs, the interpreter prints an error message and a
stack trace.  In interactive mode, it then returns to the primary
prompt; when input came from a file, it exits with a nonzero exit status
after printing the stack trace.  (Exceptions handled by an *note except:
397. clause in a *note try: 395. statement are not errors in this
context.)  Some errors are unconditionally fatal and cause an exit with
a nonzero exit; this applies to internal inconsistencies and some cases
of running out of memory.  All error messages are written to the
standard error stream; normal output from executed commands is written
to standard output.

  Typing the interrupt character (usually Control-C or DEL) to the
primary or secondary prompt cancels the input and returns to the primary
prompt.  (1) Typing an interrupt while a command is executing raises the
*note KeyboardInterrupt: 251. exception, which may be handled by a *note
try: 395. statement.

   ---------- Footnotes ----------

   (1) A problem with the GNU Readline package may prevent this.


File: python.info,  Node: Executable Python Scripts,  Next: Source Code Encoding,  Prev: Error Handling,  Up: The Interpreter and Its Environment

2.2.2.2 Executable Python Scripts
.................................

On BSD’ish Unix systems, Python scripts can be made directly executable,
like shell scripts, by putting the line

     #! /usr/bin/env python

  (assuming that the interpreter is on the user’s ‘PATH’) at the
beginning of the script and giving the file an executable mode.  The
‘#!’ must be the first two characters of the file.  On some platforms,
this first line must end with a Unix-style line ending (‘'\n'’), not a
Windows (‘'\r\n'’) line ending.  Note that the hash, or pound,
character, ‘'#'’, is used to start a comment in Python.

  The script can be given an executable mode, or permission, using the
*chmod* command:

     $ chmod +x myscript.py

  On Windows systems, there is no notion of an "executable mode".  The
Python installer automatically associates ‘.py’ files with ‘python.exe’
so that a double-click on a Python file will run it as a script.  The
extension can also be ‘.pyw’, in that case, the console window that
normally appears is suppressed.


File: python.info,  Node: Source Code Encoding,  Next: The Interactive Startup File,  Prev: Executable Python Scripts,  Up: The Interpreter and Its Environment

2.2.2.3 Source Code Encoding
............................

It is possible to use encodings different than ASCII in Python source
files.  The best way to do it is to put one more special comment line
right after the ‘#!’ line to define the source file encoding:

     # -*- coding: encoding -*-

  With that declaration, all characters in the source file will be
treated as having the encoding _encoding_, and it will be possible to
directly write Unicode string literals in the selected encoding.  The
list of possible encodings can be found in the Python Library Reference,
in the section on *note codecs: 63.

  For example, to write Unicode literals including the Euro currency
symbol, the ISO-8859-15 encoding can be used, with the Euro symbol
having the ordinal value 164.  This script, when saved in the
ISO-8859-15 encoding, will print the value 8364 (the Unicode codepoint
corresponding to the Euro symbol) and then exit:

     # -*- coding: iso-8859-15 -*-

     currency = u"€"
     print ord(currency)

  If your editor supports saving files as ‘UTF-8’ with a UTF-8 _byte
order mark_ (aka BOM), you can use that instead of an encoding
declaration.  IDLE supports this capability if ‘Options/General/Default
Source Encoding/UTF-8’ is set.  Notice that this signature is not
understood in older Python releases (2.2 and earlier), and also not
understood by the operating system for script files with ‘#!’ lines
(only used on Unix systems).

  By using UTF-8 (either through the signature or an encoding
declaration), characters of most languages in the world can be used
simultaneously in string literals and comments.  Using non-ASCII
characters in identifiers is not supported.  To display all these
characters properly, your editor must recognize that the file is UTF-8,
and it must use a font that supports all the characters in the file.


File: python.info,  Node: The Interactive Startup File,  Next: The Customization Modules,  Prev: Source Code Encoding,  Up: The Interpreter and Its Environment

2.2.2.4 The Interactive Startup File
....................................

When you use Python interactively, it is frequently handy to have some
standard commands executed every time the interpreter is started.  You
can do this by setting an environment variable named *note
PYTHONSTARTUP: 514. to the name of a file containing your start-up
commands.  This is similar to the ‘.profile’ feature of the Unix shells.

  This file is only read in interactive sessions, not when Python reads
commands from a script, and not when ‘/dev/tty’ is given as the explicit
source of commands (which otherwise behaves like an interactive
session).  It is executed in the same namespace where interactive
commands are executed, so that objects that it defines or imports can be
used without qualification in the interactive session.  You can also
change the prompts ‘sys.ps1’ and ‘sys.ps2’ in this file.

  If you want to read an additional start-up file from the current
directory, you can program this in the global start-up file using code
like ‘if os.path.isfile('.pythonrc.py'): execfile('.pythonrc.py')’.  If
you want to use the startup file in a script, you must do this
explicitly in the script:

     import os
     filename = os.environ.get('PYTHONSTARTUP')
     if filename and os.path.isfile(filename):
         execfile(filename)


File: python.info,  Node: The Customization Modules,  Prev: The Interactive Startup File,  Up: The Interpreter and Its Environment

2.2.2.5 The Customization Modules
.................................

Python provides two hooks to let you customize it: ‘sitecustomize’ and
‘usercustomize’.  To see how it works, you need first to find the
location of your user site-packages directory.  Start Python and run
this code:

     >>> import site
     >>> site.getusersitepackages()
     '/home/user/.local/lib/python2.7/site-packages'

  Now you can create a file named ‘usercustomize.py’ in that directory
and put anything you want in it.  It will affect every invocation of
Python, unless it is started with the *note -s: 2ff. option to disable
the automatic import.

  ‘sitecustomize’ works in the same way, but is typically created by an
administrator of the computer in the global site-packages directory, and
is imported before ‘usercustomize’.  See the documentation of the *note
site: 158. module for more details.


File: python.info,  Node: An Informal Introduction to Python,  Next: More Control Flow Tools,  Prev: Using the Python Interpreter,  Up: The Python Tutorial

2.3 An Informal Introduction to Python
======================================

In the following examples, input and output are distinguished by the
presence or absence of prompts (‘>>>’ and ‘...’): to repeat the example,
you must type everything after the prompt, when the prompt appears;
lines that do not begin with a prompt are output from the interpreter.
Note that a secondary prompt on a line by itself in an example means you
must type a blank line; this is used to end a multi-line command.

  Many of the examples in this manual, even those entered at the
interactive prompt, include comments.  Comments in Python start with the
hash character, ‘#’, and extend to the end of the physical line.  A
comment may appear at the start of a line or following whitespace or
code, but not within a string literal.  A hash character within a string
literal is just a hash character.  Since comments are to clarify code
and are not interpreted by Python, they may be omitted when typing in
examples.

  Some examples:

     # this is the first comment
     SPAM = 1                 # and this is the second comment
                              # ... and now a third!
     STRING = "# This is not a comment."

* Menu:

* Using Python as a Calculator:: 
* First Steps Towards Programming:: 

Using Python as a Calculator

* Numbers:: 
* Strings:: 
* Unicode Strings:: 
* Lists:: 


File: python.info,  Node: Using Python as a Calculator,  Next: First Steps Towards Programming,  Up: An Informal Introduction to Python

2.3.1 Using Python as a Calculator
----------------------------------

Let’s try some simple Python commands.  Start the interpreter and wait
for the primary prompt, ‘>>>’.  (It shouldn’t take long.)

* Menu:

* Numbers:: 
* Strings:: 
* Unicode Strings:: 
* Lists:: 

