This is python.info, produced by makeinfo version 5.2 from python.texi.

     Python 2.7.8, November 06, 2014

     Georg Brandl

     Copyright © 1990-2014, Python Software Foundation

INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.1.3.


File: python.info,  Node: Regular Expression Objects,  Next: Match Objects,  Prev: Module Contents,  Up: re --- Regular expression operations

5.7.2.3 Regular Expression Objects
..................................

 -- Class: re.RegexObject

     The *note RegexObject: 9b0. class supports the following methods
     and attributes:

      -- Method: search (string[, pos[, endpos]])

          Scan through _string_ looking for a location where this
          regular expression produces a match, and return a
          corresponding *note MatchObject: 9c8. instance.  Return ‘None’
          if no position in the string matches the pattern; note that
          this is different from finding a zero-length match at some
          point in the string.

          The optional second parameter _pos_ gives an index in the
          string where the search is to start; it defaults to ‘0’.  This
          is not completely equivalent to slicing the string; the ‘'^'’
          pattern character matches at the real beginning of the string
          and at positions just after a newline, but not necessarily at
          the index where the search is to start.

          The optional parameter _endpos_ limits how far the string will
          be searched; it will be as if the string is _endpos_
          characters long, so only the characters from _pos_ to ‘endpos
          - 1’ will be searched for a match.  If _endpos_ is less than
          _pos_, no match will be found, otherwise, if _rx_ is a
          compiled regular expression object, ‘rx.search(string, 0, 50)’
          is equivalent to ‘rx.search(string[:50], 0)’.

               >>> pattern = re.compile("d")
               >>> pattern.search("dog")     # Match at index 0
               <_sre.SRE_Match object at ...>
               >>> pattern.search("dog", 1)  # No match; search doesn't include the "d"

      -- Method: match (string[, pos[, endpos]])

          If zero or more characters at the _beginning_ of _string_
          match this regular expression, return a corresponding *note
          MatchObject: 9c8. instance.  Return ‘None’ if the string does
          not match the pattern; note that this is different from a
          zero-length match.

          The optional _pos_ and _endpos_ parameters have the same
          meaning as for the *note search(): 9c4. method.

               >>> pattern = re.compile("o")
               >>> pattern.match("dog")      # No match as "o" is not at the start of "dog".
               >>> pattern.match("dog", 1)   # Match as "o" is the 2nd character of "dog".
               <_sre.SRE_Match object at ...>

          If you want to locate a match anywhere in _string_, use *note
          search(): 9c4. instead (see also *note search() vs.  match():
          9c9.).

      -- Method: split (string, maxsplit=0)

          Identical to the *note split(): 247. function, using the
          compiled pattern.

      -- Method: findall (string[, pos[, endpos]])

          Similar to the *note findall(): 9ca. function, using the
          compiled pattern, but also accepts optional _pos_ and _endpos_
          parameters that limit the search region like for *note
          match(): 9c1.

      -- Method: finditer (string[, pos[, endpos]])

          Similar to the *note finditer(): 9cb. function, using the
          compiled pattern, but also accepts optional _pos_ and _endpos_
          parameters that limit the search region like for *note
          match(): 9c1.

      -- Method: sub (repl, string, count=0)

          Identical to the *note sub(): 248. function, using the
          compiled pattern.

      -- Method: subn (repl, string, count=0)

          Identical to the *note subn(): 249. function, using the
          compiled pattern.

      -- Attribute: flags

          The regex matching flags.  This is a combination of the flags
          given to *note compile(): 9bf. and any ‘(?...)’ inline flags
          in the pattern.

      -- Attribute: groups

          The number of capturing groups in the pattern.

      -- Attribute: groupindex

          A dictionary mapping any symbolic group names defined by
          ‘(?P<id>)’ to group numbers.  The dictionary is empty if no
          symbolic groups were used in the pattern.

      -- Attribute: pattern

          The pattern string from which the RE object was compiled.


File: python.info,  Node: Match Objects,  Next: Examples,  Prev: Regular Expression Objects,  Up: re --- Regular expression operations

5.7.2.4 Match Objects
.....................

 -- Class: re.MatchObject

     Match objects always have a boolean value of ‘True’.  Since
     ‘match()’ and ‘search()’ return ‘None’ when there is no match, you
     can test whether there was a match with a simple ‘if’ statement:

          match = re.search(pattern, string)
          if match:
              process(match)

     Match objects support the following methods and attributes:

      -- Method: expand (template)

          Return the string obtained by doing backslash substitution on
          the template string _template_, as done by the *note sub():
          9d3. method.  Escapes such as ‘\n’ are converted to the
          appropriate characters, and numeric backreferences (‘\1’,
          ‘\2’) and named backreferences (‘\g<1>’, ‘\g<name>’) are
          replaced by the contents of the corresponding group.

      -- Method: group ([group1, ...])

          Returns one or more subgroups of the match.  If there is a
          single argument, the result is a single string; if there are
          multiple arguments, the result is a tuple with one item per
          argument.  Without arguments, _group1_ defaults to zero (the
          whole match is returned).  If a _groupN_ argument is zero, the
          corresponding return value is the entire matching string; if
          it is in the inclusive range [1..99], it is the string
          matching the corresponding parenthesized group.  If a group
          number is negative or larger than the number of groups defined
          in the pattern, an *note IndexError: 4e1. exception is raised.
          If a group is contained in a part of the pattern that did not
          match, the corresponding result is ‘None’.  If a group is
          contained in a part of the pattern that matched multiple
          times, the last match is returned.

               >>> m = re.match(r"(\w+) (\w+)", "Isaac Newton, physicist")
               >>> m.group(0)       # The entire match
               'Isaac Newton'
               >>> m.group(1)       # The first parenthesized subgroup.
               'Isaac'
               >>> m.group(2)       # The second parenthesized subgroup.
               'Newton'
               >>> m.group(1, 2)    # Multiple arguments give us a tuple.
               ('Isaac', 'Newton')

          If the regular expression uses the ‘(?P<name>...)’ syntax, the
          _groupN_ arguments may also be strings identifying groups by
          their group name.  If a string argument is not used as a group
          name in the pattern, an *note IndexError: 4e1. exception is
          raised.

          A moderately complicated example:

               >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
               >>> m.group('first_name')
               'Malcolm'
               >>> m.group('last_name')
               'Reynolds'

          Named groups can also be referred to by their index:

               >>> m.group(1)
               'Malcolm'
               >>> m.group(2)
               'Reynolds'

          If a group matches multiple times, only the last match is
          accessible:

               >>> m = re.match(r"(..)+", "a1b2c3")  # Matches 3 times.
               >>> m.group(1)                        # Returns only the last match.
               'c3'

      -- Method: groups ([default])

          Return a tuple containing all the subgroups of the match, from
          1 up to however many groups are in the pattern.  The _default_
          argument is used for groups that did not participate in the
          match; it defaults to ‘None’.  (Incompatibility note: in the
          original Python 1.5 release, if the tuple was one element
          long, a string would be returned instead.  In later versions
          (from 1.5.1 on), a singleton tuple is returned in such cases.)

          For example:

               >>> m = re.match(r"(\d+)\.(\d+)", "24.1632")
               >>> m.groups()
               ('24', '1632')

          If we make the decimal place and everything after it optional,
          not all groups might participate in the match.  These groups
          will default to ‘None’ unless the _default_ argument is given:

               >>> m = re.match(r"(\d+)\.?(\d+)?", "24")
               >>> m.groups()      # Second group defaults to None.
               ('24', None)
               >>> m.groups('0')   # Now, the second group defaults to '0'.
               ('24', '0')

      -- Method: groupdict ([default])

          Return a dictionary containing all the _named_ subgroups of
          the match, keyed by the subgroup name.  The _default_ argument
          is used for groups that did not participate in the match; it
          defaults to ‘None’.  For example:

               >>> m = re.match(r"(?P<first_name>\w+) (?P<last_name>\w+)", "Malcolm Reynolds")
               >>> m.groupdict()
               {'first_name': 'Malcolm', 'last_name': 'Reynolds'}

      -- Method: start ([group])
      -- Method: end ([group])

          Return the indices of the start and end of the substring
          matched by _group_; _group_ defaults to zero (meaning the
          whole matched substring).  Return ‘-1’ if _group_ exists but
          did not contribute to the match.  For a match object _m_, and
          a group _g_ that did contribute to the match, the substring
          matched by group _g_ (equivalent to ‘m.group(g)’) is

               m.string[m.start(g):m.end(g)]

          Note that ‘m.start(group)’ will equal ‘m.end(group)’ if
          _group_ matched a null string.  For example, after ‘m =
          re.search('b(c?)', 'cba')’, ‘m.start(0)’ is 1, ‘m.end(0)’ is
          2, ‘m.start(1)’ and ‘m.end(1)’ are both 2, and ‘m.start(2)’
          raises an *note IndexError: 4e1. exception.

          An example that will remove _remove_this_ from email
          addresses:

               >>> email = "tony@tiremove_thisger.net"
               >>> m = re.search("remove_this", email)
               >>> email[:m.start()] + email[m.end():]
               'tony@tiger.net'

      -- Method: span ([group])

          For *note MatchObject: 9c8. _m_, return the 2-tuple
          ‘(m.start(group), m.end(group))’.  Note that if _group_ did
          not contribute to the match, this is ‘(-1, -1)’.  _group_
          defaults to zero, the entire match.

      -- Attribute: pos

          The value of _pos_ which was passed to the *note search():
          9c4. or *note match(): 9c3. method of the *note RegexObject:
          9b0.  This is the index into the string at which the RE engine
          started looking for a match.

      -- Attribute: endpos

          The value of _endpos_ which was passed to the *note search():
          9c4. or *note match(): 9c3. method of the *note RegexObject:
          9b0.  This is the index into the string beyond which the RE
          engine will not go.

      -- Attribute: lastindex

          The integer index of the last matched capturing group, or
          ‘None’ if no group was matched at all.  For example, the
          expressions ‘(a)b’, ‘((a)(b))’, and ‘((ab))’ will have
          ‘lastindex == 1’ if applied to the string ‘'ab'’, while the
          expression ‘(a)(b)’ will have ‘lastindex == 2’, if applied to
          the same string.

      -- Attribute: lastgroup

          The name of the last matched capturing group, or ‘None’ if the
          group didn’t have a name, or if no group was matched at all.

      -- Attribute: re

          The regular expression object whose *note match(): 9c3. or
          *note search(): 9c4. method produced this *note MatchObject:
          9c8. instance.

      -- Attribute: string

          The string passed to *note match(): 9c3. or *note search():
          9c4.


File: python.info,  Node: Examples,  Prev: Match Objects,  Up: re --- Regular expression operations

5.7.2.5 Examples
................

* Menu:

* Checking For a Pair:: 
* Simulating scanf(): Simulating scanf. 
* search() vs. match(): search vs match. 
* Making a Phonebook:: 
* Text Munging:: 
* Finding all Adverbs:: 
* Finding all Adverbs and their Positions:: 
* Raw String Notation:: 


File: python.info,  Node: Checking For a Pair,  Next: Simulating scanf,  Up: Examples

5.7.2.6 Checking For a Pair
...........................

In this example, we’ll use the following helper function to display
match objects a little more gracefully:

     def displaymatch(match):
         if match is None:
             return None
         return '<Match: %r, groups=%r>' % (match.group(), match.groups())

  Suppose you are writing a poker program where a player’s hand is
represented as a 5-character string with each character representing a
card, "a" for ace, "k" for king, "q" for queen, "j" for jack, "t" for
10, and "2" through "9" representing the card with that value.

  To see if a given string is a valid hand, one could do the following:

     >>> valid = re.compile(r"^[a2-9tjqk]{5}$")
     >>> displaymatch(valid.match("akt5q"))  # Valid.
     "<Match: 'akt5q', groups=()>"
     >>> displaymatch(valid.match("akt5e"))  # Invalid.
     >>> displaymatch(valid.match("akt"))    # Invalid.
     >>> displaymatch(valid.match("727ak"))  # Valid.
     "<Match: '727ak', groups=()>"

  That last hand, ‘"727ak"’, contained a pair, or two of the same valued
cards.  To match this with a regular expression, one could use
backreferences as such:

     >>> pair = re.compile(r".*(.).*\1")
     >>> displaymatch(pair.match("717ak"))     # Pair of 7s.
     "<Match: '717', groups=('7',)>"
     >>> displaymatch(pair.match("718ak"))     # No pairs.
     >>> displaymatch(pair.match("354aa"))     # Pair of aces.
     "<Match: '354aa', groups=('a',)>"

  To find out what card the pair consists of, one could use the *note
group(): 9dc. method of *note MatchObject: 9c8. in the following manner:

     >>> pair.match("717ak").group(1)
     '7'

     # Error because re.match() returns None, which doesn't have a group() method:
     >>> pair.match("718ak").group(1)
     Traceback (most recent call last):
       File "<pyshell#23>", line 1, in <module>
         re.match(r".*(.).*\1", "718ak").group(1)
     AttributeError: 'NoneType' object has no attribute 'group'

     >>> pair.match("354aa").group(1)
     'a'


File: python.info,  Node: Simulating scanf,  Next: search vs match,  Prev: Checking For a Pair,  Up: Examples

5.7.2.7 Simulating scanf()
..........................

Python does not currently have an equivalent to ‘scanf()’.  Regular
expressions are generally more powerful, though also more verbose, than
‘scanf()’ format strings.  The table below offers some more-or-less
equivalent mappings between ‘scanf()’ format tokens and regular
expressions.

‘scanf()’ Token                      Regular Expression
                                     
---------------------------------------------------------------------------------------
                                     
‘%c’                                 ‘.’
                                     
                                     
‘%5c’                                ‘.{5}’
                                     
                                     
‘%d’                                 ‘[-+]?\d+’
                                     
                                     
‘%e’, ‘%E’, ‘%f’, ‘%g’               ‘[-+]?(\d+(\.\d*)?|\.\d+)([eE][-+]?\d+)?’
                                     
                                     
‘%i’                                 ‘[-+]?(0[xX][\dA-Fa-f]+|0[0-7]*|\d+)’
                                     
                                     
‘%o’                                 ‘[-+]?[0-7]+’
                                     
                                     
‘%s’                                 ‘\S+’
                                     
                                     
‘%u’                                 ‘\d+’
                                     
                                     
‘%x’, ‘%X’                           ‘[-+]?(0[xX])?[\dA-Fa-f]+’
                                     

  To extract the filename and numbers from a string like

     /usr/sbin/sendmail - 0 errors, 4 warnings

  you would use a ‘scanf()’ format like

     %s - %d errors, %d warnings

  The equivalent regular expression would be

     (\S+) - (\d+) errors, (\d+) warnings


File: python.info,  Node: search vs match,  Next: Making a Phonebook,  Prev: Simulating scanf,  Up: Examples

5.7.2.8 search() vs. match()
............................

Python offers two different primitive operations based on regular
expressions: *note re.match(): 9c1. checks for a match only at the
beginning of the string, while *note re.search(): 9c0. checks for a
match anywhere in the string (this is what Perl does by default).

  For example:

     >>> re.match("c", "abcdef")  # No match
     >>> re.search("c", "abcdef") # Match
     <_sre.SRE_Match object at ...>

  Regular expressions beginning with ‘'^'’ can be used with *note
search(): 9c0. to restrict the match at the beginning of the string:

     >>> re.match("c", "abcdef")  # No match
     >>> re.search("^c", "abcdef") # No match
     >>> re.search("^a", "abcdef")  # Match
     <_sre.SRE_Match object at ...>

  Note however that in *note MULTILINE: 9b5. mode *note match(): 9c1.
only matches at the beginning of the string, whereas using *note
search(): 9c0. with a regular expression beginning with ‘'^'’ will match
at the beginning of each line.

     >>> re.match('X', 'A\nB\nX', re.MULTILINE)  # No match
     >>> re.search('^X', 'A\nB\nX', re.MULTILINE)  # Match
     <_sre.SRE_Match object at ...>


File: python.info,  Node: Making a Phonebook,  Next: Text Munging,  Prev: search vs match,  Up: Examples

5.7.2.9 Making a Phonebook
..........................

*note split(): 247. splits a string into a list delimited by the passed
pattern.  The method is invaluable for converting textual data into data
structures that can be easily read and modified by Python as
demonstrated in the following example that creates a phonebook.

  First, here is the input.  Normally it may come from a file, here we
are using triple-quoted string syntax:

     >>> text = """Ross McFluff: 834.345.1254 155 Elm Street
     ...
     ... Ronald Heathmore: 892.345.3428 436 Finley Avenue
     ... Frank Burger: 925.541.7625 662 South Dogwood Way
     ...
     ...
     ... Heather Albrecht: 548.326.4584 919 Park Place"""

  The entries are separated by one or more newlines.  Now we convert the
string into a list with each nonempty line having its own entry:

     >>> entries = re.split("\n+", text)
     >>> entries
     ['Ross McFluff: 834.345.1254 155 Elm Street',
     'Ronald Heathmore: 892.345.3428 436 Finley Avenue',
     'Frank Burger: 925.541.7625 662 South Dogwood Way',
     'Heather Albrecht: 548.326.4584 919 Park Place']

  Finally, split each entry into a list with first name, last name,
telephone number, and address.  We use the ‘maxsplit’ parameter of *note
split(): 247. because the address has spaces, our splitting pattern, in
it:

     >>> [re.split(":? ", entry, 3) for entry in entries]
     [['Ross', 'McFluff', '834.345.1254', '155 Elm Street'],
     ['Ronald', 'Heathmore', '892.345.3428', '436 Finley Avenue'],
     ['Frank', 'Burger', '925.541.7625', '662 South Dogwood Way'],
     ['Heather', 'Albrecht', '548.326.4584', '919 Park Place']]

  The ‘:?’ pattern matches the colon after the last name, so that it
does not occur in the result list.  With a ‘maxsplit’ of ‘4’, we could
separate the house number from the street name:

     >>> [re.split(":? ", entry, 4) for entry in entries]
     [['Ross', 'McFluff', '834.345.1254', '155', 'Elm Street'],
     ['Ronald', 'Heathmore', '892.345.3428', '436', 'Finley Avenue'],
     ['Frank', 'Burger', '925.541.7625', '662', 'South Dogwood Way'],
     ['Heather', 'Albrecht', '548.326.4584', '919', 'Park Place']]


File: python.info,  Node: Text Munging,  Next: Finding all Adverbs,  Prev: Making a Phonebook,  Up: Examples

5.7.2.10 Text Munging
.....................

*note sub(): 248. replaces every occurrence of a pattern with a string
or the result of a function.  This example demonstrates using *note
sub(): 248. with a function to "munge" text, or randomize the order of
all the characters in each word of a sentence except for the first and
last characters:

     >>> def repl(m):
     ...   inner_word = list(m.group(2))
     ...   random.shuffle(inner_word)
     ...   return m.group(1) + "".join(inner_word) + m.group(3)
     >>> text = "Professor Abdolmalek, please report your absences promptly."
     >>> re.sub(r"(\w)(\w+)(\w)", repl, text)
     'Poefsrosr Aealmlobdk, pslaee reorpt your abnseces plmrptoy.'
     >>> re.sub(r"(\w)(\w+)(\w)", repl, text)
     'Pofsroser Aodlambelk, plasee reoprt yuor asnebces potlmrpy.'


File: python.info,  Node: Finding all Adverbs,  Next: Finding all Adverbs and their Positions,  Prev: Text Munging,  Up: Examples

5.7.2.11 Finding all Adverbs
............................

*note findall(): 9ca. matches _all_ occurrences of a pattern, not just
the first one as *note search(): 9c0. does.  For example, if one was a
writer and wanted to find all of the adverbs in some text, he or she
might use *note findall(): 9ca. in the following manner:

     >>> text = "He was carefully disguised but captured quickly by police."
     >>> re.findall(r"\w+ly", text)
     ['carefully', 'quickly']


File: python.info,  Node: Finding all Adverbs and their Positions,  Next: Raw String Notation,  Prev: Finding all Adverbs,  Up: Examples

5.7.2.12 Finding all Adverbs and their Positions
................................................

If one wants more information about all matches of a pattern than the
matched text, *note finditer(): 9cb. is useful as it provides instances
of *note MatchObject: 9c8. instead of strings.  Continuing with the
previous example, if one was a writer who wanted to find all of the
adverbs _and their positions_ in some text, he or she would use *note
finditer(): 9cb. in the following manner:

     >>> text = "He was carefully disguised but captured quickly by police."
     >>> for m in re.finditer(r"\w+ly", text):
     ...     print '%02d-%02d: %s' % (m.start(), m.end(), m.group(0))
     07-16: carefully
     40-47: quickly


File: python.info,  Node: Raw String Notation,  Prev: Finding all Adverbs and their Positions,  Up: Examples

5.7.2.13 Raw String Notation
............................

Raw string notation (‘r"text"’) keeps regular expressions sane.  Without
it, every backslash (‘'\'’) in a regular expression would have to be
prefixed with another one to escape it.  For example, the two following
lines of code are functionally identical:

     >>> re.match(r"\W(.)\1\W", " ff ")
     <_sre.SRE_Match object at ...>
     >>> re.match("\\W(.)\\1\\W", " ff ")
     <_sre.SRE_Match object at ...>

  When one wants to match a literal backslash, it must be escaped in the
regular expression.  With raw string notation, this means ‘r"\\"’.
Without raw string notation, one must use ‘"\\\\"’, making the following
lines of code functionally identical:

     >>> re.match(r"\\", r"\\")
     <_sre.SRE_Match object at ...>
     >>> re.match("\\\\", r"\\")
     <_sre.SRE_Match object at ...>


File: python.info,  Node: struct --- Interpret strings as packed binary data,  Next: difflib --- Helpers for computing deltas,  Prev: re --- Regular expression operations,  Up: String Services

5.7.3 ‘struct’ — Interpret strings as packed binary data
--------------------------------------------------------

This module performs conversions between Python values and C structs
represented as Python strings.  This can be used in handling binary data
stored in files or from network connections, among other sources.  It
uses *note Format Strings: 9f3. as compact descriptions of the layout of
the C structs and the intended conversion to/from Python values.

     Note: By default, the result of packing a given C struct includes
     pad bytes in order to maintain proper alignment for the C types
     involved; similarly, alignment is taken into account when
     unpacking.  This behavior is chosen so that the bytes of a packed
     struct correspond exactly to the layout in memory of the
     corresponding C struct.  To handle platform-independent data
     formats or omit implicit pad bytes, use ‘standard’ size and
     alignment instead of ‘native’ size and alignment: see *note Byte
     Order, Size, and Alignment: 9f4. for details.

* Menu:

* Functions and Exceptions:: 
* Format Strings:: 
* Classes: Classes<2>. 


File: python.info,  Node: Functions and Exceptions,  Next: Format Strings,  Up: struct --- Interpret strings as packed binary data

5.7.3.1 Functions and Exceptions
................................

The module defines the following exception and functions:

 -- Exception: struct.error

     Exception raised on various occasions; argument is a string
     describing what is wrong.

 -- Function: struct.pack (fmt, v1, v2, ...)

     Return a string containing the values ‘v1, v2, ...’ packed
     according to the given format.  The arguments must match the values
     required by the format exactly.

 -- Function: struct.pack_into (fmt, buffer, offset, v1, v2, ...)

     Pack the values ‘v1, v2, ...’ according to the given format, write
     the packed bytes into the writable _buffer_ starting at _offset_.
     Note that the offset is a required argument.

     New in version 2.5.

 -- Function: struct.unpack (fmt, string)

     Unpack the string (presumably packed by ‘pack(fmt, ...)’) according
     to the given format.  The result is a tuple even if it contains
     exactly one item.  The string must contain exactly the amount of
     data required by the format (‘len(string)’ must equal
     ‘calcsize(fmt)’).

 -- Function: struct.unpack_from (fmt, buffer[, offset=0])

     Unpack the _buffer_ according to the given format.  The result is a
     tuple even if it contains exactly one item.  The _buffer_ must
     contain at least the amount of data required by the format
     (‘len(buffer[offset:])’ must be at least ‘calcsize(fmt)’).

     New in version 2.5.

 -- Function: struct.calcsize (fmt)

     Return the size of the struct (and hence of the string)
     corresponding to the given format.


File: python.info,  Node: Format Strings,  Next: Classes<2>,  Prev: Functions and Exceptions,  Up: struct --- Interpret strings as packed binary data

5.7.3.2 Format Strings
......................

Format strings are the mechanism used to specify the expected layout
when packing and unpacking data.  They are built up from *note Format
Characters: 9fa, which specify the type of data being packed/unpacked.
In addition, there are special characters for controlling the *note Byte
Order, Size, and Alignment: 9f4.

* Menu:

* Byte Order, Size, and Alignment: Byte Order Size and Alignment. 
* Format Characters:: 
* Examples: Examples<2>. 


File: python.info,  Node: Byte Order Size and Alignment,  Next: Format Characters,  Up: Format Strings

5.7.3.3 Byte Order, Size, and Alignment
.......................................

By default, C types are represented in the machine’s native format and
byte order, and properly aligned by skipping pad bytes if necessary
(according to the rules used by the C compiler).

  Alternatively, the first character of the format string can be used to
indicate the byte order, size and alignment of the packed data,
according to the following table:

Character       Byte order                   Size           Alignment
                                                            
----------------------------------------------------------------------------
                                                            
‘@’             native                       native         native
                                                            
                                                            
‘=’             native                       standard       none
                                                            
                                                            
‘<’             little-endian                standard       none
                                                            
                                                            
‘>’             big-endian                   standard       none
                                                            
                                                            
‘!’             network (= big-endian)       standard       none
                                                            

  If the first character is not one of these, ‘'@'’ is assumed.

  Native byte order is big-endian or little-endian, depending on the
host system.  For example, Intel x86 and AMD64 (x86-64) are
little-endian; Motorola 68000 and PowerPC G5 are big-endian; ARM and
Intel Itanium feature switchable endianness (bi-endian).  Use
‘sys.byteorder’ to check the endianness of your system.

  Native size and alignment are determined using the C compiler’s
‘sizeof’ expression.  This is always combined with native byte order.

  Standard size depends only on the format character; see the table in
the *note Format Characters: 9fa. section.

  Note the difference between ‘'@'’ and ‘'='’: both use native byte
order, but the size and alignment of the latter is standardized.

  The form ‘'!'’ is available for those poor souls who claim they can’t
remember whether network byte order is big-endian or little-endian.

  There is no way to indicate non-native byte order (force
byte-swapping); use the appropriate choice of ‘'<'’ or ‘'>'’.

  Notes:

  1. Padding is only automatically added between successive structure
     members.  No padding is added at the beginning or the end of the
     encoded struct.

  2. No padding is added when using non-native size and alignment, e.g.
     with ’<’, ’>’, ’=’, and ’!’.

  3. To align the end of a structure to the alignment requirement of a
     particular type, end the format with the code for that type with a
     repeat count of zero.  See *note Examples: 9fc.


File: python.info,  Node: Format Characters,  Next: Examples<2>,  Prev: Byte Order Size and Alignment,  Up: Format Strings

5.7.3.4 Format Characters
.........................

Format characters have the following meaning; the conversion between C
and Python values should be obvious given their types.  The ’Standard
size’ column refers to the size of the packed value in bytes when using
standard size; that is, when the format string starts with one of ‘'<'’,
‘'>'’, ‘'!'’ or ‘'='’.  When using native size, the size of the packed
value is platform-dependent.

Format       C Type                         Python type              Standard size        Notes
                                                                                          
-----------------------------------------------------------------------------------------------------------
                                                                                          
‘x’          pad byte                       no value
                                            
                                                                                          
‘c’          ‘char’                         string of length 1       1
                                                                     
                                                                                          
‘b’          ‘signed char’                  integer                  1                    (3)
                                                                                          
                                                                                          
‘B’          ‘unsigned char’                integer                  1                    (3)
                                                                                          
                                                                                          
‘?’          ‘_Bool’                        bool                     1                    (1)
                                                                                          
                                                                                          
‘h’          ‘short’                        integer                  2                    (3)
                                                                                          
                                                                                          
‘H’          ‘unsigned short’               integer                  2                    (3)
                                                                                          
                                                                                          
‘i’          ‘int’                          integer                  4                    (3)
                                                                                          
                                                                                          
‘I’          ‘unsigned int’                 integer                  4                    (3)
                                                                                          
                                                                                          
‘l’          ‘long’                         integer                  4                    (3)
                                                                                          
                                                                                          
‘L’          ‘unsigned long’                integer                  4                    (3)
                                                                                          
                                                                                          
‘q’          ‘long long’                    integer                  8                    (2), (3)
                                                                                          
                                                                                          
‘Q’          ‘unsigned long long’           integer                  8                    (2), (3)
                                                                                          
                                                                                          
‘f’          ‘float’                        float                    4                    (4)
                                                                                          
                                                                                          
‘d’          ‘double’                       float                    8                    (4)
                                                                                          
                                                                                          
‘s’          ‘char[]’                       string
                                            
                                                                                          
‘p’          ‘char[]’                       string
                                            
                                                                                          
‘P’          ‘void *’                       integer                                       (5), (3)
                                                                                          

  Notes:

  1. The ‘'?'’ conversion code corresponds to the ‘_Bool’ type defined
     by C99.  If this type is not available, it is simulated using a
     ‘char’.  In standard mode, it is always represented by one byte.

     New in version 2.6.

  2. The ‘'q'’ and ‘'Q'’ conversion codes are available in native mode
     only if the platform C compiler supports C ‘long long’, or, on
     Windows, ‘__int64’.  They are always available in standard modes.

     New in version 2.2.

  3. When attempting to pack a non-integer using any of the integer
     conversion codes, if the non-integer has a *note __index__(): 25f.
     method then that method is called to convert the argument to an
     integer before packing.  If no *note __index__(): 25f. method
     exists, or the call to *note __index__(): 25f. raises *note
     TypeError: 218, then the *note __int__(): 260. method is tried.
     However, the use of *note __int__(): 260. is deprecated, and will
     raise *note DeprecationWarning: 1bc.

     Changed in version 2.7: Use of the *note __index__(): 25f. method
     for non-integers is new in 2.7.

     Changed in version 2.7: Prior to version 2.7, not all integer
     conversion codes would use the *note __int__(): 260. method to
     convert, and *note DeprecationWarning: 1bc. was raised only for
     float arguments.

  4. For the ‘'f'’ and ‘'d'’ conversion codes, the packed representation
     uses the IEEE 754 binary32 (for ‘'f'’) or binary64 (for ‘'d'’)
     format, regardless of the floating-point format used by the
     platform.

  5. The ‘'P'’ format character is only available for the native byte
     ordering (selected as the default or with the ‘'@'’ byte order
     character).  The byte order character ‘'='’ chooses to use little-
     or big-endian ordering based on the host system.  The struct module
     does not interpret this as native ordering, so the ‘'P'’ format is
     not available.

  A format character may be preceded by an integral repeat count.  For
example, the format string ‘'4h'’ means exactly the same as ‘'hhhh'’.

  Whitespace characters between formats are ignored; a count and its
format must not contain whitespace though.

  For the ‘'s'’ format character, the count is interpreted as the size
of the string, not a repeat count like for the other format characters;
for example, ‘'10s'’ means a single 10-byte string, while ‘'10c'’ means
10 characters.  If a count is not given, it defaults to 1.  For packing,
the string is truncated or padded with null bytes as appropriate to make
it fit.  For unpacking, the resulting string always has exactly the
specified number of bytes.  As a special case, ‘'0s'’ means a single,
empty string (while ‘'0c'’ means 0 characters).

  The ‘'p'’ format character encodes a "Pascal string", meaning a short
variable-length string stored in a _fixed number of bytes_, given by the
count.  The first byte stored is the length of the string, or 255,
whichever is smaller.  The bytes of the string follow.  If the string
passed in to *note pack(): 25e. is too long (longer than the count minus
1), only the leading ‘count-1’ bytes of the string are stored.  If the
string is shorter than ‘count-1’, it is padded with null bytes so that
exactly count bytes in all are used.  Note that for *note unpack(): 606,
the ‘'p'’ format character consumes count bytes, but that the string
returned can never contain more than 255 characters.

  For the ‘'P'’ format character, the return value is a Python integer
or long integer, depending on the size needed to hold a pointer when it
has been cast to an integer type.  A _NULL_ pointer will always be
returned as the Python integer ‘0’.  When packing pointer-sized values,
Python integer or long integer objects may be used.  For example, the
Alpha and Merced processors use 64-bit pointer values, meaning a Python
long integer will be used to hold the pointer; other platforms use
32-bit pointers and will use a Python integer.

  For the ‘'?'’ format character, the return value is either *note True:
3b0. or *note False: 3b1.  When packing, the truth value of the argument
object is used.  Either 0 or 1 in the native or standard bool
representation will be packed, and any non-zero value will be ‘True’
when unpacking.


File: python.info,  Node: Examples<2>,  Prev: Format Characters,  Up: Format Strings

5.7.3.5 Examples
................

     Note: All examples assume a native byte order, size, and alignment
     with a big-endian machine.

  A basic example of packing/unpacking three integers:

     >>> from struct import *
     >>> pack('hhl', 1, 2, 3)
     '\x00\x01\x00\x02\x00\x00\x00\x03'
     >>> unpack('hhl', '\x00\x01\x00\x02\x00\x00\x00\x03')
     (1, 2, 3)
     >>> calcsize('hhl')
     8

  Unpacked fields can be named by assigning them to variables or by
wrapping the result in a named tuple:

     >>> record = 'raymond   \x32\x12\x08\x01\x08'
     >>> name, serialnum, school, gradelevel = unpack('<10sHHb', record)

     >>> from collections import namedtuple
     >>> Student = namedtuple('Student', 'name serialnum school gradelevel')
     >>> Student._make(unpack('<10sHHb', record))
     Student(name='raymond   ', serialnum=4658, school=264, gradelevel=8)

  The ordering of format characters may have an impact on size since the
padding needed to satisfy alignment requirements is different:

     >>> pack('ci', '*', 0x12131415)
     '*\x00\x00\x00\x12\x13\x14\x15'
     >>> pack('ic', 0x12131415, '*')
     '\x12\x13\x14\x15*'
     >>> calcsize('ci')
     8
     >>> calcsize('ic')
     5

  The following format ‘'llh0l'’ specifies two pad bytes at the end,
assuming longs are aligned on 4-byte boundaries:

     >>> pack('llh0l', 1, 2, 3)
     '\x00\x00\x00\x01\x00\x00\x00\x02\x00\x03\x00\x00'

  This only works when native size and alignment are in effect; standard
size and alignment does not enforce any alignment.

See also
........

Module *note array: e.

     Packed binary storage of homogeneous data.

Module *note xdrlib: 19f.

     Packing and unpacking of XDR data.


File: python.info,  Node: Classes<2>,  Prev: Format Strings,  Up: struct --- Interpret strings as packed binary data

5.7.3.6 Classes
...............

The *note struct: 166. module also defines the following type:

 -- Class: struct.Struct (format)

     Return a new Struct object which writes and reads binary data
     according to the format string _format_.  Creating a Struct object
     once and calling its methods is more efficient than calling the
     *note struct: 166. functions with the same format since the format
     string only needs to be compiled once.

     New in version 2.5.

     Compiled Struct objects support the following methods and
     attributes:

      -- Method: pack (v1, v2, ...)

          Identical to the *note pack(): 25e. function, using the
          compiled format.  (‘len(result)’ will equal ‘self.size’.)

      -- Method: pack_into (buffer, offset, v1, v2, ...)

          Identical to the *note pack_into(): 9f6. function, using the
          compiled format.

      -- Method: unpack (string)

          Identical to the *note unpack(): 606. function, using the
          compiled format.  (‘len(string)’ must equal ‘self.size’).

      -- Method: unpack_from (buffer, offset=0)

          Identical to the *note unpack_from(): 9f7. function, using the
          compiled format.  (‘len(buffer[offset:])’ must be at least
          ‘self.size’).

      -- Attribute: format

          The format string used to construct this Struct object.

      -- Attribute: size

          The calculated size of the struct (and hence of the string)
          corresponding to *note format: 1ef.


File: python.info,  Node: difflib --- Helpers for computing deltas,  Next: StringIO --- Read and write strings as files,  Prev: struct --- Interpret strings as packed binary data,  Up: String Services

5.7.4 ‘difflib’ — Helpers for computing deltas
----------------------------------------------

New in version 2.1.

  This module provides classes and functions for comparing sequences.
It can be used for example, for comparing files, and can produce
difference information in various formats, including HTML and context
and unified diffs.  For comparing directories and files, see also, the
*note filecmp: cb. module.

 -- Class: difflib.SequenceMatcher

     This is a flexible class for comparing pairs of sequences of any
     type, so long as the sequence elements are *note hashable: 6f5.
     The basic algorithm predates, and is a little fancier than, an
     algorithm published in the late 1980’s by Ratcliff and Obershelp
     under the hyperbolic name "gestalt pattern matching."  The idea is
     to find the longest contiguous matching subsequence that contains
     no "junk" elements (the Ratcliff and Obershelp algorithm doesn’t
     address junk).  The same idea is then applied recursively to the
     pieces of the sequences to the left and to the right of the
     matching subsequence.  This does not yield minimal edit sequences,
     but does tend to yield matches that "look right" to people.

     *Timing:* The basic Ratcliff-Obershelp algorithm is cubic time in
     the worst case and quadratic time in the expected case.  *note
     SequenceMatcher: a0a. is quadratic time for the worst case and has
     expected-case behavior dependent in a complicated way on how many
     elements the sequences have in common; best case time is linear.

     *Automatic junk heuristic:* *note SequenceMatcher: a0a. supports a
     heuristic that automatically treats certain sequence items as junk.
     The heuristic counts how many times each individual item appears in
     the sequence.  If an item’s duplicates (after the first one)
     account for more than 1% of the sequence and the sequence is at
     least 200 items long, this item is marked as "popular" and is
     treated as junk for the purpose of sequence matching.  This
     heuristic can be turned off by setting the ‘autojunk’ argument to
     ‘False’ when creating the *note SequenceMatcher: a0a.

     New in version 2.7.1: The _autojunk_ parameter.

 -- Class: difflib.Differ

     This is a class for comparing sequences of lines of text, and
     producing human-readable differences or deltas.  Differ uses *note
     SequenceMatcher: a0a. both to compare sequences of lines, and to
     compare sequences of characters within similar (near-matching)
     lines.

     Each line of a *note Differ: a0b. delta begins with a two-letter
     code:

     Code           Meaning
                    
     ---------------------------------------------------------------
                    
     ‘'- '’         line unique to sequence 1
                    
                    
     ‘'+ '’         line unique to sequence 2
                    
                    
     ‘' '’          line common to both sequences
                    
                    
     ‘'? '’         line not present in either input sequence
                    

     Lines beginning with ’‘?’’ attempt to guide the eye to intraline
     differences, and were not present in either input sequence.  These
     lines can be confusing if the sequences contain tab characters.

 -- Class: difflib.HtmlDiff

     This class can be used to create an HTML table (or a complete HTML
     file containing the table) showing a side by side, line by line
     comparison of text with inter-line and intra-line change
     highlights.  The table can be generated in either full or
     contextual difference mode.

     The constructor for this class is:

      -- Function: __init__ (tabsize=8, wrapcolumn=None, linejunk=None,
               charjunk=IS_CHARACTER_JUNK)

          Initializes instance of *note HtmlDiff: a0c.

          _tabsize_ is an optional keyword argument to specify tab stop
          spacing and defaults to ‘8’.

          _wrapcolumn_ is an optional keyword to specify column number
          where lines are broken and wrapped, defaults to ‘None’ where
          lines are not wrapped.

          _linejunk_ and _charjunk_ are optional keyword arguments
          passed into ‘ndiff()’ (used by *note HtmlDiff: a0c. to
          generate the side by side HTML differences).  See ‘ndiff()’
          documentation for argument default values and descriptions.

     The following methods are public:

      -- Function: make_file (fromlines, tolines [, fromdesc][,
               todesc][, context][, numlines])

          Compares _fromlines_ and _tolines_ (lists of strings) and
          returns a string which is a complete HTML file containing a
          table showing line by line differences with inter-line and
          intra-line changes highlighted.

          _fromdesc_ and _todesc_ are optional keyword arguments to
          specify from/to file column header strings (both default to an
          empty string).

          _context_ and _numlines_ are both optional keyword arguments.
          Set _context_ to ‘True’ when contextual differences are to be
          shown, else the default is ‘False’ to show the full files.
          _numlines_ defaults to ‘5’.  When _context_ is ‘True’
          _numlines_ controls the number of context lines which surround
          the difference highlights.  When _context_ is ‘False’
          _numlines_ controls the number of lines which are shown before
          a difference highlight when using the "next" hyperlinks
          (setting to zero would cause the "next" hyperlinks to place
          the next difference highlight at the top of the browser
          without any leading context).

      -- Function: make_table (fromlines, tolines [, fromdesc][,
               todesc][, context][, numlines])

          Compares _fromlines_ and _tolines_ (lists of strings) and
          returns a string which is a complete HTML table showing line
          by line differences with inter-line and intra-line changes
          highlighted.

          The arguments for this method are the same as those for the
          *note make_file(): a0e. method.

     ‘Tools/scripts/diff.py’ is a command-line front-end to this class
     and contains a good example of its use.

     New in version 2.4.

 -- Function: difflib.context_diff (a, b[, fromfile][, tofile][,
          fromfiledate][, tofiledate][, n][, lineterm])

     Compare _a_ and _b_ (lists of strings); return a delta (a *note
     generator: 5dc. generating the delta lines) in context diff format.

     Context diffs are a compact way of showing just the lines that have
     changed plus a few lines of context.  The changes are shown in a
     before/after style.  The number of context lines is set by _n_
     which defaults to three.

     By default, the diff control lines (those with ‘***’ or ‘---’) are
     created with a trailing newline.  This is helpful so that inputs
     created from *note file.readlines(): 642. result in diffs that are
     suitable for use with *note file.writelines(): 913. since both the
     inputs and outputs have trailing newlines.

     For inputs that do not have trailing newlines, set the _lineterm_
     argument to ‘""’ so that the output will be uniformly newline free.

     The context diff format normally has a header for filenames and
     modification times.  Any or all of these may be specified using
     strings for _fromfile_, _tofile_, _fromfiledate_, and _tofiledate_.
     The modification times are normally expressed in the ISO 8601
     format.  If not specified, the strings default to blanks.

          >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
          >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
          >>> for line in context_diff(s1, s2, fromfile='before.py', tofile='after.py'):
          ...     sys.stdout.write(line)  # doctest: +NORMALIZE_WHITESPACE
          *** before.py
          --- after.py
          ***************
          *** 1,4 ****
          ! bacon
          ! eggs
          ! ham
            guido
          --- 1,4 ----
          ! python
          ! eggy
          ! hamster
            guido

     See *note A command-line interface to difflib: a11. for a more
     detailed example.

     New in version 2.3.

 -- Function: difflib.get_close_matches (word, possibilities[, n][,
          cutoff])

     Return a list of the best "good enough" matches.  _word_ is a
     sequence for which close matches are desired (typically a string),
     and _possibilities_ is a list of sequences against which to match
     _word_ (typically a list of strings).

     Optional argument _n_ (default ‘3’) is the maximum number of close
     matches to return; _n_ must be greater than ‘0’.

     Optional argument _cutoff_ (default ‘0.6’) is a float in the range
     [0, 1].  Possibilities that don’t score at least that similar to
     _word_ are ignored.

     The best (no more than _n_) matches among the possibilities are
     returned in a list, sorted by similarity score, most similar first.

          >>> get_close_matches('appel', ['ape', 'apple', 'peach', 'puppy'])
          ['apple', 'ape']
          >>> import keyword
          >>> get_close_matches('wheel', keyword.kwlist)
          ['while']
          >>> get_close_matches('apple', keyword.kwlist)
          []
          >>> get_close_matches('accept', keyword.kwlist)
          ['except']

 -- Function: difflib.ndiff (a, b[, linejunk][, charjunk])

     Compare _a_ and _b_ (lists of strings); return a *note Differ:
     a0b.-style delta (a *note generator: 5dc. generating the delta
     lines).

     Optional keyword parameters _linejunk_ and _charjunk_ are for
     filter functions (or ‘None’):

     _linejunk_: A function that accepts a single string argument, and
     returns true if the string is junk, or false if not.  The default
     is (‘None’), starting with Python 2.3.  Before then, the default
     was the module-level function *note IS_LINE_JUNK(): a14, which
     filters out lines without visible characters, except for at most
     one pound character (‘'#'’).  As of Python 2.3, the underlying
     *note SequenceMatcher: a0a. class does a dynamic analysis of which
     lines are so frequent as to constitute noise, and this usually
     works better than the pre-2.3 default.

     _charjunk_: A function that accepts a character (a string of length
     1), and returns if the character is junk, or false if not.  The
     default is module-level function *note IS_CHARACTER_JUNK(): a15,
     which filters out whitespace characters (a blank or tab; note: bad
     idea to include newline in this!).

     ‘Tools/scripts/ndiff.py’ is a command-line front-end to this
     function.

          >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(1),
          ...              'ore\ntree\nemu\n'.splitlines(1))
          >>> print ''.join(diff),
          - one
          ?  ^
          + ore
          ?  ^
          - two
          - three
          ?  -
          + tree
          + emu

 -- Function: difflib.restore (sequence, which)

     Return one of the two sequences that generated a delta.

     Given a _sequence_ produced by *note Differ.compare(): a17. or
     *note ndiff(): a13, extract lines originating from file 1 or 2
     (parameter _which_), stripping off line prefixes.

     Example:

          >>> diff = ndiff('one\ntwo\nthree\n'.splitlines(1),
          ...              'ore\ntree\nemu\n'.splitlines(1))
          >>> diff = list(diff) # materialize the generated delta into a list
          >>> print ''.join(restore(diff, 1)),
          one
          two
          three
          >>> print ''.join(restore(diff, 2)),
          ore
          tree
          emu

 -- Function: difflib.unified_diff (a, b[, fromfile][, tofile][,
          fromfiledate][, tofiledate][, n][, lineterm])

     Compare _a_ and _b_ (lists of strings); return a delta (a *note
     generator: 5dc. generating the delta lines) in unified diff format.

     Unified diffs are a compact way of showing just the lines that have
     changed plus a few lines of context.  The changes are shown in a
     inline style (instead of separate before/after blocks).  The number
     of context lines is set by _n_ which defaults to three.

     By default, the diff control lines (those with ‘---’, ‘+++’, or
     ‘@@’) are created with a trailing newline.  This is helpful so that
     inputs created from *note file.readlines(): 642. result in diffs
     that are suitable for use with *note file.writelines(): 913. since
     both the inputs and outputs have trailing newlines.

     For inputs that do not have trailing newlines, set the _lineterm_
     argument to ‘""’ so that the output will be uniformly newline free.

     The context diff format normally has a header for filenames and
     modification times.  Any or all of these may be specified using
     strings for _fromfile_, _tofile_, _fromfiledate_, and _tofiledate_.
     The modification times are normally expressed in the ISO 8601
     format.  If not specified, the strings default to blanks.

          >>> s1 = ['bacon\n', 'eggs\n', 'ham\n', 'guido\n']
          >>> s2 = ['python\n', 'eggy\n', 'hamster\n', 'guido\n']
          >>> for line in unified_diff(s1, s2, fromfile='before.py', tofile='after.py'):
          ...     sys.stdout.write(line)   # doctest: +NORMALIZE_WHITESPACE
          --- before.py
          +++ after.py
          @@ -1,4 +1,4 @@
          -bacon
          -eggs
          -ham
          +python
          +eggy
          +hamster
           guido

     See *note A command-line interface to difflib: a11. for a more
     detailed example.

     New in version 2.3.

 -- Function: difflib.IS_LINE_JUNK (line)

     Return true for ignorable lines.  The line _line_ is ignorable if
     _line_ is blank or contains a single ‘'#'’, otherwise it is not
     ignorable.  Used as a default for parameter _linejunk_ in *note
     ndiff(): a13. before Python 2.3.

 -- Function: difflib.IS_CHARACTER_JUNK (ch)

     Return true for ignorable characters.  The character _ch_ is
     ignorable if _ch_ is a space or tab, otherwise it is not ignorable.
     Used as a default for parameter _charjunk_ in *note ndiff(): a13.

See also
........

Pattern Matching: The Gestalt Approach(1)

     Discussion of a similar algorithm by John W. Ratcliff and D. E.
     Metzener.  This was published in Dr.  Dobb’s Journal(2) in July,
     1988.

* Menu:

* SequenceMatcher Objects:: 
* SequenceMatcher Examples:: 
* Differ Objects:: 
* Differ Example:: 
* A command-line interface to difflib:: 

   ---------- Footnotes ----------

   (1) http://www.ddj.com/184407970?pgno=5

   (2) http://www.ddj.com/


File: python.info,  Node: SequenceMatcher Objects,  Next: SequenceMatcher Examples,  Up: difflib --- Helpers for computing deltas

5.7.4.1 SequenceMatcher Objects
...............................

The *note SequenceMatcher: a0a. class has this constructor:

 -- Class: difflib.SequenceMatcher (isjunk=None, a='', b='',
          autojunk=True)

     Optional argument _isjunk_ must be ‘None’ (the default) or a
     one-argument function that takes a sequence element and returns
     true if and only if the element is "junk" and should be ignored.
     Passing ‘None’ for _isjunk_ is equivalent to passing ‘lambda x: 0’;
     in other words, no elements are ignored.  For example, pass:

          lambda x: x in " \t"

     if you’re comparing lines as sequences of characters, and don’t
     want to synch up on blanks or hard tabs.

     The optional arguments _a_ and _b_ are sequences to be compared;
     both default to empty strings.  The elements of both sequences must
     be *note hashable: 6f5.

     The optional argument _autojunk_ can be used to disable the
     automatic junk heuristic.

     New in version 2.7.1: The _autojunk_ parameter.

     *note SequenceMatcher: a0a. objects have the following methods:

      -- Method: set_seqs (a, b)

          Set the two sequences to be compared.

     *note SequenceMatcher: a0a. computes and caches detailed
     information about the second sequence, so if you want to compare
     one sequence against many sequences, use *note set_seq2(): a1c. to
     set the commonly used sequence once and call *note set_seq1(): a1d.
     repeatedly, once for each of the other sequences.

      -- Method: set_seq1 (a)

          Set the first sequence to be compared.  The second sequence to
          be compared is not changed.

      -- Method: set_seq2 (b)

          Set the second sequence to be compared.  The first sequence to
          be compared is not changed.

      -- Method: find_longest_match (alo, ahi, blo, bhi)

          Find longest matching block in ‘a[alo:ahi]’ and ‘b[blo:bhi]’.

          If _isjunk_ was omitted or ‘None’, *note find_longest_match():
          a1e. returns ‘(i, j, k)’ such that ‘a[i:i+k]’ is equal to
          ‘b[j:j+k]’, where ‘alo <= i <= i+k <= ahi’ and ‘blo <= j <=
          j+k <= bhi’.  For all ‘(i', j', k')’ meeting those conditions,
          the additional conditions ‘k >= k'’, ‘i <= i'’, and if ‘i ==
          i'’, ‘j <= j'’ are also met.  In other words, of all maximal
          matching blocks, return one that starts earliest in _a_, and
          of all those maximal matching blocks that start earliest in
          _a_, return the one that starts earliest in _b_.

               >>> s = SequenceMatcher(None, " abcd", "abcd abcd")
               >>> s.find_longest_match(0, 5, 0, 9)
               Match(a=0, b=4, size=5)

          If _isjunk_ was provided, first the longest matching block is
          determined as above, but with the additional restriction that
          no junk element appears in the block.  Then that block is
          extended as far as possible by matching (only) junk elements
          on both sides.  So the resulting block never matches on junk
          except as identical junk happens to be adjacent to an
          interesting match.

          Here’s the same example as before, but considering blanks to
          be junk.  That prevents ‘' abcd'’ from matching the ‘' abcd'’
          at the tail end of the second sequence directly.  Instead only
          the ‘'abcd'’ can match, and matches the leftmost ‘'abcd'’ in
          the second sequence:

               >>> s = SequenceMatcher(lambda x: x==" ", " abcd", "abcd abcd")
               >>> s.find_longest_match(0, 5, 0, 9)
               Match(a=1, b=0, size=4)

          If no blocks match, this returns ‘(alo, blo, 0)’.

          Changed in version 2.6: This method returns a *note named
          tuple: a1f. ‘Match(a, b, size)’.

      -- Method: get_matching_blocks ()

          Return list of triples describing matching subsequences.  Each
          triple is of the form ‘(i, j, n)’, and means that ‘a[i:i+n] ==
          b[j:j+n]’.  The triples are monotonically increasing in _i_
          and _j_.

          The last triple is a dummy, and has the value ‘(len(a),
          len(b), 0)’.  It is the only triple with ‘n == 0’.  If ‘(i, j,
          n)’ and ‘(i', j', n')’ are adjacent triples in the list, and
          the second is not the last triple in the list, then ‘i+n !=
          i'’ or ‘j+n != j'’; in other words, adjacent triples always
          describe non-adjacent equal blocks.

          Changed in version 2.5: The guarantee that adjacent triples
          always describe non-adjacent blocks was implemented.

               >>> s = SequenceMatcher(None, "abxcd", "abcd")
               >>> s.get_matching_blocks()
               [Match(a=0, b=0, size=2), Match(a=3, b=2, size=2), Match(a=5, b=4, size=0)]

      -- Method: get_opcodes ()

          Return list of 5-tuples describing how to turn _a_ into _b_.
          Each tuple is of the form ‘(tag, i1, i2, j1, j2)’.  The first
          tuple has ‘i1 == j1 == 0’, and remaining tuples have _i1_
          equal to the _i2_ from the preceding tuple, and, likewise,
          _j1_ equal to the previous _j2_.

          The _tag_ values are strings, with these meanings:

          Value               Meaning
                              
          ----------------------------------------------------------------------
                              
          ‘'replace'’         ‘a[i1:i2]’ should be replaced by ‘b[j1:j2]’.
                              
                              
          ‘'delete'’          ‘a[i1:i2]’ should be deleted.  Note that ‘j1 ==
                              j2’ in this case.
                              
                              
          ‘'insert'’          ‘b[j1:j2]’ should be inserted at ‘a[i1:i1]’.
                              Note that ‘i1 == i2’ in this case.
                              
                              
          ‘'equal'’           ‘a[i1:i2] == b[j1:j2]’ (the sub-sequences are
                              equal).
                              

          For example:

               >>> a = "qabxcd"
               >>> b = "abycdf"
               >>> s = SequenceMatcher(None, a, b)
               >>> for tag, i1, i2, j1, j2 in s.get_opcodes():
               ...    print ("%7s a[%d:%d] (%s) b[%d:%d] (%s)" %
               ...           (tag, i1, i2, a[i1:i2], j1, j2, b[j1:j2]))
                delete a[0:1] (q) b[0:0] ()
                 equal a[1:3] (ab) b[0:2] (ab)
               replace a[3:4] (x) b[2:3] (y)
                 equal a[4:6] (cd) b[3:5] (cd)
                insert a[6:6] () b[5:6] (f)

      -- Method: get_grouped_opcodes ([n])

          Return a *note generator: 5dc. of groups with up to _n_ lines
          of context.

          Starting with the groups returned by *note get_opcodes(): a21,
          this method splits out smaller change clusters and eliminates
          intervening ranges which have no changes.

          The groups are returned in the same format as *note
          get_opcodes(): a21.

          New in version 2.3.

      -- Method: ratio ()

          Return a measure of the sequences’ similarity as a float in
          the range [0, 1].

          Where T is the total number of elements in both sequences, and
          M is the number of matches, this is 2.0*M / T. Note that this
          is ‘1.0’ if the sequences are identical, and ‘0.0’ if they
          have nothing in common.

          This is expensive to compute if *note get_matching_blocks():
          a20. or *note get_opcodes(): a21. hasn’t already been called,
          in which case you may want to try *note quick_ratio(): a24. or
          *note real_quick_ratio(): a25. first to get an upper bound.

      -- Method: quick_ratio ()

          Return an upper bound on *note ratio(): a23. relatively
          quickly.

      -- Method: real_quick_ratio ()

          Return an upper bound on *note ratio(): a23. very quickly.

  The three methods that return the ratio of matching to total
characters can give different results due to differing levels of
approximation, although ‘quick_ratio()’ and ‘real_quick_ratio()’ are
always at least as large as ‘ratio()’:

     >>> s = SequenceMatcher(None, "abcd", "bcde")
     >>> s.ratio()
     0.75
     >>> s.quick_ratio()
     0.75
     >>> s.real_quick_ratio()
     1.0


File: python.info,  Node: SequenceMatcher Examples,  Next: Differ Objects,  Prev: SequenceMatcher Objects,  Up: difflib --- Helpers for computing deltas

5.7.4.2 SequenceMatcher Examples
................................

This example compares two strings, considering blanks to be "junk:"

     >>> s = SequenceMatcher(lambda x: x == " ",
     ...                     "private Thread currentThread;",
     ...                     "private volatile Thread currentThread;")

  ‘ratio()’ returns a float in [0, 1], measuring the similarity of the
sequences.  As a rule of thumb, a ‘ratio()’ value over 0.6 means the
sequences are close matches:

     >>> print round(s.ratio(), 3)
     0.866

  If you’re only interested in where the sequences match,
‘get_matching_blocks()’ is handy:

     >>> for block in s.get_matching_blocks():
     ...     print "a[%d] and b[%d] match for %d elements" % block
     a[0] and b[0] match for 8 elements
     a[8] and b[17] match for 21 elements
     a[29] and b[38] match for 0 elements

  Note that the last tuple returned by ‘get_matching_blocks()’ is always
a dummy, ‘(len(a), len(b), 0)’, and this is the only case in which the
last tuple element (number of elements matched) is ‘0’.

  If you want to know how to change the first sequence into the second,
use ‘get_opcodes()’:

     >>> for opcode in s.get_opcodes():
     ...     print "%6s a[%d:%d] b[%d:%d]" % opcode
      equal a[0:8] b[0:8]
     insert a[8:8] b[8:17]
      equal a[8:29] b[17:38]

See also
........

   * The *note get_close_matches(): a12. function in this module which
     shows how simple code building on *note SequenceMatcher: a0a. can
     be used to do useful work.

   * Simple version control recipe(1) for a small application built with
     *note SequenceMatcher: a0a.

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/576729/


File: python.info,  Node: Differ Objects,  Next: Differ Example,  Prev: SequenceMatcher Examples,  Up: difflib --- Helpers for computing deltas

5.7.4.3 Differ Objects
......................

Note that *note Differ: a0b.-generated deltas make no claim to be
*minimal* diffs.  To the contrary, minimal diffs are often
counter-intuitive, because they synch up anywhere possible, sometimes
accidental matches 100 pages apart.  Restricting synch points to
contiguous matches preserves some notion of locality, at the occasional
cost of producing a longer diff.

  The *note Differ: a0b. class has this constructor:

 -- Class: difflib.Differ ([linejunk[, charjunk]])

     Optional keyword parameters _linejunk_ and _charjunk_ are for
     filter functions (or ‘None’):

     _linejunk_: A function that accepts a single string argument, and
     returns true if the string is junk.  The default is ‘None’, meaning
     that no line is considered junk.

     _charjunk_: A function that accepts a single character argument (a
     string of length 1), and returns true if the character is junk.
     The default is ‘None’, meaning that no character is considered
     junk.

     *note Differ: a0b. objects are used (deltas generated) via a single
     method:

      -- Method: compare (a, b)

          Compare two sequences of lines, and generate the delta (a
          sequence of lines).

          Each sequence must contain individual single-line strings
          ending with newlines.  Such sequences can be obtained from the
          *note readlines(): 642. method of file-like objects.  The
          delta generated also consists of newline-terminated strings,
          ready to be printed as-is via the *note writelines(): 913.
          method of a file-like object.


File: python.info,  Node: Differ Example,  Next: A command-line interface to difflib,  Prev: Differ Objects,  Up: difflib --- Helpers for computing deltas

5.7.4.4 Differ Example
......................

This example compares two texts.  First we set up the texts, sequences
of individual single-line strings ending with newlines (such sequences
can also be obtained from the *note readlines(): 642. method of
file-like objects):

     >>> text1 = '''  1. Beautiful is better than ugly.
     ...   2. Explicit is better than implicit.
     ...   3. Simple is better than complex.
     ...   4. Complex is better than complicated.
     ... '''.splitlines(1)
     >>> len(text1)
     4
     >>> text1[0][-1]
     '\n'
     >>> text2 = '''  1. Beautiful is better than ugly.
     ...   3.   Simple is better than complex.
     ...   4. Complicated is better than complex.
     ...   5. Flat is better than nested.
     ... '''.splitlines(1)

  Next we instantiate a Differ object:

     >>> d = Differ()

  Note that when instantiating a *note Differ: a0b. object we may pass
functions to filter out line and character "junk."  See the *note
Differ(): a0b. constructor for details.

  Finally, we compare the two:

     >>> result = list(d.compare(text1, text2))

  ‘result’ is a list of strings, so let’s pretty-print it:

     >>> from pprint import pprint
     >>> pprint(result)
     ['    1. Beautiful is better than ugly.\n',
      '-   2. Explicit is better than implicit.\n',
      '-   3. Simple is better than complex.\n',
      '+   3.   Simple is better than complex.\n',
      '?     ++\n',
      '-   4. Complex is better than complicated.\n',
      '?            ^                     ---- ^\n',
      '+   4. Complicated is better than complex.\n',
      '?           ++++ ^                      ^\n',
      '+   5. Flat is better than nested.\n']

  As a single multi-line string it looks like this:

     >>> import sys
     >>> sys.stdout.writelines(result)
         1. Beautiful is better than ugly.
     -   2. Explicit is better than implicit.
     -   3. Simple is better than complex.
     +   3.   Simple is better than complex.
     ?     ++
     -   4. Complex is better than complicated.
     ?            ^                     ---- ^
     +   4. Complicated is better than complex.
     ?           ++++ ^                      ^
     +   5. Flat is better than nested.


File: python.info,  Node: A command-line interface to difflib,  Prev: Differ Example,  Up: difflib --- Helpers for computing deltas

5.7.4.5 A command-line interface to difflib
...........................................

This example shows how to use difflib to create a ‘diff’-like utility.
It is also contained in the Python source distribution, as
‘Tools/scripts/diff.py’.

     """ Command line interface to difflib.py providing diffs in four formats:

     * ndiff:    lists every line and highlights interline changes.
     * context:  highlights clusters of changes in a before/after format.
     * unified:  highlights clusters of changes in an inline format.
     * html:     generates side by side comparison with change highlights.

     """

     import sys, os, time, difflib, optparse

     def main():
          # Configure the option parser
         usage = "usage: %prog [options] fromfile tofile"
         parser = optparse.OptionParser(usage)
         parser.add_option("-c", action="store_true", default=False,
                           help='Produce a context format diff (default)')
         parser.add_option("-u", action="store_true", default=False,
                           help='Produce a unified format diff')
         hlp = 'Produce HTML side by side diff (can use -c and -l in conjunction)'
         parser.add_option("-m", action="store_true", default=False, help=hlp)
         parser.add_option("-n", action="store_true", default=False,
                           help='Produce a ndiff format diff')
         parser.add_option("-l", "--lines", type="int", default=3,
                           help='Set number of context lines (default 3)')
         (options, args) = parser.parse_args()

         if len(args) == 0:
             parser.print_help()
             sys.exit(1)
         if len(args) != 2:
             parser.error("need to specify both a fromfile and tofile")

         n = options.lines
         fromfile, tofile = args # as specified in the usage string

         # we're passing these as arguments to the diff function
         fromdate = time.ctime(os.stat(fromfile).st_mtime)
         todate = time.ctime(os.stat(tofile).st_mtime)
         fromlines = open(fromfile, 'U').readlines()
         tolines = open(tofile, 'U').readlines()

         if options.u:
             diff = difflib.unified_diff(fromlines, tolines, fromfile, tofile,
                                         fromdate, todate, n=n)
         elif options.n:
             diff = difflib.ndiff(fromlines, tolines)
         elif options.m:
             diff = difflib.HtmlDiff().make_file(fromlines, tolines, fromfile,
                                                 tofile, context=options.c,
                                                 numlines=n)
         else:
             diff = difflib.context_diff(fromlines, tolines, fromfile, tofile,
                                         fromdate, todate, n=n)

         # we're using writelines because diff is a generator
         sys.stdout.writelines(diff)

     if __name__ == '__main__':
         main()


File: python.info,  Node: StringIO --- Read and write strings as files,  Next: cStringIO --- Faster version of StringIO,  Prev: difflib --- Helpers for computing deltas,  Up: String Services

5.7.5 ‘StringIO’ — Read and write strings as files
--------------------------------------------------

This module implements a file-like class, *note StringIO: 164, that
reads and writes a string buffer (also known as _memory files_).  See
the description of file objects for operations (section *note File
Objects: 643.).  (For standard strings, see *note str: 1ea. and *note
unicode: 1f5.)

 -- Class: StringIO.StringIO ([buffer])

     When a *note StringIO: 164. object is created, it can be
     initialized to an existing string by passing the string to the
     constructor.  If no string is given, the *note StringIO: 164. will
     start empty.  In both cases, the initial file position starts at
     zero.

     The *note StringIO: 164. object can accept either Unicode or 8-bit
     strings, but mixing the two may take some care.  If both are used,
     8-bit strings that cannot be interpreted as 7-bit ASCII (that use
     the 8th bit) will cause a *note UnicodeError: 433. to be raised
     when *note getvalue(): a2f. is called.

  The following methods of *note StringIO: 164. objects require special
mention:

 -- Method: StringIO.getvalue ()

     Retrieve the entire contents of the "file" at any time before the
     *note StringIO: 164. object’s *note close(): a30. method is called.
     See the note above for information about mixing Unicode and 8-bit
     strings; such mixing can cause this method to raise *note
     UnicodeError: 433.

 -- Method: StringIO.close ()

     Free the memory buffer.  Attempting to do further operations with a
     closed *note StringIO: 164. object will raise a *note ValueError:
     236.

  Example usage:

     import StringIO

     output = StringIO.StringIO()
     output.write('First line.\n')
     print >>output, 'Second line.'

     # Retrieve file contents -- this will be
     # 'First line.\nSecond line.\n'
     contents = output.getvalue()

     # Close object and discard memory buffer --
     # .getvalue() will now raise an exception.
     output.close()


File: python.info,  Node: cStringIO --- Faster version of StringIO,  Next: textwrap --- Text wrapping and filling,  Prev: StringIO --- Read and write strings as files,  Up: String Services

5.7.6 ‘cStringIO’ — Faster version of ‘StringIO’
------------------------------------------------

The module *note cStringIO: 76. provides an interface similar to that of
the *note StringIO: 164. module.  Heavy use of *note StringIO.StringIO:
2dd. objects can be made more efficient by using the function *note
StringIO(): 164. from this module instead.

 -- Function: cStringIO.StringIO ([s])

     Return a StringIO-like stream for reading or writing.

     Since this is a factory function which returns objects of built-in
     types, there’s no way to build your own version using subclassing.
     It’s not possible to set attributes on it.  Use the original *note
     StringIO: 164. module in those cases.

     Unlike the *note StringIO: 164. module, this module is not able to
     accept Unicode strings that cannot be encoded as plain ASCII
     strings.

     Another difference from the *note StringIO: 164. module is that
     calling *note StringIO(): 164. with a string parameter creates a
     read-only object.  Unlike an object created without a string
     parameter, it does not have write methods.  These objects are not
     generally visible.  They turn up in tracebacks as ‘StringI’ and
     ‘StringO’.

  The following data objects are provided as well:

 -- Data: cStringIO.InputType

     The type object of the objects created by calling *note StringIO():
     164. with a string parameter.

 -- Data: cStringIO.OutputType

     The type object of the objects returned by calling *note
     StringIO(): 164. with no parameters.

  There is a C API to the module as well; refer to the module source for
more information.

  Example usage:

     import cStringIO

     output = cStringIO.StringIO()
     output.write('First line.\n')
     print >>output, 'Second line.'

     # Retrieve file contents -- this will be
     # 'First line.\nSecond line.\n'
     contents = output.getvalue()

     # Close object and discard memory buffer --
     # .getvalue() will now raise an exception.
     output.close()


File: python.info,  Node: textwrap --- Text wrapping and filling,  Next: codecs --- Codec registry and base classes,  Prev: cStringIO --- Faster version of StringIO,  Up: String Services

5.7.7 ‘textwrap’ — Text wrapping and filling
--------------------------------------------

New in version 2.3.

  *Source code:* Lib/textwrap.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note textwrap: 177. module provides two convenience functions,
*note wrap(): a37. and *note fill(): a38, as well as *note TextWrapper:
a39, the class that does all the work, and a utility function *note
dedent(): a3a.  If you’re just wrapping or filling one or two text
strings, the convenience functions should be good enough; otherwise, you
should use an instance of *note TextWrapper: a39. for efficiency.

 -- Function: textwrap.wrap (text[, width[, ...]])

     Wraps the single paragraph in _text_ (a string) so every line is at
     most _width_ characters long.  Returns a list of output lines,
     without final newlines.

     Optional keyword arguments correspond to the instance attributes of
     *note TextWrapper: a39, documented below.  _width_ defaults to
     ‘70’.

     See the *note TextWrapper.wrap(): a3b. method for additional
     details on how *note wrap(): a37. behaves.

 -- Function: textwrap.fill (text[, width[, ...]])

     Wraps the single paragraph in _text_, and returns a single string
     containing the wrapped paragraph.  *note fill(): a38. is shorthand
     for

          "\n".join(wrap(text, ...))

     In particular, *note fill(): a38. accepts exactly the same keyword
     arguments as *note wrap(): a37.

  Both *note wrap(): a37. and *note fill(): a38. work by creating a
*note TextWrapper: a39. instance and calling a single method on it.
That instance is not reused, so for applications that wrap/fill many
text strings, it will be more efficient for you to create your own *note
TextWrapper: a39. object.

  Text is preferably wrapped on whitespaces and right after the hyphens
in hyphenated words; only then will long words be broken if necessary,
unless *note TextWrapper.break_long_words: a3c. is set to false.

  An additional utility function, *note dedent(): a3a, is provided to
remove indentation from strings that have unwanted whitespace to the
left of the text.

 -- Function: textwrap.dedent (text)

     Remove any common leading whitespace from every line in _text_.

     This can be used to make triple-quoted strings line up with the
     left edge of the display, while still presenting them in the source
     code in indented form.

     Note that tabs and spaces are both treated as whitespace, but they
     are not equal: the lines ‘" hello"’ and ‘"\thello"’ are considered
     to have no common leading whitespace.  (This behaviour is new in
     Python 2.5; older versions of this module incorrectly expanded tabs
     before searching for common leading whitespace.)

     For example:

          def test():
              # end first line with \ to avoid the empty line!
              s = '''\
              hello
                world
              '''
              print repr(s)          # prints '    hello\n      world\n    '
              print repr(dedent(s))  # prints 'hello\n  world\n'

 -- Class: textwrap.TextWrapper (...)

     The *note TextWrapper: a39. constructor accepts a number of
     optional keyword arguments.  Each argument corresponds to one
     instance attribute, so for example

          wrapper = TextWrapper(initial_indent="* ")

     is the same as

          wrapper = TextWrapper()
          wrapper.initial_indent = "* "

     You can re-use the same *note TextWrapper: a39. object many times,
     and you can change any of its options through direct assignment to
     instance attributes between uses.

     The *note TextWrapper: a39. instance attributes (and keyword
     arguments to the constructor) are as follows:

      -- Attribute: width

          (default: ‘70’) The maximum length of wrapped lines.  As long
          as there are no individual words in the input text longer than
          *note width: a3d, *note TextWrapper: a39. guarantees that no
          output line will be longer than *note width: a3d. characters.

      -- Attribute: expand_tabs

          (default: ‘True’) If true, then all tab characters in _text_
          will be expanded to spaces using the ‘expandtabs()’ method of
          _text_.

      -- Attribute: replace_whitespace

          (default: ‘True’) If true, after tab expansion but before
          wrapping, the *note wrap(): a37. method will replace each
          whitespace character with a single space.  The whitespace
          characters replaced are as follows: tab, newline, vertical
          tab, formfeed, and carriage return (‘'\t\n\v\f\r'’).

               Note: If *note expand_tabs: a3e. is false and *note
               replace_whitespace: a3f. is true, each tab character will
               be replaced by a single space, which is _not_ the same as
               tab expansion.

               Note: If *note replace_whitespace: a3f. is false,
               newlines may appear in the middle of a line and cause
               strange output.  For this reason, text should be split
               into paragraphs (using *note str.splitlines(): 8d7. or
               similar) which are wrapped separately.

      -- Attribute: drop_whitespace

          (default: ‘True’) If true, whitespace at the beginning and
          ending of every line (after wrapping but before indenting) is
          dropped.  Whitespace at the beginning of the paragraph,
          however, is not dropped if non-whitespace follows it.  If
          whitespace being dropped takes up an entire line, the whole
          line is dropped.

          New in version 2.6: Whitespace was always dropped in earlier
          versions.

      -- Attribute: initial_indent

          (default: ‘''’) String that will be prepended to the first
          line of wrapped output.  Counts towards the length of the
          first line.  The empty string is not indented.

      -- Attribute: subsequent_indent

          (default: ‘''’) String that will be prepended to all lines of
          wrapped output except the first.  Counts towards the length of
          each line except the first.

      -- Attribute: fix_sentence_endings

          (default: ‘False’) If true, *note TextWrapper: a39. attempts
          to detect sentence endings and ensure that sentences are
          always separated by exactly two spaces.  This is generally
          desired for text in a monospaced font.  However, the sentence
          detection algorithm is imperfect: it assumes that a sentence
          ending consists of a lowercase letter followed by one of
          ‘'.'’, ‘'!'’, or ‘'?'’, possibly followed by one of ‘'"'’ or
          ‘"'"’, followed by a space.  One problem with this is
          algorithm is that it is unable to detect the difference
          between "Dr."  in

               [...] Dr. Frankenstein's monster [...]

          and "Spot."  in

               [...] See Spot. See Spot run [...]

          *note fix_sentence_endings: a43. is false by default.

          Since the sentence detection algorithm relies on
          ‘string.lowercase’ for the definition of "lowercase letter,"
          and a convention of using two spaces after a period to
          separate sentences on the same line, it is specific to
          English-language texts.

      -- Attribute: break_long_words

          (default: ‘True’) If true, then words longer than *note width:
          a3d. will be broken in order to ensure that no lines are
          longer than *note width: a3d.  If it is false, long words will
          not be broken, and some lines may be longer than *note width:
          a3d.  (Long words will be put on a line by themselves, in
          order to minimize the amount by which *note width: a3d. is
          exceeded.)

      -- Attribute: break_on_hyphens

          (default: ‘True’) If true, wrapping will occur preferably on
          whitespaces and right after hyphens in compound words, as it
          is customary in English.  If false, only whitespaces will be
          considered as potentially good places for line breaks, but you
          need to set *note break_long_words: a3c. to false if you want
          truly insecable words.  Default behaviour in previous versions
          was to always allow breaking hyphenated words.

          New in version 2.6.

     *note TextWrapper: a39. also provides two public methods, analogous
     to the module-level convenience functions:

      -- Method: wrap (text)

          Wraps the single paragraph in _text_ (a string) so every line
          is at most *note width: a3d. characters long.  All wrapping
          options are taken from instance attributes of the *note
          TextWrapper: a39. instance.  Returns a list of output lines,
          without final newlines.  If the wrapped output has no content,
          the returned list is empty.

      -- Method: fill (text)

          Wraps the single paragraph in _text_, and returns a single
          string containing the wrapped paragraph.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/textwrap.py


File: python.info,  Node: codecs --- Codec registry and base classes,  Next: unicodedata --- Unicode Database,  Prev: textwrap --- Text wrapping and filling,  Up: String Services

5.7.8 ‘codecs’ — Codec registry and base classes
------------------------------------------------

This module defines base classes for standard Python codecs (encoders
and decoders) and provides access to the internal Python codec registry
which manages the codec and error handling lookup process.

  It defines the following functions:

 -- Function: codecs.encode (obj[, encoding[, errors]])

     Encodes _obj_ using the codec registered for _encoding_.  The
     default encoding is ‘'ascii'’.

     _Errors_ may be given to set the desired error handling scheme.
     The default error handler is ‘'strict'’ meaning that encoding
     errors raise *note ValueError: 236. (or a more codec specific
     subclass, such as *note UnicodeEncodeError: 957.).  Refer to *note
     Codec Base Classes: 8bf. for more information on codec error
     handling.

     New in version 2.4.

 -- Function: codecs.decode (obj[, encoding[, errors]])

     Decodes _obj_ using the codec registered for _encoding_.  The
     default encoding is ‘'ascii'’.

     _Errors_ may be given to set the desired error handling scheme.
     The default error handler is ‘'strict'’ meaning that decoding
     errors raise *note ValueError: 236. (or a more codec specific
     subclass, such as *note UnicodeDecodeError: 958.).  Refer to *note
     Codec Base Classes: 8bf. for more information on codec error
     handling.

     New in version 2.4.

 -- Function: codecs.register (search_function)

     Register a codec search function.  Search functions are expected to
     take one argument, the encoding name in all lower case letters, and
     return a ‘CodecInfo’ object having the following attributes:

        * ‘name’ The name of the encoding;

        * ‘encode’ The stateless encoding function;

        * ‘decode’ The stateless decoding function;

        * ‘incrementalencoder’ An incremental encoder class or factory
          function;

        * ‘incrementaldecoder’ An incremental decoder class or factory
          function;

        * ‘streamwriter’ A stream writer class or factory function;

        * ‘streamreader’ A stream reader class or factory function.

     The various functions or classes take the following arguments:

     _encode_ and _decode_: These must be functions or methods which
     have the same interface as the *note encode(): a4b./*note decode():
     a4c. methods of Codec instances (see *note Codec Interface: a4d.).
     The functions/methods are expected to work in a stateless mode.

     _incrementalencoder_ and _incrementaldecoder_: These have to be
     factory functions providing the following interface:

          ‘factory(errors='strict')’

     The factory functions must return objects providing the interfaces
     defined by the base classes *note IncrementalEncoder: a4e. and
     *note IncrementalDecoder: a4f, respectively.  Incremental codecs
     can maintain state.

     _streamreader_ and _streamwriter_: These have to be factory
     functions providing the following interface:

          ‘factory(stream, errors='strict')’

     The factory functions must return objects providing the interfaces
     defined by the base classes *note StreamReader: a50. and *note
     StreamWriter: a51, respectively.  Stream codecs can maintain state.

     Possible values for errors are

        * ‘'strict'’: raise an exception in case of an encoding error

        * ‘'replace'’: replace malformed data with a suitable
          replacement marker, such as ‘'?'’ or ‘'\ufffd'’

        * ‘'ignore'’: ignore malformed data and continue without further
          notice

        * ‘'xmlcharrefreplace'’: replace with the appropriate XML
          character reference (for encoding only)

        * ‘'backslashreplace'’: replace with backslashed escape
          sequences (for encoding only)

     as well as any other error handling name defined via *note
     register_error(): 43e.

     In case a search function cannot find a given encoding, it should
     return ‘None’.

 -- Function: codecs.lookup (encoding)

     Looks up the codec info in the Python codec registry and returns a
     ‘CodecInfo’ object as defined above.

     Encodings are first looked up in the registry’s cache.  If not
     found, the list of registered search functions is scanned.  If no
     ‘CodecInfo’ object is found, a *note LookupError: 891. is raised.
     Otherwise, the ‘CodecInfo’ object is stored in the cache and
     returned to the caller.

  To simplify access to the various codecs, the module provides these
additional functions which use *note lookup(): 94b. for the codec
lookup:

 -- Function: codecs.getencoder (encoding)

     Look up the codec for the given encoding and return its encoder
     function.

     Raises a *note LookupError: 891. in case the encoding cannot be
     found.

 -- Function: codecs.getdecoder (encoding)

     Look up the codec for the given encoding and return its decoder
     function.

     Raises a *note LookupError: 891. in case the encoding cannot be
     found.

 -- Function: codecs.getincrementalencoder (encoding)

     Look up the codec for the given encoding and return its incremental
     encoder class or factory function.

     Raises a *note LookupError: 891. in case the encoding cannot be
     found or the codec doesn’t support an incremental encoder.

     New in version 2.5.

 -- Function: codecs.getincrementaldecoder (encoding)

     Look up the codec for the given encoding and return its incremental
     decoder class or factory function.

     Raises a *note LookupError: 891. in case the encoding cannot be
     found or the codec doesn’t support an incremental decoder.

     New in version 2.5.

 -- Function: codecs.getreader (encoding)

     Look up the codec for the given encoding and return its
     StreamReader class or factory function.

     Raises a *note LookupError: 891. in case the encoding cannot be
     found.

 -- Function: codecs.getwriter (encoding)

     Look up the codec for the given encoding and return its
     StreamWriter class or factory function.

     Raises a *note LookupError: 891. in case the encoding cannot be
     found.

 -- Function: codecs.register_error (name, error_handler)

     Register the error handling function _error_handler_ under the name
     _name_.  _error_handler_ will be called during encoding and
     decoding in case of an error, when _name_ is specified as the
     errors parameter.

     For encoding _error_handler_ will be called with a *note
     UnicodeEncodeError: 957. instance, which contains information about
     the location of the error.  The error handler must either raise
     this or a different exception or return a tuple with a replacement
     for the unencodable part of the input and a position where encoding
     should continue.  The encoder will encode the replacement and
     continue encoding the original input at the specified position.
     Negative position values will be treated as being relative to the
     end of the input string.  If the resulting position is out of bound
     an *note IndexError: 4e1. will be raised.

     Decoding and translating works similar, except *note
     UnicodeDecodeError: 958. or *note UnicodeTranslateError: 959. will
     be passed to the handler and that the replacement from the error
     handler will be put into the output directly.

 -- Function: codecs.lookup_error (name)

     Return the error handler previously registered under the name
     _name_.

     Raises a *note LookupError: 891. in case the handler cannot be
     found.

 -- Function: codecs.strict_errors (exception)

     Implements the ‘strict’ error handling: each encoding or decoding
     error raises a *note UnicodeError: 433.

 -- Function: codecs.replace_errors (exception)

     Implements the ‘replace’ error handling: malformed data is replaced
     with a suitable replacement character such as ‘'?'’ in bytestrings
     and ‘'\ufffd'’ in Unicode strings.

 -- Function: codecs.ignore_errors (exception)

     Implements the ‘ignore’ error handling: malformed data is ignored
     and encoding or decoding is continued without further notice.

 -- Function: codecs.xmlcharrefreplace_errors (exception)

     Implements the ‘xmlcharrefreplace’ error handling (for encoding
     only): the unencodable character is replaced by an appropriate XML
     character reference.

 -- Function: codecs.backslashreplace_errors (exception)

     Implements the ‘backslashreplace’ error handling (for encoding
     only): the unencodable character is replaced by a backslashed
     escape sequence.

  To simplify working with encoded files or stream, the module also
defines these utility functions:

 -- Function: codecs.open (filename, mode[, encoding[, errors[,
          buffering]]])

     Open an encoded file using the given _mode_ and return a wrapped
     version providing transparent encoding/decoding.  The default file
     mode is ‘'r'’ meaning to open the file in read mode.

          Note: The wrapped version will only accept the object format
          defined by the codecs, i.e.  Unicode objects for most built-in
          codecs.  Output is also codec-dependent and will usually be
          Unicode as well.

          Note: Files are always opened in binary mode, even if no
          binary mode was specified.  This is done to avoid data loss
          due to encodings using 8-bit values.  This means that no
          automatic conversion of ‘'\n'’ is done on reading and writing.

     _encoding_ specifies the encoding which is to be used for the file.

     _errors_ may be given to define the error handling.  It defaults to
     ‘'strict'’ which causes a *note ValueError: 236. to be raised in
     case an encoding error occurs.

     _buffering_ has the same meaning as for the built-in *note open():
     2d6. function.  It defaults to line buffered.

 -- Function: codecs.EncodedFile (file, input[, output[, errors]])

     Return a wrapped version of file which provides transparent
     encoding translation.

     Strings written to the wrapped file are interpreted according to
     the given _input_ encoding and then written to the original file as
     strings using the _output_ encoding.  The intermediate encoding
     will usually be Unicode but depends on the specified codecs.

     If _output_ is not given, it defaults to _input_.

     _errors_ may be given to define the error handling.  It defaults to
     ‘'strict'’, which causes *note ValueError: 236. to be raised in
     case an encoding error occurs.

 -- Function: codecs.iterencode (iterable, encoding[, errors])

     Uses an incremental encoder to iteratively encode the input
     provided by _iterable_.  This function is a *note generator: 5dc.
     _errors_ (as well as any other keyword argument) is passed through
     to the incremental encoder.

     New in version 2.5.

 -- Function: codecs.iterdecode (iterable, encoding[, errors])

     Uses an incremental decoder to iteratively decode the input
     provided by _iterable_.  This function is a *note generator: 5dc.
     _errors_ (as well as any other keyword argument) is passed through
     to the incremental decoder.

     New in version 2.5.

  The module also provides the following constants which are useful for
reading and writing to platform dependent files:

 -- Data: codecs.BOM
 -- Data: codecs.BOM_BE
 -- Data: codecs.BOM_LE
 -- Data: codecs.BOM_UTF8
 -- Data: codecs.BOM_UTF16
 -- Data: codecs.BOM_UTF16_BE
 -- Data: codecs.BOM_UTF16_LE
 -- Data: codecs.BOM_UTF32
 -- Data: codecs.BOM_UTF32_BE
 -- Data: codecs.BOM_UTF32_LE

     These constants define various encodings of the Unicode byte order
     mark (BOM) used in UTF-16 and UTF-32 data streams to indicate the
     byte order used in the stream or file and in UTF-8 as a Unicode
     signature.  *note BOM_UTF16: a65. is either *note BOM_UTF16_BE:
     a66. or *note BOM_UTF16_LE: a67. depending on the platform’s native
     byte order, *note BOM: a61. is an alias for *note BOM_UTF16: a65,
     *note BOM_LE: a63. for *note BOM_UTF16_LE: a67. and *note BOM_BE:
     a62. for *note BOM_UTF16_BE: a66.  The others represent the BOM in
     UTF-8 and UTF-32 encodings.

* Menu:

* Codec Base Classes:: 
* Encodings and Unicode:: 
* Standard Encodings:: 
* Python Specific Encodings:: 
* encodings.idna: encodings idna --- Internationalized Domain Names in Applications. Internationalized Domain Names in Applications
* encodings.utf_8_sig: encodings utf_8_sig --- UTF-8 codec with BOM signature. UTF-8 codec with BOM signature

Codec Base Classes

* Codec Objects:: 
* IncrementalEncoder Objects:: 
* IncrementalDecoder Objects:: 
* StreamWriter Objects:: 
* StreamReader Objects:: 
* StreamReaderWriter Objects:: 
* StreamRecoder Objects:: 


File: python.info,  Node: Codec Base Classes,  Next: Encodings and Unicode,  Up: codecs --- Codec registry and base classes

5.7.8.1 Codec Base Classes
..........................

The *note codecs: 63. module defines a set of base classes which define
the interface and can also be used to easily write your own codecs for
use in Python.

  Each codec has to define four interfaces to make it usable as codec in
Python: stateless encoder, stateless decoder, stream reader and stream
writer.  The stream reader and writers typically reuse the stateless
encoder/decoder to implement the file protocols.

  The ‘Codec’ class defines the interface for stateless
encoders/decoders.

  To simplify and standardize error handling, the *note encode(): a4b.
and *note decode(): a4c. methods may implement different error handling
schemes by providing the _errors_ string argument.  The following string
values are defined and implemented by all standard Python codecs:

Value                         Meaning
                              
----------------------------------------------------------------------------------
                              
‘'strict'’                    Raise *note UnicodeError: 433. (or a subclass);
                              this is the default.
                              
                              
‘'ignore'’                    Ignore the character and continue with the next.
                              
                              
‘'replace'’                   Replace with a suitable replacement character;
                              Python will use the official U+FFFD REPLACEMENT
                              CHARACTER for the built-in Unicode codecs on
                              decoding and ’?’ on encoding.
                              
                              
‘'xmlcharrefreplace'’         Replace with the appropriate XML character
                              reference (only for encoding).
                              
                              
‘'backslashreplace'’          Replace with backslashed escape sequences (only
                              for encoding).
                              

  The set of allowed values can be extended via *note register_error():
43e.

* Menu:

* Codec Objects:: 
* IncrementalEncoder Objects:: 
* IncrementalDecoder Objects:: 
* StreamWriter Objects:: 
* StreamReader Objects:: 
* StreamReaderWriter Objects:: 
* StreamRecoder Objects:: 


File: python.info,  Node: Codec Objects,  Next: IncrementalEncoder Objects,  Up: Codec Base Classes

5.7.8.2 Codec Objects
.....................

The ‘Codec’ class defines these methods which also define the function
interfaces of the stateless encoder and decoder:

 -- Method: Codec.encode (input[, errors])

     Encodes the object _input_ and returns a tuple (output object,
     length consumed).  While codecs are not restricted to use with
     Unicode, in a Unicode context, encoding converts a Unicode object
     to a plain string using a particular character set encoding (e.g.,
     ‘cp1252’ or ‘iso-8859-1’).

     _errors_ defines the error handling to apply.  It defaults to
     ‘'strict'’ handling.

     The method may not store state in the ‘Codec’ instance.  Use
     ‘StreamCodec’ for codecs which have to keep state in order to make
     encoding/decoding efficient.

     The encoder must be able to handle zero length input and return an
     empty object of the output object type in this situation.

 -- Method: Codec.decode (input[, errors])

     Decodes the object _input_ and returns a tuple (output object,
     length consumed).  In a Unicode context, decoding converts a plain
     string encoded using a particular character set encoding to a
     Unicode object.

     _input_ must be an object which provides the ‘bf_getreadbuf’ buffer
     slot.  Python strings, buffer objects and memory mapped files are
     examples of objects providing this slot.

     _errors_ defines the error handling to apply.  It defaults to
     ‘'strict'’ handling.

     The method may not store state in the ‘Codec’ instance.  Use
     ‘StreamCodec’ for codecs which have to keep state in order to make
     encoding/decoding efficient.

     The decoder must be able to handle zero length input and return an
     empty object of the output object type in this situation.

  The *note IncrementalEncoder: a4e. and *note IncrementalDecoder: a4f.
classes provide the basic interface for incremental encoding and
decoding.  Encoding/decoding the input isn’t done with one call to the
stateless encoder/decoder function, but with multiple calls to the *note
encode(): a6d./*note decode(): a6e. method of the incremental
encoder/decoder.  The incremental encoder/decoder keeps track of the
encoding/decoding process during method calls.

  The joined output of calls to the *note encode(): a6d./*note decode():
a6e. method is the same as if all the single inputs were joined into
one, and this input was encoded/decoded with the stateless
encoder/decoder.


File: python.info,  Node: IncrementalEncoder Objects,  Next: IncrementalDecoder Objects,  Prev: Codec Objects,  Up: Codec Base Classes

5.7.8.3 IncrementalEncoder Objects
..................................

New in version 2.5.

  The *note IncrementalEncoder: a4e. class is used for encoding an input
in multiple steps.  It defines the following methods which every
incremental encoder must define in order to be compatible with the
Python codec registry.

 -- Class: codecs.IncrementalEncoder ([errors])

     Constructor for an *note IncrementalEncoder: a4e. instance.

     All incremental encoders must provide this constructor interface.
     They are free to add additional keyword arguments, but only the
     ones defined here are used by the Python codec registry.

     The *note IncrementalEncoder: a4e. may implement different error
     handling schemes by providing the _errors_ keyword argument.  These
     parameters are predefined:

        * ‘'strict'’ Raise *note ValueError: 236. (or a subclass); this
          is the default.

        * ‘'ignore'’ Ignore the character and continue with the next.

        * ‘'replace'’ Replace with a suitable replacement character

        * ‘'xmlcharrefreplace'’ Replace with the appropriate XML
          character reference

        * ‘'backslashreplace'’ Replace with backslashed escape
          sequences.

     The _errors_ argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note IncrementalEncoder: a4e. object.

     The set of allowed values for the _errors_ argument can be extended
     with *note register_error(): 43e.

      -- Method: encode (object[, final])

          Encodes _object_ (taking the current state of the encoder into
          account) and returns the resulting encoded object.  If this is
          the last call to *note encode(): a48. _final_ must be true
          (the default is false).

      -- Method: reset ()

          Reset the encoder to the initial state.


File: python.info,  Node: IncrementalDecoder Objects,  Next: StreamWriter Objects,  Prev: IncrementalEncoder Objects,  Up: Codec Base Classes

5.7.8.4 IncrementalDecoder Objects
..................................

The *note IncrementalDecoder: a4f. class is used for decoding an input
in multiple steps.  It defines the following methods which every
incremental decoder must define in order to be compatible with the
Python codec registry.

 -- Class: codecs.IncrementalDecoder ([errors])

     Constructor for an *note IncrementalDecoder: a4f. instance.

     All incremental decoders must provide this constructor interface.
     They are free to add additional keyword arguments, but only the
     ones defined here are used by the Python codec registry.

     The *note IncrementalDecoder: a4f. may implement different error
     handling schemes by providing the _errors_ keyword argument.  These
     parameters are predefined:

        * ‘'strict'’ Raise *note ValueError: 236. (or a subclass); this
          is the default.

        * ‘'ignore'’ Ignore the character and continue with the next.

        * ‘'replace'’ Replace with a suitable replacement character.

     The _errors_ argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note IncrementalDecoder: a4f. object.

     The set of allowed values for the _errors_ argument can be extended
     with *note register_error(): 43e.

      -- Method: decode (object[, final])

          Decodes _object_ (taking the current state of the decoder into
          account) and returns the resulting decoded object.  If this is
          the last call to *note decode(): a49. _final_ must be true
          (the default is false).  If _final_ is true the decoder must
          decode the input completely and must flush all buffers.  If
          this isn’t possible (e.g.  because of incomplete byte
          sequences at the end of the input) it must initiate error
          handling just like in the stateless case (which might raise an
          exception).

      -- Method: reset ()

          Reset the decoder to the initial state.

  The *note StreamWriter: a51. and *note StreamReader: a50. classes
provide generic working interfaces which can be used to implement new
encoding submodules very easily.  See ‘encodings.utf_8’ for an example
of how this is done.


File: python.info,  Node: StreamWriter Objects,  Next: StreamReader Objects,  Prev: IncrementalDecoder Objects,  Up: Codec Base Classes

5.7.8.5 StreamWriter Objects
............................

The *note StreamWriter: a51. class is a subclass of ‘Codec’ and defines
the following methods which every stream writer must define in order to
be compatible with the Python codec registry.

 -- Class: codecs.StreamWriter (stream[, errors])

     Constructor for a *note StreamWriter: a51. instance.

     All stream writers must provide this constructor interface.  They
     are free to add additional keyword arguments, but only the ones
     defined here are used by the Python codec registry.

     _stream_ must be a file-like object open for writing binary data.

     The *note StreamWriter: a51. may implement different error handling
     schemes by providing the _errors_ keyword argument.  These
     parameters are predefined:

        * ‘'strict'’ Raise *note ValueError: 236. (or a subclass); this
          is the default.

        * ‘'ignore'’ Ignore the character and continue with the next.

        * ‘'replace'’ Replace with a suitable replacement character

        * ‘'xmlcharrefreplace'’ Replace with the appropriate XML
          character reference

        * ‘'backslashreplace'’ Replace with backslashed escape
          sequences.

     The _errors_ argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note StreamWriter: a51. object.

     The set of allowed values for the _errors_ argument can be extended
     with *note register_error(): 43e.

      -- Method: write (object)

          Writes the object’s contents encoded to the stream.

      -- Method: writelines (list)

          Writes the concatenated list of strings to the stream
          (possibly by reusing the *note write(): a77. method).

      -- Method: reset ()

          Flushes and resets the codec buffers used for keeping state.

          Calling this method should ensure that the data on the output
          is put into a clean state that allows appending of new fresh
          data without having to rescan the whole stream to recover
          state.

  In addition to the above methods, the *note StreamWriter: a51. must
also inherit all other methods and attributes from the underlying
stream.


File: python.info,  Node: StreamReader Objects,  Next: StreamReaderWriter Objects,  Prev: StreamWriter Objects,  Up: Codec Base Classes

5.7.8.6 StreamReader Objects
............................

The *note StreamReader: a50. class is a subclass of ‘Codec’ and defines
the following methods which every stream reader must define in order to
be compatible with the Python codec registry.

 -- Class: codecs.StreamReader (stream[, errors])

     Constructor for a *note StreamReader: a50. instance.

     All stream readers must provide this constructor interface.  They
     are free to add additional keyword arguments, but only the ones
     defined here are used by the Python codec registry.

     _stream_ must be a file-like object open for reading (binary) data.

     The *note StreamReader: a50. may implement different error handling
     schemes by providing the _errors_ keyword argument.  These
     parameters are defined:

        * ‘'strict'’ Raise *note ValueError: 236. (or a subclass); this
          is the default.

        * ‘'ignore'’ Ignore the character and continue with the next.

        * ‘'replace'’ Replace with a suitable replacement character.

     The _errors_ argument will be assigned to an attribute of the same
     name.  Assigning to this attribute makes it possible to switch
     between different error handling strategies during the lifetime of
     the *note StreamReader: a50. object.

     The set of allowed values for the _errors_ argument can be extended
     with *note register_error(): 43e.

      -- Method: read ([size[, chars[, firstline]]])

          Decodes data from the stream and returns the resulting object.

          _chars_ indicates the number of characters to read from the
          stream.  *note read(): a7c. will never return more than
          _chars_ characters, but it might return less, if there are not
          enough characters available.

          _size_ indicates the approximate maximum number of bytes to
          read from the stream for decoding purposes.  The decoder can
          modify this setting as appropriate.  The default value -1
          indicates to read and decode as much as possible.  _size_ is
          intended to prevent having to decode huge files in one step.

          _firstline_ indicates that it would be sufficient to only
          return the first line, if there are decoding errors on later
          lines.

          The method should use a greedy read strategy meaning that it
          should read as much data as is allowed within the definition
          of the encoding and the given size, e.g.  if optional encoding
          endings or state markers are available on the stream, these
          should be read too.

          Changed in version 2.4: _chars_ argument added.

          Changed in version 2.4.2: _firstline_ argument added.

      -- Method: readline ([size[, keepends]])

          Read one line from the input stream and return the decoded
          data.

          _size_, if given, is passed as size argument to the stream’s
          *note read(): a7c. method.

          If _keepends_ is false line-endings will be stripped from the
          lines returned.

          Changed in version 2.4: _keepends_ argument added.

      -- Method: readlines ([sizehint[, keepends]])

          Read all lines available on the input stream and return them
          as a list of lines.

          Line-endings are implemented using the codec’s decoder method
          and are included in the list entries if _keepends_ is true.

          _sizehint_, if given, is passed as the _size_ argument to the
          stream’s *note read(): a7c. method.

      -- Method: reset ()

          Resets the codec buffers used for keeping state.

          Note that no stream repositioning should take place.  This
          method is primarily intended to be able to recover from
          decoding errors.

  In addition to the above methods, the *note StreamReader: a50. must
also inherit all other methods and attributes from the underlying
stream.

  The next two base classes are included for convenience.  They are not
needed by the codec registry, but may provide useful in practice.


File: python.info,  Node: StreamReaderWriter Objects,  Next: StreamRecoder Objects,  Prev: StreamReader Objects,  Up: Codec Base Classes

5.7.8.7 StreamReaderWriter Objects
..................................

The *note StreamReaderWriter: a82. allows wrapping streams which work in
both read and write modes.

  The design is such that one can use the factory functions returned by
the *note lookup(): 94b. function to construct the instance.

 -- Class: codecs.StreamReaderWriter (stream, Reader, Writer, errors)

     Creates a *note StreamReaderWriter: a82. instance.  _stream_ must
     be a file-like object.  _Reader_ and _Writer_ must be factory
     functions or classes providing the *note StreamReader: a50. and
     *note StreamWriter: a51. interface resp.  Error handling is done in
     the same way as defined for the stream readers and writers.

  *note StreamReaderWriter: a82. instances define the combined
interfaces of *note StreamReader: a50. and *note StreamWriter: a51.
classes.  They inherit all other methods and attributes from the
underlying stream.


File: python.info,  Node: StreamRecoder Objects,  Prev: StreamReaderWriter Objects,  Up: Codec Base Classes

5.7.8.8 StreamRecoder Objects
.............................

The *note StreamRecoder: a85. provide a frontend - backend view of
encoding data which is sometimes useful when dealing with different
encoding environments.

  The design is such that one can use the factory functions returned by
the *note lookup(): 94b. function to construct the instance.

 -- Class: codecs.StreamRecoder (stream, encode, decode, Reader, Writer,
          errors)

     Creates a *note StreamRecoder: a85. instance which implements a
     two-way conversion: _encode_ and _decode_ work on the frontend (the
     input to ‘read()’ and output of ‘write()’) while _Reader_ and
     _Writer_ work on the backend (reading and writing to the stream).

     You can use these objects to do transparent direct recodings from
     e.g.  Latin-1 to UTF-8 and back.

     _stream_ must be a file-like object.

     _encode_, _decode_ must adhere to the ‘Codec’ interface.  _Reader_,
     _Writer_ must be factory functions or classes providing objects of
     the *note StreamReader: a50. and *note StreamWriter: a51. interface
     respectively.

     _encode_ and _decode_ are needed for the frontend translation,
     _Reader_ and _Writer_ for the backend translation.  The
     intermediate format used is determined by the two sets of codecs,
     e.g.  the Unicode codecs will use Unicode as the intermediate
     encoding.

     Error handling is done in the same way as defined for the stream
     readers and writers.

  *note StreamRecoder: a85. instances define the combined interfaces of
*note StreamReader: a50. and *note StreamWriter: a51. classes.  They
inherit all other methods and attributes from the underlying stream.


File: python.info,  Node: Encodings and Unicode,  Next: Standard Encodings,  Prev: Codec Base Classes,  Up: codecs --- Codec registry and base classes

5.7.8.9 Encodings and Unicode
.............................

Unicode strings are stored internally as sequences of codepoints (to be
precise as *note Py_UNICODE: a88. arrays).  Depending on the way Python
is compiled (either via ‘--enable-unicode=ucs2’ or
‘--enable-unicode=ucs4’, with the former being the default) *note
Py_UNICODE: a88. is either a 16-bit or 32-bit data type.  Once a Unicode
object is used outside of CPU and memory, CPU endianness and how these
arrays are stored as bytes become an issue.  Transforming a unicode
object into a sequence of bytes is called encoding and recreating the
unicode object from the sequence of bytes is known as decoding.  There
are many different methods for how this transformation can be done
(these methods are also called encodings).  The simplest method is to
map the codepoints 0-255 to the bytes ‘0x0’-‘0xff’.  This means that a
unicode object that contains codepoints above ‘U+00FF’ can’t be encoded
with this method (which is called ‘'latin-1'’ or ‘'iso-8859-1'’).
‘unicode.encode()’ will raise a *note UnicodeEncodeError: 957. that
looks like this: ‘UnicodeEncodeError: 'latin-1' codec can't encode
character u'\u1234' in position 3: ordinal not in range(256)’.

  There’s another group of encodings (the so called charmap encodings)
that choose a different subset of all unicode code points and how these
codepoints are mapped to the bytes ‘0x0’-‘0xff’.  To see how this is
done simply open e.g.  ‘encodings/cp1252.py’ (which is an encoding that
is used primarily on Windows).  There’s a string constant with 256
characters that shows you which character is mapped to which byte value.

  All of these encodings can only encode 256 of the 1114112 codepoints
defined in unicode.  A simple and straightforward way that can store
each Unicode code point, is to store each codepoint as four consecutive
bytes.  There are two possibilities: store the bytes in big endian or in
little endian order.  These two encodings are called ‘UTF-32-BE’ and
‘UTF-32-LE’ respectively.  Their disadvantage is that if e.g.  you use
‘UTF-32-BE’ on a little endian machine you will always have to swap
bytes on encoding and decoding.  ‘UTF-32’ avoids this problem: bytes
will always be in natural endianness.  When these bytes are read by a
CPU with a different endianness, then bytes have to be swapped though.
To be able to detect the endianness of a ‘UTF-16’ or ‘UTF-32’ byte
sequence, there’s the so called BOM ("Byte Order Mark").  This is the
Unicode character ‘U+FEFF’.  This character can be prepended to every
‘UTF-16’ or ‘UTF-32’ byte sequence.  The byte swapped version of this
character (‘0xFFFE’) is an illegal character that may not appear in a
Unicode text.  So when the first character in an ‘UTF-16’ or ‘UTF-32’
byte sequence appears to be a ‘U+FFFE’ the bytes have to be swapped on
decoding.  Unfortunately the character ‘U+FEFF’ had a second purpose as
a ‘ZERO WIDTH NO-BREAK SPACE’: a character that has no width and doesn’t
allow a word to be split.  It can e.g.  be used to give hints to a
ligature algorithm.  With Unicode 4.0 using ‘U+FEFF’ as a ‘ZERO WIDTH
NO-BREAK SPACE’ has been deprecated (with ‘U+2060’ (‘WORD JOINER’)
assuming this role).  Nevertheless Unicode software still must be able
to handle ‘U+FEFF’ in both roles: as a BOM it’s a device to determine
the storage layout of the encoded bytes, and vanishes once the byte
sequence has been decoded into a Unicode string; as a ‘ZERO WIDTH
NO-BREAK SPACE’ it’s a normal character that will be decoded like any
other.

  There’s another encoding that is able to encoding the full range of
Unicode characters: UTF-8.  UTF-8 is an 8-bit encoding, which means
there are no issues with byte order in UTF-8.  Each byte in a UTF-8 byte
sequence consists of two parts: marker bits (the most significant bits)
and payload bits.  The marker bits are a sequence of zero to four ‘1’
bits followed by a ‘0’ bit.  Unicode characters are encoded like this
(with x being payload bits, which when concatenated give the Unicode
character):

Range                                   Encoding
                                        
-------------------------------------------------------------------------------------------
                                        
‘U-00000000’ ...  ‘U-0000007F’          0xxxxxxx
                                        
                                        
‘U-00000080’ ...  ‘U-000007FF’          110xxxxx 10xxxxxx
                                        
                                        
‘U-00000800’ ...  ‘U-0000FFFF’          1110xxxx 10xxxxxx 10xxxxxx
                                        
                                        
‘U-00010000’ ...  ‘U-0010FFFF’          11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
                                        

  The least significant bit of the Unicode character is the rightmost x
bit.

  As UTF-8 is an 8-bit encoding no BOM is required and any ‘U+FEFF’
character in the decoded Unicode string (even if it’s the first
character) is treated as a ‘ZERO WIDTH NO-BREAK SPACE’.

  Without external information it’s impossible to reliably determine
which encoding was used for encoding a Unicode string.  Each charmap
encoding can decode any random byte sequence.  However that’s not
possible with UTF-8, as UTF-8 byte sequences have a structure that
doesn’t allow arbitrary byte sequences.  To increase the reliability
with which a UTF-8 encoding can be detected, Microsoft invented a
variant of UTF-8 (that Python 2.5 calls ‘"utf-8-sig"’) for its Notepad
program: Before any of the Unicode characters is written to the file, a
UTF-8 encoded BOM (which looks like this as a byte sequence: ‘0xef’,
‘0xbb’, ‘0xbf’) is written.  As it’s rather improbable that any charmap
encoded file starts with these byte values (which would e.g.  map to

          LATIN SMALL LETTER I WITH DIAERESIS 
          RIGHT-POINTING DOUBLE ANGLE QUOTATION MARK 
          INVERTED QUESTION MARK 

  in iso-8859-1), this increases the probability that a ‘utf-8-sig’
encoding can be correctly guessed from the byte sequence.  So here the
BOM is not used to be able to determine the byte order used for
generating the byte sequence, but as a signature that helps in guessing
the encoding.  On encoding the utf-8-sig codec will write ‘0xef’,
‘0xbb’, ‘0xbf’ as the first three bytes to the file.  On decoding
‘utf-8-sig’ will skip those three bytes if they appear as the first
three bytes in the file.  In UTF-8, the use of the BOM is discouraged
and should generally be avoided.


File: python.info,  Node: Standard Encodings,  Next: Python Specific Encodings,  Prev: Encodings and Unicode,  Up: codecs --- Codec registry and base classes

5.7.8.10 Standard Encodings
...........................

Python comes with a number of codecs built-in, either implemented as C
functions or with dictionaries as mapping tables.  The following table
lists the codecs by name, together with a few common aliases, and the
languages for which the encoding is likely used.  Neither the list of
aliases nor the list of languages is meant to be exhaustive.  Notice
that spelling alternatives that only differ in case or use a hyphen
instead of an underscore are also valid aliases; therefore, e.g.
‘'utf-8'’ is a valid alias for the ‘'utf_8'’ codec.

  Many of the character sets support the same languages.  They vary in
individual characters (e.g.  whether the EURO SIGN is supported or not),
and in the assignment of characters to code positions.  For the European
languages in particular, the following variants typically exist:

   * an ISO 8859 codeset

   * a Microsoft Windows code page, which is typically derived from a
     8859 codeset, but replaces control characters with additional
     graphic characters

   * an IBM EBCDIC code page

   * an IBM PC code page, which is ASCII compatible

Codec                 Aliases                              Languages
                                                           
------------------------------------------------------------------------------------------------
                                                           
ascii                 646, us-ascii                        English
                                                           
                                                           
big5                  big5-tw, csbig5                      Traditional Chinese
                                                           
                                                           
big5hkscs             big5-hkscs, hkscs                    Traditional Chinese
                                                           
                                                           
cp037                 IBM037, IBM039                       English
                                                           
                                                           
cp424                 EBCDIC-CP-HE, IBM424                 Hebrew
                                                           
                                                           
cp437                 437, IBM437                          English
                                                           
                                                           
cp500                 EBCDIC-CP-BE, EBCDIC-CP-CH, IBM500   Western Europe
                                                           
                                                           
cp720                                                      Arabic
                                                           
                                                           
cp737                                                      Greek
                                                           
                                                           
cp775                 IBM775                               Baltic languages
                                                           
                                                           
cp850                 850, IBM850                          Western Europe
                                                           
                                                           
cp852                 852, IBM852                          Central and Eastern Europe
                                                           
                                                           
cp855                 855, IBM855                          Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
cp856                                                      Hebrew
                                                           
                                                           
cp857                 857, IBM857                          Turkish
                                                           
                                                           
cp858                 858, IBM858                          Western Europe
                                                           
                                                           
cp860                 860, IBM860                          Portuguese
                                                           
                                                           
cp861                 861, CP-IS, IBM861                   Icelandic
                                                           
                                                           
cp862                 862, IBM862                          Hebrew
                                                           
                                                           
cp863                 863, IBM863                          Canadian
                                                           
                                                           
cp864                 IBM864                               Arabic
                                                           
                                                           
cp865                 865, IBM865                          Danish, Norwegian
                                                           
                                                           
cp866                 866, IBM866                          Russian
                                                           
                                                           
cp869                 869, CP-GR, IBM869                   Greek
                                                           
                                                           
cp874                                                      Thai
                                                           
                                                           
cp875                                                      Greek
                                                           
                                                           
cp932                 932, ms932, mskanji, ms-kanji        Japanese
                                                           
                                                           
cp949                 949, ms949, uhc                      Korean
                                                           
                                                           
cp950                 950, ms950                           Traditional Chinese
                                                           
                                                           
cp1006                                                     Urdu
                                                           
                                                           
cp1026                ibm1026                              Turkish
                                                           
                                                           
cp1140                ibm1140                              Western Europe
                                                           
                                                           
cp1250                windows-1250                         Central and Eastern Europe
                                                           
                                                           
cp1251                windows-1251                         Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
cp1252                windows-1252                         Western Europe
                                                           
                                                           
cp1253                windows-1253                         Greek
                                                           
                                                           
cp1254                windows-1254                         Turkish
                                                           
                                                           
cp1255                windows-1255                         Hebrew
                                                           
                                                           
cp1256                windows-1256                         Arabic
                                                           
                                                           
cp1257                windows-1257                         Baltic languages
                                                           
                                                           
cp1258                windows-1258                         Vietnamese
                                                           
                                                           
euc_jp                eucjp, ujis, u-jis                   Japanese
                                                           
                                                           
euc_jis_2004          jisx0213, eucjis2004                 Japanese
                                                           
                                                           
euc_jisx0213          eucjisx0213                          Japanese
                                                           
                                                           
euc_kr                euckr, korean, ksc5601, ks_c-5601,   Korean
                      ks_c-5601-1987, ksx1001, ks_x-1001   
                      
                                                           
gb2312                chinese, csiso58gb231280, euc- cn,   Simplified Chinese
                      euccn, eucgb2312-cn, gb2312-1980,    
                      gb2312-80, iso- ir-58
                      
                                                           
gbk                   936, cp936, ms936                    Unified Chinese
                                                           
                                                           
gb18030               gb18030-2000                         Unified Chinese
                                                           
                                                           
hz                    hzgb, hz-gb, hz-gb-2312              Simplified Chinese
                                                           
                                                           
iso2022_jp            csiso2022jp, iso2022jp,              Japanese
                      iso-2022-jp                          
                      
                                                           
iso2022_jp_1          iso2022jp-1, iso-2022-jp-1           Japanese
                                                           
                                                           
iso2022_jp_2          iso2022jp-2, iso-2022-jp-2           Japanese, Korean, Simplified
                                                           Chinese, Western Europe, Greek
                                                           
                                                           
iso2022_jp_2004       iso2022jp-2004, iso-2022-jp-2004     Japanese
                                                           
                                                           
iso2022_jp_3          iso2022jp-3, iso-2022-jp-3           Japanese
                                                           
                                                           
iso2022_jp_ext        iso2022jp-ext, iso-2022-jp-ext       Japanese
                                                           
                                                           
iso2022_kr            csiso2022kr, iso2022kr,              Korean
                      iso-2022-kr                          
                      
                                                           
latin_1               iso-8859-1, iso8859-1, 8859,         West Europe
                      cp819, latin, latin1, L1             
                      
                                                           
iso8859_2             iso-8859-2, latin2, L2               Central and Eastern Europe
                                                           
                                                           
iso8859_3             iso-8859-3, latin3, L3               Esperanto, Maltese
                                                           
                                                           
iso8859_4             iso-8859-4, latin4, L4               Baltic languages
                                                           
                                                           
iso8859_5             iso-8859-5, cyrillic                 Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
iso8859_6             iso-8859-6, arabic                   Arabic
                                                           
                                                           
iso8859_7             iso-8859-7, greek, greek8            Greek
                                                           
                                                           
iso8859_8             iso-8859-8, hebrew                   Hebrew
                                                           
                                                           
iso8859_9             iso-8859-9, latin5, L5               Turkish
                                                           
                                                           
iso8859_10            iso-8859-10, latin6, L6              Nordic languages
                                                           
                                                           
iso8859_13            iso-8859-13, latin7, L7              Baltic languages
                                                           
                                                           
iso8859_14            iso-8859-14, latin8, L8              Celtic languages
                                                           
                                                           
iso8859_15            iso-8859-15, latin9, L9              Western Europe
                                                           
                                                           
iso8859_16            iso-8859-16, latin10, L10            South-Eastern Europe
                                                           
                                                           
johab                 cp1361, ms1361                       Korean
                                                           
                                                           
koi8_r                                                     Russian
                                                           
                                                           
koi8_u                                                     Ukrainian
                                                           
                                                           
mac_cyrillic          maccyrillic                          Bulgarian, Byelorussian,
                                                           Macedonian, Russian, Serbian
                                                           
                                                           
mac_greek             macgreek                             Greek
                                                           
                                                           
mac_iceland           maciceland                           Icelandic
                                                           
                                                           
mac_latin2            maclatin2, maccentraleurope          Central and Eastern Europe
                                                           
                                                           
mac_roman             macroman                             Western Europe
                                                           
                                                           
mac_turkish           macturkish                           Turkish
                                                           
                                                           
ptcp154               csptcp154, pt154, cp154,             Kazakh
                      cyrillic-asian                       
                      
                                                           
shift_jis             csshiftjis, shiftjis, sjis, s_jis    Japanese
                                                           
                                                           
shift_jis_2004        shiftjis2004, sjis_2004, sjis2004    Japanese
                                                           
                                                           
shift_jisx0213        shiftjisx0213, sjisx0213,            Japanese
                      s_jisx0213                           
                      
                                                           
utf_32                U32, utf32                           all languages
                                                           
                                                           
utf_32_be             UTF-32BE                             all languages
                                                           
                                                           
utf_32_le             UTF-32LE                             all languages
                                                           
                                                           
utf_16                U16, utf16                           all languages
                                                           
                                                           
utf_16_be             UTF-16BE                             all languages (BMP only)
                                                           
                                                           
utf_16_le             UTF-16LE                             all languages (BMP only)
                                                           
                                                           
utf_7                 U7, unicode-1-1-utf-7                all languages
                                                           
                                                           
utf_8                 U8, UTF, utf8                        all languages
                                                           
                                                           
utf_8_sig                                                  all languages
                                                           


File: python.info,  Node: Python Specific Encodings,  Next: encodings idna --- Internationalized Domain Names in Applications,  Prev: Standard Encodings,  Up: codecs --- Codec registry and base classes

5.7.8.11 Python Specific Encodings
..................................

A number of predefined codecs are specific to Python, so their codec
names have no meaning outside Python.  These are listed in the tables
below based on the expected input and output types (note that while text
encodings are the most common use case for codecs, the underlying codec
infrastructure supports arbitrary data transforms rather than just text
encodings).  For asymmetric codecs, the stated purpose describes the
encoding direction.

  The following codecs provide unicode-to-str encoding (1) and
str-to-unicode decoding (2), similar to the Unicode text encodings.

Codec                    Aliases                         Purpose
                                                         
-----------------------------------------------------------------------------------------
                                                         
idna                                                     Implements RFC 3490(3), see
                                                         also *note encodings.idna:
                                                         c6.
                                                         
                                                         
mbcs                     dbcs                            Windows only: Encode operand
                                                         according to the ANSI
                                                         codepage (CP_ACP)
                                                         
                                                         
palmos                                                   Encoding of PalmOS 3.5
                                                         
                                                         
punycode                                                 Implements RFC 3492(4)
                                                         
                                                         
raw_unicode_escape                                       Produce a string that is
                                                         suitable as raw Unicode
                                                         literal in Python source code
                                                         
                                                         
rot_13                   rot13                           Returns the Caesar-cypher
                                                         encryption of the operand
                                                         
                                                         
undefined                                                Raise an exception for all
                                                         conversions.  Can be used as
                                                         the system encoding if no
                                                         automatic *note coercion:
                                                         a8b. between byte and Unicode
                                                         strings is desired.
                                                         
                                                         
unicode_escape                                           Produce a string that is
                                                         suitable as Unicode literal
                                                         in Python source code
                                                         
                                                         
unicode_internal                                         Return the internal
                                                         representation of the operand
                                                         

  New in version 2.3: The ‘idna’ and ‘punycode’ encodings.

  The following codecs provide str-to-str encoding and decoding (5).

Codec                    Aliases                         Purpose                         Encoder/decoder
                                                                                         
----------------------------------------------------------------------------------------------------------------------------
                                                                                         
base64_codec             base64, base-64                 Convert operand to MIME         *note base64.b64encode(): a8c,
                                                         base64 (the result always       *note base64.b64decode(): a8d.
                                                         includes a trailing ‘'\n'’)     
                                                         
                                                                                         
bz2_codec                bz2                             Compress the operand using      *note bz2.compress(): a8e, *note
                                                         bz2                             bz2.decompress(): a8f.
                                                                                         
                                                                                         
hex_codec                hex                             Convert operand to              *note base64.b16encode(): a90,
                                                         hexadecimal representation,     *note base64.b16decode(): a91.
                                                         with two digits per byte        
                                                         
                                                                                         
quopri_codec             quopri, quoted-printable,       Convert operand to MIME         *note quopri.encodestring():
                         quotedprintable                 quoted printable                a92, *note
                                                                                         quopri.decodestring(): a93.
                                                                                         
                                                                                         
string_escape                                            Produce a string that is
                                                         suitable as string literal in
                                                         Python source code
                                                         
                                                                                         
uu_codec                 uu                              Convert the operand using       *note uu.encode(): a94, *note
                                                         uuencode                        uu.decode(): a95.
                                                                                         
                                                                                         
zlib_codec               zip, zlib                       Compress the operand using      *note zlib.compress(): a96,
                                                         gzip                            *note zlib.decompress(): a97.
                                                                                         

   ---------- Footnotes ----------

   (1) str objects are also accepted as input in place of unicode
objects.  They are implicitly converted to unicode by decoding them
using the default encoding.  If this conversion fails, it may lead to
encoding operations raising *note UnicodeDecodeError: 958.

   (2) unicode objects are also accepted as input in place of str
objects.  They are implicitly converted to str by encoding them using
the default encoding.  If this conversion fails, it may lead to decoding
operations raising *note UnicodeEncodeError: 957.

   (3) http://tools.ietf.org/html/rfc3490.html

   (4) http://tools.ietf.org/html/rfc3492.html

   (5) unicode objects are also accepted as input in place of str
objects.  They are implicitly converted to str by encoding them using
the default encoding.  If this conversion fails, it may lead to decoding
operations raising *note UnicodeEncodeError: 957.


File: python.info,  Node: encodings idna --- Internationalized Domain Names in Applications,  Next: encodings utf_8_sig --- UTF-8 codec with BOM signature,  Prev: Python Specific Encodings,  Up: codecs --- Codec registry and base classes

5.7.8.12 ‘encodings.idna’ — Internationalized Domain Names in Applications
..........................................................................

New in version 2.3.

  This module implements RFC 3490(1) (Internationalized Domain Names in
Applications) and RFC 3492(2) (Nameprep: A Stringprep Profile for
Internationalized Domain Names (IDN)). It builds upon the ‘punycode’
encoding and *note stringprep: 165.

  These RFCs together define a protocol to support non-ASCII characters
in domain names.  A domain name containing non-ASCII characters (such as
‘www.Alliancefrançaise.nu’) is converted into an ASCII-compatible
encoding (ACE, such as ‘www.xn--alliancefranaise-npb.nu’).  The ACE form
of the domain name is then used in all places where arbitrary characters
are not allowed by the protocol, such as DNS queries, HTTP ‘Host’
fields, and so on.  This conversion is carried out in the application;
if possible invisible to the user: The application should transparently
convert Unicode domain labels to IDNA on the wire, and convert back ACE
labels to Unicode before presenting them to the user.

  Python supports this conversion in several ways: the ‘idna’ codec
performs conversion between Unicode and ACE, separating an input string
into labels based on the separator characters defined in section 3.1(3)
(1) of RFC 3490(4) and converting each label to ACE as required, and
conversely separating an input byte string into labels based on the ‘.’
separator and converting any ACE labels found into unicode.
Furthermore, the *note socket: 15c. module transparently converts
Unicode host names to ACE, so that applications need not be concerned
about converting host names themselves when they pass them to the socket
module.  On top of that, modules that have host names as function
parameters, such as *note httplib: ee. and *note ftplib: d8, accept
Unicode host names (*note httplib: ee. then also transparently sends an
IDNA hostname in the ‘Host’ field if it sends that field at all).

  When receiving host names from the wire (such as in reverse name
lookup), no automatic conversion to Unicode is performed: Applications
wishing to present such host names to the user should decode them to
Unicode.

  The module *note encodings.idna: c6. also implements the nameprep
procedure, which performs certain normalizations on host names, to
achieve case-insensitivity of international domain names, and to unify
similar characters.  The nameprep functions can be used directly if
desired.

 -- Function: encodings.idna.nameprep (label)

     Return the nameprepped version of _label_.  The implementation
     currently assumes query strings, so ‘AllowUnassigned’ is true.

 -- Function: encodings.idna.ToASCII (label)

     Convert a label to ASCII, as specified in RFC 3490(5).
     ‘UseSTD3ASCIIRules’ is assumed to be false.

 -- Function: encodings.idna.ToUnicode (label)

     Convert a label to Unicode, as specified in RFC 3490(6).

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc3490.html

   (2) http://tools.ietf.org/html/rfc3492.html

   (3) http://tools.ietf.org/html/rfc3490#section-3.1

   (4) http://tools.ietf.org/html/rfc3490.html

   (5) http://tools.ietf.org/html/rfc3490.html

   (6) http://tools.ietf.org/html/rfc3490.html


File: python.info,  Node: encodings utf_8_sig --- UTF-8 codec with BOM signature,  Prev: encodings idna --- Internationalized Domain Names in Applications,  Up: codecs --- Codec registry and base classes

5.7.8.13 ‘encodings.utf_8_sig’ — UTF-8 codec with BOM signature
...............................................................

New in version 2.5.

  This module implements a variant of the UTF-8 codec: On encoding a
UTF-8 encoded BOM will be prepended to the UTF-8 encoded bytes.  For the
stateful encoder this is only done once (on the first write to the byte
stream).  For decoding an optional UTF-8 encoded BOM at the start of the
data will be skipped.


File: python.info,  Node: unicodedata --- Unicode Database,  Next: stringprep --- Internet String Preparation,  Prev: codecs --- Codec registry and base classes,  Up: String Services

5.7.9 ‘unicodedata’ — Unicode Database
--------------------------------------

This module provides access to the Unicode Character Database which
defines character properties for all Unicode characters.  The data in
this database is based on the ‘UnicodeData.txt’ file version 5.2.0 which
is publicly available from ‘ftp://ftp.unicode.org/’.

  The module uses the same names and symbols as defined by the
UnicodeData File Format 5.2.0 (see
‘http://www.unicode.org/reports/tr44/tr44-4.html’).  It defines the
following functions:

 -- Function: unicodedata.lookup (name)

     Look up character by name.  If a character with the given name is
     found, return the corresponding Unicode character.  If not found,
     *note KeyError: 205. is raised.

 -- Function: unicodedata.name (unichr[, default])

     Returns the name assigned to the Unicode character _unichr_ as a
     string.  If no name is defined, _default_ is returned, or, if not
     given, *note ValueError: 236. is raised.

 -- Function: unicodedata.decimal (unichr[, default])

     Returns the decimal value assigned to the Unicode character
     _unichr_ as integer.  If no such value is defined, _default_ is
     returned, or, if not given, *note ValueError: 236. is raised.

 -- Function: unicodedata.digit (unichr[, default])

     Returns the digit value assigned to the Unicode character _unichr_
     as integer.  If no such value is defined, _default_ is returned,
     or, if not given, *note ValueError: 236. is raised.

 -- Function: unicodedata.numeric (unichr[, default])

     Returns the numeric value assigned to the Unicode character
     _unichr_ as float.  If no such value is defined, _default_ is
     returned, or, if not given, *note ValueError: 236. is raised.

 -- Function: unicodedata.category (unichr)

     Returns the general category assigned to the Unicode character
     _unichr_ as string.

 -- Function: unicodedata.bidirectional (unichr)

     Returns the bidirectional class assigned to the Unicode character
     _unichr_ as string.  If no such value is defined, an empty string
     is returned.

 -- Function: unicodedata.combining (unichr)

     Returns the canonical combining class assigned to the Unicode
     character _unichr_ as integer.  Returns ‘0’ if no combining class
     is defined.

 -- Function: unicodedata.east_asian_width (unichr)

     Returns the east asian width assigned to the Unicode character
     _unichr_ as string.

     New in version 2.4.

 -- Function: unicodedata.mirrored (unichr)

     Returns the mirrored property assigned to the Unicode character
     _unichr_ as integer.  Returns ‘1’ if the character has been
     identified as a "mirrored" character in bidirectional text, ‘0’
     otherwise.

 -- Function: unicodedata.decomposition (unichr)

     Returns the character decomposition mapping assigned to the Unicode
     character _unichr_ as string.  An empty string is returned in case
     no such mapping is defined.

 -- Function: unicodedata.normalize (form, unistr)

     Return the normal form _form_ for the Unicode string _unistr_.
     Valid values for _form_ are ’NFC’, ’NFKC’, ’NFD’, and ’NFKD’.

     The Unicode standard defines various normalization forms of a
     Unicode string, based on the definition of canonical equivalence
     and compatibility equivalence.  In Unicode, several characters can
     be expressed in various way.  For example, the character U+00C7
     (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as the
     sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING
     CEDILLA).

     For each character, there are two normal forms: normal form C and
     normal form D. Normal form D (NFD) is also known as canonical
     decomposition, and translates each character into its decomposed
     form.  Normal form C (NFC) first applies a canonical decomposition,
     then composes pre-combined characters again.

     In addition to these two forms, there are two additional normal
     forms based on compatibility equivalence.  In Unicode, certain
     characters are supported which normally would be unified with other
     characters.  For example, U+2160 (ROMAN NUMERAL ONE) is really the
     same thing as U+0049 (LATIN CAPITAL LETTER I). However, it is
     supported in Unicode for compatibility with existing character sets
     (e.g.  gb2312).

     The normal form KD (NFKD) will apply the compatibility
     decomposition, i.e.  replace all compatibility characters with
     their equivalents.  The normal form KC (NFKC) first applies the
     compatibility decomposition, followed by the canonical composition.

     Even if two unicode strings are normalized and look the same to a
     human reader, if one has combining characters and the other
     doesn’t, they may not compare equal.

     New in version 2.3.

  In addition, the module exposes the following constant:

 -- Data: unicodedata.unidata_version

     The version of the Unicode database used in this module.

     New in version 2.3.

 -- Data: unicodedata.ucd_3_2_0

     This is an object that has the same methods as the entire module,
     but uses the Unicode database version 3.2 instead, for applications
     that require this specific version of the Unicode database (such as
     IDNA).

     New in version 2.5.

  Examples:

     >>> import unicodedata
     >>> unicodedata.lookup('LEFT CURLY BRACKET')
     u'{'
     >>> unicodedata.name(u'/')
     'SOLIDUS'
     >>> unicodedata.decimal(u'9')
     9
     >>> unicodedata.decimal(u'a')
     Traceback (most recent call last):
       File "<stdin>", line 1, in ?
     ValueError: not a decimal
     >>> unicodedata.category(u'A')  # 'L'etter, 'u'ppercase
     'Lu'
     >>> unicodedata.bidirectional(u'\u0660') # 'A'rabic, 'N'umber
     'AN'


File: python.info,  Node: stringprep --- Internet String Preparation,  Next: fpformat --- Floating point conversions,  Prev: unicodedata --- Unicode Database,  Up: String Services

5.7.10 ‘stringprep’ — Internet String Preparation
-------------------------------------------------

New in version 2.3.

  When identifying things (such as host names) in the internet, it is
often necessary to compare such identifications for "equality".  Exactly
how this comparison is executed may depend on the application domain,
e.g.  whether it should be case-insensitive or not.  It may be also
necessary to restrict the possible identifications, to allow only
identifications consisting of "printable" characters.

  RFC 3454(1) defines a procedure for "preparing" Unicode strings in
internet protocols.  Before passing strings onto the wire, they are
processed with the preparation procedure, after which they have a
certain normalized form.  The RFC defines a set of tables, which can be
combined into profiles.  Each profile must define which tables it uses,
and what other optional parts of the ‘stringprep’ procedure are part of
the profile.  One example of a ‘stringprep’ profile is ‘nameprep’, which
is used for internationalized domain names.

  The module *note stringprep: 165. only exposes the tables from RFC
3454.  As these tables would be very large to represent them as
dictionaries or lists, the module uses the Unicode character database
internally.  The module source code itself was generated using the
‘mkstringprep.py’ utility.

  As a result, these tables are exposed as functions, not as data
structures.  There are two kinds of tables in the RFC: sets and
mappings.  For a set, *note stringprep: 165. provides the
"characteristic function", i.e.  a function that returns true if the
parameter is part of the set.  For mappings, it provides the mapping
function: given the key, it returns the associated value.  Below is a
list of all functions available in the module.

 -- Function: stringprep.in_table_a1 (code)

     Determine whether _code_ is in tableA.1 (Unassigned code points in
     Unicode 3.2).

 -- Function: stringprep.in_table_b1 (code)

     Determine whether _code_ is in tableB.1 (Commonly mapped to
     nothing).

 -- Function: stringprep.map_table_b2 (code)

     Return the mapped value for _code_ according to tableB.2 (Mapping
     for case-folding used with NFKC).

 -- Function: stringprep.map_table_b3 (code)

     Return the mapped value for _code_ according to tableB.3 (Mapping
     for case-folding used with no normalization).

 -- Function: stringprep.in_table_c11 (code)

     Determine whether _code_ is in tableC.1.1 (ASCII space characters).

 -- Function: stringprep.in_table_c12 (code)

     Determine whether _code_ is in tableC.1.2 (Non-ASCII space
     characters).

 -- Function: stringprep.in_table_c11_c12 (code)

     Determine whether _code_ is in tableC.1 (Space characters, union of
     C.1.1 and C.1.2).

 -- Function: stringprep.in_table_c21 (code)

     Determine whether _code_ is in tableC.2.1 (ASCII control
     characters).

 -- Function: stringprep.in_table_c22 (code)

     Determine whether _code_ is in tableC.2.2 (Non-ASCII control
     characters).

 -- Function: stringprep.in_table_c21_c22 (code)

     Determine whether _code_ is in tableC.2 (Control characters, union
     of C.2.1 and C.2.2).

 -- Function: stringprep.in_table_c3 (code)

     Determine whether _code_ is in tableC.3 (Private use).

 -- Function: stringprep.in_table_c4 (code)

     Determine whether _code_ is in tableC.4 (Non-character code
     points).

 -- Function: stringprep.in_table_c5 (code)

     Determine whether _code_ is in tableC.5 (Surrogate codes).

 -- Function: stringprep.in_table_c6 (code)

     Determine whether _code_ is in tableC.6 (Inappropriate for plain
     text).

 -- Function: stringprep.in_table_c7 (code)

     Determine whether _code_ is in tableC.7 (Inappropriate for
     canonical representation).

 -- Function: stringprep.in_table_c8 (code)

     Determine whether _code_ is in tableC.8 (Change display properties
     or are deprecated).

 -- Function: stringprep.in_table_c9 (code)

     Determine whether _code_ is in tableC.9 (Tagging characters).

 -- Function: stringprep.in_table_d1 (code)

     Determine whether _code_ is in tableD.1 (Characters with
     bidirectional property "R" or "AL").

 -- Function: stringprep.in_table_d2 (code)

     Determine whether _code_ is in tableD.2 (Characters with
     bidirectional property "L").

   ---------- Footnotes ----------

   (1) http://tools.ietf.org/html/rfc3454.html


File: python.info,  Node: fpformat --- Floating point conversions,  Prev: stringprep --- Internet String Preparation,  Up: String Services

5.7.11 ‘fpformat’ — Floating point conversions
----------------------------------------------

Deprecated since version 2.6: The *note fpformat: d5. module has been
removed in Python 3.

  The *note fpformat: d5. module defines functions for dealing with
floating point numbers representations in 100% pure Python.

     Note: This module is unnecessary: everything here can be done using
     the ‘%’ string interpolation operator described in the *note String
     Formatting Operations: 524. section.

  The *note fpformat: d5. module defines the following functions and an
exception:

 -- Function: fpformat.fix (x, digs)

     Format _x_ as ‘[-]ddd.ddd’ with _digs_ digits after the point and
     at least one digit before.  If ‘digs <= 0’, the decimal point is
     suppressed.

     _x_ can be either a number or a string that looks like one.  _digs_
     is an integer.

     Return value is a string.

 -- Function: fpformat.sci (x, digs)

     Format _x_ as ‘[-]d.dddE[+-]ddd’ with _digs_ digits after the point
     and exactly one digit before.  If ‘digs <= 0’, one digit is kept
     and the point is suppressed.

     _x_ can be either a real number, or a string that looks like one.
     _digs_ is an integer.

     Return value is a string.

 -- Exception: fpformat.NotANumber

     Exception raised when a string passed to *note fix(): ac2. or *note
     sci(): ac3. as the _x_ parameter does not look like a number.  This
     is a subclass of *note ValueError: 236. when the standard
     exceptions are strings.  The exception value is the improperly
     formatted string that caused the exception to be raised.

  Example:

     >>> import fpformat
     >>> fpformat.fix(1.23, 1)
     '1.2'


File: python.info,  Node: Data Types,  Next: Numeric and Mathematical Modules,  Prev: String Services,  Up: The Python Standard Library

5.8 Data Types
==============

The modules described in this chapter provide a variety of specialized
data types such as dates and times, fixed-type arrays, heap queues,
synchronized queues, and sets.

  Python also provides some built-in data types, in particular, *note
dict: 305, *note list: 3bc, *note set: 36a. (which along with *note
frozenset: 36b, replaces the deprecated *note sets: 14f. module), and
*note tuple: 408.  The *note str: 1ea. class can be used to handle
binary data and 8-bit text, and the *note unicode: 1f5. class to handle
Unicode text.

  The following modules are documented in this chapter:

* Menu:

* datetime: datetime --- Basic date and time types. Basic date and time types
* calendar: calendar --- General calendar-related functions. General calendar-related functions
* collections: collections --- High-performance container datatypes. High-performance container datatypes
* heapq: heapq --- Heap queue algorithm. Heap queue algorithm
* bisect: bisect --- Array bisection algorithm. Array bisection algorithm
* array: array --- Efficient arrays of numeric values. Efficient arrays of numeric values
* sets: sets --- Unordered collections of unique elements. Unordered collections of unique elements
* sched: sched --- Event scheduler. Event scheduler
* mutex: mutex --- Mutual exclusion support. Mutual exclusion support
* Queue: Queue --- A synchronized queue class. A synchronized queue class
* weakref: weakref --- Weak references. Weak references
* UserDict: UserDict --- Class wrapper for dictionary objects. Class wrapper for dictionary objects
* UserList: UserList --- Class wrapper for list objects. Class wrapper for list objects
* UserString: UserString --- Class wrapper for string objects. Class wrapper for string objects
* types: types --- Names for built-in types. Names for built-in types
* new: new --- Creation of runtime internal objects. Creation of runtime internal objects
* copy: copy --- Shallow and deep copy operations. Shallow and deep copy operations
* pprint: pprint --- Data pretty printer. Data pretty printer
* repr: repr --- Alternate repr implementation. Alternate repr() implementation

datetime — Basic date and time types

* Available Types:: 
* timedelta Objects:: 
* date Objects:: 
* datetime Objects:: 
* time Objects:: 
* tzinfo Objects:: 
* strftime() and strptime() Behavior: strftime and strptime Behavior. 

collections — High-performance container datatypes

* Counter objects:: 
* deque objects:: 
* defaultdict objects:: 
* namedtuple() Factory Function for Tuples with Named Fields: namedtuple Factory Function for Tuples with Named Fields. 
* OrderedDict objects:: 
* Collections Abstract Base Classes:: 

deque objects

* deque Recipes:: 

defaultdict objects

* defaultdict Examples:: 

OrderedDict objects

* OrderedDict Examples and Recipes:: 

heapq — Heap queue algorithm

* Basic Examples:: 
* Priority Queue Implementation Notes:: 
* Theory:: 

bisect — Array bisection algorithm

* Searching Sorted Lists:: 
* Other Examples:: 

sets — Unordered collections of unique elements

* Set Objects:: 
* Example:: 
* Protocol for automatic conversion to immutable:: 
* Comparison to the built-in set types:: 

sched — Event scheduler

* Scheduler Objects:: 

mutex — Mutual exclusion support

* Mutex Objects:: 

Queue — A synchronized queue class

* Queue Objects:: 

weakref — Weak references

* Weak Reference Objects:: 
* Example: Example<2>. 

pprint — Data pretty printer

* PrettyPrinter Objects:: 
* pprint Example:: 

repr — Alternate repr() implementation

* Repr Objects:: 
* Subclassing Repr Objects:: 


File: python.info,  Node: datetime --- Basic date and time types,  Next: calendar --- General calendar-related functions,  Up: Data Types

5.8.1 ‘datetime’ — Basic date and time types
--------------------------------------------

New in version 2.3.

  The *note datetime: 7d. module supplies classes for manipulating dates
and times in both simple and complex ways.  While date and time
arithmetic is supported, the focus of the implementation is on efficient
attribute extraction for output formatting and manipulation.  For
related functionality, see also the *note time: 17a. and *note calendar:
1f. modules.

  There are two kinds of date and time objects: "naive" and "aware".

  An aware object has sufficient knowledge of applicable algorithmic and
political time adjustments, such as time zone and daylight saving time
information, to locate itself relative to other aware objects.  An aware
object is used to represent a specific moment in time that is not open
to interpretation (1).

  A naive object does not contain enough information to unambiguously
locate itself relative to other date/time objects.  Whether a naive
object represents Coordinated Universal Time (UTC), local time, or time
in some other timezone is purely up to the program, just like it’s up to
the program whether a particular number represents metres, miles, or
mass.  Naive objects are easy to understand and to work with, at the
cost of ignoring some aspects of reality.

  For applications requiring aware objects, *note datetime: 2da. and
*note time: 35e. objects have an optional time zone information
attribute, *note tzinfo: aca, that can be set to an instance of a
subclass of the abstract *note tzinfo: aca. class.  These *note tzinfo:
aca. objects capture information about the offset from UTC time, the
time zone name, and whether Daylight Saving Time is in effect.  Note
that no concrete *note tzinfo: aca. classes are supplied by the *note
datetime: 7d. module.  Supporting timezones at whatever level of detail
is required is up to the application.  The rules for time adjustment
across the world are more political than rational, and there is no
standard suitable for every application.

  The *note datetime: 7d. module exports the following constants:

 -- Data: datetime.MINYEAR

     The smallest year number allowed in a *note date: 35d. or *note
     datetime: 2da. object.  *note MINYEAR: acb. is ‘1’.

 -- Data: datetime.MAXYEAR

     The largest year number allowed in a *note date: 35d. or *note
     datetime: 2da. object.  *note MAXYEAR: acc. is ‘9999’.

See also
........

Module *note calendar: 1f.

     General calendar related functions.

Module *note time: 17a.

     Time access and conversions.

* Menu:

* Available Types:: 
* timedelta Objects:: 
* date Objects:: 
* datetime Objects:: 
* time Objects:: 
* tzinfo Objects:: 
* strftime() and strptime() Behavior: strftime and strptime Behavior. 

   ---------- Footnotes ----------

   (1) If, that is, we ignore the effects of Relativity


File: python.info,  Node: Available Types,  Next: timedelta Objects,  Up: datetime --- Basic date and time types

5.8.1.1 Available Types
.......................

 -- Class: datetime.date

     An idealized naive date, assuming the current Gregorian calendar
     always was, and always will be, in effect.  Attributes: ‘year’,
     ‘month’, and ‘day’.

 -- Class: datetime.time

     An idealized time, independent of any particular day, assuming that
     every day has exactly 24*60*60 seconds (there is no notion of "leap
     seconds" here).  Attributes: ‘hour’, ‘minute’, ‘second’,
     ‘microsecond’, and *note tzinfo: aca.

 -- Class: datetime.datetime

     A combination of a date and a time.  Attributes: ‘year’, ‘month’,
     ‘day’, ‘hour’, ‘minute’, ‘second’, ‘microsecond’, and *note tzinfo:
     aca.

 -- Class: datetime.timedelta

     A duration expressing the difference between two *note date: 35d,
     *note time: 35e, or *note datetime: 2da. instances to microsecond
     resolution.

 -- Class: datetime.tzinfo

     An abstract base class for time zone information objects.  These
     are used by the *note datetime: 2da. and *note time: 35e. classes
     to provide a customizable notion of time adjustment (for example,
     to account for time zone and/or daylight saving time).

  Objects of these types are immutable.

  Objects of the *note date: 35d. type are always naive.

  An object of type *note time: 35e. or *note datetime: 2da. may be
naive or aware.  A *note datetime: 2da. object _d_ is aware if
‘d.tzinfo’ is not ‘None’ and ‘d.tzinfo.utcoffset(d)’ does not return
‘None’.  If ‘d.tzinfo’ is ‘None’, or if ‘d.tzinfo’ is not ‘None’ but
‘d.tzinfo.utcoffset(d)’ returns ‘None’, _d_ is naive.  A *note time:
35e. object _t_ is aware if ‘t.tzinfo’ is not ‘None’ and
‘t.tzinfo.utcoffset(None)’ does not return ‘None’.  Otherwise, _t_ is
naive.

  The distinction between naive and aware doesn’t apply to *note
timedelta: 210. objects.

  Subclass relationships:

     object
         timedelta
         tzinfo
         time
         date
             datetime


File: python.info,  Node: timedelta Objects,  Next: date Objects,  Prev: Available Types,  Up: datetime --- Basic date and time types

5.8.1.2 ‘timedelta’ Objects
...........................

A *note timedelta: 210. object represents a duration, the difference
between two dates or times.

 -- Class: datetime.timedelta ([days[, seconds[, microseconds[,
          milliseconds[, minutes[, hours[, weeks]]]]]]])

     All arguments are optional and default to ‘0’.  Arguments may be
     ints, longs, or floats, and may be positive or negative.

     Only _days_, _seconds_ and _microseconds_ are stored internally.
     Arguments are converted to those units:

        * A millisecond is converted to 1000 microseconds.

        * A minute is converted to 60 seconds.

        * An hour is converted to 3600 seconds.

        * A week is converted to 7 days.

     and days, seconds and microseconds are then normalized so that the
     representation is unique, with

        * ‘0 <= microseconds < 1000000’

        * ‘0 <= seconds < 3600*24’ (the number of seconds in one day)

        * ‘-999999999 <= days <= 999999999’

     If any argument is a float and there are fractional microseconds,
     the fractional microseconds left over from all arguments are
     combined and their sum is rounded to the nearest microsecond.  If
     no argument is a float, the conversion and normalization processes
     are exact (no information is lost).

     If the normalized value of days lies outside the indicated range,
     *note OverflowError: 2db. is raised.

     Note that normalization of negative values may be surprising at
     first.  For example,

          >>> from datetime import timedelta
          >>> d = timedelta(microseconds=-1)
          >>> (d.days, d.seconds, d.microseconds)
          (-1, 86399, 999999)

  Class attributes are:

 -- Attribute: timedelta.min

     The most negative *note timedelta: 210. object,
     ‘timedelta(-999999999)’.

 -- Attribute: timedelta.max

     The most positive *note timedelta: 210. object,
     ‘timedelta(days=999999999, hours=23, minutes=59, seconds=59,
     microseconds=999999)’.

 -- Attribute: timedelta.resolution

     The smallest possible difference between non-equal *note timedelta:
     210. objects, ‘timedelta(microseconds=1)’.

  Note that, because of normalization, ‘timedelta.max’ >
‘-timedelta.min’.  ‘-timedelta.max’ is not representable as a *note
timedelta: 210. object.

  Instance attributes (read-only):

Attribute              Value
                       
------------------------------------------------------------------------
                       
‘days’                 Between -999999999 and 999999999 inclusive
                       
                       
‘seconds’              Between 0 and 86399 inclusive
                       
                       
‘microseconds’         Between 0 and 999999 inclusive
                       

  Supported operations:

Operation                            Result
                                     
-----------------------------------------------------------------------------------------
                                     
‘t1 = t2 + t3’                       Sum of _t2_ and _t3_.  Afterwards _t1_-_t2_ ==
                                     _t3_ and _t1_-_t3_ == _t2_ are true.  (1)
                                     
                                     
‘t1 = t2 - t3’                       Difference of _t2_ and _t3_.  Afterwards _t1_ ==
                                     _t2_ - _t3_ and _t2_ == _t1_ + _t3_ are true.
                                     (1)
                                     
                                     
‘t1 = t2 * i or t1 = i * t2’         Delta multiplied by an integer or long.
                                     Afterwards _t1_ // i == _t2_ is true, provided ‘i
                                     != 0’.
                                     
                                     
                                     In general, _t1_ * i == _t1_ * (i-1) + _t1_ is
                                     true.  (1)
                                     
                                     
‘t1 = t2 // i’                       The floor is computed and the remainder (if any)
                                     is thrown away.  (3)
                                     
                                     
‘+t1’                                Returns a *note timedelta: 210. object with the
                                     same value.  (2)
                                     
                                     
‘-t1’                                equivalent to *note timedelta: 210.(-_t1.days_,
                                     -_t1.seconds_, -_t1.microseconds_), and to _t1_*
                                     -1.  (1)(4)
                                     
                                     
‘abs(t)’                             equivalent to +_t_ when ‘t.days >= 0’, and to
                                     -_t_ when ‘t.days < 0’.  (2)
                                     
                                     
‘str(t)’                             Returns a string in the form ‘[D day[s],
                                     ][H]H:MM:SS[.UUUUUU]’, where D is negative for
                                     negative ‘t’.  (5)
                                     
                                     
‘repr(t)’                            Returns a string in the form
                                     ‘datetime.timedelta(D[, S[, U]])’, where D is
                                     negative for negative ‘t’.  (5)
                                     

  Notes:

  1. This is exact, but may overflow.

  2. This is exact, and cannot overflow.

  3. Division by 0 raises *note ZeroDivisionError: 5ac.

  4. -_timedelta.max_ is not representable as a *note timedelta: 210.
     object.

  5. String representations of *note timedelta: 210. objects are
     normalized similarly to their internal representation.  This leads
     to somewhat unusual results for negative timedeltas.  For example:

          >>> timedelta(hours=-5)
          datetime.timedelta(-1, 68400)
          >>> print(_)
          -1 day, 19:00:00

  In addition to the operations listed above *note timedelta: 210.
objects support certain additions and subtractions with *note date: 35d.
and *note datetime: 2da. objects (see below).

  Comparisons of *note timedelta: 210. objects are supported with the
*note timedelta: 210. object representing the smaller duration
considered to be the smaller timedelta.  In order to stop mixed-type
comparisons from falling back to the default comparison by object
address, when a *note timedelta: 210. object is compared to an object of
a different type, *note TypeError: 218. is raised unless the comparison
is ‘==’ or ‘!=’.  The latter cases return *note False: 3b1. or *note
True: 3b0, respectively.

  *note timedelta: 210. objects are *note hashable: 6f5. (usable as
dictionary keys), support efficient pickling, and in Boolean contexts, a
*note timedelta: 210. object is considered to be true if and only if it
isn’t equal to ‘timedelta(0)’.

  Instance methods:

 -- Method: timedelta.total_seconds ()

     Return the total number of seconds contained in the duration.
     Equivalent to ‘(td.microseconds + (td.seconds + td.days * 24 *
     3600) * 10**6) / 10**6’ computed with true division enabled.

     Note that for very large time intervals (greater than 270 years on
     most platforms) this method will lose microsecond accuracy.

     New in version 2.7.

  Example usage:

     >>> from datetime import timedelta
     >>> year = timedelta(days=365)
     >>> another_year = timedelta(weeks=40, days=84, hours=23,
     ...                          minutes=50, seconds=600)  # adds up to 365 days
     >>> year.total_seconds()
     31536000.0
     >>> year == another_year
     True
     >>> ten_years = 10 * year
     >>> ten_years, ten_years.days // 365
     (datetime.timedelta(3650), 10)
     >>> nine_years = ten_years - year
     >>> nine_years, nine_years.days // 365
     (datetime.timedelta(3285), 9)
     >>> three_years = nine_years // 3;
     >>> three_years, three_years.days // 365
     (datetime.timedelta(1095), 3)
     >>> abs(three_years - ten_years) == 2 * three_years + year
     True


File: python.info,  Node: date Objects,  Next: datetime Objects,  Prev: timedelta Objects,  Up: datetime --- Basic date and time types

5.8.1.3 ‘date’ Objects
......................

A *note date: 35d. object represents a date (year, month and day) in an
idealized calendar, the current Gregorian calendar indefinitely extended
in both directions.  January 1 of year 1 is called day number 1, January
2 of year 1 is called day number 2, and so on.  This matches the
definition of the "proleptic Gregorian" calendar in Dershowitz and
Reingold’s book Calendrical Calculations, where it’s the base calendar
for all computations.  See the book for algorithms for converting
between proleptic Gregorian ordinals and many other calendar systems.

 -- Class: datetime.date (year, month, day)

     All arguments are required.  Arguments may be ints or longs, in the
     following ranges:

        * ‘MINYEAR <= year <= MAXYEAR’

        * ‘1 <= month <= 12’

        * ‘1 <= day <= number of days in the given month and year’

     If an argument outside those ranges is given, *note ValueError:
     236. is raised.

  Other constructors, all class methods:

 -- Class Method: date.today ()

     Return the current local date.  This is equivalent to
     ‘date.fromtimestamp(time.time())’.

 -- Class Method: date.fromtimestamp (timestamp)

     Return the local date corresponding to the POSIX timestamp, such as
     is returned by *note time.time(): 461.  This may raise *note
     ValueError: 236, if the timestamp is out of the range of values
     supported by the platform C ‘localtime()’ function.  It’s common
     for this to be restricted to years from 1970 through 2038.  Note
     that on non-POSIX systems that include leap seconds in their notion
     of a timestamp, leap seconds are ignored by *note fromtimestamp():
     ad6.

 -- Class Method: date.fromordinal (ordinal)

     Return the date corresponding to the proleptic Gregorian ordinal,
     where January 1 of year 1 has ordinal 1.  *note ValueError: 236. is
     raised unless ‘1 <= ordinal <= date.max.toordinal()’.  For any date
     _d_, ‘date.fromordinal(d.toordinal()) == d’.

  Class attributes:

 -- Attribute: date.min

     The earliest representable date, ‘date(MINYEAR, 1, 1)’.

 -- Attribute: date.max

     The latest representable date, ‘date(MAXYEAR, 12, 31)’.

 -- Attribute: date.resolution

     The smallest possible difference between non-equal date objects,
     ‘timedelta(days=1)’.

  Instance attributes (read-only):

 -- Attribute: date.year

     Between *note MINYEAR: acb. and *note MAXYEAR: acc. inclusive.

 -- Attribute: date.month

     Between 1 and 12 inclusive.

 -- Attribute: date.day

     Between 1 and the number of days in the given month of the given
     year.

  Supported operations:

Operation                           Result
                                    
---------------------------------------------------------------------------------------
                                    
‘date2 = date1 + timedelta’         _date2_ is ‘timedelta.days’ days removed from
                                    _date1_.  (1)
                                    
                                    
‘date2 = date1 - timedelta’         Computes _date2_ such that ‘date2 + timedelta ==
                                    date1’.  (2)
                                    
                                    
‘timedelta = date1 - date2’         (3)
                                    
                                    
‘date1 < date2’                     _date1_ is considered less than _date2_ when
                                    _date1_ precedes _date2_ in time.  (4)
                                    

  Notes:

  1. _date2_ is moved forward in time if ‘timedelta.days > 0’, or
     backward if ‘timedelta.days < 0’.  Afterward ‘date2 - date1 ==
     timedelta.days’.  ‘timedelta.seconds’ and ‘timedelta.microseconds’
     are ignored.  *note OverflowError: 2db. is raised if ‘date2.year’
     would be smaller than *note MINYEAR: acb. or larger than *note
     MAXYEAR: acc.

  2. This isn’t quite equivalent to date1 + (-timedelta), because
     -timedelta in isolation can overflow in cases where date1 -
     timedelta does not.  ‘timedelta.seconds’ and
     ‘timedelta.microseconds’ are ignored.

  3. This is exact, and cannot overflow.  timedelta.seconds and
     timedelta.microseconds are 0, and date2 + timedelta == date1 after.

  4. In other words, ‘date1 < date2’ if and only if ‘date1.toordinal() <
     date2.toordinal()’.  In order to stop comparison from falling back
     to the default scheme of comparing object addresses, date
     comparison normally raises *note TypeError: 218. if the other
     comparand isn’t also a *note date: 35d. object.  However,
     ‘NotImplemented’ is returned instead if the other comparand has a
     ‘timetuple()’ attribute.  This hook gives other kinds of date
     objects a chance at implementing mixed-type comparison.  If not,
     when a *note date: 35d. object is compared to an object of a
     different type, *note TypeError: 218. is raised unless the
     comparison is ‘==’ or ‘!=’.  The latter cases return *note False:
     3b1. or *note True: 3b0, respectively.

  Dates can be used as dictionary keys.  In Boolean contexts, all *note
date: 35d. objects are considered to be true.

  Instance methods:

 -- Method: date.replace (year, month, day)

     Return a date with the same value, except for those parameters
     given new values by whichever keyword arguments are specified.  For
     example, if ‘d == date(2002, 12, 31)’, then ‘d.replace(day=26) ==
     date(2002, 12, 26)’.

 -- Method: date.timetuple ()

     Return a *note time.struct_time: ae0. such as returned by *note
     time.localtime(): ae1.  The hours, minutes and seconds are 0, and
     the DST flag is -1.  ‘d.timetuple()’ is equivalent to
     ‘time.struct_time((d.year, d.month, d.day, 0, 0, 0, d.weekday(),
     yday, -1))’, where ‘yday = d.toordinal() - date(d.year, 1,
     1).toordinal() + 1’ is the day number within the current year
     starting with ‘1’ for January 1st.

 -- Method: date.toordinal ()

     Return the proleptic Gregorian ordinal of the date, where January 1
     of year 1 has ordinal 1.  For any *note date: 35d. object _d_,
     ‘date.fromordinal(d.toordinal()) == d’.

 -- Method: date.weekday ()

     Return the day of the week as an integer, where Monday is 0 and
     Sunday is 6.  For example, ‘date(2002, 12, 4).weekday() == 2’, a
     Wednesday.  See also *note isoweekday(): ae4.

 -- Method: date.isoweekday ()

     Return the day of the week as an integer, where Monday is 1 and
     Sunday is 7.  For example, ‘date(2002, 12, 4).isoweekday() == 3’, a
     Wednesday.  See also *note weekday(): ae3, *note isocalendar():
     ae5.

 -- Method: date.isocalendar ()

     Return a 3-tuple, (ISO year, ISO week number, ISO weekday).

     The ISO calendar is a widely used variant of the Gregorian
     calendar.  See
     ‘http://www.phys.uu.nl/~vgent/calendar/isocalendar.htm’ for a good
     explanation.

     The ISO year consists of 52 or 53 full weeks, and where a week
     starts on a Monday and ends on a Sunday.  The first week of an ISO
     year is the first (Gregorian) calendar week of a year containing a
     Thursday.  This is called week number 1, and the ISO year of that
     Thursday is the same as its Gregorian year.

     For example, 2004 begins on a Thursday, so the first week of ISO
     year 2004 begins on Monday, 29 Dec 2003 and ends on Sunday, 4 Jan
     2004, so that ‘date(2003, 12, 29).isocalendar() == (2004, 1, 1)’
     and ‘date(2004, 1, 4).isocalendar() == (2004, 1, 7)’.

 -- Method: date.isoformat ()

     Return a string representing the date in ISO 8601 format,
     ’YYYY-MM-DD’.  For example, ‘date(2002, 12, 4).isoformat() ==
     '2002-12-04'’.

 -- Method: date.__str__ ()

     For a date _d_, ‘str(d)’ is equivalent to ‘d.isoformat()’.

 -- Method: date.ctime ()

     Return a string representing the date, for example ‘date(2002, 12,
     4).ctime() == 'Wed Dec 4 00:00:00 2002'’.  ‘d.ctime()’ is
     equivalent to ‘time.ctime(time.mktime(d.timetuple()))’ on platforms
     where the native C ‘ctime()’ function (which *note time.ctime():
     ae9. invokes, but which *note date.ctime(): ae8. does not invoke)
     conforms to the C standard.

 -- Method: date.strftime (format)

     Return a string representing the date, controlled by an explicit
     format string.  Format codes referring to hours, minutes or seconds
     will see 0 values.  For a complete list of formatting directives,
     see section *note strftime() and strptime() Behavior: aeb.

 -- Method: date.__format__ (format)

     Same as *note date.strftime(): aea.  This makes it possible to
     specify format string for a *note date: 35d. object when using
     *note str.format(): 1d2.  See section *note strftime() and
     strptime() Behavior: aeb.

  Example of counting days to an event:

     >>> import time
     >>> from datetime import date
     >>> today = date.today()
     >>> today
     datetime.date(2007, 12, 5)
     >>> today == date.fromtimestamp(time.time())
     True
     >>> my_birthday = date(today.year, 6, 24)
     >>> if my_birthday < today:
     ...     my_birthday = my_birthday.replace(year=today.year + 1)
     >>> my_birthday
     datetime.date(2008, 6, 24)
     >>> time_to_birthday = abs(my_birthday - today)
     >>> time_to_birthday.days
     202

  Example of working with *note date: 35d.:

     >>> from datetime import date
     >>> d = date.fromordinal(730920) # 730920th day after 1. 1. 0001
     >>> d
     datetime.date(2002, 3, 11)
     >>> t = d.timetuple()
     >>> for i in t:
     ...     print i
     2002                # year
     3                   # month
     11                  # day
     0
     0
     0
     0                   # weekday (0 = Monday)
     70                  # 70th day in the year
     -1
     >>> ic = d.isocalendar()
     >>> for i in ic:
     ...     print i
     2002                # ISO year
     11                  # ISO week number
     1                   # ISO day number ( 1 = Monday )
     >>> d.isoformat()
     '2002-03-11'
     >>> d.strftime("%d/%m/%y")
     '11/03/02'
     >>> d.strftime("%A %d. %B %Y")
     'Monday 11. March 2002'
     >>> 'The {1} is {0:%d}, the {2} is {0:%B}.'.format(d, "day", "month")
     'The day is 11, the month is March.'


File: python.info,  Node: datetime Objects,  Next: time Objects,  Prev: date Objects,  Up: datetime --- Basic date and time types

5.8.1.4 ‘datetime’ Objects
..........................

A *note datetime: 2da. object is a single object containing all the
information from a *note date: 35d. object and a *note time: 35e.
object.  Like a *note date: 35d. object, *note datetime: 2da. assumes
the current Gregorian calendar extended in both directions; like a time
object, *note datetime: 2da. assumes there are exactly 3600*24 seconds
in every day.

  Constructor:

 -- Class: datetime.datetime (year, month, day[, hour[, minute[,
          second[, microsecond[, tzinfo]]]]])

     The year, month and day arguments are required.  _tzinfo_ may be
     ‘None’, or an instance of a *note tzinfo: aca. subclass.  The
     remaining arguments may be ints or longs, in the following ranges:

        * ‘MINYEAR <= year <= MAXYEAR’

        * ‘1 <= month <= 12’

        * ‘1 <= day <= number of days in the given month and year’

        * ‘0 <= hour < 24’

        * ‘0 <= minute < 60’

        * ‘0 <= second < 60’

        * ‘0 <= microsecond < 1000000’

     If an argument outside those ranges is given, *note ValueError:
     236. is raised.

  Other constructors, all class methods:

 -- Class Method: datetime.today ()

     Return the current local datetime, with *note tzinfo: aca. ‘None’.
     This is equivalent to ‘datetime.fromtimestamp(time.time())’.  See
     also *note now(): af0, *note fromtimestamp(): af1.

 -- Class Method: datetime.now ([tz])

     Return the current local date and time.  If optional argument _tz_
     is ‘None’ or not specified, this is like *note today(): aef, but,
     if possible, supplies more precision than can be gotten from going
     through a *note time.time(): 461. timestamp (for example, this may
     be possible on platforms supplying the C ‘gettimeofday()’
     function).

     Else _tz_ must be an instance of a class *note tzinfo: aca.
     subclass, and the current date and time are converted to _tz_’s
     time zone.  In this case the result is equivalent to
     ‘tz.fromutc(datetime.utcnow().replace(tzinfo=tz))’.  See also *note
     today(): aef, *note utcnow(): af2.

 -- Class Method: datetime.utcnow ()

     Return the current UTC date and time, with *note tzinfo: aca.
     ‘None’.  This is like *note now(): af0, but returns the current UTC
     date and time, as a naive *note datetime: 2da. object.  See also
     *note now(): af0.

 -- Class Method: datetime.fromtimestamp (timestamp[, tz])

     Return the local date and time corresponding to the POSIX
     timestamp, such as is returned by *note time.time(): 461.  If
     optional argument _tz_ is ‘None’ or not specified, the timestamp is
     converted to the platform’s local date and time, and the returned
     *note datetime: 2da. object is naive.

     Else _tz_ must be an instance of a class *note tzinfo: aca.
     subclass, and the timestamp is converted to _tz_’s time zone.  In
     this case the result is equivalent to
     ‘tz.fromutc(datetime.utcfromtimestamp(timestamp).replace(tzinfo=tz))’.

     *note fromtimestamp(): af1. may raise *note ValueError: 236, if the
     timestamp is out of the range of values supported by the platform C
     ‘localtime()’ or ‘gmtime()’ functions.  It’s common for this to be
     restricted to years in 1970 through 2038.  Note that on non-POSIX
     systems that include leap seconds in their notion of a timestamp,
     leap seconds are ignored by *note fromtimestamp(): af1, and then
     it’s possible to have two timestamps differing by a second that
     yield identical *note datetime: 2da. objects.  See also *note
     utcfromtimestamp(): af3.

 -- Class Method: datetime.utcfromtimestamp (timestamp)

     Return the UTC *note datetime: 2da. corresponding to the POSIX
     timestamp, with *note tzinfo: aca. ‘None’.  This may raise *note
     ValueError: 236, if the timestamp is out of the range of values
     supported by the platform C ‘gmtime()’ function.  It’s common for
     this to be restricted to years in 1970 through 2038.  See also
     *note fromtimestamp(): af1.

 -- Class Method: datetime.fromordinal (ordinal)

     Return the *note datetime: 2da. corresponding to the proleptic
     Gregorian ordinal, where January 1 of year 1 has ordinal 1.  *note
     ValueError: 236. is raised unless ‘1 <= ordinal <=
     datetime.max.toordinal()’.  The hour, minute, second and
     microsecond of the result are all 0, and *note tzinfo: aca. is
     ‘None’.

 -- Class Method: datetime.combine (date, time)

     Return a new *note datetime: 2da. object whose date components are
     equal to the given *note date: 35d. object’s, and whose time
     components and *note tzinfo: aca. attributes are equal to the given
     *note time: 35e. object’s.  For any *note datetime: 2da. object
     _d_, ‘d == datetime.combine(d.date(), d.timetz())’.  If date is a
     *note datetime: 2da. object, its time components and *note tzinfo:
     aca. attributes are ignored.

 -- Class Method: datetime.strptime (date_string, format)

     Return a *note datetime: 2da. corresponding to _date_string_,
     parsed according to _format_.  This is equivalent to
     ‘datetime(*(time.strptime(date_string, format)[0:6]))’.  *note
     ValueError: 236. is raised if the date_string and format can’t be
     parsed by *note time.strptime(): 3bd. or if it returns a value
     which isn’t a time tuple.  For a complete list of formatting
     directives, see section *note strftime() and strptime() Behavior:
     aeb.

     New in version 2.5.

  Class attributes:

 -- Attribute: datetime.min

     The earliest representable *note datetime: 2da, ‘datetime(MINYEAR,
     1, 1, tzinfo=None)’.

 -- Attribute: datetime.max

     The latest representable *note datetime: 2da, ‘datetime(MAXYEAR,
     12, 31, 23, 59, 59, 999999, tzinfo=None)’.

 -- Attribute: datetime.resolution

     The smallest possible difference between non-equal *note datetime:
     2da. objects, ‘timedelta(microseconds=1)’.

  Instance attributes (read-only):

 -- Attribute: datetime.year

     Between *note MINYEAR: acb. and *note MAXYEAR: acc. inclusive.

 -- Attribute: datetime.month

     Between 1 and 12 inclusive.

 -- Attribute: datetime.day

     Between 1 and the number of days in the given month of the given
     year.

 -- Attribute: datetime.hour

     In ‘range(24)’.

 -- Attribute: datetime.minute

     In ‘range(60)’.

 -- Attribute: datetime.second

     In ‘range(60)’.

 -- Attribute: datetime.microsecond

     In ‘range(1000000)’.

 -- Attribute: datetime.tzinfo

     The object passed as the _tzinfo_ argument to the *note datetime:
     2da. constructor, or ‘None’ if none was passed.

  Supported operations:

Operation                                   Result
                                            
---------------------------------------------------------------------------------
                                            
‘datetime2 = datetime1 + timedelta’         (1)
                                            
                                            
‘datetime2 = datetime1 - timedelta’         (2)
                                            
                                            
‘timedelta = datetime1 - datetime2’         (3)
                                            
                                            
‘datetime1 < datetime2’                     Compares *note datetime: 2da. to
                                            *note datetime: 2da.  (4)
                                            

  1. datetime2 is a duration of timedelta removed from datetime1, moving
     forward in time if ‘timedelta.days’ > 0, or backward if
     ‘timedelta.days’ < 0.  The result has the same *note tzinfo: aca.
     attribute as the input datetime, and datetime2 - datetime1 ==
     timedelta after.  *note OverflowError: 2db. is raised if
     datetime2.year would be smaller than *note MINYEAR: acb. or larger
     than *note MAXYEAR: acc.  Note that no time zone adjustments are
     done even if the input is an aware object.

  2. Computes the datetime2 such that datetime2 + timedelta ==
     datetime1.  As for addition, the result has the same *note tzinfo:
     aca. attribute as the input datetime, and no time zone adjustments
     are done even if the input is aware.  This isn’t quite equivalent
     to datetime1 + (-timedelta), because -timedelta in isolation can
     overflow in cases where datetime1 - timedelta does not.

  3. Subtraction of a *note datetime: 2da. from a *note datetime: 2da.
     is defined only if both operands are naive, or if both are aware.
     If one is aware and the other is naive, *note TypeError: 218. is
     raised.

     If both are naive, or both are aware and have the same *note
     tzinfo: aca. attribute, the *note tzinfo: aca. attributes are
     ignored, and the result is a *note timedelta: 210. object _t_ such
     that ‘datetime2 + t == datetime1’.  No time zone adjustments are
     done in this case.

     If both are aware and have different *note tzinfo: aca. attributes,
     ‘a-b’ acts as if _a_ and _b_ were first converted to naive UTC
     datetimes first.  The result is ‘(a.replace(tzinfo=None) -
     a.utcoffset()) - (b.replace(tzinfo=None) - b.utcoffset())’ except
     that the implementation never overflows.

  4. _datetime1_ is considered less than _datetime2_ when _datetime1_
     precedes _datetime2_ in time.

     If one comparand is naive and the other is aware, *note TypeError:
     218. is raised.  If both comparands are aware, and have the same
     *note tzinfo: aca. attribute, the common *note tzinfo: aca.
     attribute is ignored and the base datetimes are compared.  If both
     comparands are aware and have different *note tzinfo: aca.
     attributes, the comparands are first adjusted by subtracting their
     UTC offsets (obtained from ‘self.utcoffset()’).

          Note: In order to stop comparison from falling back to the
          default scheme of comparing object addresses, datetime
          comparison normally raises *note TypeError: 218. if the other
          comparand isn’t also a *note datetime: 2da. object.  However,
          ‘NotImplemented’ is returned instead if the other comparand
          has a ‘timetuple()’ attribute.  This hook gives other kinds of
          date objects a chance at implementing mixed-type comparison.
          If not, when a *note datetime: 2da. object is compared to an
          object of a different type, *note TypeError: 218. is raised
          unless the comparison is ‘==’ or ‘!=’.  The latter cases
          return *note False: 3b1. or *note True: 3b0, respectively.

  *note datetime: 2da. objects can be used as dictionary keys.  In
Boolean contexts, all *note datetime: 2da. objects are considered to be
true.

  Instance methods:

 -- Method: datetime.date ()

     Return *note date: 35d. object with same year, month and day.

 -- Method: datetime.time ()

     Return *note time: 35e. object with same hour, minute, second and
     microsecond.  *note tzinfo: aca. is ‘None’.  See also method *note
     timetz(): b04.

 -- Method: datetime.timetz ()

     Return *note time: 35e. object with same hour, minute, second,
     microsecond, and tzinfo attributes.  See also method *note time():
     17a.

 -- Method: datetime.replace ([year[, month[, day[, hour[, minute[,
          second[, microsecond[, tzinfo]]]]]]]])

     Return a datetime with the same attributes, except for those
     attributes given new values by whichever keyword arguments are
     specified.  Note that ‘tzinfo=None’ can be specified to create a
     naive datetime from an aware datetime with no conversion of date
     and time data.

 -- Method: datetime.astimezone (tz)

     Return a *note datetime: 2da. object with new *note tzinfo: aca.
     attribute _tz_, adjusting the date and time data so the result is
     the same UTC time as _self_, but in _tz_’s local time.

     _tz_ must be an instance of a *note tzinfo: aca. subclass, and its
     *note utcoffset(): b07. and *note dst(): b08. methods must not
     return ‘None’.  _self_ must be aware (‘self.tzinfo’ must not be
     ‘None’, and ‘self.utcoffset()’ must not return ‘None’).

     If ‘self.tzinfo’ is _tz_, ‘self.astimezone(tz)’ is equal to _self_:
     no adjustment of date or time data is performed.  Else the result
     is local time in time zone _tz_, representing the same UTC time as
     _self_: after ‘astz = dt.astimezone(tz)’, ‘astz - astz.utcoffset()’
     will usually have the same date and time data as ‘dt -
     dt.utcoffset()’.  The discussion of class *note tzinfo: aca.
     explains the cases at Daylight Saving Time transition boundaries
     where this cannot be achieved (an issue only if _tz_ models both
     standard and daylight time).

     If you merely want to attach a time zone object _tz_ to a datetime
     _dt_ without adjustment of date and time data, use
     ‘dt.replace(tzinfo=tz)’.  If you merely want to remove the time
     zone object from an aware datetime _dt_ without conversion of date
     and time data, use ‘dt.replace(tzinfo=None)’.

     Note that the default *note tzinfo.fromutc(): b09. method can be
     overridden in a *note tzinfo: aca. subclass to affect the result
     returned by *note astimezone(): b06.  Ignoring error cases, *note
     astimezone(): b06. acts like:

          def astimezone(self, tz):
              if self.tzinfo is tz:
                  return self
              # Convert self to UTC, and attach the new time zone object.
              utc = (self - self.utcoffset()).replace(tzinfo=tz)
              # Convert from UTC to tz's local time.
              return tz.fromutc(utc)

 -- Method: datetime.utcoffset ()

     If *note tzinfo: aca. is ‘None’, returns ‘None’, else returns
     ‘self.tzinfo.utcoffset(self)’, and raises an exception if the
     latter doesn’t return ‘None’, or a *note timedelta: 210. object
     representing a whole number of minutes with magnitude less than one
     day.

 -- Method: datetime.dst ()

     If *note tzinfo: aca. is ‘None’, returns ‘None’, else returns
     ‘self.tzinfo.dst(self)’, and raises an exception if the latter
     doesn’t return ‘None’, or a *note timedelta: 210. object
     representing a whole number of minutes with magnitude less than one
     day.

 -- Method: datetime.tzname ()

     If *note tzinfo: aca. is ‘None’, returns ‘None’, else returns
     ‘self.tzinfo.tzname(self)’, raises an exception if the latter
     doesn’t return ‘None’ or a string object,

 -- Method: datetime.timetuple ()

     Return a *note time.struct_time: ae0. such as returned by *note
     time.localtime(): ae1.  ‘d.timetuple()’ is equivalent to
     ‘time.struct_time((d.year, d.month, d.day, d.hour, d.minute,
     d.second, d.weekday(), yday, dst))’, where ‘yday = d.toordinal() -
     date(d.year, 1, 1).toordinal() + 1’ is the day number within the
     current year starting with ‘1’ for January 1st.  The ‘tm_isdst’
     flag of the result is set according to the *note dst(): b08.
     method: *note tzinfo: aca. is ‘None’ or *note dst(): b08. returns
     ‘None’, ‘tm_isdst’ is set to ‘-1’; else if *note dst(): b08.
     returns a non-zero value, ‘tm_isdst’ is set to ‘1’; else ‘tm_isdst’
     is set to ‘0’.

 -- Method: datetime.utctimetuple ()

     If *note datetime: 2da. instance _d_ is naive, this is the same as
     ‘d.timetuple()’ except that ‘tm_isdst’ is forced to 0 regardless of
     what ‘d.dst()’ returns.  DST is never in effect for a UTC time.

     If _d_ is aware, _d_ is normalized to UTC time, by subtracting
     ‘d.utcoffset()’, and a *note time.struct_time: ae0. for the
     normalized time is returned.  ‘tm_isdst’ is forced to 0.  Note that
     the result’s ‘tm_year’ member may be *note MINYEAR: acb.-1 or *note
     MAXYEAR: acc.+1, if _d_.year was ‘MINYEAR’ or ‘MAXYEAR’ and UTC
     adjustment spills over a year boundary.

 -- Method: datetime.toordinal ()

     Return the proleptic Gregorian ordinal of the date.  The same as
     ‘self.date().toordinal()’.

 -- Method: datetime.weekday ()

     Return the day of the week as an integer, where Monday is 0 and
     Sunday is 6.  The same as ‘self.date().weekday()’.  See also *note
     isoweekday(): b0f.

 -- Method: datetime.isoweekday ()

     Return the day of the week as an integer, where Monday is 1 and
     Sunday is 7.  The same as ‘self.date().isoweekday()’.  See also
     *note weekday(): b0e, *note isocalendar(): b10.

 -- Method: datetime.isocalendar ()

     Return a 3-tuple, (ISO year, ISO week number, ISO weekday).  The
     same as ‘self.date().isocalendar()’.

 -- Method: datetime.isoformat ([sep])

     Return a string representing the date and time in ISO 8601 format,
     YYYY-MM-DDTHH:MM:SS.mmmmmm or, if *note microsecond: b00. is 0,
     YYYY-MM-DDTHH:MM:SS

     If *note utcoffset(): b07. does not return ‘None’, a 6-character
     string is appended, giving the UTC offset in (signed) hours and
     minutes: YYYY-MM-DDTHH:MM:SS.mmmmmm+HH:MM or, if *note microsecond:
     b00. is 0 YYYY-MM-DDTHH:MM:SS+HH:MM

     The optional argument _sep_ (default ‘'T'’) is a one-character
     separator, placed between the date and time portions of the result.
     For example,

          >>> from datetime import tzinfo, timedelta, datetime
          >>> class TZ(tzinfo):
          ...     def utcoffset(self, dt): return timedelta(minutes=-399)
          ...
          >>> datetime(2002, 12, 25, tzinfo=TZ()).isoformat(' ')
          '2002-12-25 00:00:00-06:39'

 -- Method: datetime.__str__ ()

     For a *note datetime: 2da. instance _d_, ‘str(d)’ is equivalent to
     ‘d.isoformat(' ')’.

 -- Method: datetime.ctime ()

     Return a string representing the date and time, for example
     ‘datetime(2002, 12, 4, 20, 30, 40).ctime() == 'Wed Dec 4 20:30:40
     2002'’.  ‘d.ctime()’ is equivalent to
     ‘time.ctime(time.mktime(d.timetuple()))’ on platforms where the
     native C ‘ctime()’ function (which *note time.ctime(): ae9.
     invokes, but which *note datetime.ctime(): b13. does not invoke)
     conforms to the C standard.

 -- Method: datetime.strftime (format)

     Return a string representing the date and time, controlled by an
     explicit format string.  For a complete list of formatting
     directives, see section *note strftime() and strptime() Behavior:
     aeb.

 -- Method: datetime.__format__ (format)

     Same as *note datetime.strftime(): b14.  This makes it possible to
     specify format string for a *note datetime: 2da. object when using
     *note str.format(): 1d2.  See section *note strftime() and
     strptime() Behavior: aeb.

  Examples of working with datetime objects:

     >>> from datetime import datetime, date, time
     >>> # Using datetime.combine()
     >>> d = date(2005, 7, 14)
     >>> t = time(12, 30)
     >>> datetime.combine(d, t)
     datetime.datetime(2005, 7, 14, 12, 30)
     >>> # Using datetime.now() or datetime.utcnow()
     >>> datetime.now()
     datetime.datetime(2007, 12, 6, 16, 29, 43, 79043)   # GMT +1
     >>> datetime.utcnow()
     datetime.datetime(2007, 12, 6, 15, 29, 43, 79060)
     >>> # Using datetime.strptime()
     >>> dt = datetime.strptime("21/11/06 16:30", "%d/%m/%y %H:%M")
     >>> dt
     datetime.datetime(2006, 11, 21, 16, 30)
     >>> # Using datetime.timetuple() to get tuple of all attributes
     >>> tt = dt.timetuple()
     >>> for it in tt:
     ...     print it
     ...
     2006    # year
     11      # month
     21      # day
     16      # hour
     30      # minute
     0       # second
     1       # weekday (0 = Monday)
     325     # number of days since 1st January
     -1      # dst - method tzinfo.dst() returned None
     >>> # Date in ISO format
     >>> ic = dt.isocalendar()
     >>> for it in ic:
     ...     print it
     ...
     2006    # ISO year
     47      # ISO week
     2       # ISO weekday
     >>> # Formatting datetime
     >>> dt.strftime("%A, %d. %B %Y %I:%M%p")
     'Tuesday, 21. November 2006 04:30PM'
     >>> 'The {1} is {0:%d}, the {2} is {0:%B}, the {3} is {0:%I:%M%p}.'.format(dt, "day", "month", "time")
     'The day is 21, the month is November, the time is 04:30PM.'

  Using datetime with tzinfo:

     >>> from datetime import timedelta, datetime, tzinfo
     >>> class GMT1(tzinfo):
     ...     def utcoffset(self, dt):
     ...         return timedelta(hours=1) + self.dst(dt)
     ...     def dst(self, dt):
     ...         # DST starts last Sunday in March
     ...         d = datetime(dt.year, 4, 1)   # ends last Sunday in October
     ...         self.dston = d - timedelta(days=d.weekday() + 1)
     ...         d = datetime(dt.year, 11, 1)
     ...         self.dstoff = d - timedelta(days=d.weekday() + 1)
     ...         if self.dston <=  dt.replace(tzinfo=None) < self.dstoff:
     ...             return timedelta(hours=1)
     ...         else:
     ...             return timedelta(0)
     ...     def tzname(self,dt):
     ...          return "GMT +1"
     ...
     >>> class GMT2(tzinfo):
     ...     def utcoffset(self, dt):
     ...         return timedelta(hours=2) + self.dst(dt)
     ...     def dst(self, dt):
     ...         d = datetime(dt.year, 4, 1)
     ...         self.dston = d - timedelta(days=d.weekday() + 1)
     ...         d = datetime(dt.year, 11, 1)
     ...         self.dstoff = d - timedelta(days=d.weekday() + 1)
     ...         if self.dston <=  dt.replace(tzinfo=None) < self.dstoff:
     ...             return timedelta(hours=1)
     ...         else:
     ...             return timedelta(0)
     ...     def tzname(self,dt):
     ...         return "GMT +2"
     ...
     >>> gmt1 = GMT1()
     >>> # Daylight Saving Time
     >>> dt1 = datetime(2006, 11, 21, 16, 30, tzinfo=gmt1)
     >>> dt1.dst()
     datetime.timedelta(0)
     >>> dt1.utcoffset()
     datetime.timedelta(0, 3600)
     >>> dt2 = datetime(2006, 6, 14, 13, 0, tzinfo=gmt1)
     >>> dt2.dst()
     datetime.timedelta(0, 3600)
     >>> dt2.utcoffset()
     datetime.timedelta(0, 7200)
     >>> # Convert datetime to another time zone
     >>> dt3 = dt2.astimezone(GMT2())
     >>> dt3     # doctest: +ELLIPSIS
     datetime.datetime(2006, 6, 14, 14, 0, tzinfo=<GMT2 object at 0x...>)
     >>> dt2     # doctest: +ELLIPSIS
     datetime.datetime(2006, 6, 14, 13, 0, tzinfo=<GMT1 object at 0x...>)
     >>> dt2.utctimetuple() == dt3.utctimetuple()
     True


File: python.info,  Node: time Objects,  Next: tzinfo Objects,  Prev: datetime Objects,  Up: datetime --- Basic date and time types

5.8.1.5 ‘time’ Objects
......................

A time object represents a (local) time of day, independent of any
particular day, and subject to adjustment via a *note tzinfo: aca.
object.

 -- Class: datetime.time ([hour[, minute[, second[, microsecond[,
          tzinfo]]]]])

     All arguments are optional.  _tzinfo_ may be ‘None’, or an instance
     of a *note tzinfo: aca. subclass.  The remaining arguments may be
     ints or longs, in the following ranges:

        * ‘0 <= hour < 24’

        * ‘0 <= minute < 60’

        * ‘0 <= second < 60’

        * ‘0 <= microsecond < 1000000’.

     If an argument outside those ranges is given, *note ValueError:
     236. is raised.  All default to ‘0’ except _tzinfo_, which defaults
     to *note None: 39a.

  Class attributes:

 -- Attribute: time.min

     The earliest representable *note time: 35e, ‘time(0, 0, 0, 0)’.

 -- Attribute: time.max

     The latest representable *note time: 35e, ‘time(23, 59, 59,
     999999)’.

 -- Attribute: time.resolution

     The smallest possible difference between non-equal *note time: 35e.
     objects, ‘timedelta(microseconds=1)’, although note that arithmetic
     on *note time: 35e. objects is not supported.

  Instance attributes (read-only):

 -- Attribute: time.hour

     In ‘range(24)’.

 -- Attribute: time.minute

     In ‘range(60)’.

 -- Attribute: time.second

     In ‘range(60)’.

 -- Attribute: time.microsecond

     In ‘range(1000000)’.

 -- Attribute: time.tzinfo

     The object passed as the tzinfo argument to the *note time: 35e.
     constructor, or ‘None’ if none was passed.

  Supported operations:

   * comparison of *note time: 35e. to *note time: 35e, where _a_ is
     considered less than _b_ when _a_ precedes _b_ in time.  If one
     comparand is naive and the other is aware, *note TypeError: 218. is
     raised.  If both comparands are aware, and have the same *note
     tzinfo: aca. attribute, the common *note tzinfo: aca. attribute is
     ignored and the base times are compared.  If both comparands are
     aware and have different *note tzinfo: aca. attributes, the
     comparands are first adjusted by subtracting their UTC offsets
     (obtained from ‘self.utcoffset()’).  In order to stop mixed-type
     comparisons from falling back to the default comparison by object
     address, when a *note time: 35e. object is compared to an object of
     a different type, *note TypeError: 218. is raised unless the
     comparison is ‘==’ or ‘!=’.  The latter cases return *note False:
     3b1. or *note True: 3b0, respectively.

   * hash, use as dict key

   * efficient pickling

   * in Boolean contexts, a *note time: 35e. object is considered to be
     true if and only if, after converting it to minutes and subtracting
     ‘utcoffset()’ (or ‘0’ if that’s ‘None’), the result is non-zero.

  Instance methods:

 -- Method: time.replace ([hour[, minute[, second[, microsecond[,
          tzinfo]]]]])

     Return a *note time: 35e. with the same value, except for those
     attributes given new values by whichever keyword arguments are
     specified.  Note that ‘tzinfo=None’ can be specified to create a
     naive *note time: 35e. from an aware *note time: 35e, without
     conversion of the time data.

 -- Method: time.isoformat ()

     Return a string representing the time in ISO 8601 format,
     HH:MM:SS.mmmmmm or, if self.microsecond is 0, HH:MM:SS If *note
     utcoffset(): b22. does not return ‘None’, a 6-character string is
     appended, giving the UTC offset in (signed) hours and minutes:
     HH:MM:SS.mmmmmm+HH:MM or, if self.microsecond is 0, HH:MM:SS+HH:MM

 -- Method: time.__str__ ()

     For a time _t_, ‘str(t)’ is equivalent to ‘t.isoformat()’.

 -- Method: time.strftime (format)

     Return a string representing the time, controlled by an explicit
     format string.  For a complete list of formatting directives, see
     section *note strftime() and strptime() Behavior: aeb.

 -- Method: time.__format__ (format)

     Same as *note time.strftime(): b24.  This makes it possible to
     specify format string for a *note time: 35e. object when using
     *note str.format(): 1d2.  See section *note strftime() and
     strptime() Behavior: aeb.

 -- Method: time.utcoffset ()

     If *note tzinfo: aca. is ‘None’, returns ‘None’, else returns
     ‘self.tzinfo.utcoffset(None)’, and raises an exception if the
     latter doesn’t return ‘None’ or a *note timedelta: 210. object
     representing a whole number of minutes with magnitude less than one
     day.

 -- Method: time.dst ()

     If *note tzinfo: aca. is ‘None’, returns ‘None’, else returns
     ‘self.tzinfo.dst(None)’, and raises an exception if the latter
     doesn’t return ‘None’, or a *note timedelta: 210. object
     representing a whole number of minutes with magnitude less than one
     day.

 -- Method: time.tzname ()

     If *note tzinfo: aca. is ‘None’, returns ‘None’, else returns
     ‘self.tzinfo.tzname(None)’, or raises an exception if the latter
     doesn’t return ‘None’ or a string object.

  Example:

     >>> from datetime import time, tzinfo
     >>> class GMT1(tzinfo):
     ...     def utcoffset(self, dt):
     ...         return timedelta(hours=1)
     ...     def dst(self, dt):
     ...         return timedelta(0)
     ...     def tzname(self,dt):
     ...         return "Europe/Prague"
     ...
     >>> t = time(12, 10, 30, tzinfo=GMT1())
     >>> t                               # doctest: +ELLIPSIS
     datetime.time(12, 10, 30, tzinfo=<GMT1 object at 0x...>)
     >>> gmt = GMT1()
     >>> t.isoformat()
     '12:10:30+01:00'
     >>> t.dst()
     datetime.timedelta(0)
     >>> t.tzname()
     'Europe/Prague'
     >>> t.strftime("%H:%M:%S %Z")
     '12:10:30 Europe/Prague'
     >>> 'The {} is {:%H:%M}.'.format("time", t)
     'The time is 12:10.'


File: python.info,  Node: tzinfo Objects,  Next: strftime and strptime Behavior,  Prev: time Objects,  Up: datetime --- Basic date and time types

5.8.1.6 ‘tzinfo’ Objects
........................

*note tzinfo: aca. is an abstract base class, meaning that this class
should not be instantiated directly.  You need to derive a concrete
subclass, and (at least) supply implementations of the standard *note
tzinfo: aca. methods needed by the *note datetime: 2da. methods you use.
The *note datetime: 7d. module does not supply any concrete subclasses
of *note tzinfo: aca.

  An instance of (a concrete subclass of) *note tzinfo: aca. can be
passed to the constructors for *note datetime: 2da. and *note time: 35e.
objects.  The latter objects view their attributes as being in local
time, and the *note tzinfo: aca. object supports methods revealing
offset of local time from UTC, the name of the time zone, and DST
offset, all relative to a date or time object passed to them.

  Special requirement for pickling: A *note tzinfo: aca. subclass must
have an *note __init__(): 37c. method that can be called with no
arguments, else it can be pickled but possibly not unpickled again.
This is a technical requirement that may be relaxed in the future.

  A concrete subclass of *note tzinfo: aca. may need to implement the
following methods.  Exactly which methods are needed depends on the uses
made of aware *note datetime: 7d. objects.  If in doubt, simply
implement all of them.

 -- Method: tzinfo.utcoffset (self, dt)

     Return offset of local time from UTC, in minutes east of UTC. If
     local time is west of UTC, this should be negative.  Note that this
     is intended to be the total offset from UTC; for example, if a
     *note tzinfo: aca. object represents both time zone and DST
     adjustments, *note utcoffset(): b2a. should return their sum.  If
     the UTC offset isn’t known, return ‘None’.  Else the value returned
     must be a *note timedelta: 210. object specifying a whole number of
     minutes in the range -1439 to 1439 inclusive (1440 = 24*60; the
     magnitude of the offset must be less than one day).  Most
     implementations of *note utcoffset(): b2a. will probably look like
     one of these two:

          return CONSTANT                 # fixed-offset class
          return CONSTANT + self.dst(dt)  # daylight-aware class

     If *note utcoffset(): b2a. does not return ‘None’, *note dst():
     b2b. should not return ‘None’ either.

     The default implementation of *note utcoffset(): b2a. raises *note
     NotImplementedError: 94e.

 -- Method: tzinfo.dst (self, dt)

     Return the daylight saving time (DST) adjustment, in minutes east
     of UTC, or ‘None’ if DST information isn’t known.  Return
     ‘timedelta(0)’ if DST is not in effect.  If DST is in effect,
     return the offset as a *note timedelta: 210. object (see *note
     utcoffset(): b2a. for details).  Note that DST offset, if
     applicable, has already been added to the UTC offset returned by
     *note utcoffset(): b2a, so there’s no need to consult *note dst():
     b2b. unless you’re interested in obtaining DST info separately.
     For example, *note datetime.timetuple(): b0b. calls its *note
     tzinfo: aca. attribute’s *note dst(): b2b. method to determine how
     the ‘tm_isdst’ flag should be set, and *note tzinfo.fromutc(): b09.
     calls *note dst(): b2b. to account for DST changes when crossing
     time zones.

     An instance _tz_ of a *note tzinfo: aca. subclass that models both
     standard and daylight times must be consistent in this sense:

     ‘tz.utcoffset(dt) - tz.dst(dt)’

     must return the same result for every *note datetime: 2da. _dt_
     with ‘dt.tzinfo == tz’ For sane *note tzinfo: aca. subclasses, this
     expression yields the time zone’s "standard offset", which should
     not depend on the date or the time, but only on geographic
     location.  The implementation of *note datetime.astimezone(): b06.
     relies on this, but cannot detect violations; it’s the programmer’s
     responsibility to ensure it.  If a *note tzinfo: aca. subclass
     cannot guarantee this, it may be able to override the default
     implementation of *note tzinfo.fromutc(): b09. to work correctly
     with ‘astimezone()’ regardless.

     Most implementations of *note dst(): b2b. will probably look like
     one of these two:

          def dst(self, dt):
              # a fixed-offset class:  doesn't account for DST
              return timedelta(0)

     or

          def dst(self, dt):
              # Code to set dston and dstoff to the time zone's DST
              # transition times based on the input dt.year, and expressed
              # in standard local time.  Then

              if dston <= dt.replace(tzinfo=None) < dstoff:
                  return timedelta(hours=1)
              else:
                  return timedelta(0)

     The default implementation of *note dst(): b2b. raises *note
     NotImplementedError: 94e.

 -- Method: tzinfo.tzname (self, dt)

     Return the time zone name corresponding to the *note datetime: 2da.
     object _dt_, as a string.  Nothing about string names is defined by
     the *note datetime: 7d. module, and there’s no requirement that it
     mean anything in particular.  For example, "GMT", "UTC", "-500",
     "-5:00", "EDT", "US/Eastern", "America/New York" are all valid
     replies.  Return ‘None’ if a string name isn’t known.  Note that
     this is a method rather than a fixed string primarily because some
     *note tzinfo: aca. subclasses will wish to return different names
     depending on the specific value of _dt_ passed, especially if the
     *note tzinfo: aca. class is accounting for daylight time.

     The default implementation of *note tzname(): b2c. raises *note
     NotImplementedError: 94e.

  These methods are called by a *note datetime: 2da. or *note time: 35e.
object, in response to their methods of the same names.  A *note
datetime: 2da. object passes itself as the argument, and a *note time:
35e. object passes ‘None’ as the argument.  A *note tzinfo: aca.
subclass’s methods should therefore be prepared to accept a _dt_
argument of ‘None’, or of class *note datetime: 2da.

  When ‘None’ is passed, it’s up to the class designer to decide the
best response.  For example, returning ‘None’ is appropriate if the
class wishes to say that time objects don’t participate in the *note
tzinfo: aca. protocols.  It may be more useful for ‘utcoffset(None)’ to
return the standard UTC offset, as there is no other convention for
discovering the standard offset.

  When a *note datetime: 2da. object is passed in response to a *note
datetime: 2da. method, ‘dt.tzinfo’ is the same object as _self_.  *note
tzinfo: aca. methods can rely on this, unless user code calls *note
tzinfo: aca. methods directly.  The intent is that the *note tzinfo:
aca. methods interpret _dt_ as being in local time, and not need worry
about objects in other timezones.

  There is one more *note tzinfo: aca. method that a subclass may wish
to override:

 -- Method: tzinfo.fromutc (self, dt)

     This is called from the default *note datetime.astimezone(): b06.
     implementation.  When called from that, ‘dt.tzinfo’ is _self_, and
     _dt_’s date and time data are to be viewed as expressing a UTC
     time.  The purpose of *note fromutc(): b09. is to adjust the date
     and time data, returning an equivalent datetime in _self_’s local
     time.

     Most *note tzinfo: aca. subclasses should be able to inherit the
     default *note fromutc(): b09. implementation without problems.
     It’s strong enough to handle fixed-offset time zones, and time
     zones accounting for both standard and daylight time, and the
     latter even if the DST transition times differ in different years.
     An example of a time zone the default *note fromutc(): b09.
     implementation may not handle correctly in all cases is one where
     the standard offset (from UTC) depends on the specific date and
     time passed, which can happen for political reasons.  The default
     implementations of ‘astimezone()’ and *note fromutc(): b09. may not
     produce the result you want if the result is one of the hours
     straddling the moment the standard offset changes.

     Skipping code for error cases, the default *note fromutc(): b09.
     implementation acts like:

          def fromutc(self, dt):
              # raise ValueError error if dt.tzinfo is not self
              dtoff = dt.utcoffset()
              dtdst = dt.dst()
              # raise ValueError if dtoff is None or dtdst is None
              delta = dtoff - dtdst  # this is self's standard offset
              if delta:
                  dt += delta   # convert to standard local time
                  dtdst = dt.dst()
                  # raise ValueError if dtdst is None
              if dtdst:
                  return dt + dtdst
              else:
                  return dt

  Example *note tzinfo: aca. classes:

     from datetime import tzinfo, timedelta, datetime

     ZERO = timedelta(0)
     HOUR = timedelta(hours=1)

     # A UTC class.

     class UTC(tzinfo):
         """UTC"""

         def utcoffset(self, dt):
             return ZERO

         def tzname(self, dt):
             return "UTC"

         def dst(self, dt):
             return ZERO

     utc = UTC()

     # A class building tzinfo objects for fixed-offset time zones.
     # Note that FixedOffset(0, "UTC") is a different way to build a
     # UTC tzinfo object.

     class FixedOffset(tzinfo):
         """Fixed offset in minutes east from UTC."""

         def __init__(self, offset, name):
             self.__offset = timedelta(minutes = offset)
             self.__name = name

         def utcoffset(self, dt):
             return self.__offset

         def tzname(self, dt):
             return self.__name

         def dst(self, dt):
             return ZERO

     # A class capturing the platform's idea of local time.

     import time as _time

     STDOFFSET = timedelta(seconds = -_time.timezone)
     if _time.daylight:
         DSTOFFSET = timedelta(seconds = -_time.altzone)
     else:
         DSTOFFSET = STDOFFSET

     DSTDIFF = DSTOFFSET - STDOFFSET

     class LocalTimezone(tzinfo):

         def utcoffset(self, dt):
             if self._isdst(dt):
                 return DSTOFFSET
             else:
                 return STDOFFSET

         def dst(self, dt):
             if self._isdst(dt):
                 return DSTDIFF
             else:
                 return ZERO

         def tzname(self, dt):
             return _time.tzname[self._isdst(dt)]

         def _isdst(self, dt):
             tt = (dt.year, dt.month, dt.day,
                   dt.hour, dt.minute, dt.second,
                   dt.weekday(), 0, 0)
             stamp = _time.mktime(tt)
             tt = _time.localtime(stamp)
             return tt.tm_isdst > 0

     Local = LocalTimezone()


     # A complete implementation of current DST rules for major US time zones.

     def first_sunday_on_or_after(dt):
         days_to_go = 6 - dt.weekday()
         if days_to_go:
             dt += timedelta(days_to_go)
         return dt


     # US DST Rules
     #
     # This is a simplified (i.e., wrong for a few cases) set of rules for US
     # DST start and end times. For a complete and up-to-date set of DST rules
     # and timezone definitions, visit the Olson Database (or try pytz):
     # http://www.twinsun.com/tz/tz-link.htm
     # http://sourceforge.net/projects/pytz/ (might not be up-to-date)
     #
     # In the US, since 2007, DST starts at 2am (standard time) on the second
     # Sunday in March, which is the first Sunday on or after Mar 8.
     DSTSTART_2007 = datetime(1, 3, 8, 2)
     # and ends at 2am (DST time; 1am standard time) on the first Sunday of Nov.
     DSTEND_2007 = datetime(1, 11, 1, 1)
     # From 1987 to 2006, DST used to start at 2am (standard time) on the first
     # Sunday in April and to end at 2am (DST time; 1am standard time) on the last
     # Sunday of October, which is the first Sunday on or after Oct 25.
     DSTSTART_1987_2006 = datetime(1, 4, 1, 2)
     DSTEND_1987_2006 = datetime(1, 10, 25, 1)
     # From 1967 to 1986, DST used to start at 2am (standard time) on the last
     # Sunday in April (the one on or after April 24) and to end at 2am (DST time;
     # 1am standard time) on the last Sunday of October, which is the first Sunday
     # on or after Oct 25.
     DSTSTART_1967_1986 = datetime(1, 4, 24, 2)
     DSTEND_1967_1986 = DSTEND_1987_2006

     class USTimeZone(tzinfo):

         def __init__(self, hours, reprname, stdname, dstname):
             self.stdoffset = timedelta(hours=hours)
             self.reprname = reprname
             self.stdname = stdname
             self.dstname = dstname

         def __repr__(self):
             return self.reprname

         def tzname(self, dt):
             if self.dst(dt):
                 return self.dstname
             else:
                 return self.stdname

         def utcoffset(self, dt):
             return self.stdoffset + self.dst(dt)

         def dst(self, dt):
             if dt is None or dt.tzinfo is None:
                 # An exception may be sensible here, in one or both cases.
                 # It depends on how you want to treat them.  The default
                 # fromutc() implementation (called by the default astimezone()
                 # implementation) passes a datetime with dt.tzinfo is self.
                 return ZERO
             assert dt.tzinfo is self

             # Find start and end times for US DST. For years before 1967, return
             # ZERO for no DST.
             if 2006 < dt.year:
                 dststart, dstend = DSTSTART_2007, DSTEND_2007
             elif 1986 < dt.year < 2007:
                 dststart, dstend = DSTSTART_1987_2006, DSTEND_1987_2006
             elif 1966 < dt.year < 1987:
                 dststart, dstend = DSTSTART_1967_1986, DSTEND_1967_1986
             else:
                 return ZERO

             start = first_sunday_on_or_after(dststart.replace(year=dt.year))
             end = first_sunday_on_or_after(dstend.replace(year=dt.year))

             # Can't compare naive to aware objects, so strip the timezone from
             # dt first.
             if start <= dt.replace(tzinfo=None) < end:
                 return HOUR
             else:
                 return ZERO

     Eastern  = USTimeZone(-5, "Eastern",  "EST", "EDT")
     Central  = USTimeZone(-6, "Central",  "CST", "CDT")
     Mountain = USTimeZone(-7, "Mountain", "MST", "MDT")
     Pacific  = USTimeZone(-8, "Pacific",  "PST", "PDT")


  Note that there are unavoidable subtleties twice per year in a *note
tzinfo: aca. subclass accounting for both standard and daylight time, at
the DST transition points.  For concreteness, consider US Eastern (UTC
-0500), where EDT begins the minute after 1:59 (EST) on the second
Sunday in March, and ends the minute after 1:59 (EDT) on the first
Sunday in November:

       UTC   3:MM  4:MM  5:MM  6:MM  7:MM  8:MM
       EST  22:MM 23:MM  0:MM  1:MM  2:MM  3:MM
       EDT  23:MM  0:MM  1:MM  2:MM  3:MM  4:MM

     start  22:MM 23:MM  0:MM  1:MM  3:MM  4:MM

       end  23:MM  0:MM  1:MM  1:MM  2:MM  3:MM

  When DST starts (the "start" line), the local wall clock leaps from
1:59 to 3:00.  A wall time of the form 2:MM doesn’t really make sense on
that day, so ‘astimezone(Eastern)’ won’t deliver a result with ‘hour ==
2’ on the day DST begins.  In order for ‘astimezone()’ to make this
guarantee, the ‘rzinfo.dst()’ method must consider times in the "missing
hour" (2:MM for Eastern) to be in daylight time.

  When DST ends (the "end" line), there’s a potentially worse problem:
there’s an hour that can’t be spelled unambiguously in local wall time:
the last hour of daylight time.  In Eastern, that’s times of the form
5:MM UTC on the day daylight time ends.  The local wall clock leaps from
1:59 (daylight time) back to 1:00 (standard time) again.  Local times of
the form 1:MM are ambiguous.  ‘astimezone()’ mimics the local clock’s
behavior by mapping two adjacent UTC hours into the same local hour
then.  In the Eastern example, UTC times of the form 5:MM and 6:MM both
map to 1:MM when converted to Eastern.  In order for ‘astimezone()’ to
make this guarantee, the *note tzinfo.dst(): b2b. method must consider
times in the "repeated hour" to be in standard time.  This is easily
arranged, as in the example, by expressing DST switch times in the time
zone’s standard local time.

  Applications that can’t bear such ambiguities should avoid using
hybrid *note tzinfo: aca. subclasses; there are no ambiguities when
using UTC, or any other fixed-offset *note tzinfo: aca. subclass (such
as a class representing only EST (fixed offset -5 hours), or only EDT
(fixed offset -4 hours)).

See also
........

pytz(1)

     The standard library has no *note tzinfo: aca. instances, but there
     exists a third-party library which brings the _IANA timezone
     database_ (also known as the Olson database) to Python: _pytz_.

     _pytz_ contains up-to-date information and its usage is
     recommended.

IANA timezone database(2)

     The Time Zone Database (often called tz or zoneinfo) contains code
     and data that represent the history of local time for many
     representative locations around the globe.  It is updated
     periodically to reflect changes made by political bodies to time
     zone boundaries, UTC offsets, and daylight-saving rules.

   ---------- Footnotes ----------

   (1) http://pypi.python.org/pypi/pytz/

   (2) http://www.iana.org/time-zones


File: python.info,  Node: strftime and strptime Behavior,  Prev: tzinfo Objects,  Up: datetime --- Basic date and time types

5.8.1.7 ‘strftime()’ and ‘strptime()’ Behavior
..............................................

*note date: 35d, *note datetime: 2da, and *note time: 35e. objects all
support a ‘strftime(format)’ method, to create a string representing the
time under the control of an explicit format string.  Broadly speaking,
‘d.strftime(fmt)’ acts like the *note time: 17a. module’s
‘time.strftime(fmt, d.timetuple())’ although not all objects support a
‘timetuple()’ method.

  Conversely, the *note datetime.strptime(): af6. class method creates a
*note datetime: 2da. object from a string representing a date and time
and a corresponding format string.  ‘datetime.strptime(date_string,
format)’ is equivalent to ‘datetime(*(time.strptime(date_string,
format)[0:6]))’.

  For *note time: 35e. objects, the format codes for year, month, and
day should not be used, as time objects have no such values.  If they’re
used anyway, ‘1900’ is substituted for the year, and ‘1’ for the month
and day.

  For *note date: 35d. objects, the format codes for hours, minutes,
seconds, and microseconds should not be used, as *note date: 35d.
objects have no such values.  If they’re used anyway, ‘0’ is substituted
for them.

  The full set of format codes supported varies across platforms,
because Python calls the platform C library’s ‘strftime()’ function, and
platform variations are common.  To see the full set of format codes
supported on your platform, consult the ‘strftime(3)’ documentation.

  The following is a list of all the format codes that the C standard
(1989 version) requires, and these work on all platforms with a standard
C implementation.  Note that the 1999 version of the C standard added
additional format codes.

  The exact range of years for which ‘strftime()’ works also varies
across platforms.  Regardless of platform, years before 1900 cannot be
used.

Directive       Meaning                              Example                      Notes
                                                                                  
----------------------------------------------------------------------------------------------
                                                                                  
‘%a’            Weekday as locale’s abbreviated           Sun, Mon, ..., Sat (en_US); (1)
                name.                                     So, Mo, ..., Sa (de_DE) 
                                                     
                                                                                  
‘%A’            Weekday as locale’s full name.            Sunday, Monday, ..., Saturday (en_US); (1)
                                                          Sonntag, Montag, ..., Samstag (de_DE) 
                                                     
                                                                                  
‘%w’            Weekday as a decimal number, where   0, 1, ..., 6
                0 is Sunday and 6 is Saturday.       
                
                                                                                  
‘%d’            Day of the month as a zero-padded    01, 02, ..., 31
                decimal number.                      
                
                                                                                  
‘%b’            Month as locale’s abbreviated             Jan, Feb, ..., Dec (en_US); (1)
                name.                                     Jan, Feb, ..., Dez (de_DE) 
                                                     
                                                                                  
‘%B’            Month as locale’s full name.              January, February, ..., December (en_US); (1)
                                                          Januar, Februar, ..., Dezember (de_DE) 
                                                     
                                                                                  
‘%m’            Month as a zero-padded decimal       01, 02, ..., 12
                number.                              
                
                                                                                  
‘%y’            Year without century as a            00, 01, ..., 99
                zero-padded decimal number.          
                
                                                                                  
‘%Y’            Year with century as a decimal       1970, 1988, 2001, 2013
                number.                              
                
                                                                                  
‘%H’            Hour (24-hour clock) as a            00, 01, ..., 23
                zero-padded decimal number.          
                
                                                                                  
‘%I’            Hour (12-hour clock) as a            01, 02, ..., 12
                zero-padded decimal number.          
                
                                                                                  
‘%p’            Locale’s equivalent of either AM          AM, PM (en_US);         (1), (2)
                or PM.                                    am, pm (de_DE)          
                                                     
                                                                                  
‘%M’            Minute as a zero-padded decimal      00, 01, ..., 59
                number.                              
                
                                                                                  
‘%S’            Second as a zero-padded decimal      00, 01, ..., 59              (3)
                number.                                                           
                
                                                                                  
‘%f’            Microsecond as a decimal number,     000000, 000001, ...,         (4)
                zero-padded on the left.             999999                       
                                                     
                                                                                  
‘%z’            UTC offset in the form +HHMM or      (empty), +0000, -0400,       (5)
                -HHMM (empty string if the the       +1030                        
                object is naive).                    
                
                                                                                  
‘%Z’            Time zone name (empty string if      (empty), UTC, EST, CST
                the object is naive).                
                
                                                                                  
‘%j’            Day of the year as a zero-padded     001, 002, ..., 366
                decimal number.                      
                
                                                                                  
‘%U’            Week number of the year (Sunday as   00, 01, ..., 53              (6)
                the first day of the week) as a                                   
                zero padded decimal number.  All
                days in a new year preceding the
                first Sunday are considered to be
                in week 0.
                
                                                                                  
‘%W’            Week number of the year (Monday as   00, 01, ..., 53              (6)
                the first day of the week) as a                                   
                decimal number.  All days in a new
                year preceding the first Monday
                are considered to be in week 0.
                
                                                                                  
‘%c’            Locale’s appropriate date and time        Tue Aug 16 21:30:00 1988 (en_US); (1)
                representation.                           Di 16 Aug 21:30:00 1988 (de_DE) 
                                                     
                                                                                  
‘%x’            Locale’s appropriate date                 08/16/88 (None);        (1)
                representation.                           08/16/1988 (en_US);     
                                                          16.08.1988 (de_DE) 
                                                     
                                                                                  
‘%X’            Locale’s appropriate time                 21:30:00 (en_US);       (1)
                representation.                           21:30:00 (de_DE)        
                                                     
                                                                                  
‘%%’            A literal ‘'%'’ character.           %
                                                     

  Notes:

  1. Because the format depends on the current locale, care should be
     taken when making assumptions about the output value.  Field
     orderings will vary (for example, "month/day/year" versus
     "day/month/year"), and the output may contain Unicode characters
     encoded using the locale’s default encoding (for example, if the
     current locale is ‘ja_JP’, the default encoding could be any one of
     ‘eucJP’, ‘SJIS’, or ‘utf-8’; use *note locale.getlocale(): b2e. to
     determine the current locale’s encoding).

  2. When used with the ‘strptime()’ method, the ‘%p’ directive only
     affects the output hour field if the ‘%I’ directive is used to
     parse the hour.

  3. Unlike the *note time: 17a. module, the *note datetime: 7d. module
     does not support leap seconds.

  4. ‘%f’ is an extension to the set of format characters in the C
     standard (but implemented separately in datetime objects, and
     therefore always available).  When used with the ‘strptime()’
     method, the ‘%f’ directive accepts from one to six digits and zero
     pads on the right.

     New in version 2.6.

  5. For a naive object, the ‘%z’ and ‘%Z’ format codes are replaced by
     empty strings.

     For an aware object:

     ‘%z’

          ‘utcoffset()’ is transformed into a 5-character string of the
          form +HHMM or -HHMM, where HH is a 2-digit string giving the
          number of UTC offset hours, and MM is a 2-digit string giving
          the number of UTC offset minutes.  For example, if
          ‘utcoffset()’ returns ‘timedelta(hours=-3, minutes=-30)’, ‘%z’
          is replaced with the string ‘'-0330'’.

     ‘%Z’

          If ‘tzname()’ returns ‘None’, ‘%Z’ is replaced by an empty
          string.  Otherwise ‘%Z’ is replaced by the returned value,
          which must be a string.

  6. When used with the ‘strptime()’ method, ‘%U’ and ‘%W’ are only used
     in calculations when the day of the week and the year are
     specified.


File: python.info,  Node: calendar --- General calendar-related functions,  Next: collections --- High-performance container datatypes,  Prev: datetime --- Basic date and time types,  Up: Data Types

5.8.2 ‘calendar’ — General calendar-related functions
-----------------------------------------------------

*Source code:* Lib/calendar.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module allows you to output calendars like the Unix *cal*
program, and provides additional useful functions related to the
calendar.  By default, these calendars have Monday as the first day of
the week, and Sunday as the last (the European convention).  Use *note
setfirstweekday(): b31. to set the first day of the week to Sunday (6)
or to any other weekday.  Parameters that specify dates are given as
integers.  For related functionality, see also the *note datetime: 7d.
and *note time: 17a. modules.

  Most of these functions and classes rely on the *note datetime: 7d.
module which uses an idealized calendar, the current Gregorian calendar
indefinitely extended in both directions.  This matches the definition
of the "proleptic Gregorian" calendar in Dershowitz and Reingold’s book
"Calendrical Calculations", where it’s the base calendar for all
computations.

 -- Class: calendar.Calendar ([firstweekday])

     Creates a *note Calendar: b32. object.  _firstweekday_ is an
     integer specifying the first day of the week.  ‘0’ is Monday (the
     default), ‘6’ is Sunday.

     A *note Calendar: b32. object provides several methods that can be
     used for preparing the calendar data for formatting.  This class
     doesn’t do any formatting itself.  This is the job of subclasses.

     New in version 2.5.

     *note Calendar: b32. instances have the following methods:

      -- Method: iterweekdays ()

          Return an iterator for the week day numbers that will be used
          for one week.  The first value from the iterator will be the
          same as the value of the *note firstweekday: b34. property.

      -- Method: itermonthdates (year, month)

          Return an iterator for the month _month_ (1-12) in the year
          _year_.  This iterator will return all days (as *note
          datetime.date: 35d. objects) for the month and all days before
          the start of the month or after the end of the month that are
          required to get a complete week.

      -- Method: itermonthdays2 (year, month)

          Return an iterator for the month _month_ in the year _year_
          similar to *note itermonthdates(): b35.  Days returned will be
          tuples consisting of a day number and a week day number.

      -- Method: itermonthdays (year, month)

          Return an iterator for the month _month_ in the year _year_
          similar to *note itermonthdates(): b35.  Days returned will
          simply be day numbers.

      -- Method: monthdatescalendar (year, month)

          Return a list of the weeks in the month _month_ of the _year_
          as full weeks.  Weeks are lists of seven *note datetime.date:
          35d. objects.

      -- Method: monthdays2calendar (year, month)

          Return a list of the weeks in the month _month_ of the _year_
          as full weeks.  Weeks are lists of seven tuples of day numbers
          and weekday numbers.

      -- Method: monthdayscalendar (year, month)

          Return a list of the weeks in the month _month_ of the _year_
          as full weeks.  Weeks are lists of seven day numbers.

      -- Method: yeardatescalendar (year[, width])

          Return the data for the specified year ready for formatting.
          The return value is a list of month rows.  Each month row
          contains up to _width_ months (defaulting to 3).  Each month
          contains between 4 and 6 weeks and each week contains 1–7
          days.  Days are *note datetime.date: 35d. objects.

      -- Method: yeardays2calendar (year[, width])

          Return the data for the specified year ready for formatting
          (similar to *note yeardatescalendar(): b3b.).  Entries in the
          week lists are tuples of day numbers and weekday numbers.  Day
          numbers outside this month are zero.

      -- Method: yeardayscalendar (year[, width])

          Return the data for the specified year ready for formatting
          (similar to *note yeardatescalendar(): b3b.).  Entries in the
          week lists are day numbers.  Day numbers outside this month
          are zero.

 -- Class: calendar.TextCalendar ([firstweekday])

     This class can be used to generate plain text calendars.

     New in version 2.5.

     *note TextCalendar: b3e. instances have the following methods:

      -- Method: formatmonth (theyear, themonth[, w[, l]])

          Return a month’s calendar in a multi-line string.  If _w_ is
          provided, it specifies the width of the date columns, which
          are centered.  If _l_ is given, it specifies the number of
          lines that each week will use.  Depends on the first weekday
          as specified in the constructor or set by the *note
          setfirstweekday(): b31. method.

      -- Method: prmonth (theyear, themonth[, w[, l]])

          Print a month’s calendar as returned by *note formatmonth():
          b3f.

      -- Method: formatyear (theyear[, w[, l[, c[, m]]]])

          Return a _m_-column calendar for an entire year as a
          multi-line string.  Optional parameters _w_, _l_, and _c_ are
          for date column width, lines per week, and number of spaces
          between month columns, respectively.  Depends on the first
          weekday as specified in the constructor or set by the *note
          setfirstweekday(): b31. method.  The earliest year for which a
          calendar can be generated is platform-dependent.

      -- Method: pryear (theyear[, w[, l[, c[, m]]]])

          Print the calendar for an entire year as returned by *note
          formatyear(): b41.

 -- Class: calendar.HTMLCalendar ([firstweekday])

     This class can be used to generate HTML calendars.

     New in version 2.5.

     *note HTMLCalendar: b43. instances have the following methods:

      -- Method: formatmonth (theyear, themonth[, withyear])

          Return a month’s calendar as an HTML table.  If _withyear_ is
          true the year will be included in the header, otherwise just
          the month name will be used.

      -- Method: formatyear (theyear[, width])

          Return a year’s calendar as an HTML table.  _width_
          (defaulting to 3) specifies the number of months per row.

      -- Method: formatyearpage (theyear[, width[, css[, encoding]]])

          Return a year’s calendar as a complete HTML page.  _width_
          (defaulting to 3) specifies the number of months per row.
          _css_ is the name for the cascading style sheet to be used.
          *note None: 39a. can be passed if no style sheet should be
          used.  _encoding_ specifies the encoding to be used for the
          output (defaulting to the system default encoding).

 -- Class: calendar.LocaleTextCalendar ([firstweekday[, locale]])

     This subclass of *note TextCalendar: b3e. can be passed a locale
     name in the constructor and will return month and weekday names in
     the specified locale.  If this locale includes an encoding all
     strings containing month and weekday names will be returned as
     unicode.

     New in version 2.5.

 -- Class: calendar.LocaleHTMLCalendar ([firstweekday[, locale]])

     This subclass of *note HTMLCalendar: b43. can be passed a locale
     name in the constructor and will return month and weekday names in
     the specified locale.  If this locale includes an encoding all
     strings containing month and weekday names will be returned as
     unicode.

     New in version 2.5.

     Note: The ‘formatweekday()’ and ‘formatmonthname()’ methods of
     these two classes temporarily change the current locale to the
     given _locale_.  Because the current locale is a process-wide
     setting, they are not thread-safe.

  For simple text calendars this module provides the following
functions.

 -- Function: calendar.setfirstweekday (weekday)

     Sets the weekday (‘0’ is Monday, ‘6’ is Sunday) to start each week.
     The values ‘MONDAY’, ‘TUESDAY’, ‘WEDNESDAY’, ‘THURSDAY’, ‘FRIDAY’,
     ‘SATURDAY’, and ‘SUNDAY’ are provided for convenience.  For
     example, to set the first weekday to Sunday:

          import calendar
          calendar.setfirstweekday(calendar.SUNDAY)

     New in version 2.0.

 -- Function: calendar.firstweekday ()

     Returns the current setting for the weekday to start each week.

     New in version 2.0.

 -- Function: calendar.isleap (year)

     Returns *note True: 3b0. if _year_ is a leap year, otherwise *note
     False: 3b1.

 -- Function: calendar.leapdays (y1, y2)

     Returns the number of leap years in the range from _y1_ to _y2_
     (exclusive), where _y1_ and _y2_ are years.

     Changed in version 2.0: This function didn’t work for ranges
     spanning a century change in Python 1.5.2.

 -- Function: calendar.weekday (year, month, day)

     Returns the day of the week (‘0’ is Monday) for _year_
     (‘1970’–...), _month_ (‘1’–‘12’), _day_ (‘1’–‘31’).

 -- Function: calendar.weekheader (n)

     Return a header containing abbreviated weekday names.  _n_
     specifies the width in characters for one weekday.

 -- Function: calendar.monthrange (year, month)

     Returns weekday of first day of the month and number of days in
     month, for the specified _year_ and _month_.

 -- Function: calendar.monthcalendar (year, month)

     Returns a matrix representing a month’s calendar.  Each row
     represents a week; days outside of the month a represented by
     zeros.  Each week begins with Monday unless set by *note
     setfirstweekday(): b31.

 -- Function: calendar.prmonth (theyear, themonth[, w[, l]])

     Prints a month’s calendar as returned by *note month(): b50.

 -- Function: calendar.month (theyear, themonth[, w[, l]])

     Returns a month’s calendar in a multi-line string using the
     ‘formatmonth()’ of the *note TextCalendar: b3e. class.

     New in version 2.0.

 -- Function: calendar.prcal (year[, w[, l[c]]])

     Prints the calendar for an entire year as returned by *note
     calendar(): 1f.

 -- Function: calendar.calendar (year[, w[, l[c]]])

     Returns a 3-column calendar for an entire year as a multi-line
     string using the ‘formatyear()’ of the *note TextCalendar: b3e.
     class.

     New in version 2.0.

 -- Function: calendar.timegm (tuple)

     An unrelated but handy function that takes a time tuple such as
     returned by the *note gmtime(): b54. function in the *note time:
     17a. module, and returns the corresponding Unix timestamp value,
     assuming an epoch of 1970, and the POSIX encoding.  In fact, *note
     time.gmtime(): b54. and *note timegm(): b53. are each others’
     inverse.

     New in version 2.0.

  The *note calendar: 1f. module exports the following data attributes:

 -- Data: calendar.day_name

     An array that represents the days of the week in the current
     locale.

 -- Data: calendar.day_abbr

     An array that represents the abbreviated days of the week in the
     current locale.

 -- Data: calendar.month_name

     An array that represents the months of the year in the current
     locale.  This follows normal convention of January being month
     number 1, so it has a length of 13 and ‘month_name[0]’ is the empty
     string.

 -- Data: calendar.month_abbr

     An array that represents the abbreviated months of the year in the
     current locale.  This follows normal convention of January being
     month number 1, so it has a length of 13 and ‘month_abbr[0]’ is the
     empty string.

See also
........

Module *note datetime: 7d.

     Object-oriented interface to dates and times with similar
     functionality to the *note time: 17a. module.

Module *note time: 17a.

     Low-level time related functions.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/calendar.py


File: python.info,  Node: collections --- High-performance container datatypes,  Next: heapq --- Heap queue algorithm,  Prev: calendar --- General calendar-related functions,  Up: Data Types

5.8.3 ‘collections’ — High-performance container datatypes
----------------------------------------------------------

New in version 2.4.

  *Source code:* Lib/collections.py(1) and Lib/_abcoll.py(2)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module implements specialized container datatypes providing
alternatives to Python’s general purpose built-in containers, *note
dict: 305, *note list: 3bc, *note set: 36a, and *note tuple: 408.

*note namedtuple():       factory function for creating tuple subclasses with named fields         New in version 2.6.
1cf.                                                                                               

*note deque: 209.         list-like container with fast appends and pops on either end             New in version 2.4.
                                                                                                   
                                                                                                   
*note Counter: 1b6.       dict subclass for counting hashable objects                              New in version 2.7.
                                                                                                   
                                                                                                   
*note OrderedDict: 1b5.   dict subclass that remembers the order entries were added                New in version 2.7.
                                                                                                   
                                                                                                   
*note defaultdict: 8f8.   dict subclass that calls a factory function to supply missing values     New in version 2.5.
                                                                                                   

  In addition to the concrete container classes, the collections module
provides *note abstract base classes: b5b. that can be used to test
whether a class provides a particular interface, for example, whether it
is hashable or a mapping.

* Menu:

* Counter objects:: 
* deque objects:: 
* defaultdict objects:: 
* namedtuple() Factory Function for Tuples with Named Fields: namedtuple Factory Function for Tuples with Named Fields. 
* OrderedDict objects:: 
* Collections Abstract Base Classes:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/collections.py

   (2) http://hg.python.org/cpython/file/2.7/Lib/_abcoll.py


File: python.info,  Node: Counter objects,  Next: deque objects,  Up: collections --- High-performance container datatypes

5.8.3.1 ‘Counter’ objects
.........................

A counter tool is provided to support convenient and rapid tallies.  For
example:

     >>> # Tally occurrences of words in a list
     >>> cnt = Counter()
     >>> for word in ['red', 'blue', 'red', 'green', 'blue', 'blue']:
     ...     cnt[word] += 1
     >>> cnt
     Counter({'blue': 3, 'red': 2, 'green': 1})

     >>> # Find the ten most common words in Hamlet
     >>> import re
     >>> words = re.findall(r'\w+', open('hamlet.txt').read().lower())
     >>> Counter(words).most_common(10)
     [('the', 1143), ('and', 966), ('to', 762), ('of', 669), ('i', 631),
      ('you', 554),  ('a', 546), ('my', 514), ('hamlet', 471), ('in', 451)]

 -- Class: collections.Counter ([iterable-or-mapping])

     A *note Counter: 1b6. is a *note dict: 305. subclass for counting
     hashable objects.  It is an unordered collection where elements are
     stored as dictionary keys and their counts are stored as dictionary
     values.  Counts are allowed to be any integer value including zero
     or negative counts.  The *note Counter: 1b6. class is similar to
     bags or multisets in other languages.

     Elements are counted from an _iterable_ or initialized from another
     _mapping_ (or counter):

          >>> c = Counter()                           # a new, empty counter
          >>> c = Counter('gallahad')                 # a new counter from an iterable
          >>> c = Counter({'red': 4, 'blue': 2})      # a new counter from a mapping
          >>> c = Counter(cats=4, dogs=8)             # a new counter from keyword args

     Counter objects have a dictionary interface except that they return
     a zero count for missing items instead of raising a *note KeyError:
     205.:

          >>> c = Counter(['eggs', 'ham'])
          >>> c['bacon']                              # count of a missing element is zero
          0

     Setting a count to zero does not remove an element from a counter.
     Use ‘del’ to remove it entirely:

          >>> c['sausage'] = 0                        # counter entry with a zero count
          >>> del c['sausage']                        # del actually removes the entry

     New in version 2.7.

     Counter objects support three methods beyond those available for
     all dictionaries:

      -- Method: elements ()

          Return an iterator over elements repeating each as many times
          as its count.  Elements are returned in arbitrary order.  If
          an element’s count is less than one, *note elements(): 207.
          will ignore it.

               >>> c = Counter(a=4, b=2, c=0, d=-2)
               >>> list(c.elements())
               ['a', 'a', 'a', 'a', 'b', 'b']

      -- Method: most_common ([n])

          Return a list of the _n_ most common elements and their counts
          from the most common to the least.  If _n_ is not specified,
          *note most_common(): 206. returns _all_ elements in the
          counter.  Elements with equal counts are ordered arbitrarily:

               >>> Counter('abracadabra').most_common(3)
               [('a', 5), ('r', 2), ('b', 2)]

      -- Method: subtract ([iterable-or-mapping])

          Elements are subtracted from an _iterable_ or from another
          _mapping_ (or counter).  Like *note dict.update(): 402. but
          subtracts counts instead of replacing them.  Both inputs and
          outputs may be zero or negative.

               >>> c = Counter(a=4, b=2, c=0, d=-2)
               >>> d = Counter(a=1, b=2, c=3, d=4)
               >>> c.subtract(d)
               >>> c
               Counter({'a': 3, 'b': 0, 'c': -3, 'd': -6})

     The usual dictionary methods are available for *note Counter: 1b6.
     objects except for two which work differently for counters.

      -- Method: fromkeys (iterable)

          This class method is not implemented for *note Counter: 1b6.
          objects.

      -- Method: update ([iterable-or-mapping])

          Elements are counted from an _iterable_ or added-in from
          another _mapping_ (or counter).  Like *note dict.update():
          402. but adds counts instead of replacing them.  Also, the
          _iterable_ is expected to be a sequence of elements, not a
          sequence of ‘(key, value)’ pairs.

  Common patterns for working with *note Counter: 1b6. objects:

     sum(c.values())                 # total of all counts
     c.clear()                       # reset all counts
     list(c)                         # list unique elements
     set(c)                          # convert to a set
     dict(c)                         # convert to a regular dictionary
     c.items()                       # convert to a list of (elem, cnt) pairs
     Counter(dict(list_of_pairs))    # convert from a list of (elem, cnt) pairs
     c.most_common()[:-n-1:-1]       # n least common elements
     c += Counter()                  # remove zero and negative counts

  Several mathematical operations are provided for combining *note
Counter: 1b6. objects to produce multisets (counters that have counts
greater than zero).  Addition and subtraction combine counters by adding
or subtracting the counts of corresponding elements.  Intersection and
union return the minimum and maximum of corresponding counts.  Each
operation can accept inputs with signed counts, but the output will
exclude results with counts of zero or less.

     >>> c = Counter(a=3, b=1)
     >>> d = Counter(a=1, b=2)
     >>> c + d                       # add two counters together:  c[x] + d[x]
     Counter({'a': 4, 'b': 3})
     >>> c - d                       # subtract (keeping only positive counts)
     Counter({'a': 2})
     >>> c & d                       # intersection:  min(c[x], d[x])
     Counter({'a': 1, 'b': 1})
     >>> c | d                       # union:  max(c[x], d[x])
     Counter({'a': 3, 'b': 2})

     Note: Counters were primarily designed to work with positive
     integers to represent running counts; however, care was taken to
     not unnecessarily preclude use cases needing other types or
     negative values.  To help with those use cases, this section
     documents the minimum range and type restrictions.

        * The *note Counter: 1b6. class itself is a dictionary subclass
          with no restrictions on its keys and values.  The values are
          intended to be numbers representing counts, but you _could_
          store anything in the value field.

        * The ‘most_common()’ method requires only that the values be
          orderable.

        * For in-place operations such as ‘c[key] += 1’, the value type
          need only support addition and subtraction.  So fractions,
          floats, and decimals would work and negative values are
          supported.  The same is also true for ‘update()’ and
          ‘subtract()’ which allow negative and zero values for both
          inputs and outputs.

        * The multiset methods are designed only for use cases with
          positive values.  The inputs may be negative or zero, but only
          outputs with positive values are created.  There are no type
          restrictions, but the value type needs to support addition,
          subtraction, and comparison.

        * The ‘elements()’ method requires integer counts.  It ignores
          zero and negative counts.

See also
........

   * Counter class(1) adapted for Python 2.5 and an early Bag recipe(2)
     for Python 2.4.

   * Bag class(3) in Smalltalk.

   * Wikipedia entry for Multisets(4).

   * C++ multisets(5) tutorial with examples.

   * For mathematical operations on multisets and their use cases, see
     _Knuth, Donald.  The Art of Computer Programming Volume II, Section
     4.6.3, Exercise 19_.

   * To enumerate all distinct multisets of a given size over a given
     set of elements, see *note
     itertools.combinations_with_replacement(): b5f.

          map(Counter, combinations_with_replacement(’ABC’, 2)) –> AA AB
          AC BB BC CC

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/576611/

   (2) http://code.activestate.com/recipes/259174/

   (3) 
http://www.gnu.org/software/smalltalk/manual-base/html_node/Bag.html

   (4) http://en.wikipedia.org/wiki/Multiset

   (5) 
http://www.demo2s.com/Tutorial/Cpp/0380__set-multiset/Catalog0380__set-multiset.htm


File: python.info,  Node: deque objects,  Next: defaultdict objects,  Prev: Counter objects,  Up: collections --- High-performance container datatypes

5.8.3.2 ‘deque’ objects
.......................

 -- Class: collections.deque ([iterable[, maxlen]])

     Returns a new deque object initialized left-to-right (using *note
     append(): b61.) with data from _iterable_.  If _iterable_ is not
     specified, the new deque is empty.

     Deques are a generalization of stacks and queues (the name is
     pronounced "deck" and is short for "double-ended queue").  Deques
     support thread-safe, memory efficient appends and pops from either
     side of the deque with approximately the same O(1) performance in
     either direction.

     Though *note list: 3bc. objects support similar operations, they
     are optimized for fast fixed-length operations and incur O(n)
     memory movement costs for ‘pop(0)’ and ‘insert(0, v)’ operations
     which change both the size and position of the underlying data
     representation.

     New in version 2.4.

     If _maxlen_ is not specified or is _None_, deques may grow to an
     arbitrary length.  Otherwise, the deque is bounded to the specified
     maximum length.  Once a bounded length deque is full, when new
     items are added, a corresponding number of items are discarded from
     the opposite end.  Bounded length deques provide functionality
     similar to the ‘tail’ filter in Unix.  They are also useful for
     tracking transactions and other pools of data where only the most
     recent activity is of interest.

     Changed in version 2.6: Added _maxlen_ parameter.

     Deque objects support the following methods:

      -- Method: append (x)

          Add _x_ to the right side of the deque.

      -- Method: appendleft (x)

          Add _x_ to the left side of the deque.

      -- Method: clear ()

          Remove all elements from the deque leaving it with length 0.

      -- Method: count (x)

          Count the number of deque elements equal to _x_.

          New in version 2.7.

      -- Method: extend (iterable)

          Extend the right side of the deque by appending elements from
          the iterable argument.

      -- Method: extendleft (iterable)

          Extend the left side of the deque by appending elements from
          _iterable_.  Note, the series of left appends results in
          reversing the order of elements in the iterable argument.

      -- Method: pop ()

          Remove and return an element from the right side of the deque.
          If no elements are present, raises an *note IndexError: 4e1.

      -- Method: popleft ()

          Remove and return an element from the left side of the deque.
          If no elements are present, raises an *note IndexError: 4e1.

      -- Method: remove (value)

          Removed the first occurrence of _value_.  If not found, raises
          a *note ValueError: 236.

          New in version 2.5.

      -- Method: reverse ()

          Reverse the elements of the deque in-place and then return
          ‘None’.

          New in version 2.7.

      -- Method: rotate (n)

          Rotate the deque _n_ steps to the right.  If _n_ is negative,
          rotate to the left.  Rotating one step to the right is
          equivalent to: ‘d.appendleft(d.pop())’.

     Deque objects also provide one read-only attribute:

      -- Attribute: maxlen

          Maximum size of a deque or _None_ if unbounded.

          New in version 2.7.

  In addition to the above, deques support iteration, pickling,
‘len(d)’, ‘reversed(d)’, ‘copy.copy(d)’, ‘copy.deepcopy(d)’, membership
testing with the *note in: 428. operator, and subscript references such
as ‘d[-1]’.  Indexed access is O(1) at both ends but slows to O(n) in
the middle.  For fast random access, use lists instead.

  Example:

     >>> from collections import deque
     >>> d = deque('ghi')                 # make a new deque with three items
     >>> for elem in d:                   # iterate over the deque's elements
     ...     print elem.upper()
     G
     H
     I

     >>> d.append('j')                    # add a new entry to the right side
     >>> d.appendleft('f')                # add a new entry to the left side
     >>> d                                # show the representation of the deque
     deque(['f', 'g', 'h', 'i', 'j'])

     >>> d.pop()                          # return and remove the rightmost item
     'j'
     >>> d.popleft()                      # return and remove the leftmost item
     'f'
     >>> list(d)                          # list the contents of the deque
     ['g', 'h', 'i']
     >>> d[0]                             # peek at leftmost item
     'g'
     >>> d[-1]                            # peek at rightmost item
     'i'

     >>> list(reversed(d))                # list the contents of a deque in reverse
     ['i', 'h', 'g']
     >>> 'h' in d                         # search the deque
     True
     >>> d.extend('jkl')                  # add multiple elements at once
     >>> d
     deque(['g', 'h', 'i', 'j', 'k', 'l'])
     >>> d.rotate(1)                      # right rotation
     >>> d
     deque(['l', 'g', 'h', 'i', 'j', 'k'])
     >>> d.rotate(-1)                     # left rotation
     >>> d
     deque(['g', 'h', 'i', 'j', 'k', 'l'])

     >>> deque(reversed(d))               # make a new deque in reverse order
     deque(['l', 'k', 'j', 'i', 'h', 'g'])
     >>> d.clear()                        # empty the deque
     >>> d.pop()                          # cannot pop from an empty deque
     Traceback (most recent call last):
       File "<pyshell#6>", line 1, in -toplevel-
         d.pop()
     IndexError: pop from an empty deque

     >>> d.extendleft('abc')              # extendleft() reverses the input order
     >>> d
     deque(['c', 'b', 'a'])

* Menu:

* deque Recipes:: 

