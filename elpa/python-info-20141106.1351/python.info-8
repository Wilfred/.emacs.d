This is python.info, produced by makeinfo version 5.2 from python.texi.

     Python 2.7.8, November 06, 2014

     Georg Brandl

     Copyright © 1990-2014, Python Software Foundation

INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.1.3.


File: python.info,  Node: deque Recipes,  Up: deque objects

5.8.3.3 ‘deque’ Recipes
.......................

This section shows various approaches to working with deques.

  Bounded length deques provide functionality similar to the ‘tail’
filter in Unix:

     def tail(filename, n=10):
         'Return the last n lines of a file'
         return deque(open(filename), n)

  Another approach to using deques is to maintain a sequence of recently
added elements by appending to the right and popping to the left:

     def moving_average(iterable, n=3):
         # moving_average([40, 30, 50, 46, 39, 44]) --> 40.0 42.0 45.0 43.0
         # http://en.wikipedia.org/wiki/Moving_average
         it = iter(iterable)
         d = deque(itertools.islice(it, n-1))
         d.appendleft(0)
         s = sum(d)
         for elem in it:
             s += elem - d.popleft()
             d.append(elem)
             yield s / float(n)

  The ‘rotate()’ method provides a way to implement *note deque: 209.
slicing and deletion.  For example, a pure Python implementation of ‘del
d[n]’ relies on the ‘rotate()’ method to position elements to be popped:

     def delete_nth(d, n):
         d.rotate(-n)
         d.popleft()
         d.rotate(n)

  To implement *note deque: 209. slicing, use a similar approach
applying ‘rotate()’ to bring a target element to the left side of the
deque.  Remove old entries with ‘popleft()’, add new entries with
‘extend()’, and then reverse the rotation.  With minor variations on
that approach, it is easy to implement Forth style stack manipulations
such as ‘dup’, ‘drop’, ‘swap’, ‘over’, ‘pick’, ‘rot’, and ‘roll’.


File: python.info,  Node: defaultdict objects,  Next: namedtuple Factory Function for Tuples with Named Fields,  Prev: deque objects,  Up: collections --- High-performance container datatypes

5.8.3.4 ‘defaultdict’ objects
.............................

 -- Class: collections.defaultdict ([default_factory[, ...]])

     Returns a new dictionary-like object.  *note defaultdict: 8f8. is a
     subclass of the built-in *note dict: 305. class.  It overrides one
     method and adds one writable instance variable.  The remaining
     functionality is the same as for the *note dict: 305. class and is
     not documented here.

     The first argument provides the initial value for the *note
     default_factory: b6c. attribute; it defaults to ‘None’.  All
     remaining arguments are treated the same as if they were passed to
     the *note dict: 305. constructor, including keyword arguments.

     New in version 2.5.

     *note defaultdict: 8f8. objects support the following method in
     addition to the standard *note dict: 305. operations:

      -- Method: __missing__ (key)

          If the *note default_factory: b6c. attribute is ‘None’, this
          raises a *note KeyError: 205. exception with the _key_ as
          argument.

          If *note default_factory: b6c. is not ‘None’, it is called
          without arguments to provide a default value for the given
          _key_, this value is inserted in the dictionary for the _key_,
          and returned.

          If calling *note default_factory: b6c. raises an exception
          this exception is propagated unchanged.

          This method is called by the *note __getitem__(): 44f. method
          of the *note dict: 305. class when the requested key is not
          found; whatever it returns or raises is then returned or
          raised by *note __getitem__(): 44f.

          Note that *note __missing__(): b6d. is _not_ called for any
          operations besides *note __getitem__(): 44f.  This means that
          ‘get()’ will, like normal dictionaries, return ‘None’ as a
          default rather than using *note default_factory: b6c.

     *note defaultdict: 8f8. objects support the following instance
     variable:

      -- Attribute: default_factory

          This attribute is used by the *note __missing__(): b6d.
          method; it is initialized from the first argument to the
          constructor, if present, or to ‘None’, if absent.

* Menu:

* defaultdict Examples:: 


File: python.info,  Node: defaultdict Examples,  Up: defaultdict objects

5.8.3.5 ‘defaultdict’ Examples
..............................

Using *note list: 3bc. as the ‘default_factory’, it is easy to group a
sequence of key-value pairs into a dictionary of lists:

     >>> s = [('yellow', 1), ('blue', 2), ('yellow', 3), ('blue', 4), ('red', 1)]
     >>> d = defaultdict(list)
     >>> for k, v in s:
     ...     d[k].append(v)
     ...
     >>> d.items()
     [('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]

  When each key is encountered for the first time, it is not already in
the mapping; so an entry is automatically created using the
‘default_factory’ function which returns an empty *note list: 3bc.  The
‘list.append()’ operation then attaches the value to the new list.  When
keys are encountered again, the look-up proceeds normally (returning the
list for that key) and the ‘list.append()’ operation adds another value
to the list.  This technique is simpler and faster than an equivalent
technique using *note dict.setdefault(): 903.:

     >>> d = {}
     >>> for k, v in s:
     ...     d.setdefault(k, []).append(v)
     ...
     >>> d.items()
     [('blue', [2, 4]), ('red', [1]), ('yellow', [1, 3])]

  Setting the ‘default_factory’ to *note int: 1f2. makes the *note
defaultdict: 8f8. useful for counting (like a bag or multiset in other
languages):

     >>> s = 'mississippi'
     >>> d = defaultdict(int)
     >>> for k in s:
     ...     d[k] += 1
     ...
     >>> d.items()
     [('i', 4), ('p', 2), ('s', 4), ('m', 1)]

  When a letter is first encountered, it is missing from the mapping, so
the ‘default_factory’ function calls *note int(): 1f2. to supply a
default count of zero.  The increment operation then builds up the count
for each letter.

  The function *note int(): 1f2. which always returns zero is just a
special case of constant functions.  A faster and more flexible way to
create constant functions is to use *note itertools.repeat(): b6f. which
can supply any constant value (not just zero):

     >>> def constant_factory(value):
     ...     return itertools.repeat(value).next
     >>> d = defaultdict(constant_factory('<missing>'))
     >>> d.update(name='John', action='ran')
     >>> '%(name)s %(action)s to %(object)s' % d
     'John ran to <missing>'

  Setting the ‘default_factory’ to *note set: 36a. makes the *note
defaultdict: 8f8. useful for building a dictionary of sets:

     >>> s = [('red', 1), ('blue', 2), ('red', 3), ('blue', 4), ('red', 1), ('blue', 4)]
     >>> d = defaultdict(set)
     >>> for k, v in s:
     ...     d[k].add(v)
     ...
     >>> d.items()
     [('blue', set([2, 4])), ('red', set([1, 3]))]


File: python.info,  Node: namedtuple Factory Function for Tuples with Named Fields,  Next: OrderedDict objects,  Prev: defaultdict objects,  Up: collections --- High-performance container datatypes

5.8.3.6 ‘namedtuple()’ Factory Function for Tuples with Named Fields
....................................................................

Named tuples assign meaning to each position in a tuple and allow for
more readable, self-documenting code.  They can be used wherever regular
tuples are used, and they add the ability to access fields by name
instead of position index.

 -- Function: collections.namedtuple (typename, field_names[,
          verbose=False][, rename=False])

     Returns a new tuple subclass named _typename_.  The new subclass is
     used to create tuple-like objects that have fields accessible by
     attribute lookup as well as being indexable and iterable.
     Instances of the subclass also have a helpful docstring (with
     typename and field_names) and a helpful *note __repr__(): 486.
     method which lists the tuple contents in a ‘name=value’ format.

     The _field_names_ are a sequence of strings such as ‘['x', 'y']’.
     Alternatively, _field_names_ can be a single string with each
     fieldname separated by whitespace and/or commas, for example ‘'x
     y'’ or ‘'x, y'’.

     Any valid Python identifier may be used for a fieldname except for
     names starting with an underscore.  Valid identifiers consist of
     letters, digits, and underscores but do not start with a digit or
     underscore and cannot be a *note keyword: fd. such as _class_,
     _for_, _return_, _global_, _pass_, _print_, or _raise_.

     If _rename_ is true, invalid fieldnames are automatically replaced
     with positional names.  For example, ‘['abc', 'def', 'ghi', 'abc']’
     is converted to ‘['abc', '_1', 'ghi', '_3']’, eliminating the
     keyword ‘def’ and the duplicate fieldname ‘abc’.

     If _verbose_ is true, the class definition is printed just before
     being built.

     Named tuple instances do not have per-instance dictionaries, so
     they are lightweight and require no more memory than regular
     tuples.

     New in version 2.6.

     Changed in version 2.7: added support for _rename_.

  Example:

     >>> Point = namedtuple('Point', ['x', 'y'], verbose=True)
     class Point(tuple):
         'Point(x, y)'

         __slots__ = ()

         _fields = ('x', 'y')

         def __new__(_cls, x, y):
             'Create a new instance of Point(x, y)'
             return _tuple.__new__(_cls, (x, y))

         @classmethod
         def _make(cls, iterable, new=tuple.__new__, len=len):
             'Make a new Point object from a sequence or iterable'
             result = new(cls, iterable)
             if len(result) != 2:
                 raise TypeError('Expected 2 arguments, got %d' % len(result))
             return result

         def __repr__(self):
             'Return a nicely formatted representation string'
             return 'Point(x=%r, y=%r)' % self

         def _asdict(self):
             'Return a new OrderedDict which maps field names to their values'
             return OrderedDict(zip(self._fields, self))

         def _replace(_self, **kwds):
             'Return a new Point object replacing specified fields with new values'
             result = _self._make(map(kwds.pop, ('x', 'y'), _self))
             if kwds:
                 raise ValueError('Got unexpected field names: %r' % kwds.keys())
             return result

         def __getnewargs__(self):
             'Return self as a plain tuple.   Used by copy and pickle.'
             return tuple(self)

         __dict__ = _property(_asdict)

         def __getstate__(self):
             'Exclude the OrderedDict from pickling'
             pass

         x = _property(_itemgetter(0), doc='Alias for field number 0')

         y = _property(_itemgetter(1), doc='Alias for field number 1')


     >>> p = Point(11, y=22)     # instantiate with positional or keyword arguments
     >>> p[0] + p[1]             # indexable like the plain tuple (11, 22)
     33
     >>> x, y = p                # unpack like a regular tuple
     >>> x, y
     (11, 22)
     >>> p.x + p.y               # fields also accessible by name
     33
     >>> p                       # readable __repr__ with a name=value style
     Point(x=11, y=22)

  Named tuples are especially useful for assigning field names to result
tuples returned by the *note csv: 77. or *note sqlite3: 15f. modules:

     EmployeeRecord = namedtuple('EmployeeRecord', 'name, age, title, department, paygrade')

     import csv
     for emp in map(EmployeeRecord._make, csv.reader(open("employees.csv", "rb"))):
         print emp.name, emp.title

     import sqlite3
     conn = sqlite3.connect('/companydata')
     cursor = conn.cursor()
     cursor.execute('SELECT name, age, title, department, paygrade FROM employees')
     for emp in map(EmployeeRecord._make, cursor.fetchall()):
         print emp.name, emp.title

  In addition to the methods inherited from tuples, named tuples support
three additional methods and one attribute.  To prevent conflicts with
field names, the method and attribute names start with an underscore.

 -- Class Method: somenamedtuple._make (iterable)

     Class method that makes a new instance from an existing sequence or
     iterable.

          >>> t = [11, 22]
          >>> Point._make(t)
          Point(x=11, y=22)

 -- Method: somenamedtuple._asdict ()

     Return a new *note OrderedDict: 1b5. which maps field names to
     their corresponding values:

          >>> p._asdict()
          OrderedDict([('x', 11), ('y', 22)])

     Changed in version 2.7: Returns an *note OrderedDict: 1b5. instead
     of a regular *note dict: 305.

 -- Method: somenamedtuple._replace (kwargs)

     Return a new instance of the named tuple replacing specified fields
     with new values:

          >>> p = Point(x=11, y=22)
          >>> p._replace(x=33)
          Point(x=33, y=22)

          >>> for partnum, record in inventory.items():
                  inventory[partnum] = record._replace(price=newprices[partnum], timestamp=time.now())

 -- Attribute: somenamedtuple._fields

     Tuple of strings listing the field names.  Useful for introspection
     and for creating new named tuple types from existing named tuples.

          >>> p._fields            # view the field names
          ('x', 'y')

          >>> Color = namedtuple('Color', 'red green blue')
          >>> Pixel = namedtuple('Pixel', Point._fields + Color._fields)
          >>> Pixel(11, 22, 128, 255, 0)
          Pixel(x=11, y=22, red=128, green=255, blue=0)

  To retrieve a field whose name is stored in a string, use the *note
getattr(): 875. function:

     >>> getattr(p, 'x')
     11

  To convert a dictionary to a named tuple, use the double-star-operator
(as described in *note Unpacking Argument Lists: 550.):

     >>> d = {'x': 11, 'y': 22}
     >>> Point(**d)
     Point(x=11, y=22)

  Since a named tuple is a regular Python class, it is easy to add or
change functionality with a subclass.  Here is how to add a calculated
field and a fixed-width print format:

     >>> class Point(namedtuple('Point', 'x y')):
             __slots__ = ()
             @property
             def hypot(self):
                 return (self.x ** 2 + self.y ** 2) ** 0.5
             def __str__(self):
                 return 'Point: x=%6.3f  y=%6.3f  hypot=%6.3f' % (self.x, self.y, self.hypot)

     >>> for p in Point(3, 4), Point(14, 5/7.):
             print p
     Point: x= 3.000  y= 4.000  hypot= 5.000
     Point: x=14.000  y= 0.714  hypot=14.018

  The subclass shown above sets ‘__slots__’ to an empty tuple.  This
helps keep memory requirements low by preventing the creation of
instance dictionaries.

  Subclassing is not useful for adding new, stored fields.  Instead,
simply create a new named tuple type from the ‘_fields’ attribute:

     >>> Point3D = namedtuple('Point3D', Point._fields + ('z',))

  Default values can be implemented by using ‘_replace()’ to customize a
prototype instance:

     >>> Account = namedtuple('Account', 'owner balance transaction_count')
     >>> default_account = Account('<owner name>', 0.0, 0)
     >>> johns_account = default_account._replace(owner='John')

  Enumerated constants can be implemented with named tuples, but it is
simpler and more efficient to use a simple class declaration:

     >>> Status = namedtuple('Status', 'open pending closed')._make(range(3))
     >>> Status.open, Status.pending, Status.closed
     (0, 1, 2)
     >>> class Status:
             open, pending, closed = range(3)

See also
........

Named tuple recipe(1) adapted for Python 2.4.

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/500261/


File: python.info,  Node: OrderedDict objects,  Next: Collections Abstract Base Classes,  Prev: namedtuple Factory Function for Tuples with Named Fields,  Up: collections --- High-performance container datatypes

5.8.3.7 ‘OrderedDict’ objects
.............................

Ordered dictionaries are just like regular dictionaries but they
remember the order that items were inserted.  When iterating over an
ordered dictionary, the items are returned in the order their keys were
first added.

 -- Class: collections.OrderedDict ([items])

     Return an instance of a dict subclass, supporting the usual *note
     dict: 305. methods.  An _OrderedDict_ is a dict that remembers the
     order that keys were first inserted.  If a new entry overwrites an
     existing entry, the original insertion position is left unchanged.
     Deleting an entry and reinserting it will move it to the end.

     New in version 2.7.

 -- Method: OrderedDict.popitem (last=True)

     The *note popitem(): 1cd. method for ordered dictionaries returns
     and removes a (key, value) pair.  The pairs are returned in LIFO
     order if _last_ is true or FIFO order if false.

  In addition to the usual mapping methods, ordered dictionaries also
support reverse iteration using *note reversed(): 3f8.

  Equality tests between *note OrderedDict: 1b5. objects are
order-sensitive and are implemented as
‘list(od1.items())==list(od2.items())’.  Equality tests between *note
OrderedDict: 1b5. objects and other *note Mapping: 20d. objects are
order-insensitive like regular dictionaries.  This allows *note
OrderedDict: 1b5. objects to be substituted anywhere a regular
dictionary is used.

  The *note OrderedDict: 1b5. constructor and ‘update()’ method both
accept keyword arguments, but their order is lost because Python’s
function call semantics pass-in keyword arguments using a regular
unordered dictionary.

See also
........

Equivalent OrderedDict recipe(1) that runs on Python 2.4 or later.

* Menu:

* OrderedDict Examples and Recipes:: 

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/576693/


File: python.info,  Node: OrderedDict Examples and Recipes,  Up: OrderedDict objects

5.8.3.8 ‘OrderedDict’ Examples and Recipes
..........................................

Since an ordered dictionary remembers its insertion order, it can be
used in conjuction with sorting to make a sorted dictionary:

     >>> # regular unsorted dictionary
     >>> d = {'banana': 3, 'apple':4, 'pear': 1, 'orange': 2}

     >>> # dictionary sorted by key
     >>> OrderedDict(sorted(d.items(), key=lambda t: t[0]))
     OrderedDict([('apple', 4), ('banana', 3), ('orange', 2), ('pear', 1)])

     >>> # dictionary sorted by value
     >>> OrderedDict(sorted(d.items(), key=lambda t: t[1]))
     OrderedDict([('pear', 1), ('orange', 2), ('banana', 3), ('apple', 4)])

     >>> # dictionary sorted by length of the key string
     >>> OrderedDict(sorted(d.items(), key=lambda t: len(t[0])))
     OrderedDict([('pear', 1), ('apple', 4), ('orange', 2), ('banana', 3)])

  The new sorted dictionaries maintain their sort order when entries are
deleted.  But when new keys are added, the keys are appended to the end
and the sort is not maintained.

  It is also straight-forward to create an ordered dictionary variant
that remembers the order the keys were _last_ inserted.  If a new entry
overwrites an existing entry, the original insertion position is changed
and moved to the end:

     class LastUpdatedOrderedDict(OrderedDict):
         'Store items in the order the keys were last added'

         def __setitem__(self, key, value):
             if key in self:
                 del self[key]
             OrderedDict.__setitem__(self, key, value)

  An ordered dictionary can be combined with the *note Counter: 1b6.
class so that the counter remembers the order elements are first
encountered:

     class OrderedCounter(Counter, OrderedDict):
          'Counter that remembers the order elements are first encountered'

          def __repr__(self):
              return '%s(%r)' % (self.__class__.__name__, OrderedDict(self))

          def __reduce__(self):
              return self.__class__, (OrderedDict(self),)


File: python.info,  Node: Collections Abstract Base Classes,  Prev: OrderedDict objects,  Up: collections --- High-performance container datatypes

5.8.3.9 Collections Abstract Base Classes
.........................................

The collections module offers the following *note ABCs: 886.:

ABC                           Inherits from             Abstract Methods           Mixin Methods
                                                                                   
--------------------------------------------------------------------------------------------------------------------------------------------
                                                                                   
*note Container: b77.                                   ‘__contains__’
                                                        
                                                                                   
*note Hashable: b78.                                    ‘__hash__’
                                                        
                                                                                   
*note Iterable: b79.                                    ‘__iter__’
                                                        
                                                                                   
*note Iterator: b7a.          *note Iterable: b79.      ‘next’                     ‘__iter__’
                                                                                   
                                                                                   
*note Sized: b7b.                                       ‘__len__’
                                                        
                                                                                   
*note Callable: b7c.                                    ‘__call__’
                                                        
                                                                                   
*note Sequence: b7d.          *note Sized: b7b, *note   ‘__getitem__’, ‘__len__’   ‘__contains__’, ‘__iter__’, ‘__reversed__’, ‘index’,
                              Iterable: b79, *note                                 and ‘count’
                              Container: b77.                                      
                              
                                                                                   
*note MutableSequence: b7e.   *note Sequence: b7d.      ‘__getitem__’,             Inherited *note Sequence: b7d. methods and ‘append’,
                                                        ‘__setitem__’,             ‘reverse’, ‘extend’, ‘pop’, ‘remove’, and ‘__iadd__’
                                                        ‘__delitem__’,             
                                                        ‘__len__’, ‘insert’
                                                        
                                                                                   
*note Set: b7f.               *note Sized: b7b, *note   ‘__contains__’,            ‘__le__’, ‘__lt__’, ‘__eq__’, ‘__ne__’, ‘__gt__’,
                              Iterable: b79, *note      ‘__iter__’, ‘__len__’      ‘__ge__’, ‘__and__’, ‘__or__’, ‘__sub__’, ‘__xor__’,
                              Container: b77.                                      and ‘isdisjoint’
                                                                                   
                                                                                   
*note MutableSet: b80.        *note Set: b7f.           ‘__contains__’,            Inherited *note Set: b7f. methods and ‘clear’, ‘pop’,
                                                        ‘__iter__’, ‘__len__’,     ‘remove’, ‘__ior__’, ‘__iand__’, ‘__ixor__’, and
                                                        ‘add’, ‘discard’           ‘__isub__’
                                                                                   
                                                                                   
*note Mapping: 20d.           *note Sized: b7b, *note   ‘__getitem__’,             ‘__contains__’, ‘keys’, ‘items’, ‘values’, ‘get’,
                              Iterable: b79, *note      ‘__iter__’, ‘__len__’      ‘__eq__’, and ‘__ne__’
                              Container: b77.                                      
                              
                                                                                   
*note MutableMapping: b81.    *note Mapping: 20d.       ‘__getitem__’,             Inherited *note Mapping: 20d. methods and ‘pop’,
                                                        ‘__setitem__’,             ‘popitem’, ‘clear’, ‘update’, and ‘setdefault’
                                                        ‘__delitem__’,             
                                                        ‘__iter__’, ‘__len__’
                                                        
                                                                                   
*note MappingView: b82.       *note Sized: b7b.                                    ‘__len__’
                                                                                   
                                                                                   
*note ItemsView: b83.         *note MappingView: b82,                              ‘__contains__’, ‘__iter__’
                              *note Set: b7f.                                      
                              
                                                                                   
*note KeysView: b84.          *note MappingView: b82,                              ‘__contains__’, ‘__iter__’
                              *note Set: b7f.                                      
                              
                                                                                   
*note ValuesView: b85.        *note MappingView: b82.                              ‘__contains__’, ‘__iter__’
                                                                                   

 -- Class: collections.Container
 -- Class: collections.Hashable
 -- Class: collections.Sized
 -- Class: collections.Callable

     ABCs for classes that provide respectively the methods *note
     __contains__(): 322, *note __hash__(): 335, *note __len__(): 40a,
     and *note __call__(): 6fa.

 -- Class: collections.Iterable

     ABC for classes that provide the *note __iter__(): 321. method.
     See also the definition of *note iterable: 8cc.

 -- Class: collections.Iterator

     ABC for classes that provide the *note __iter__(): 321. and *note
     next(): 399. methods.  See also the definition of *note iterator:
     87f.

 -- Class: collections.Sequence
 -- Class: collections.MutableSequence

     ABCs for read-only and mutable *note sequences: b86.

 -- Class: collections.Set
 -- Class: collections.MutableSet

     ABCs for read-only and mutable sets.

 -- Class: collections.Mapping
 -- Class: collections.MutableMapping

     ABCs for read-only and mutable *note mappings: 8f7.

 -- Class: collections.MappingView
 -- Class: collections.ItemsView
 -- Class: collections.KeysView
 -- Class: collections.ValuesView

     ABCs for mapping, items, keys, and values *note views: b87.

  These ABCs allow us to ask classes or instances if they provide
particular functionality, for example:

     size = None
     if isinstance(myvar, collections.Sized):
         size = len(myvar)

  Several of the ABCs are also useful as mixins that make it easier to
develop classes supporting container APIs.  For example, to write a
class supporting the full *note Set: b7f. API, it only necessary to
supply the three underlying abstract methods: *note __contains__(): 322,
*note __iter__(): 321, and *note __len__(): 40a.  The ABC supplies the
remaining methods such as *note __and__(): 73a. and ‘isdisjoint()’

     class ListBasedSet(collections.Set):
          ''' Alternate set implementation favoring space over speed
              and not requiring the set elements to be hashable. '''
          def __init__(self, iterable):
              self.elements = lst = []
              for value in iterable:
                  if value not in lst:
                      lst.append(value)
          def __iter__(self):
              return iter(self.elements)
          def __contains__(self, value):
              return value in self.elements
          def __len__(self):
              return len(self.elements)

     s1 = ListBasedSet('abcdef')
     s2 = ListBasedSet('defghi')
     overlap = s1 & s2            # The __and__() method is supported automatically

  Notes on using *note Set: b7f. and *note MutableSet: b80. as a mixin:

  1. Since some set operations create new sets, the default mixin
     methods need a way to create new instances from an iterable.  The
     class constructor is assumed to have a signature in the form
     ‘ClassName(iterable)’.  That assumption is factored-out to an
     internal classmethod called ‘_from_iterable()’ which calls
     ‘cls(iterable)’ to produce a new set.  If the *note Set: b7f. mixin
     is being used in a class with a different constructor signature,
     you will need to override ‘_from_iterable()’ with a classmethod
     that can construct new instances from an iterable argument.

  2. To override the comparisons (presumably for speed, as the semantics
     are fixed), redefine *note __le__(): 21e. and then the other
     operations will automatically follow suit.

  3. The *note Set: b7f. mixin provides a ‘_hash()’ method to compute a
     hash value for the set; however, *note __hash__(): 335. is not
     defined because not all sets are hashable or immutable.  To add set
     hashabilty using mixins, inherit from both *note Set(): b7f. and
     *note Hashable(): b78, then define ‘__hash__ = Set._hash’.

See also
........

   * OrderedSet recipe(1) for an example built on *note MutableSet: b80.

   * For more about ABCs, see the *note abc: 4. module and PEP 3119(2).

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/576694/

   (2) http://www.python.org/dev/peps/pep-3119


File: python.info,  Node: heapq --- Heap queue algorithm,  Next: bisect --- Array bisection algorithm,  Prev: collections --- High-performance container datatypes,  Up: Data Types

5.8.4 ‘heapq’ — Heap queue algorithm
------------------------------------

New in version 2.3.

  *Source code:* Lib/heapq.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module provides an implementation of the heap queue algorithm,
also known as the priority queue algorithm.

  Heaps are binary trees for which every parent node has a value less
than or equal to any of its children.  This implementation uses arrays
for which ‘heap[k] <= heap[2*k+1]’ and ‘heap[k] <= heap[2*k+2]’ for all
_k_, counting elements from zero.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that its smallest element is always the root,
‘heap[0]’.

  The API below differs from textbook heap algorithms in two aspects:
(a) We use zero-based indexing.  This makes the relationship between the
index for a node and the indexes for its children slightly less obvious,
but is more suitable since Python uses zero-based indexing.  (b) Our pop
method returns the smallest item, not the largest (called a "min heap"
in textbooks; a "max heap" is more common in texts because of its
suitability for in-place sorting).

  These two make it possible to view the heap as a regular Python list
without surprises: ‘heap[0]’ is the smallest item, and ‘heap.sort()’
maintains the heap invariant!

  To create a heap, use a list initialized to ‘[]’, or you can transform
a populated list into a heap via function *note heapify(): b8a.

  The following functions are provided:

 -- Function: heapq.heappush (heap, item)

     Push the value _item_ onto the _heap_, maintaining the heap
     invariant.

 -- Function: heapq.heappop (heap)

     Pop and return the smallest item from the _heap_, maintaining the
     heap invariant.  If the heap is empty, *note IndexError: 4e1. is
     raised.

 -- Function: heapq.heappushpop (heap, item)

     Push _item_ on the heap, then pop and return the smallest item from
     the _heap_.  The combined action runs more efficiently than *note
     heappush(): b8b. followed by a separate call to *note heappop():
     b8c.

     New in version 2.6.

 -- Function: heapq.heapify (x)

     Transform list _x_ into a heap, in-place, in linear time.

 -- Function: heapq.heapreplace (heap, item)

     Pop and return the smallest item from the _heap_, and also push the
     new _item_.  The heap size doesn’t change.  If the heap is empty,
     *note IndexError: 4e1. is raised.

     This one step operation is more efficient than a *note heappop():
     b8c. followed by *note heappush(): b8b. and can be more appropriate
     when using a fixed-size heap.  The pop/push combination always
     returns an element from the heap and replaces it with _item_.

     The value returned may be larger than the _item_ added.  If that
     isn’t desired, consider using *note heappushpop(): b8d. instead.
     Its push/pop combination returns the smaller of the two values,
     leaving the larger value on the heap.

  The module also offers three general purpose functions based on heaps.

 -- Function: heapq.merge (*iterables)

     Merge multiple sorted inputs into a single sorted output (for
     example, merge timestamped entries from multiple log files).
     Returns an *note iterator: 87f. over the sorted values.

     Similar to ‘sorted(itertools.chain(*iterables))’ but returns an
     iterable, does not pull the data into memory all at once, and
     assumes that each of the input streams is already sorted (smallest
     to largest).

     New in version 2.6.

 -- Function: heapq.nlargest (n, iterable[, key])

     Return a list with the _n_ largest elements from the dataset
     defined by _iterable_.  _key_, if provided, specifies a function of
     one argument that is used to extract a comparison key from each
     element in the iterable: ‘key=str.lower’ Equivalent to:
     ‘sorted(iterable, key=key, reverse=True)[:n]’

     New in version 2.4.

     Changed in version 2.5: Added the optional _key_ argument.

 -- Function: heapq.nsmallest (n, iterable[, key])

     Return a list with the _n_ smallest elements from the dataset
     defined by _iterable_.  _key_, if provided, specifies a function of
     one argument that is used to extract a comparison key from each
     element in the iterable: ‘key=str.lower’ Equivalent to:
     ‘sorted(iterable, key=key)[:n]’

     New in version 2.4.

     Changed in version 2.5: Added the optional _key_ argument.

  The latter two functions perform best for smaller values of _n_.  For
larger values, it is more efficient to use the *note sorted(): 223.
function.  Also, when ‘n==1’, it is more efficient to use the built-in
*note min(): 224. and *note max(): 225. functions.

* Menu:

* Basic Examples:: 
* Priority Queue Implementation Notes:: 
* Theory:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/heapq.py


File: python.info,  Node: Basic Examples,  Next: Priority Queue Implementation Notes,  Up: heapq --- Heap queue algorithm

5.8.4.1 Basic Examples
......................

A heapsort(1) can be implemented by pushing all values onto a heap and
then popping off the smallest values one at a time:

     >>> def heapsort(iterable):
     ...     'Equivalent to sorted(iterable)'
     ...     h = []
     ...     for value in iterable:
     ...         heappush(h, value)
     ...     return [heappop(h) for i in range(len(h))]
     ...
     >>> heapsort([1, 3, 5, 7, 9, 2, 4, 6, 8, 0])
     [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

  Heap elements can be tuples.  This is useful for assigning comparison
values (such as task priorities) alongside the main record being
tracked:

     >>> h = []
     >>> heappush(h, (5, 'write code'))
     >>> heappush(h, (7, 'release product'))
     >>> heappush(h, (1, 'write spec'))
     >>> heappush(h, (3, 'create tests'))
     >>> heappop(h)
     (1, 'write spec')

   ---------- Footnotes ----------

   (1) http://en.wikipedia.org/wiki/Heapsort


File: python.info,  Node: Priority Queue Implementation Notes,  Next: Theory,  Prev: Basic Examples,  Up: heapq --- Heap queue algorithm

5.8.4.2 Priority Queue Implementation Notes
...........................................

A priority queue(1) is common use for a heap, and it presents several
implementation challenges:

   * Sort stability: how do you get two tasks with equal priorities to
     be returned in the order they were originally added?

   * In the future with Python 3, tuple comparison breaks for (priority,
     task) pairs if the priorities are equal and the tasks do not have a
     default comparison order.

   * If the priority of a task changes, how do you move it to a new
     position in the heap?

   * Or if a pending task needs to be deleted, how do you find it and
     remove it from the queue?

  A solution to the first two challenges is to store entries as
3-element list including the priority, an entry count, and the task.
The entry count serves as a tie-breaker so that two tasks with the same
priority are returned in the order they were added.  And since no two
entry counts are the same, the tuple comparison will never attempt to
directly compare two tasks.

  The remaining challenges revolve around finding a pending task and
making changes to its priority or removing it entirely.  Finding a task
can be done with a dictionary pointing to an entry in the queue.

  Removing the entry or changing its priority is more difficult because
it would break the heap structure invariants.  So, a possible solution
is to mark the existing entry as removed and add a new entry with the
revised priority:

     pq = []                         # list of entries arranged in a heap
     entry_finder = {}               # mapping of tasks to entries
     REMOVED = '<removed-task>'      # placeholder for a removed task
     counter = itertools.count()     # unique sequence count

     def add_task(task, priority=0):
         'Add a new task or update the priority of an existing task'
         if task in entry_finder:
             remove_task(task)
         count = next(counter)
         entry = [priority, count, task]
         entry_finder[task] = entry
         heappush(pq, entry)

     def remove_task(task):
         'Mark an existing task as REMOVED.  Raise KeyError if not found.'
         entry = entry_finder.pop(task)
         entry[-1] = REMOVED

     def pop_task():
         'Remove and return the lowest priority task. Raise KeyError if empty.'
         while pq:
             priority, count, task = heappop(pq)
             if task is not REMOVED:
                 del entry_finder[task]
                 return task
         raise KeyError('pop from an empty priority queue')

   ---------- Footnotes ----------

   (1) http://en.wikipedia.org/wiki/Priority_queue


File: python.info,  Node: Theory,  Prev: Priority Queue Implementation Notes,  Up: heapq --- Heap queue algorithm

5.8.4.3 Theory
..............

Heaps are arrays for which ‘a[k] <= a[2*k+1]’ and ‘a[k] <= a[2*k+2]’ for
all _k_, counting elements from 0.  For the sake of comparison,
non-existing elements are considered to be infinite.  The interesting
property of a heap is that ‘a[0]’ is always its smallest element.

  The strange invariant above is meant to be an efficient memory
representation for a tournament.  The numbers below are _k_, not ‘a[k]’:

                                    0

                   1                                 2

           3               4                5               6

       7       8       9       10      11      12      13      14

     15 16   17 18   19 20   21 22   23 24   25 26   27 28   29 30

  In the tree above, each cell _k_ is topping ‘2*k+1’ and ‘2*k+2’.  In
an usual binary tournament we see in sports, each cell is the winner
over the two cells it tops, and we can trace the winner down the tree to
see all opponents s/he had.  However, in many computer applications of
such tournaments, we do not need to trace the history of a winner.  To
be more memory efficient, when a winner is promoted, we try to replace
it by something else at a lower level, and the rule becomes that a cell
and the two cells it tops contain three different items, but the top
cell "wins" over the two topped cells.

  If this heap invariant is protected at all time, index 0 is clearly
the overall winner.  The simplest algorithmic way to remove it and find
the "next" winner is to move some loser (let’s say cell 30 in the
diagram above) into the 0 position, and then percolate this new 0 down
the tree, exchanging values, until the invariant is re-established.
This is clearly logarithmic on the total number of items in the tree.
By iterating over all items, you get an O(n log n) sort.

  A nice feature of this sort is that you can efficiently insert new
items while the sort is going on, provided that the inserted items are
not "better" than the last 0’th element you extracted.  This is
especially useful in simulation contexts, where the tree holds all
incoming events, and the "win" condition means the smallest scheduled
time.  When an event schedules other events for execution, they are
scheduled into the future, so they can easily go into the heap.  So, a
heap is a good structure for implementing schedulers (this is what I
used for my MIDI sequencer :-).

  Various structures for implementing schedulers have been extensively
studied, and heaps are good for this, as they are reasonably speedy, the
speed is almost constant, and the worst case is not much different than
the average case.  However, there are other representations which are
more efficient overall, yet the worst cases might be terrible.

  Heaps are also very useful in big disk sorts.  You most probably all
know that a big sort implies producing "runs" (which are pre-sorted
sequences, which size is usually related to the amount of CPU memory),
followed by a merging passes for these runs, which merging is often very
cleverly organised (1).  It is very important that the initial sort
produces the longest runs possible.  Tournaments are a good way to that.
If, using all the memory available to hold a tournament, you replace and
percolate items that happen to fit the current run, you’ll produce runs
which are twice the size of the memory for random input, and much better
for input fuzzily ordered.

  Moreover, if you output the 0’th item on disk and get an input which
may not fit in the current tournament (because the value "wins" over the
last output value), it cannot fit in the heap, so the size of the heap
decreases.  The freed memory could be cleverly reused immediately for
progressively building a second heap, which grows at exactly the same
rate the first heap is melting.  When the first heap completely
vanishes, you switch heaps and start a new run.  Clever and quite
effective!

  In a word, heaps are useful memory structures to know.  I use them in
a few applications, and I think it is good to keep a ’heap’ module
around.  :-)

   ---------- Footnotes ----------

   (1) The disk balancing algorithms which are current, nowadays, are
more annoying than clever, and this is a consequence of the seeking
capabilities of the disks.  On devices which cannot seek, like big tape
drives, the story was quite different, and one had to be very clever to
ensure (far in advance) that each tape movement will be the most
effective possible (that is, will best participate at "progressing" the
merge).  Some tapes were even able to read backwards, and this was also
used to avoid the rewinding time.  Believe me, real good tape sorts were
quite spectacular to watch!  From all times, sorting has always been a
Great Art!  :-)


File: python.info,  Node: bisect --- Array bisection algorithm,  Next: array --- Efficient arrays of numeric values,  Prev: heapq --- Heap queue algorithm,  Up: Data Types

5.8.5 ‘bisect’ — Array bisection algorithm
------------------------------------------

New in version 2.1.

  *Source code:* Lib/bisect.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module provides support for maintaining a list in sorted order
without having to sort the list after each insertion.  For long lists of
items with expensive comparison operations, this can be an improvement
over the more common approach.  The module is called *note bisect: 1b.
because it uses a basic bisection algorithm to do its work.  The source
code may be most useful as a working example of the algorithm (the
boundary conditions are already right!).

  The following functions are provided:

 -- Function: bisect.bisect_left (a, x, lo=0, hi=len(a))

     Locate the insertion point for _x_ in _a_ to maintain sorted order.
     The parameters _lo_ and _hi_ may be used to specify a subset of the
     list which should be considered; by default the entire list is
     used.  If _x_ is already present in _a_, the insertion point will
     be before (to the left of) any existing entries.  The return value
     is suitable for use as the first parameter to ‘list.insert()’
     assuming that _a_ is already sorted.

     The returned insertion point _i_ partitions the array _a_ into two
     halves so that ‘all(val < x for val in a[lo:i])’ for the left side
     and ‘all(val >= x for val in a[i:hi])’ for the right side.

 -- Function: bisect.bisect_right (a, x, lo=0, hi=len(a))
 -- Function: bisect.bisect (a, x, lo=0, hi=len(a))

     Similar to *note bisect_left(): b97, but returns an insertion point
     which comes after (to the right of) any existing entries of _x_ in
     _a_.

     The returned insertion point _i_ partitions the array _a_ into two
     halves so that ‘all(val <= x for val in a[lo:i])’ for the left side
     and ‘all(val > x for val in a[i:hi])’ for the right side.

 -- Function: bisect.insort_left (a, x, lo=0, hi=len(a))

     Insert _x_ in _a_ in sorted order.  This is equivalent to
     ‘a.insert(bisect.bisect_left(a, x, lo, hi), x)’ assuming that _a_
     is already sorted.  Keep in mind that the O(log n) search is
     dominated by the slow O(n) insertion step.

 -- Function: bisect.insort_right (a, x, lo=0, hi=len(a))
 -- Function: bisect.insort (a, x, lo=0, hi=len(a))

     Similar to *note insort_left(): b9a, but inserting _x_ in _a_ after
     any existing entries of _x_.

See also
........

SortedCollection recipe(2) that uses bisect to build a full-featured
collection class with straight-forward search methods and support for a
key-function.  The keys are precomputed to save unnecessary calls to the
key function during searches.

* Menu:

* Searching Sorted Lists:: 
* Other Examples:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/bisect.py

   (2) http://code.activestate.com/recipes/577197-sortedcollection/


File: python.info,  Node: Searching Sorted Lists,  Next: Other Examples,  Up: bisect --- Array bisection algorithm

5.8.5.1 Searching Sorted Lists
..............................

The above *note bisect(): 1b. functions are useful for finding insertion
points but can be tricky or awkward to use for common searching tasks.
The following five functions show how to transform them into the
standard lookups for sorted lists:

     def index(a, x):
         'Locate the leftmost value exactly equal to x'
         i = bisect_left(a, x)
         if i != len(a) and a[i] == x:
             return i
         raise ValueError

     def find_lt(a, x):
         'Find rightmost value less than x'
         i = bisect_left(a, x)
         if i:
             return a[i-1]
         raise ValueError

     def find_le(a, x):
         'Find rightmost value less than or equal to x'
         i = bisect_right(a, x)
         if i:
             return a[i-1]
         raise ValueError

     def find_gt(a, x):
         'Find leftmost value greater than x'
         i = bisect_right(a, x)
         if i != len(a):
             return a[i]
         raise ValueError

     def find_ge(a, x):
         'Find leftmost item greater than or equal to x'
         i = bisect_left(a, x)
         if i != len(a):
             return a[i]
         raise ValueError


File: python.info,  Node: Other Examples,  Prev: Searching Sorted Lists,  Up: bisect --- Array bisection algorithm

5.8.5.2 Other Examples
......................

The *note bisect(): 1b. function can be useful for numeric table
lookups.  This example uses *note bisect(): 1b. to look up a letter
grade for an exam score (say) based on a set of ordered numeric
breakpoints: 90 and up is an ’A’, 80 to 89 is a ’B’, and so on:

     >>> def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):
             i = bisect(breakpoints, score)
             return grades[i]

     >>> [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]
     ['F', 'A', 'C', 'C', 'B', 'A', 'A']

  Unlike the *note sorted(): 223. function, it does not make sense for
the *note bisect(): 1b. functions to have _key_ or _reversed_ arguments
because that would lead to an inefficient design (successive calls to
bisect functions would not "remember" all of the previous key lookups).

  Instead, it is better to search a list of precomputed keys to find the
index of the record in question:

     >>> data = [('red', 5), ('blue', 1), ('yellow', 8), ('black', 0)]
     >>> data.sort(key=lambda r: r[1])
     >>> keys = [r[1] for r in data]         # precomputed list of keys
     >>> data[bisect_left(keys, 0)]
     ('black', 0)
     >>> data[bisect_left(keys, 1)]
     ('blue', 1)
     >>> data[bisect_left(keys, 5)]
     ('red', 5)
     >>> data[bisect_left(keys, 8)]
     ('yellow', 8)


File: python.info,  Node: array --- Efficient arrays of numeric values,  Next: sets --- Unordered collections of unique elements,  Prev: bisect --- Array bisection algorithm,  Up: Data Types

5.8.6 ‘array’ — Efficient arrays of numeric values
--------------------------------------------------

This module defines an object type which can compactly represent an
array of basic values: characters, integers, floating point numbers.
Arrays are sequence types and behave very much like lists, except that
the type of objects stored in them is constrained.  The type is
specified at object creation time by using a _type code_, which is a
single character.  The following type codes are defined:

Type code       C Type               Python Type             Minimum size in bytes
                                                             
-----------------------------------------------------------------------------------------
                                                             
‘'c'’           char                 character               1
                                                             
                                                             
‘'b'’           signed char          int                     1
                                                             
                                                             
‘'B'’           unsigned char        int                     1
                                                             
                                                             
‘'u'’           Py_UNICODE           Unicode character       2 (see note)
                                                             
                                                             
‘'h'’           signed short         int                     2
                                                             
                                                             
‘'H'’           unsigned short       int                     2
                                                             
                                                             
‘'i'’           signed int           int                     2
                                                             
                                                             
‘'I'’           unsigned int         long                    2
                                                             
                                                             
‘'l'’           signed long          int                     4
                                                             
                                                             
‘'L'’           unsigned long        long                    4
                                                             
                                                             
‘'f'’           float                float                   4
                                                             
                                                             
‘'d'’           double               float                   8
                                                             

     Note: The ‘'u'’ typecode corresponds to Python’s unicode character.
     On narrow Unicode builds this is 2-bytes, on wide builds this is
     4-bytes.

  The actual representation of values is determined by the machine
architecture (strictly speaking, by the C implementation).  The actual
size can be accessed through the ‘itemsize’ attribute.  The values
stored for ‘'L'’ and ‘'I'’ items will be represented as Python long
integers when retrieved, because Python’s plain integer type cannot
represent the full range of C’s unsigned (long) integers.

  The module defines the following type:

 -- Class: array.array (typecode[, initializer])

     A new array whose items are restricted by _typecode_, and
     initialized from the optional _initializer_ value, which must be a
     list, string, or iterable over elements of the appropriate type.

     Changed in version 2.4: Formerly, only lists or strings were
     accepted.

     If given a list or string, the initializer is passed to the new
     array’s *note fromlist(): ba2, *note fromstring(): ba3, or *note
     fromunicode(): ba4. method (see below) to add initial items to the
     array.  Otherwise, the iterable initializer is passed to the *note
     extend(): ba5. method.

 -- Data: array.ArrayType

     Obsolete alias for *note array: e.

  Array objects support the ordinary sequence operations of indexing,
slicing, concatenation, and multiplication.  When using slice
assignment, the assigned value must be an array object with the same
type code; in all other cases, *note TypeError: 218. is raised.  Array
objects also implement the buffer interface, and may be used wherever
buffer objects are supported.

  The following data items and methods are also supported:

 -- Attribute: array.typecode

     The typecode character used to create the array.

 -- Attribute: array.itemsize

     The length in bytes of one array item in the internal
     representation.

 -- Method: array.append (x)

     Append a new item with value _x_ to the end of the array.

 -- Method: array.buffer_info ()

     Return a tuple ‘(address, length)’ giving the current memory
     address and the length in elements of the buffer used to hold
     array’s contents.  The size of the memory buffer in bytes can be
     computed as ‘array.buffer_info()[1] * array.itemsize’.  This is
     occasionally useful when working with low-level (and inherently
     unsafe) I/O interfaces that require memory addresses, such as
     certain ‘ioctl()’ operations.  The returned numbers are valid as
     long as the array exists and no length-changing operations are
     applied to it.

          Note: When using array objects from code written in C or C++
          (the only way to effectively make use of this information), it
          makes more sense to use the buffer interface supported by
          array objects.  This method is maintained for backward
          compatibility and should be avoided in new code.  The buffer
          interface is documented in *note Buffers and Memoryview
          Objects: 94a.

 -- Method: array.byteswap ()

     "Byteswap" all items of the array.  This is only supported for
     values which are 1, 2, 4, or 8 bytes in size; for other types of
     values, *note RuntimeError: 39b. is raised.  It is useful when
     reading data from a file written on a machine with a different byte
     order.

 -- Method: array.count (x)

     Return the number of occurrences of _x_ in the array.

 -- Method: array.extend (iterable)

     Append items from _iterable_ to the end of the array.  If
     _iterable_ is another array, it must have _exactly_ the same type
     code; if not, *note TypeError: 218. will be raised.  If _iterable_
     is not an array, it must be iterable and its elements must be the
     right type to be appended to the array.

     Changed in version 2.4: Formerly, the argument could only be
     another array.

 -- Method: array.fromfile (f, n)

     Read _n_ items (as machine values) from the file object _f_ and
     append them to the end of the array.  If less than _n_ items are
     available, *note EOFError: 88a. is raised, but the items that were
     available are still inserted into the array.  _f_ must be a real
     built-in file object; something else with a *note read(): bae.
     method won’t do.

 -- Method: array.fromlist (list)

     Append items from the list.  This is equivalent to ‘for x in list:
     a.append(x)’ except that if there is a type error, the array is
     unchanged.

 -- Method: array.fromstring (s)

     Appends items from the string, interpreting the string as an array
     of machine values (as if it had been read from a file using the
     *note fromfile(): bad. method).

 -- Method: array.fromunicode (s)

     Extends this array with data from the given unicode string.  The
     array must be a type ‘'u'’ array; otherwise a *note ValueError:
     236. is raised.  Use ‘array.fromstring(unicodestring.encode(enc))’
     to append Unicode data to an array of some other type.

 -- Method: array.index (x)

     Return the smallest _i_ such that _i_ is the index of the first
     occurrence of _x_ in the array.

 -- Method: array.insert (i, x)

     Insert a new item with value _x_ in the array before position _i_.
     Negative values are treated as being relative to the end of the
     array.

 -- Method: array.pop ([i])

     Removes the item with the index _i_ from the array and returns it.
     The optional argument defaults to ‘-1’, so that by default the last
     item is removed and returned.

 -- Method: array.read (f, n)

     Deprecated since version 1.5.1: Use the *note fromfile(): bad.
     method.

     Read _n_ items (as machine values) from the file object _f_ and
     append them to the end of the array.  If less than _n_ items are
     available, *note EOFError: 88a. is raised, but the items that were
     available are still inserted into the array.  _f_ must be a real
     built-in file object; something else with a *note read(): bae.
     method won’t do.

 -- Method: array.remove (x)

     Remove the first occurrence of _x_ from the array.

 -- Method: array.reverse ()

     Reverse the order of the items in the array.

 -- Method: array.tofile (f)

     Write all items (as machine values) to the file object _f_.

 -- Method: array.tolist ()

     Convert the array to an ordinary list with the same items.

 -- Method: array.tostring ()

     Convert the array to an array of machine values and return the
     string representation (the same sequence of bytes that would be
     written to a file by the *note tofile(): bb4. method.)

 -- Method: array.tounicode ()

     Convert the array to a unicode string.  The array must be a type
     ‘'u'’ array; otherwise a *note ValueError: 236. is raised.  Use
     ‘array.tostring().decode(enc)’ to obtain a unicode string from an
     array of some other type.

 -- Method: array.write (f)

     Deprecated since version 1.5.1: Use the *note tofile(): bb4.
     method.

     Write all items (as machine values) to the file object _f_.

  When an array object is printed or converted to a string, it is
represented as ‘array(typecode, initializer)’.  The _initializer_ is
omitted if the array is empty, otherwise it is a string if the
_typecode_ is ‘'c'’, otherwise it is a list of numbers.  The string is
guaranteed to be able to be converted back to an array with the same
type and value using *note eval(): 360, so long as the *note array(): e.
function has been imported using ‘from array import array’.  Examples:

     array('l')
     array('c', 'hello world')
     array('u', u'hello \u2641')
     array('l', [1, 2, 3, 4, 5])
     array('d', [1.0, 2.0, 3.14])

See also
........

Module *note struct: 166.

     Packing and unpacking of heterogeneous binary data.

Module *note xdrlib: 19f.

     Packing and unpacking of External Data Representation (XDR) data as
     used in some remote procedure call systems.

The Numerical Python Documentation(1)

     The Numeric Python extension (NumPy) defines another array type;
     see ‘http://www.numpy.org/’ for further information about Numerical
     Python.

   ---------- Footnotes ----------

   (1) http://docs.scipy.org/doc/


File: python.info,  Node: sets --- Unordered collections of unique elements,  Next: sched --- Event scheduler,  Prev: array --- Efficient arrays of numeric values,  Up: Data Types

5.8.7 ‘sets’ — Unordered collections of unique elements
-------------------------------------------------------

New in version 2.3.

  Deprecated since version 2.6: The built-in *note set: 36a./*note
frozenset: 36b. types replace this module.

  The *note sets: 14f. module provides classes for constructing and
manipulating unordered collections of unique elements.  Common uses
include membership testing, removing duplicates from a sequence, and
computing standard math operations on sets such as intersection, union,
difference, and symmetric difference.

  Like other collections, sets support ‘x in set’, ‘len(set)’, and ‘for
x in set’.  Being an unordered collection, sets do not record element
position or order of insertion.  Accordingly, sets do not support
indexing, slicing, or other sequence-like behavior.

  Most set applications use the *note Set: bbb. class which provides
every set method except for *note __hash__(): 335.  For advanced
applications requiring a hash method, the *note ImmutableSet: bbc. class
adds a *note __hash__(): 335. method but omits methods which alter the
contents of the set.  Both *note Set: bbb. and *note ImmutableSet: bbc.
derive from ‘BaseSet’, an abstract class useful for determining whether
something is a set: ‘isinstance(obj, BaseSet)’.

  The set classes are implemented using dictionaries.  Accordingly, the
requirements for set elements are the same as those for dictionary keys;
namely, that the element defines both *note __eq__(): 21c. and *note
__hash__(): 335.  As a result, sets cannot contain mutable elements such
as lists or dictionaries.  However, they can contain immutable
collections such as tuples or instances of *note ImmutableSet: bbc.  For
convenience in implementing sets of sets, inner sets are automatically
converted to immutable form, for example, ‘Set([Set(['dog'])])’ is
transformed to ‘Set([ImmutableSet(['dog'])])’.

 -- Class: sets.Set ([iterable])

     Constructs a new empty *note Set: bbb. object.  If the optional
     _iterable_ parameter is supplied, updates the set with elements
     obtained from iteration.  All of the elements in _iterable_ should
     be immutable or be transformable to an immutable using the protocol
     described in section *note Protocol for automatic conversion to
     immutable: bbd.

 -- Class: sets.ImmutableSet ([iterable])

     Constructs a new empty *note ImmutableSet: bbc. object.  If the
     optional _iterable_ parameter is supplied, updates the set with
     elements obtained from iteration.  All of the elements in
     _iterable_ should be immutable or be transformable to an immutable
     using the protocol described in section *note Protocol for
     automatic conversion to immutable: bbd.

     Because *note ImmutableSet: bbc. objects provide a *note
     __hash__(): 335. method, they can be used as set elements or as
     dictionary keys.  *note ImmutableSet: bbc. objects do not have
     methods for adding or removing elements, so all of the elements
     must be known when the constructor is called.

* Menu:

* Set Objects:: 
* Example:: 
* Protocol for automatic conversion to immutable:: 
* Comparison to the built-in set types:: 


File: python.info,  Node: Set Objects,  Next: Example,  Up: sets --- Unordered collections of unique elements

5.8.7.1 Set Objects
...................

Instances of *note Set: bbb. and *note ImmutableSet: bbc. both provide
the following operations:

Operation                           Equivalent       Result
                                                     
-------------------------------------------------------------------------------------------
                                                     
‘len(s)’                                             cardinality of set _s_
                                                     
                                                     
‘x in s’                                             test _x_ for membership in _s_
                                                     
                                                     
‘x not in s’                                         test _x_ for non-membership in _s_
                                                     
                                                     
‘s.issubset(t)’                     ‘s <= t’         test whether every element in _s_
                                                     is in _t_
                                                     
                                                     
‘s.issuperset(t)’                   ‘s >= t’         test whether every element in _t_
                                                     is in _s_
                                                     
                                                     
‘s.union(t)’                        ‘s | t’          new set with elements from both _s_
                                                     and _t_
                                                     
                                                     
‘s.intersection(t)’                 ‘s & t’          new set with elements common to _s_
                                                     and _t_
                                                     
                                                     
‘s.difference(t)’                   ‘s - t’          new set with elements in _s_ but
                                                     not in _t_
                                                     
                                                     
‘s.symmetric_difference(t)’         ‘s ^ t’          new set with elements in either _s_
                                                     or _t_ but not both
                                                     
                                                     
‘s.copy()’                                           new set with a shallow copy of _s_
                                                     

  Note, the non-operator versions of ‘union()’, ‘intersection()’,
‘difference()’, and ‘symmetric_difference()’ will accept any iterable as
an argument.  In contrast, their operator based counterparts require
their arguments to be sets.  This precludes error-prone constructions
like ‘Set('abc') & 'cbs'’ in favor of the more readable
‘Set('abc').intersection('cbs')’.

  Changed in version 2.3.1: Formerly all arguments were required to be
sets.

  In addition, both *note Set: bbb. and *note ImmutableSet: bbc. support
set to set comparisons.  Two sets are equal if and only if every element
of each set is contained in the other (each is a subset of the other).
A set is less than another set if and only if the first set is a proper
subset of the second set (is a subset, but is not equal).  A set is
greater than another set if and only if the first set is a proper
superset of the second set (is a superset, but is not equal).

  The subset and equality comparisons do not generalize to a complete
ordering function.  For example, any two disjoint sets are not equal and
are not subsets of each other, so _all_ of the following return ‘False’:
‘a<b’, ‘a==b’, or ‘a>b’.  Accordingly, sets do not implement the *note
__cmp__(): 221. method.

  Since sets only define partial ordering (subset relationships), the
output of the ‘list.sort()’ method is undefined for lists of sets.

  The following table lists operations available in *note ImmutableSet:
bbc. but not found in *note Set: bbb.:

Operation         Result
                  
-----------------------------------------------------
                  
‘hash(s)’         returns a hash value for _s_
                  

  The following table lists operations available in *note Set: bbb. but
not found in *note ImmutableSet: bbc.:

Operation                                  Equivalent        Result
                                                             
---------------------------------------------------------------------------------------------------
                                                             
‘s.update(t)’                              _s_ |= _t_        return set _s_ with elements added
                                                             from _t_
                                                             
                                                             
‘s.intersection_update(t)’                 _s_ &= _t_        return set _s_ keeping only
                                                             elements also found in _t_
                                                             
                                                             
‘s.difference_update(t)’                   _s_ -= _t_        return set _s_ after removing
                                                             elements found in _t_
                                                             
                                                             
‘s.symmetric_difference_update(t)’         _s_ ^= _t_        return set _s_ with elements from
                                                             _s_ or _t_ but not both
                                                             
                                                             
‘s.add(x)’                                                   add element _x_ to set _s_
                                                             
                                                             
‘s.remove(x)’                                                remove _x_ from set _s_; raises
                                                             *note KeyError: 205. if not present
                                                             
                                                             
‘s.discard(x)’                                               removes _x_ from set _s_ if present
                                                             
                                                             
‘s.pop()’                                                    remove and return an arbitrary
                                                             element from _s_; raises *note
                                                             KeyError: 205. if empty
                                                             
                                                             
‘s.clear()’                                                  remove all elements from set _s_
                                                             

  Note, the non-operator versions of ‘update()’,
‘intersection_update()’, ‘difference_update()’, and
‘symmetric_difference_update()’ will accept any iterable as an argument.

  Changed in version 2.3.1: Formerly all arguments were required to be
sets.

  Also note, the module also includes a ‘union_update()’ method which is
an alias for ‘update()’.  The method is included for backwards
compatibility.  Programmers should prefer the ‘update()’ method because
it is supported by the built-in *note set(): 36a. and *note frozenset():
36b. types.


File: python.info,  Node: Example,  Next: Protocol for automatic conversion to immutable,  Prev: Set Objects,  Up: sets --- Unordered collections of unique elements

5.8.7.2 Example
...............

     >>> from sets import Set
     >>> engineers = Set(['John', 'Jane', 'Jack', 'Janice'])
     >>> programmers = Set(['Jack', 'Sam', 'Susan', 'Janice'])
     >>> managers = Set(['Jane', 'Jack', 'Susan', 'Zack'])
     >>> employees = engineers | programmers | managers           # union
     >>> engineering_management = engineers & managers            # intersection
     >>> fulltime_management = managers - engineers - programmers # difference
     >>> engineers.add('Marvin')                                  # add element
     >>> print engineers # doctest: +SKIP
     Set(['Jane', 'Marvin', 'Janice', 'John', 'Jack'])
     >>> employees.issuperset(engineers)     # superset test
     False
     >>> employees.update(engineers)         # update from another set
     >>> employees.issuperset(engineers)
     True
     >>> for group in [engineers, programmers, managers, employees]: # doctest: +SKIP
     ...     group.discard('Susan')          # unconditionally remove element
     ...     print group
     ...
     Set(['Jane', 'Marvin', 'Janice', 'John', 'Jack'])
     Set(['Janice', 'Jack', 'Sam'])
     Set(['Jane', 'Zack', 'Jack'])
     Set(['Jack', 'Sam', 'Jane', 'Marvin', 'Janice', 'John', 'Zack'])


File: python.info,  Node: Protocol for automatic conversion to immutable,  Next: Comparison to the built-in set types,  Prev: Example,  Up: sets --- Unordered collections of unique elements

5.8.7.3 Protocol for automatic conversion to immutable
......................................................

Sets can only contain immutable elements.  For convenience, mutable
*note Set: bbb. objects are automatically copied to an *note
ImmutableSet: bbc. before being added as a set element.

  The mechanism is to always add a *note hashable: 6f5. element, or if
it is not hashable, the element is checked to see if it has an
‘__as_immutable__()’ method which returns an immutable equivalent.

  Since *note Set: bbb. objects have a ‘__as_immutable__()’ method
returning an instance of *note ImmutableSet: bbc, it is possible to
construct sets of sets.

  A similar mechanism is needed by the *note __contains__(): 322. and
‘remove()’ methods which need to hash an element to check for membership
in a set.  Those methods check an element for hashability and, if not,
check for a ‘__as_temporarily_immutable__()’ method which returns the
element wrapped by a class that provides temporary methods for *note
__hash__(): 335, *note __eq__(): 21c, and *note __ne__(): 4bd.

  The alternate mechanism spares the need to build a separate copy of
the original mutable object.

  *note Set: bbb. objects implement the ‘__as_temporarily_immutable__()’
method which returns the *note Set: bbb. object wrapped by a new class
‘_TemporarilyImmutableSet’.

  The two mechanisms for adding hashability are normally invisible to
the user; however, a conflict can arise in a multi-threaded environment
where one thread is updating a set while another has temporarily wrapped
it in ‘_TemporarilyImmutableSet’.  In other words, sets of mutable sets
are not thread-safe.


File: python.info,  Node: Comparison to the built-in set types,  Prev: Protocol for automatic conversion to immutable,  Up: sets --- Unordered collections of unique elements

5.8.7.4 Comparison to the built-in ‘set’ types
..............................................

The built-in *note set: 36a. and *note frozenset: 36b. types were
designed based on lessons learned from the *note sets: 14f. module.  The
key differences are:

   * *note Set: bbb. and *note ImmutableSet: bbc. were renamed to *note
     set: 36a. and *note frozenset: 36b.

   * There is no equivalent to ‘BaseSet’.  Instead, use ‘isinstance(x,
     (set, frozenset))’.

   * The hash algorithm for the built-ins performs significantly better
     (fewer collisions) for most datasets.

   * The built-in versions have more space efficient pickles.

   * The built-in versions do not have a ‘union_update()’ method.
     Instead, use the ‘update()’ method which is equivalent.

   * The built-in versions do not have a ‘_repr(sorted=True)’ method.
     Instead, use the built-in *note repr(): 145. and *note sorted():
     223. functions: ‘repr(sorted(s))’.

   * The built-in version does not have a protocol for automatic
     conversion to immutable.  Many found this feature to be confusing
     and no one in the community reported having found real uses for it.


File: python.info,  Node: sched --- Event scheduler,  Next: mutex --- Mutual exclusion support,  Prev: sets --- Unordered collections of unique elements,  Up: Data Types

5.8.8 ‘sched’ — Event scheduler
-------------------------------

*Source code:* Lib/sched.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note sched: 14c. module defines a class which implements a
general purpose event scheduler:

 -- Class: sched.scheduler (timefunc, delayfunc)

     The *note scheduler: bc6. class defines a generic interface to
     scheduling events.  It needs two functions to actually deal with
     the "outside world" — _timefunc_ should be callable without
     arguments, and return a number (the "time", in any units
     whatsoever).  The _delayfunc_ function should be callable with one
     argument, compatible with the output of _timefunc_, and should
     delay that many time units.  _delayfunc_ will also be called with
     the argument ‘0’ after each event is run to allow other threads an
     opportunity to run in multi-threaded applications.

  Example:

     >>> import sched, time
     >>> s = sched.scheduler(time.time, time.sleep)
     >>> def print_time(): print "From print_time", time.time()
     ...
     >>> def print_some_times():
     ...     print time.time()
     ...     s.enter(5, 1, print_time, ())
     ...     s.enter(10, 1, print_time, ())
     ...     s.run()
     ...     print time.time()
     ...
     >>> print_some_times()
     930343690.257
     From print_time 930343695.274
     From print_time 930343700.273
     930343700.276

  In multi-threaded environments, the *note scheduler: bc6. class has
limitations with respect to thread-safety, inability to insert a new
task before the one currently pending in a running scheduler, and
holding up the main thread until the event queue is empty.  Instead, the
preferred approach is to use the *note threading.Timer: bc7. class
instead.

  Example:

     >>> import time
     >>> from threading import Timer
     >>> def print_time():
     ...     print "From print_time", time.time()
     ...
     >>> def print_some_times():
     ...     print time.time()
     ...     Timer(5, print_time, ()).start()
     ...     Timer(10, print_time, ()).start()
     ...     time.sleep(11)  # sleep while time-delay events execute
     ...     print time.time()
     ...
     >>> print_some_times()
     930343690.257
     From print_time 930343695.274
     From print_time 930343700.273
     930343701.301

* Menu:

* Scheduler Objects:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/sched.py


File: python.info,  Node: Scheduler Objects,  Up: sched --- Event scheduler

5.8.8.1 Scheduler Objects
.........................

*note scheduler: bc6. instances have the following methods and
attributes:

 -- Method: scheduler.enterabs (time, priority, action, argument)

     Schedule a new event.  The _time_ argument should be a numeric type
     compatible with the return value of the _timefunc_ function passed
     to the constructor.  Events scheduled for the same _time_ will be
     executed in the order of their _priority_.

     Executing the event means executing ‘action(*argument)’.
     _argument_ must be a sequence holding the parameters for _action_.

     Return value is an event which may be used for later cancellation
     of the event (see *note cancel(): bcb.).

 -- Method: scheduler.enter (delay, priority, action, argument)

     Schedule an event for _delay_ more time units.  Other than the
     relative time, the other arguments, the effect and the return value
     are the same as those for *note enterabs(): bca.

 -- Method: scheduler.cancel (event)

     Remove the event from the queue.  If _event_ is not an event
     currently in the queue, this method will raise a *note ValueError:
     236.

 -- Method: scheduler.empty ()

     Return true if the event queue is empty.

 -- Method: scheduler.run ()

     Run all scheduled events.  This function will wait (using the
     ‘delayfunc()’ function passed to the constructor) for the next
     event, then execute it and so on until there are no more scheduled
     events.

     Either _action_ or _delayfunc_ can raise an exception.  In either
     case, the scheduler will maintain a consistent state and propagate
     the exception.  If an exception is raised by _action_, the event
     will not be attempted in future calls to *note run(): bce.

     If a sequence of events takes longer to run than the time available
     before the next event, the scheduler will simply fall behind.  No
     events will be dropped; the calling code is responsible for
     canceling events which are no longer pertinent.

 -- Attribute: scheduler.queue

     Read-only attribute returning a list of upcoming events in the
     order they will be run.  Each event is shown as a *note named
     tuple: a1f. with the following fields: time, priority, action,
     argument.

     New in version 2.6.


File: python.info,  Node: mutex --- Mutual exclusion support,  Next: Queue --- A synchronized queue class,  Prev: sched --- Event scheduler,  Up: Data Types

5.8.9 ‘mutex’ — Mutual exclusion support
----------------------------------------

Deprecated since version 2.6: The *note mutex: 11f. module has been
removed in Python 3.

  The *note mutex: 11f. module defines a class that allows
mutual-exclusion via acquiring and releasing locks.  It does not require
(or imply) *note threading: 179. or multi-tasking, though it could be
useful for those purposes.

  The *note mutex: 11f. module defines the following class:

 -- Class: mutex.mutex

     Create a new (unlocked) mutex.

     A mutex has two pieces of state — a "locked" bit and a queue.  When
     the mutex is not locked, the queue is empty.  Otherwise, the queue
     contains zero or more ‘(function, argument)’ pairs representing
     functions (or methods) waiting to acquire the lock.  When the mutex
     is unlocked while the queue is not empty, the first queue entry is
     removed and its ‘function(argument)’ pair called, implying it now
     has the lock.

     Of course, no multi-threading is implied – hence the funny
     interface for *note lock(): bd3, where a function is called once
     the lock is acquired.

* Menu:

* Mutex Objects:: 


File: python.info,  Node: Mutex Objects,  Up: mutex --- Mutual exclusion support

5.8.9.1 Mutex Objects
.....................

*note mutex: 11f. objects have following methods:

 -- Method: mutex.test ()

     Check whether the mutex is locked.

 -- Method: mutex.testandset ()

     "Atomic" test-and-set, grab the lock if it is not set, and return
     ‘True’, otherwise, return ‘False’.

 -- Method: mutex.lock (function, argument)

     Execute ‘function(argument)’, unless the mutex is locked.  In the
     case it is locked, place the function and argument on the queue.
     See *note unlock(): bd8. for explanation of when
     ‘function(argument)’ is executed in that case.

 -- Method: mutex.unlock ()

     Unlock the mutex if queue is empty, otherwise execute the first
     element in the queue.


File: python.info,  Node: Queue --- A synchronized queue class,  Next: weakref --- Weak references,  Prev: mutex --- Mutual exclusion support,  Up: Data Types

5.8.10 ‘Queue’ — A synchronized queue class
-------------------------------------------

     Note: The *note Queue: 140. module has been renamed to ‘queue’ in
     Python 3.  The *note 2to3: bdb. tool will automatically adapt
     imports when converting your sources to Python 3.

  *Source code:* Lib/Queue.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note Queue: 140. module implements multi-producer, multi-consumer
queues.  It is especially useful in threaded programming when
information must be exchanged safely between multiple threads.  The
*note Queue: 140. class in this module implements all the required
locking semantics.  It depends on the availability of thread support in
Python; see the *note threading: 179. module.

  The module implements three types of queue, which differ only in the
order in which the entries are retrieved.  In a FIFO queue, the first
tasks added are the first retrieved.  In a LIFO queue, the most recently
added entry is the first retrieved (operating like a stack).  With a
priority queue, the entries are kept sorted (using the *note heapq: e7.
module) and the lowest valued entry is retrieved first.

  The *note Queue: 140. module defines the following classes and
exceptions:

 -- Class: Queue.Queue (maxsize=0)

     Constructor for a FIFO queue.  _maxsize_ is an integer that sets
     the upperbound limit on the number of items that can be placed in
     the queue.  Insertion will block once this size has been reached,
     until queue items are consumed.  If _maxsize_ is less than or equal
     to zero, the queue size is infinite.

 -- Class: Queue.LifoQueue (maxsize=0)

     Constructor for a LIFO queue.  _maxsize_ is an integer that sets
     the upperbound limit on the number of items that can be placed in
     the queue.  Insertion will block once this size has been reached,
     until queue items are consumed.  If _maxsize_ is less than or equal
     to zero, the queue size is infinite.

     New in version 2.6.

 -- Class: Queue.PriorityQueue (maxsize=0)

     Constructor for a priority queue.  _maxsize_ is an integer that
     sets the upperbound limit on the number of items that can be placed
     in the queue.  Insertion will block once this size has been
     reached, until queue items are consumed.  If _maxsize_ is less than
     or equal to zero, the queue size is infinite.

     The lowest valued entries are retrieved first (the lowest valued
     entry is the one returned by ‘sorted(list(entries))[0]’).  A
     typical pattern for entries is a tuple in the form:
     ‘(priority_number, data)’.

     New in version 2.6.

 -- Exception: Queue.Empty

     Exception raised when non-blocking *note get(): bde. (or *note
     get_nowait(): bdf.) is called on a *note Queue: 140. object which
     is empty.

 -- Exception: Queue.Full

     Exception raised when non-blocking *note put(): be1. (or *note
     put_nowait(): be2.) is called on a *note Queue: 140. object which
     is full.

See also
........

*note collections.deque: 209. is an alternative implementation of
unbounded queues with fast atomic ‘append()’ and ‘popleft()’ operations
that do not require locking.

* Menu:

* Queue Objects:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/Queue.py


File: python.info,  Node: Queue Objects,  Up: Queue --- A synchronized queue class

5.8.10.1 Queue Objects
......................

Queue objects (*note Queue: 140, *note LifoQueue: bdc, or *note
PriorityQueue: bdd.) provide the public methods described below.

 -- Method: Queue.qsize ()

     Return the approximate size of the queue.  Note, qsize() > 0
     doesn’t guarantee that a subsequent get() will not block, nor will
     qsize() < maxsize guarantee that put() will not block.

 -- Method: Queue.empty ()

     Return ‘True’ if the queue is empty, ‘False’ otherwise.  If empty()
     returns ‘True’ it doesn’t guarantee that a subsequent call to put()
     will not block.  Similarly, if empty() returns ‘False’ it doesn’t
     guarantee that a subsequent call to get() will not block.

 -- Method: Queue.full ()

     Return ‘True’ if the queue is full, ‘False’ otherwise.  If full()
     returns ‘True’ it doesn’t guarantee that a subsequent call to get()
     will not block.  Similarly, if full() returns ‘False’ it doesn’t
     guarantee that a subsequent call to put() will not block.

 -- Method: Queue.put (item[, block[, timeout]])

     Put _item_ into the queue.  If optional args _block_ is true and
     _timeout_ is None (the default), block if necessary until a free
     slot is available.  If _timeout_ is a positive number, it blocks at
     most _timeout_ seconds and raises the *note Full: be0. exception if
     no free slot was available within that time.  Otherwise (_block_ is
     false), put an item on the queue if a free slot is immediately
     available, else raise the *note Full: be0. exception (_timeout_ is
     ignored in that case).

     New in version 2.3: The _timeout_ parameter.

 -- Method: Queue.put_nowait (item)

     Equivalent to ‘put(item, False)’.

 -- Method: Queue.get ([block[, timeout]])

     Remove and return an item from the queue.  If optional args _block_
     is true and _timeout_ is None (the default), block if necessary
     until an item is available.  If _timeout_ is a positive number, it
     blocks at most _timeout_ seconds and raises the *note Empty: 819.
     exception if no item was available within that time.  Otherwise
     (_block_ is false), return an item if one is immediately available,
     else raise the *note Empty: 819. exception (_timeout_ is ignored in
     that case).

     New in version 2.3: The _timeout_ parameter.

 -- Method: Queue.get_nowait ()

     Equivalent to ‘get(False)’.

  Two methods are offered to support tracking whether enqueued tasks
have been fully processed by daemon consumer threads.

 -- Method: Queue.task_done ()

     Indicate that a formerly enqueued task is complete.  Used by queue
     consumer threads.  For each *note get(): bde. used to fetch a task,
     a subsequent call to *note task_done(): be8. tells the queue that
     the processing on the task is complete.

     If a *note join(): be9. is currently blocking, it will resume when
     all items have been processed (meaning that a *note task_done():
     be8. call was received for every item that had been *note put():
     be1. into the queue).

     Raises a *note ValueError: 236. if called more times than there
     were items placed in the queue.

     New in version 2.5.

 -- Method: Queue.join ()

     Blocks until all items in the queue have been gotten and processed.

     The count of unfinished tasks goes up whenever an item is added to
     the queue.  The count goes down whenever a consumer thread calls
     *note task_done(): be8. to indicate that the item was retrieved and
     all work on it is complete.  When the count of unfinished tasks
     drops to zero, *note join(): be9. unblocks.

     New in version 2.5.

  Example of how to wait for enqueued tasks to be completed:

     def worker():
         while True:
             item = q.get()
             do_work(item)
             q.task_done()

     q = Queue()
     for i in range(num_worker_threads):
          t = Thread(target=worker)
          t.daemon = True
          t.start()

     for item in source():
         q.put(item)

     q.join()       # block until all tasks are done


File: python.info,  Node: weakref --- Weak references,  Next: UserDict --- Class wrapper for dictionary objects,  Prev: Queue --- A synchronized queue class,  Up: Data Types

5.8.11 ‘weakref’ — Weak references
----------------------------------

New in version 2.1.

  *Source code:* Lib/weakref.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note weakref: 195. module allows the Python programmer to create
_weak references_ to objects.

  In the following, the term _referent_ means the object which is
referred to by a weak reference.

  A weak reference to an object is not enough to keep the object alive:
when the only remaining references to a referent are weak references,
*note garbage collection: 60e. is free to destroy the referent and reuse
its memory for something else.  A primary use for weak references is to
implement caches or mappings holding large objects, where it’s desired
that a large object not be kept alive solely because it appears in a
cache or mapping.

  For example, if you have a number of large binary image objects, you
may wish to associate a name with each.  If you used a Python dictionary
to map names to images, or images to names, the image objects would
remain alive just because they appeared as values or keys in the
dictionaries.  The *note WeakKeyDictionary: bec. and *note
WeakValueDictionary: bed. classes supplied by the *note weakref: 195.
module are an alternative, using weak references to construct mappings
that don’t keep objects alive solely because they appear in the mapping
objects.  If, for example, an image object is a value in a *note
WeakValueDictionary: bed, then when the last remaining references to
that image object are the weak references held by weak mappings, garbage
collection can reclaim the object, and its corresponding entries in weak
mappings are simply deleted.

  *note WeakKeyDictionary: bec. and *note WeakValueDictionary: bed. use
weak references in their implementation, setting up callback functions
on the weak references that notify the weak dictionaries when a key or
value has been reclaimed by garbage collection.  Most programs should
find that using one of these weak dictionary types is all they need –
it’s not usually necessary to create your own weak references directly.
The low-level machinery used by the weak dictionary implementations is
exposed by the *note weakref: 195. module for the benefit of advanced
uses.

  Not all objects can be weakly referenced; those objects which can
include class instances, functions written in Python (but not in C),
methods (both bound and unbound), sets, frozensets, file objects, *note
generator: 5dc.s, type objects, ‘DBcursor’ objects from the *note bsddb:
1c. module, sockets, arrays, deques, regular expression pattern objects,
and code objects.

  Changed in version 2.4: Added support for files, sockets, arrays, and
patterns.

  Changed in version 2.7: Added support for thread.lock, threading.Lock,
and code objects.

  Several built-in types such as *note list: 3bc. and *note dict: 305.
do not directly support weak references but can add support through
subclassing:

     class Dict(dict):
         pass

     obj = Dict(red=1, green=2, blue=3)   # this object is weak referenceable

*CPython implementation detail:* Other built-in types such as *note
tuple: 408. and *note long: 1f3. do not support weak references even
when subclassed.

  Extension types can easily be made to support weak references; see
*note Weak Reference Support: bee.

 -- Class: weakref.ref (object[, callback])

     Return a weak reference to _object_.  The original object can be
     retrieved by calling the reference object if the referent is still
     alive; if the referent is no longer alive, calling the reference
     object will cause *note None: 39a. to be returned.  If _callback_
     is provided and not *note None: 39a, and the returned weakref
     object is still alive, the callback will be called when the object
     is about to be finalized; the weak reference object will be passed
     as the only parameter to the callback; the referent will no longer
     be available.

     It is allowable for many weak references to be constructed for the
     same object.  Callbacks registered for each weak reference will be
     called from the most recently registered callback to the oldest
     registered callback.

     Exceptions raised by the callback will be noted on the standard
     error output, but cannot be propagated; they are handled in exactly
     the same way as exceptions raised from an object’s *note __del__():
     709. method.

     Weak references are *note hashable: 6f5. if the _object_ is
     hashable.  They will maintain their hash value even after the
     _object_ was deleted.  If *note hash(): 70b. is called the first
     time only after the _object_ was deleted, the call will raise *note
     TypeError: 218.

     Weak references support tests for equality, but not ordering.  If
     the referents are still alive, two references have the same
     equality relationship as their referents (regardless of the
     _callback_).  If either referent has been deleted, the references
     are equal only if the reference objects are the same object.

     Changed in version 2.4: This is now a subclassable type rather than
     a factory function; it derives from *note object: 1f1.

 -- Function: weakref.proxy (object[, callback])

     Return a proxy to _object_ which uses a weak reference.  This
     supports use of the proxy in most contexts instead of requiring the
     explicit dereferencing used with weak reference objects.  The
     returned object will have a type of either ‘ProxyType’ or
     ‘CallableProxyType’, depending on whether _object_ is callable.
     Proxy objects are not *note hashable: 6f5. regardless of the
     referent; this avoids a number of problems related to their
     fundamentally mutable nature, and prevent their use as dictionary
     keys.  _callback_ is the same as the parameter of the same name to
     the *note ref(): bef. function.

 -- Function: weakref.getweakrefcount (object)

     Return the number of weak references and proxies which refer to
     _object_.

 -- Function: weakref.getweakrefs (object)

     Return a list of all weak reference and proxy objects which refer
     to _object_.

 -- Class: weakref.WeakKeyDictionary ([dict])

     Mapping class that references keys weakly.  Entries in the
     dictionary will be discarded when there is no longer a strong
     reference to the key.  This can be used to associate additional
     data with an object owned by other parts of an application without
     adding attributes to those objects.  This can be especially useful
     with objects that override attribute accesses.

          Note: Caution: Because a *note WeakKeyDictionary: bec. is
          built on top of a Python dictionary, it must not change size
          when iterating over it.  This can be difficult to ensure for a
          *note WeakKeyDictionary: bec. because actions performed by the
          program during iteration may cause items in the dictionary to
          vanish "by magic" (as a side effect of garbage collection).

  *note WeakKeyDictionary: bec. objects have the following additional
methods.  These expose the internal references directly.  The references
are not guaranteed to be "live" at the time they are used, so the result
of calling the references needs to be checked before being used.  This
can be used to avoid creating references that will cause the garbage
collector to keep the keys around longer than needed.

 -- Method: WeakKeyDictionary.iterkeyrefs ()

     Return an iterable of the weak references to the keys.

     New in version 2.5.

 -- Method: WeakKeyDictionary.keyrefs ()

     Return a list of weak references to the keys.

     New in version 2.5.

 -- Class: weakref.WeakValueDictionary ([dict])

     Mapping class that references values weakly.  Entries in the
     dictionary will be discarded when no strong reference to the value
     exists any more.

          Note: Caution: Because a *note WeakValueDictionary: bed. is
          built on top of a Python dictionary, it must not change size
          when iterating over it.  This can be difficult to ensure for a
          *note WeakValueDictionary: bed. because actions performed by
          the program during iteration may cause items in the dictionary
          to vanish "by magic" (as a side effect of garbage collection).

  *note WeakValueDictionary: bed. objects have the following additional
methods.  These method have the same issues as the ‘iterkeyrefs()’ and
‘keyrefs()’ methods of *note WeakKeyDictionary: bec. objects.

 -- Method: WeakValueDictionary.itervaluerefs ()

     Return an iterable of the weak references to the values.

     New in version 2.5.

 -- Method: WeakValueDictionary.valuerefs ()

     Return a list of weak references to the values.

     New in version 2.5.

 -- Class: weakref.WeakSet ([elements])

     Set class that keeps weak references to its elements.  An element
     will be discarded when no strong reference to it exists any more.

     New in version 2.7.

 -- Data: weakref.ReferenceType

     The type object for weak references objects.

 -- Data: weakref.ProxyType

     The type object for proxies of objects which are not callable.

 -- Data: weakref.CallableProxyType

     The type object for proxies of callable objects.

 -- Data: weakref.ProxyTypes

     Sequence containing all the type objects for proxies.  This can
     make it simpler to test if an object is a proxy without being
     dependent on naming both proxy types.

 -- Exception: weakref.ReferenceError

     Exception raised when a proxy object is used but the underlying
     object has been collected.  This is the same as the standard *note
     ReferenceError: 4c3. exception.

See also
........

PEP 0205(2) - Weak References

     The proposal and rationale for this feature, including links to
     earlier implementations and information about similar features in
     other languages.

* Menu:

* Weak Reference Objects:: 
* Example: Example<2>. 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/weakref.py

   (2) http://www.python.org/dev/peps/pep-0205


File: python.info,  Node: Weak Reference Objects,  Next: Example<2>,  Up: weakref --- Weak references

5.8.11.1 Weak Reference Objects
...............................

Weak reference objects have no attributes or methods, but do allow the
referent to be obtained, if it still exists, by calling it:

     >>> import weakref
     >>> class Object:
     ...     pass
     ...
     >>> o = Object()
     >>> r = weakref.ref(o)
     >>> o2 = r()
     >>> o is o2
     True

  If the referent no longer exists, calling the reference object returns
*note None: 39a.:

     >>> del o, o2
     >>> print r()
     None

  Testing that a weak reference object is still live should be done
using the expression ‘ref() is not None’.  Normally, application code
that needs to use a reference object should follow this pattern:

     # r is a weak reference object
     o = r()
     if o is None:
         # referent has been garbage collected
         print "Object has been deallocated; can't frobnicate."
     else:
         print "Object is still live!"
         o.do_something_useful()

  Using a separate test for "liveness" creates race conditions in
threaded applications; another thread can cause a weak reference to
become invalidated before the weak reference is called; the idiom shown
above is safe in threaded applications as well as single-threaded
applications.

  Specialized versions of *note ref: bef. objects can be created through
subclassing.  This is used in the implementation of the *note
WeakValueDictionary: bed. to reduce the memory overhead for each entry
in the mapping.  This may be most useful to associate additional
information with a reference, but could also be used to insert
additional processing on calls to retrieve the referent.

  This example shows how a subclass of *note ref: bef. can be used to
store additional information about an object and affect the value that’s
returned when the referent is accessed:

     import weakref

     class ExtendedRef(weakref.ref):
         def __init__(self, ob, callback=None, **annotations):
             super(ExtendedRef, self).__init__(ob, callback)
             self.__counter = 0
             for k, v in annotations.iteritems():
                 setattr(self, k, v)

         def __call__(self):
             """Return a pair containing the referent and the number of
             times the reference has been called.
             """
             ob = super(ExtendedRef, self).__call__()
             if ob is not None:
                 self.__counter += 1
                 ob = (ob, self.__counter)
             return ob


File: python.info,  Node: Example<2>,  Prev: Weak Reference Objects,  Up: weakref --- Weak references

5.8.11.2 Example
................

This simple example shows how an application can use objects IDs to
retrieve objects that it has seen before.  The IDs of the objects can
then be used in other data structures without forcing the objects to
remain alive, but the objects can still be retrieved by ID if they do.

     import weakref

     _id2obj_dict = weakref.WeakValueDictionary()

     def remember(obj):
         oid = id(obj)
         _id2obj_dict[oid] = obj
         return oid

     def id2obj(oid):
         return _id2obj_dict[oid]


File: python.info,  Node: UserDict --- Class wrapper for dictionary objects,  Next: UserList --- Class wrapper for list objects,  Prev: weakref --- Weak references,  Up: Data Types

5.8.12 ‘UserDict’ — Class wrapper for dictionary objects
--------------------------------------------------------

*Source code:* Lib/UserDict.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The module defines a mixin, *note DictMixin: c00, defining all
dictionary methods for classes that already have a minimum mapping
interface.  This greatly simplifies writing classes that need to be
substitutable for dictionaries (such as the shelve module).

  This module also defines a class, *note UserDict: 18c, that acts as a
wrapper around dictionary objects.  The need for this class has been
largely supplanted by the ability to subclass directly from *note dict:
305. (a feature that became available starting with Python version 2.2).
Prior to the introduction of *note dict: 305, the *note UserDict: 18c.
class was used to create dictionary-like sub-classes that obtained new
behaviors by overriding existing methods or adding new ones.

  The *note UserDict: 18c. module defines the *note UserDict: 18c. class
and *note DictMixin: c00.:

 -- Class: UserDict.UserDict ([initialdata])

     Class that simulates a dictionary.  The instance’s contents are
     kept in a regular dictionary, which is accessible via the ‘data’
     attribute of *note UserDict: 18c. instances.  If _initialdata_ is
     provided, ‘data’ is initialized with its contents; note that a
     reference to _initialdata_ will not be kept, allowing it be used
     for other purposes.

          Note: For backward compatibility, instances of *note UserDict:
          18c. are not iterable.

 -- Class: UserDict.IterableUserDict ([initialdata])

     Subclass of *note UserDict: 18c. that supports direct iteration
     (e.g.  ‘for key in myDict’).

  In addition to supporting the methods and operations of mappings (see
section *note Mapping Types — dict: 54c.), *note UserDict: 18c. and
*note IterableUserDict: c02. instances provide the following attribute:

 -- Attribute: IterableUserDict.data

     A real dictionary used to store the contents of the *note UserDict:
     18c. class.

 -- Class: UserDict.DictMixin

     Mixin defining all dictionary methods for classes that already have
     a minimum dictionary interface including *note __getitem__(): 44f,
     *note __setitem__(): 465, *note __delitem__(): 466, and ‘keys()’.

     This mixin should be used as a superclass.  Adding each of the
     above methods adds progressively more functionality.  For instance,
     defining all but *note __delitem__(): 466. will preclude only
     ‘pop()’ and ‘popitem()’ from the full interface.

     In addition to the four base methods, progressively more efficiency
     comes with defining *note __contains__(): 322, *note __iter__():
     321, and ‘iteritems()’.

     Since the mixin has no knowledge of the subclass constructor, it
     does not define *note __init__(): 37c. or *note copy(): 71.

     Starting with Python version 2.6, it is recommended to use *note
     collections.MutableMapping: b81. instead of *note DictMixin: c00.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/UserDict.py


File: python.info,  Node: UserList --- Class wrapper for list objects,  Next: UserString --- Class wrapper for string objects,  Prev: UserDict --- Class wrapper for dictionary objects,  Up: Data Types

5.8.13 ‘UserList’ — Class wrapper for list objects
--------------------------------------------------

     Note: When Python 2.2 was released, many of the use cases for this
     class were subsumed by the ability to subclass *note list: 3bc.
     directly.  However, a handful of use cases remain.

     This module provides a list-interface around an underlying data
     store.  By default, that data store is a *note list: 3bc.; however,
     it can be used to wrap a list-like interface around other objects
     (such as persistent storage).

     In addition, this class can be mixed-in with built-in classes using
     multiple inheritance.  This can sometimes be useful.  For example,
     you can inherit from *note UserList: 18d. and *note str: 1ea. at
     the same time.  That would not be possible with both a real *note
     list: 3bc. and a real *note str: 1ea.

  This module defines a class that acts as a wrapper around list
objects.  It is a useful base class for your own list-like classes,
which can inherit from them and override existing methods or add new
ones.  In this way one can add new behaviors to lists.

  The *note UserList: 18d. module defines the *note UserList: 18d.
class:

 -- Class: UserList.UserList ([list])

     Class that simulates a list.  The instance’s contents are kept in a
     regular list, which is accessible via the *note data: c06.
     attribute of *note UserList: 18d. instances.  The instance’s
     contents are initially set to a copy of _list_, defaulting to the
     empty list ‘[]’.  _list_ can be any iterable, e.g.  a real Python
     list or a *note UserList: 18d. object.

          Note: The *note UserList: 18d. class has been moved to the
          *note collections: 65. module in Python 3.  The *note 2to3:
          bdb. tool will automatically adapt imports when converting
          your sources to Python 3.

  In addition to supporting the methods and operations of mutable
sequences (see section *note Sequence Types — str, unicode, list, tuple,
bytearray, buffer, xrange: 521.), *note UserList: 18d. instances provide
the following attribute:

 -- Attribute: UserList.data

     A real Python list object used to store the contents of the *note
     UserList: 18d. class.

  *Subclassing requirements:* Subclasses of *note UserList: 18d. are
expected to offer a constructor which can be called with either no
arguments or one argument.  List operations which return a new sequence
attempt to create an instance of the actual implementation class.  To do
so, it assumes that the constructor can be called with a single
parameter, which is a sequence object used as a data source.

  If a derived class does not wish to comply with this requirement, all
of the special methods supported by this class will need to be
overridden; please consult the sources for information about the methods
which need to be provided in that case.

  Changed in version 2.0: Python versions 1.5.2 and 1.6 also required
that the constructor be callable with no parameters, and offer a mutable
‘data’ attribute.  Earlier versions of Python did not attempt to create
instances of the derived class.


File: python.info,  Node: UserString --- Class wrapper for string objects,  Next: types --- Names for built-in types,  Prev: UserList --- Class wrapper for list objects,  Up: Data Types

5.8.14 ‘UserString’ — Class wrapper for string objects
------------------------------------------------------

     Note: This *note UserString: 18e. class from this module is
     available for backward compatibility only.  If you are writing code
     that does not need to work with versions of Python earlier than
     Python 2.2, please consider subclassing directly from the built-in
     *note str: 1ea. type instead of using *note UserString: 18e. (there
     is no built-in equivalent to *note MutableString: c08.).

  This module defines a class that acts as a wrapper around string
objects.  It is a useful base class for your own string-like classes,
which can inherit from them and override existing methods or add new
ones.  In this way one can add new behaviors to strings.

  It should be noted that these classes are highly inefficient compared
to real string or Unicode objects; this is especially the case for *note
MutableString: c08.

  The *note UserString: 18e. module defines the following classes:

 -- Class: UserString.UserString ([sequence])

     Class that simulates a string or a Unicode string object.  The
     instance’s content is kept in a regular string or Unicode string
     object, which is accessible via the ‘data’ attribute of *note
     UserString: 18e. instances.  The instance’s contents are initially
     set to a copy of _sequence_.  _sequence_ can be either a regular
     Python string or Unicode string, an instance of *note UserString:
     18e. (or a subclass) or an arbitrary sequence which can be
     converted into a string using the built-in *note str(): 1ea.
     function.

          Note: The *note UserString: 18e. class has been moved to the
          *note collections: 65. module in Python 3.  The *note 2to3:
          bdb. tool will automatically adapt imports when converting
          your sources to Python 3.

 -- Class: UserString.MutableString ([sequence])

     This class is derived from the *note UserString: 18e. above and
     redefines strings to be _mutable_.  Mutable strings can’t be used
     as dictionary keys, because dictionaries require _immutable_
     objects as keys.  The main intention of this class is to serve as
     an educational example for inheritance and necessity to remove
     (override) the *note __hash__(): 335. method in order to trap
     attempts to use a mutable object as dictionary key, which would be
     otherwise very error prone and hard to track down.

     Deprecated since version 2.6: The *note MutableString: c08. class
     has been removed in Python 3.

  In addition to supporting the methods and operations of string and
Unicode objects (see section *note String Methods: 522.), *note
UserString: 18e. instances provide the following attribute:

 -- Attribute: MutableString.data

     A real Python string or Unicode object used to store the content of
     the *note UserString: 18e. class.


File: python.info,  Node: types --- Names for built-in types,  Next: new --- Creation of runtime internal objects,  Prev: UserString --- Class wrapper for string objects,  Up: Data Types

5.8.15 ‘types’ — Names for built-in types
-----------------------------------------

*Source code:* Lib/types.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module defines names for some object types that are used by the
standard Python interpreter, but not for the types defined by various
extension modules.  Also, it does not include some of the types that
arise during processing such as the ‘listiterator’ type.  It is safe to
use ‘from types import *’ — the module does not export any names besides
the ones listed here.  New names exported by future versions of this
module will all end in ‘Type’.

  Typical use is for functions that do different things depending on
their argument types, like the following:

     from types import *
     def delete(mylist, item):
         if type(item) is IntType:
            del mylist[item]
         else:
            mylist.remove(item)

  Starting in Python 2.2, built-in factory functions such as *note
int(): 1f2. and *note str(): 1ea. are also names for the corresponding
types.  This is now the preferred way to access the type instead of
using the *note types: 185. module.  Accordingly, the example above
should be written as follows:

     def delete(mylist, item):
         if isinstance(item, int):
            del mylist[item]
         else:
            mylist.remove(item)

  The module defines the following names:

 -- Data: types.NoneType

     The type of ‘None’.

 -- Data: types.TypeType

     The type of type objects (such as returned by *note type(): 490.);
     alias of the built-in *note type: 490.

 -- Data: types.BooleanType

     The type of the *note bool: 43c. values ‘True’ and ‘False’; alias
     of the built-in *note bool: 43c.

     New in version 2.3.

 -- Data: types.IntType

     The type of integers (e.g.  ‘1’); alias of the built-in *note int:
     1f2.

 -- Data: types.LongType

     The type of long integers (e.g.  ‘1L’); alias of the built-in *note
     long: 1f3.

 -- Data: types.FloatType

     The type of floating point numbers (e.g.  ‘1.0’); alias of the
     built-in *note float: 1eb.

 -- Data: types.ComplexType

     The type of complex numbers (e.g.  ‘1.0j’).  This is not defined if
     Python was built without complex number support.

 -- Data: types.StringType

     The type of character strings (e.g.  ‘'Spam'’); alias of the
     built-in *note str: 1ea.

 -- Data: types.UnicodeType

     The type of Unicode character strings (e.g.  ‘u'Spam'’).  This is
     not defined if Python was built without Unicode support.  It’s an
     alias of the built-in *note unicode: 1f5.

 -- Data: types.TupleType

     The type of tuples (e.g.  ‘(1, 2, 3, 'Spam')’); alias of the
     built-in *note tuple: 408.

 -- Data: types.ListType

     The type of lists (e.g.  ‘[0, 1, 2, 3]’); alias of the built-in
     *note list: 3bc.

 -- Data: types.DictType

     The type of dictionaries (e.g.  ‘{'Bacon': 1, 'Ham': 0}’); alias of
     the built-in *note dict: 305.

 -- Data: types.DictionaryType

     An alternate name for ‘DictType’.

 -- Data: types.FunctionType
 -- Data: types.LambdaType

     The type of user-defined functions and functions created by *note
     lambda: 403. expressions.

 -- Data: types.GeneratorType

     The type of *note generator: 5dc.-iterator objects, produced by
     calling a generator function.

     New in version 2.2.

 -- Data: types.CodeType

     The type for code objects such as returned by *note compile(): 1fb.

 -- Data: types.ClassType

     The type of user-defined old-style classes.

 -- Data: types.InstanceType

     The type of instances of user-defined classes.

 -- Data: types.MethodType

     The type of methods of user-defined class instances.

 -- Data: types.UnboundMethodType

     An alternate name for ‘MethodType’.

 -- Data: types.BuiltinFunctionType
 -- Data: types.BuiltinMethodType

     The type of built-in functions like *note len(): 520. or *note
     sys.exit(): 2a7, and methods of built-in classes.  (Here, the term
     "built-in" means "written in C".)

 -- Data: types.ModuleType

     The type of modules.

 -- Data: types.FileType

     The type of open file objects such as ‘sys.stdout’; alias of the
     built-in *note file: 1f9.

 -- Data: types.XRangeType

     The type of range objects returned by *note xrange(): 45b.; alias
     of the built-in *note xrange: 45b.

 -- Data: types.SliceType

     The type of objects returned by *note slice(): 450.; alias of the
     built-in *note slice: 450.

 -- Data: types.EllipsisType

     The type of ‘Ellipsis’.

 -- Data: types.TracebackType

     The type of traceback objects such as found in ‘sys.exc_traceback’.

 -- Data: types.FrameType

     The type of frame objects such as found in ‘tb.tb_frame’ if ‘tb’ is
     a traceback object.

 -- Data: types.BufferType

     The type of buffer objects created by the *note buffer(): 316.
     function.

 -- Data: types.DictProxyType

     The type of dict proxies, such as ‘TypeType.__dict__’.

 -- Data: types.NotImplementedType

     The type of ‘NotImplemented’

 -- Data: types.GetSetDescriptorType

     The type of objects defined in extension modules with
     ‘PyGetSetDef’, such as ‘FrameType.f_locals’ or
     ‘array.array.typecode’.  This type is used as descriptor for object
     attributes; it has the same purpose as the *note property: 487.
     type, but for classes defined in extension modules.

     New in version 2.5.

 -- Data: types.MemberDescriptorType

     The type of objects defined in extension modules with
     ‘PyMemberDef’, such as ‘datetime.timedelta.days’.  This type is
     used as descriptor for simple C data members which use standard
     conversion functions; it has the same purpose as the *note
     property: 487. type, but for classes defined in extension modules.

     *CPython implementation detail:* In other implementations of
     Python, this type may be identical to ‘GetSetDescriptorType’.

     New in version 2.5.

 -- Data: types.StringTypes

     A sequence containing ‘StringType’ and ‘UnicodeType’ used to
     facilitate easier checking for any string object.  Using this is
     more portable than using a sequence of the two string types
     constructed elsewhere since it only contains ‘UnicodeType’ if it
     has been built in the running version of Python.  For example:
     ‘isinstance(s, types.StringTypes)’.

     New in version 2.2.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/types.py


File: python.info,  Node: new --- Creation of runtime internal objects,  Next: copy --- Shallow and deep copy operations,  Prev: types --- Names for built-in types,  Up: Data Types

5.8.16 ‘new’ — Creation of runtime internal objects
---------------------------------------------------

Deprecated since version 2.6: The *note new: 122. module has been
removed in Python 3.  Use the *note types: 185. module’s classes
instead.

  The *note new: 122. module allows an interface to the interpreter
object creation functions.  This is for use primarily in marshal-type
functions, when a new object needs to be created "magically" and not by
using the regular creation functions.  This module provides a low-level
interface to the interpreter, so care must be exercised when using this
module.  It is possible to supply non-sensical arguments which crash the
interpreter when the object is used.

  The *note new: 122. module defines the following functions:

 -- Function: new.instance (class[, dict])

     This function creates an instance of _class_ with dictionary _dict_
     without calling the *note __init__(): 37c. constructor.  If _dict_
     is omitted or ‘None’, a new, empty dictionary is created for the
     new instance.  Note that there are no guarantees that the object
     will be in a consistent state.

 -- Function: new.instancemethod (function, instance, class)

     This function will return a method object, bound to _instance_, or
     unbound if _instance_ is ‘None’.  _function_ must be callable.

 -- Function: new.function (code, globals[, name[, argdefs[, closure]]])

     Returns a (Python) function with the given code and globals.  If
     _name_ is given, it must be a string or ‘None’.  If it is a string,
     the function will have the given name, otherwise the function name
     will be taken from ‘code.co_name’.  If _argdefs_ is given, it must
     be a tuple and will be used to determine the default values of
     parameters.  If _closure_ is given, it must be ‘None’ or a tuple of
     cell objects containing objects to bind to the names in
     ‘code.co_freevars’.

 -- Function: new.code (argcount, nlocals, stacksize, flags, codestring,
          constants, names, varnames, filename, name, firstlineno,
          lnotab)

     This function is an interface to the *note PyCode_New(): 2b8. C
     function.

 -- Function: new.module (name[, doc])

     This function returns a new module object with name _name_.  _name_
     must be a string.  The optional _doc_ argument can have any type.

 -- Function: new.classobj (name, baseclasses, dict)

     This function returns a new class object, with name _name_, derived
     from _baseclasses_ (which should be a tuple of classes) and with
     namespace _dict_.


File: python.info,  Node: copy --- Shallow and deep copy operations,  Next: pprint --- Data pretty printer,  Prev: new --- Creation of runtime internal objects,  Up: Data Types

5.8.17 ‘copy’ — Shallow and deep copy operations
------------------------------------------------

Assignment statements in Python do not copy objects, they create
bindings between a target and an object.  For collections that are
mutable or contain mutable items, a copy is sometimes needed so one can
change one copy without changing the other.  This module provides
generic shallow and deep copy operations (explained below).

  Interface summary:

 -- Function: copy.copy (x)

     Return a shallow copy of _x_.

 -- Function: copy.deepcopy (x)

     Return a deep copy of _x_.

 -- Exception: copy.error

     Raised for module specific errors.

  The difference between shallow and deep copying is only relevant for
compound objects (objects that contain other objects, like lists or
class instances):

   * A _shallow copy_ constructs a new compound object and then (to the
     extent possible) inserts _references_ into it to the objects found
     in the original.

   * A _deep copy_ constructs a new compound object and then,
     recursively, inserts _copies_ into it of the objects found in the
     original.

  Two problems often exist with deep copy operations that don’t exist
with shallow copy operations:

   * Recursive objects (compound objects that, directly or indirectly,
     contain a reference to themselves) may cause a recursive loop.

   * Because deep copy copies _everything_ it may copy too much, e.g.,
     administrative data structures that should be shared even between
     copies.

  The *note deepcopy(): 20f. function avoids these problems by:

   * keeping a "memo" dictionary of objects already copied during the
     current copying pass; and

   * letting user-defined classes override the copying operation or the
     set of components copied.

  This module does not copy types like module, method, stack trace,
stack frame, file, socket, window, array, or any similar types.  It does
"copy" functions and classes (shallow and deeply), by returning the
original object unchanged; this is compatible with the way these are
treated by the *note pickle: 12d. module.

  Shallow copies of dictionaries can be made using *note dict.copy():
8fb, and of lists by assigning a slice of the entire list, for example,
‘copied_list = original_list[:]’.

  Changed in version 2.5: Added copying functions.

  Classes can use the same interfaces to control copying that they use
to control pickling.  See the description of module *note pickle: 12d.
for information on these methods.  The *note copy: 71. module does not
use the *note copy_reg: 72. registration module.

  In order for a class to define its own copy implementation, it can
define special methods ‘__copy__()’ and ‘__deepcopy__()’.  The former is
called to implement the shallow copy operation; no additional arguments
are passed.  The latter is called to implement the deep copy operation;
it is passed one argument, the memo dictionary.  If the ‘__deepcopy__()’
implementation needs to make a deep copy of a component, it should call
the *note deepcopy(): 20f. function with the component as first argument
and the memo dictionary as second argument.

See also
........

Module *note pickle: 12d.

     Discussion of the special methods used to support object state
     retrieval and restoration.


File: python.info,  Node: pprint --- Data pretty printer,  Next: repr --- Alternate repr implementation,  Prev: copy --- Shallow and deep copy operations,  Up: Data Types

5.8.18 ‘pprint’ — Data pretty printer
-------------------------------------

*Source code:* Lib/pprint.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note pprint: 138. module provides a capability to "pretty-print"
arbitrary Python data structures in a form which can be used as input to
the interpreter.  If the formatted structures include objects which are
not fundamental Python types, the representation may not be loadable.
This may be the case if objects such as files, sockets, classes, or
instances are included, as well as many other built-in objects which are
not representable as Python constants.

  The formatted representation keeps objects on a single line if it can,
and breaks them onto multiple lines if they don’t fit within the allowed
width.  Construct *note PrettyPrinter: c3e. objects explicitly if you
need to adjust the width constraint.

  Changed in version 2.5: Dictionaries are sorted by key before the
display is computed; before 2.5, a dictionary was sorted only if its
display required more than one line, although that wasn’t documented.

  Changed in version 2.6: Added support for *note set: 36a. and *note
frozenset: 36b.

  The *note pprint: 138. module defines one class:

 -- Class: pprint.PrettyPrinter (indent=1, width=80, depth=None,
          stream=None)

     Construct a *note PrettyPrinter: c3e. instance.  This constructor
     understands several keyword parameters.  An output stream may be
     set using the _stream_ keyword; the only method used on the stream
     object is the file protocol’s ‘write()’ method.  If not specified,
     the *note PrettyPrinter: c3e. adopts ‘sys.stdout’.  Three
     additional parameters may be used to control the formatted
     representation.  The keywords are _indent_, _depth_, and _width_.
     The amount of indentation added for each recursive level is
     specified by _indent_; the default is one.  Other values can cause
     output to look a little odd, but can make nesting easier to spot.
     The number of levels which may be printed is controlled by _depth_;
     if the data structure being printed is too deep, the next contained
     level is replaced by ‘...’.  By default, there is no constraint on
     the depth of the objects being formatted.  The desired output width
     is constrained using the _width_ parameter; the default is 80
     characters.  If a structure cannot be formatted within the
     constrained width, a best effort will be made.

          >>> import pprint
          >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
          >>> stuff.insert(0, stuff[:])
          >>> pp = pprint.PrettyPrinter(indent=4)
          >>> pp.pprint(stuff)
          [   ['spam', 'eggs', 'lumberjack', 'knights', 'ni'],
              'spam',
              'eggs',
              'lumberjack',
              'knights',
              'ni']
          >>> tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',
          ... ('parrot', ('fresh fruit',))))))))
          >>> pp = pprint.PrettyPrinter(depth=6)
          >>> pp.pprint(tup)
          ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead', (...)))))))

  The *note PrettyPrinter: c3e. class supports several derivative
functions:

 -- Function: pprint.pformat (object, indent=1, width=80, depth=None)

     Return the formatted representation of _object_ as a string.
     _indent_, _width_ and _depth_ will be passed to the *note
     PrettyPrinter: c3e. constructor as formatting parameters.

     Changed in version 2.4: The parameters _indent_, _width_ and
     _depth_ were added.

 -- Function: pprint.pprint (object, stream=None, indent=1, width=80,
          depth=None)

     Prints the formatted representation of _object_ on _stream_,
     followed by a newline.  If _stream_ is ‘None’, ‘sys.stdout’ is
     used.  This may be used in the interactive interpreter instead of a
     *note print: 4e0. statement for inspecting values.  _indent_,
     _width_ and _depth_ will be passed to the *note PrettyPrinter: c3e.
     constructor as formatting parameters.

          >>> import pprint
          >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
          >>> stuff.insert(0, stuff)
          >>> pprint.pprint(stuff)
          [<Recursion on list with id=...>,
           'spam',
           'eggs',
           'lumberjack',
           'knights',
           'ni']

     Changed in version 2.4: The parameters _indent_, _width_ and
     _depth_ were added.

 -- Function: pprint.isreadable (object)

     Determine if the formatted representation of _object_ is
     "readable," or can be used to reconstruct the value using *note
     eval(): 360.  This always returns ‘False’ for recursive objects.

          >>> pprint.isreadable(stuff)
          False

 -- Function: pprint.isrecursive (object)

     Determine if _object_ requires a recursive representation.

  One more support function is also defined:

 -- Function: pprint.saferepr (object)

     Return a string representation of _object_, protected against
     recursive data structures.  If the representation of _object_
     exposes a recursive entry, the recursive reference will be
     represented as ‘<Recursion on typename with id=number>’.  The
     representation is not otherwise formatted.

          >>> pprint.saferepr(stuff)
          "[<Recursion on list with id=...>, 'spam', 'eggs', 'lumberjack', 'knights', 'ni']"

* Menu:

* PrettyPrinter Objects:: 
* pprint Example:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/pprint.py


File: python.info,  Node: PrettyPrinter Objects,  Next: pprint Example,  Up: pprint --- Data pretty printer

5.8.18.1 PrettyPrinter Objects
..............................

*note PrettyPrinter: c3e. instances have the following methods:

 -- Method: PrettyPrinter.pformat (object)

     Return the formatted representation of _object_.  This takes into
     account the options passed to the *note PrettyPrinter: c3e.
     constructor.

 -- Method: PrettyPrinter.pprint (object)

     Print the formatted representation of _object_ on the configured
     stream, followed by a newline.

  The following methods provide the implementations for the
corresponding functions of the same names.  Using these methods on an
instance is slightly more efficient since new *note PrettyPrinter: c3e.
objects don’t need to be created.

 -- Method: PrettyPrinter.isreadable (object)

     Determine if the formatted representation of the object is
     "readable," or can be used to reconstruct the value using *note
     eval(): 360.  Note that this returns ‘False’ for recursive objects.
     If the _depth_ parameter of the *note PrettyPrinter: c3e. is set
     and the object is deeper than allowed, this returns ‘False’.

 -- Method: PrettyPrinter.isrecursive (object)

     Determine if the object requires a recursive representation.

  This method is provided as a hook to allow subclasses to modify the
way objects are converted to strings.  The default implementation uses
the internals of the *note saferepr(): c43. implementation.

 -- Method: PrettyPrinter.format (object, context, maxlevels, level)

     Returns three values: the formatted version of _object_ as a
     string, a flag indicating whether the result is readable, and a
     flag indicating whether recursion was detected.  The first argument
     is the object to be presented.  The second is a dictionary which
     contains the *note id(): 3b2. of objects that are part of the
     current presentation context (direct and indirect containers for
     _object_ that are affecting the presentation) as the keys; if an
     object needs to be presented which is already represented in
     _context_, the third return value should be ‘True’.  Recursive
     calls to the *note format(): 1ef. method should add additional
     entries for containers to this dictionary.  The third argument,
     _maxlevels_, gives the requested limit to recursion; this will be
     ‘0’ if there is no requested limit.  This argument should be passed
     unmodified to recursive calls.  The fourth argument, _level_, gives
     the current level; recursive calls should be passed a value less
     than that of the current call.

     New in version 2.3.


File: python.info,  Node: pprint Example,  Prev: PrettyPrinter Objects,  Up: pprint --- Data pretty printer

5.8.18.2 pprint Example
.......................

This example demonstrates several uses of the *note pprint(): 138.
function and its parameters.

     >>> import pprint
     >>> tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',
     ... ('parrot', ('fresh fruit',))))))))
     >>> stuff = ['a' * 10, tup, ['a' * 30, 'b' * 30], ['c' * 20, 'd' * 20]]
     >>> pprint.pprint(stuff)
     ['aaaaaaaaaa',
      ('spam',
       ('eggs',
        ('lumberjack',
         ('knights', ('ni', ('dead', ('parrot', ('fresh fruit',)))))))),
      ['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'],
      ['cccccccccccccccccccc', 'dddddddddddddddddddd']]
     >>> pprint.pprint(stuff, depth=3)
     ['aaaaaaaaaa',
      ('spam', ('eggs', (...))),
      ['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa', 'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'],
      ['cccccccccccccccccccc', 'dddddddddddddddddddd']]
     >>> pprint.pprint(stuff, width=60)
     ['aaaaaaaaaa',
      ('spam',
       ('eggs',
        ('lumberjack',
         ('knights',
          ('ni', ('dead', ('parrot', ('fresh fruit',)))))))),
      ['aaaaaaaaaaaaaaaaaaaaaaaaaaaaaa',
       'bbbbbbbbbbbbbbbbbbbbbbbbbbbbbb'],
      ['cccccccccccccccccccc', 'dddddddddddddddddddd']]


File: python.info,  Node: repr --- Alternate repr implementation,  Prev: pprint --- Data pretty printer,  Up: Data Types

5.8.19 ‘repr’ — Alternate ‘repr()’ implementation
-------------------------------------------------

     Note: The *note repr: 145. module has been renamed to ‘reprlib’ in
     Python 3.  The *note 2to3: bdb. tool will automatically adapt
     imports when converting your sources to Python 3.

  *Source code:* Lib/repr.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note repr: 145. module provides a means for producing object
representations with limits on the size of the resulting strings.  This
is used in the Python debugger and may be useful in other contexts as
well.

  This module provides a class, an instance, and a function:

 -- Class: repr.Repr

     Class which provides formatting services useful in implementing
     functions similar to the built-in *note repr(): 876.; size limits
     for different object types are added to avoid the generation of
     representations which are excessively long.

 -- Data: repr.aRepr

     This is an instance of *note Repr: c4f. which is used to provide
     the *note repr(): c51. function described below.  Changing the
     attributes of this object will affect the size limits used by *note
     repr(): c51. and the Python debugger.

 -- Function: repr.repr (obj)

     This is the *note repr(): c52. method of ‘aRepr’.  It returns a
     string similar to that returned by the built-in function of the
     same name, but with limits on most sizes.

* Menu:

* Repr Objects:: 
* Subclassing Repr Objects:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/repr.py


File: python.info,  Node: Repr Objects,  Next: Subclassing Repr Objects,  Up: repr --- Alternate repr implementation

5.8.19.1 Repr Objects
.....................

*note Repr: c4f. instances provide several attributes which can be used
to provide size limits for the representations of different object
types, and methods which format specific object types.

 -- Attribute: Repr.maxlevel

     Depth limit on the creation of recursive representations.  The
     default is ‘6’.

 -- Attribute: Repr.maxdict
 -- Attribute: Repr.maxlist
 -- Attribute: Repr.maxtuple
 -- Attribute: Repr.maxset
 -- Attribute: Repr.maxfrozenset
 -- Attribute: Repr.maxdeque
 -- Attribute: Repr.maxarray

     Limits on the number of entries represented for the named object
     type.  The default is ‘4’ for *note maxdict: c56, ‘5’ for *note
     maxarray: c5c, and ‘6’ for the others.

     New in version 2.4: *note maxset: c59, *note maxfrozenset: c5a, and
     *note set: 36a.

 -- Attribute: Repr.maxlong

     Maximum number of characters in the representation for a long
     integer.  Digits are dropped from the middle.  The default is ‘40’.

 -- Attribute: Repr.maxstring

     Limit on the number of characters in the representation of the
     string.  Note that the "normal" representation of the string is
     used as the character source: if escape sequences are needed in the
     representation, these may be mangled when the representation is
     shortened.  The default is ‘30’.

 -- Attribute: Repr.maxother

     This limit is used to control the size of object types for which no
     specific formatting method is available on the *note Repr: c4f.
     object.  It is applied in a similar manner as *note maxstring: c5e.
     The default is ‘20’.

 -- Method: Repr.repr (obj)

     The equivalent to the built-in *note repr(): 876. that uses the
     formatting imposed by the instance.

 -- Method: Repr.repr1 (obj, level)

     Recursive implementation used by *note repr(): c52.  This uses the
     type of _obj_ to determine which formatting method to call, passing
     it _obj_ and _level_.  The type-specific methods should call *note
     repr1(): c60. to perform recursive formatting, with ‘level - 1’ for
     the value of _level_ in the recursive call.

 -- Method: Repr.repr_TYPE (obj, level)

     Formatting methods for specific types are implemented as methods
     with a name based on the type name.  In the method name, *TYPE* is
     replaced by ‘string.join(string.split(type(obj).__name__, '_'))’.
     Dispatch to these methods is handled by ‘repr1()’.  Type-specific
     methods which need to recursively format a value should call
     ‘self.repr1(subobj, level - 1)’.


File: python.info,  Node: Subclassing Repr Objects,  Prev: Repr Objects,  Up: repr --- Alternate repr implementation

5.8.19.2 Subclassing Repr Objects
.................................

The use of dynamic dispatching by *note Repr.repr1(): c60. allows
subclasses of *note Repr: c4f. to add support for additional built-in
object types or to modify the handling of types already supported.  This
example shows how special support for file objects could be added:

     import repr as reprlib
     import sys

     class MyRepr(reprlib.Repr):
         def repr_file(self, obj, level):
             if obj.name in ['<stdin>', '<stdout>', '<stderr>']:
                 return obj.name
             else:
                 return repr(obj)

     aRepr = MyRepr()
     print aRepr.repr(sys.stdin)          # prints '<stdin>'


File: python.info,  Node: Numeric and Mathematical Modules,  Next: File and Directory Access,  Prev: Data Types,  Up: The Python Standard Library

5.9 Numeric and Mathematical Modules
====================================

The modules described in this chapter provide numeric and math-related
functions and data types.  The *note numbers: 125. module defines an
abstract hierarchy of numeric types.  The *note math: 10c. and *note
cmath: 60. modules contain various mathematical functions for
floating-point and complex numbers.  For users more interested in
decimal accuracy than in speed, the *note decimal: 80. module supports
exact representations of decimal numbers.

  The following modules are documented in this chapter:

* Menu:

* numbers: numbers --- Numeric abstract base classes. Numeric abstract base classes
* math: math --- Mathematical functions. Mathematical functions
* cmath: cmath --- Mathematical functions for complex numbers. Mathematical functions for complex numbers
* decimal: decimal --- Decimal fixed point and floating point arithmetic. Decimal fixed point and floating point arithmetic
* fractions: fractions --- Rational numbers. Rational numbers
* random: random --- Generate pseudo-random numbers. Generate pseudo-random numbers
* itertools: itertools --- Functions creating iterators for efficient looping. Functions creating iterators for efficient looping
* functools: functools --- Higher-order functions and operations on callable objects. Higher-order functions and operations on callable
                        objects
* operator: operator --- Standard operators as functions. Standard operators as functions

numbers — Numeric abstract base classes

* The numeric tower:: 
* Notes for type implementors:: 

Notes for type implementors

* Adding More Numeric ABCs:: 
* Implementing the arithmetic operations:: 

math — Mathematical functions

* Number-theoretic and representation functions:: 
* Power and logarithmic functions:: 
* Trigonometric functions:: 
* Angular conversion:: 
* Hyperbolic functions:: 
* Special functions:: 
* Constants:: 

cmath — Mathematical functions for complex numbers

* Conversions to and from polar coordinates:: 
* Power and logarithmic functions: Power and logarithmic functions<2>. 
* Trigonometric functions: Trigonometric functions<2>. 
* Hyperbolic functions: Hyperbolic functions<2>. 
* Classification functions:: 
* Constants: Constants<2>. 

decimal — Decimal fixed point and floating point arithmetic

* Quick-start Tutorial:: 
* Decimal objects:: 
* Context objects:: 
* Signals:: 
* Floating Point Notes:: 
* Working with threads:: 
* Recipes:: 
* Decimal FAQ:: 

Decimal objects

* Logical operands:: 

Floating Point Notes

* Mitigating round-off error with increased precision:: 
* Special values:: 

itertools — Functions creating iterators for efficient looping

* Itertool functions:: 
* Recipes: Recipes<2>. 

functools — Higher-order functions and operations on callable objects

* partial Objects:: 

operator — Standard operators as functions

* Mapping Operators to Functions:: 


File: python.info,  Node: numbers --- Numeric abstract base classes,  Next: math --- Mathematical functions,  Up: Numeric and Mathematical Modules

5.9.1 ‘numbers’ — Numeric abstract base classes
-----------------------------------------------

New in version 2.6.

  The *note numbers: 125. module ( PEP 3141(1)) defines a hierarchy of
numeric *note abstract base classes: 886. which progressively define
more operations.  None of the types defined in this module can be
instantiated.

 -- Class: numbers.Number

     The root of the numeric hierarchy.  If you just want to check if an
     argument _x_ is a number, without caring what kind, use
     ‘isinstance(x, Number)’.

* Menu:

* The numeric tower:: 
* Notes for type implementors:: 

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-3141


File: python.info,  Node: The numeric tower,  Next: Notes for type implementors,  Up: numbers --- Numeric abstract base classes

5.9.1.1 The numeric tower
.........................

 -- Class: numbers.Complex

     Subclasses of this type describe complex numbers and include the
     operations that work on the built-in *note complex: 1ec. type.
     These are: conversions to *note complex: 1ec. and *note bool: 43c,
     *note real: c69, *note imag: c6a, ‘+’, ‘-’, ‘*’, ‘/’, *note abs():
     5bf, *note conjugate(): c6b, ‘==’, and ‘!=’.  All except ‘-’ and
     ‘!=’ are abstract.

      -- Attribute: real

          Abstract.  Retrieves the real component of this number.

      -- Attribute: imag

          Abstract.  Retrieves the imaginary component of this number.

      -- Method: conjugate ()

          Abstract.  Returns the complex conjugate.  For example,
          ‘(1+3j).conjugate() == (1-3j)’.

 -- Class: numbers.Real

     To *note Complex: 6f1, *note Real: 6f0. adds the operations that
     work on real numbers.

     In short, those are: a conversion to *note float: 1eb, *note
     math.trunc(): 32d, *note round(): 1c5, *note math.floor(): 32b,
     *note math.ceil(): 32c, *note divmod(): 73d, ‘//’, ‘%’, ‘<’, ‘<=’,
     ‘>’, and ‘>=’.

     Real also provides defaults for *note complex(): 1ec, *note real:
     c69, *note imag: c6a, and *note conjugate(): c6b.

 -- Class: numbers.Rational

     Subtypes *note Real: 6f0. and adds *note numerator: c6c. and *note
     denominator: c6d. properties, which should be in lowest terms.
     With these, it provides a default for *note float(): 1eb.

      -- Attribute: numerator

          Abstract.

      -- Attribute: denominator

          Abstract.

 -- Class: numbers.Integral

     Subtypes *note Rational: 32a. and adds a conversion to *note int:
     1f2.  Provides defaults for *note float(): 1eb, *note numerator:
     c6c, and *note denominator: c6d.  Adds abstract methods for ‘**’
     and bit-string operations: ‘<<’, ‘>>’, ‘&’, ‘^’, ‘|’, ‘~’.


File: python.info,  Node: Notes for type implementors,  Prev: The numeric tower,  Up: numbers --- Numeric abstract base classes

5.9.1.2 Notes for type implementors
...................................

Implementors should be careful to make equal numbers equal and hash them
to the same values.  This may be subtle if there are two different
extensions of the real numbers.  For example, *note fractions.Fraction:
217. implements *note hash(): 70b. as follows:

     def __hash__(self):
         if self.denominator == 1:
             # Get integers right.
             return hash(self.numerator)
         # Expensive check, but definitely correct.
         if self == float(self):
             return hash(float(self))
         else:
             # Use tuple's hash to avoid a high collision rate on
             # simple fractions.
             return hash((self.numerator, self.denominator))

* Menu:

* Adding More Numeric ABCs:: 
* Implementing the arithmetic operations:: 


File: python.info,  Node: Adding More Numeric ABCs,  Next: Implementing the arithmetic operations,  Up: Notes for type implementors

5.9.1.3 Adding More Numeric ABCs
................................

There are, of course, more possible ABCs for numbers, and this would be
a poor hierarchy if it precluded the possibility of adding those.  You
can add ‘MyFoo’ between *note Complex: 6f1. and *note Real: 6f0. with:

     class MyFoo(Complex): ...
     MyFoo.register(Real)


File: python.info,  Node: Implementing the arithmetic operations,  Prev: Adding More Numeric ABCs,  Up: Notes for type implementors

5.9.1.4 Implementing the arithmetic operations
..............................................

We want to implement the arithmetic operations so that mixed-mode
operations either call an implementation whose author knew about the
types of both arguments, or convert both to the nearest built in type
and do the operation there.  For subtypes of *note Integral: 6ef, this
means that *note __add__(): 725. and *note __radd__(): 726. should be
defined as:

     class MyIntegral(Integral):

         def __add__(self, other):
             if isinstance(other, MyIntegral):
                 return do_my_adding_stuff(self, other)
             elif isinstance(other, OtherTypeIKnowAbout):
                 return do_my_other_adding_stuff(self, other)
             else:
                 return NotImplemented

         def __radd__(self, other):
             if isinstance(other, MyIntegral):
                 return do_my_adding_stuff(other, self)
             elif isinstance(other, OtherTypeIKnowAbout):
                 return do_my_other_adding_stuff(other, self)
             elif isinstance(other, Integral):
                 return int(other) + int(self)
             elif isinstance(other, Real):
                 return float(other) + float(self)
             elif isinstance(other, Complex):
                 return complex(other) + complex(self)
             else:
                 return NotImplemented

  There are 5 different cases for a mixed-type operation on subclasses
of *note Complex: 6f1.  I’ll refer to all of the above code that doesn’t
refer to ‘MyIntegral’ and ‘OtherTypeIKnowAbout’ as "boilerplate".  ‘a’
will be an instance of ‘A’, which is a subtype of *note Complex: 6f1.
(‘a : A <: Complex’), and ‘b : B <: Complex’.  I’ll consider ‘a + b’:

       1. If ‘A’ defines an *note __add__(): 725. which accepts ‘b’, all
          is well.

       2. If ‘A’ falls back to the boilerplate code, and it were to
          return a value from *note __add__(): 725, we’d miss the
          possibility that ‘B’ defines a more intelligent *note
          __radd__(): 726, so the boilerplate should return *note
          NotImplemented: 20e. from *note __add__(): 725.  (Or ‘A’ may
          not implement *note __add__(): 725. at all.)

       3. Then ‘B’’s *note __radd__(): 726. gets a chance.  If it
          accepts ‘a’, all is well.

       4. If it falls back to the boilerplate, there are no more
          possible methods to try, so this is where the default
          implementation should live.

       5. If ‘B <: A’, Python tries ‘B.__radd__’ before ‘A.__add__’.
          This is ok, because it was implemented with knowledge of ‘A’,
          so it can handle those instances before delegating to *note
          Complex: 6f1.

  If ‘A <: Complex’ and ‘B <: Real’ without sharing any other knowledge,
then the appropriate shared operation is the one involving the built in
*note complex: 1ec, and both *note __radd__(): 726. s land there, so
‘a+b == b+a’.

  Because most of the operations on any given type will be very similar,
it can be useful to define a helper function which generates the forward
and reverse instances of any given operator.  For example, *note
fractions.Fraction: 217. uses:

     def _operator_fallbacks(monomorphic_operator, fallback_operator):
         def forward(a, b):
             if isinstance(b, (int, long, Fraction)):
                 return monomorphic_operator(a, b)
             elif isinstance(b, float):
                 return fallback_operator(float(a), b)
             elif isinstance(b, complex):
                 return fallback_operator(complex(a), b)
             else:
                 return NotImplemented
         forward.__name__ = '__' + fallback_operator.__name__ + '__'
         forward.__doc__ = monomorphic_operator.__doc__

         def reverse(b, a):
             if isinstance(a, Rational):
                 # Includes ints.
                 return monomorphic_operator(a, b)
             elif isinstance(a, numbers.Real):
                 return fallback_operator(float(a), float(b))
             elif isinstance(a, numbers.Complex):
                 return fallback_operator(complex(a), complex(b))
             else:
                 return NotImplemented
         reverse.__name__ = '__r' + fallback_operator.__name__ + '__'
         reverse.__doc__ = monomorphic_operator.__doc__

         return forward, reverse

     def _add(a, b):
         """a + b"""
         return Fraction(a.numerator * b.denominator +
                         b.numerator * a.denominator,
                         a.denominator * b.denominator)

     __add__, __radd__ = _operator_fallbacks(_add, operator.add)

     # ...


File: python.info,  Node: math --- Mathematical functions,  Next: cmath --- Mathematical functions for complex numbers,  Prev: numbers --- Numeric abstract base classes,  Up: Numeric and Mathematical Modules

5.9.2 ‘math’ — Mathematical functions
-------------------------------------

This module is always available.  It provides access to the mathematical
functions defined by the C standard.

  These functions cannot be used with complex numbers; use the functions
of the same name from the *note cmath: 60. module if you require support
for complex numbers.  The distinction between functions which support
complex numbers and those which don’t is made since most users do not
want to learn quite as much mathematics as required to understand
complex numbers.  Receiving an exception instead of a complex result
allows earlier detection of the unexpected complex number used as a
parameter, so that the programmer can determine how and why it was
generated in the first place.

  The following functions are provided by this module.  Except when
explicitly noted otherwise, all return values are floats.

* Menu:

* Number-theoretic and representation functions:: 
* Power and logarithmic functions:: 
* Trigonometric functions:: 
* Angular conversion:: 
* Hyperbolic functions:: 
* Special functions:: 
* Constants:: 


File: python.info,  Node: Number-theoretic and representation functions,  Next: Power and logarithmic functions,  Up: math --- Mathematical functions

5.9.2.1 Number-theoretic and representation functions
.....................................................

 -- Function: math.ceil (x)

     Return the ceiling of _x_ as a float, the smallest integer value
     greater than or equal to _x_.

 -- Function: math.copysign (x, y)

     Return _x_ with the sign of _y_.  On a platform that supports
     signed zeros, ‘copysign(1.0, -0.0)’ returns _-1.0_.

     New in version 2.6.

 -- Function: math.fabs (x)

     Return the absolute value of _x_.

 -- Function: math.factorial (x)

     Return _x_ factorial.  Raises *note ValueError: 236. if _x_ is not
     integral or is negative.

     New in version 2.6.

 -- Function: math.floor (x)

     Return the floor of _x_ as a float, the largest integer value less
     than or equal to _x_.

 -- Function: math.fmod (x, y)

     Return ‘fmod(x, y)’, as defined by the platform C library.  Note
     that the Python expression ‘x % y’ may not return the same result.
     The intent of the C standard is that ‘fmod(x, y)’ be exactly
     (mathematically; to infinite precision) equal to ‘x - n*y’ for some
     integer _n_ such that the result has the same sign as _x_ and
     magnitude less than ‘abs(y)’.  Python’s ‘x % y’ returns a result
     with the sign of _y_ instead, and may not be exactly computable for
     float arguments.  For example, ‘fmod(-1e-100, 1e100)’ is ‘-1e-100’,
     but the result of Python’s ‘-1e-100 % 1e100’ is ‘1e100-1e-100’,
     which cannot be represented exactly as a float, and rounds to the
     surprising ‘1e100’.  For this reason, function *note fmod(): 7d2.
     is generally preferred when working with floats, while Python’s ‘x
     % y’ is preferred when working with integers.

 -- Function: math.frexp (x)

     Return the mantissa and exponent of _x_ as the pair ‘(m, e)’.  _m_
     is a float and _e_ is an integer such that ‘x == m * 2**e’ exactly.
     If _x_ is zero, returns ‘(0.0, 0)’, otherwise ‘0.5 <= abs(m) < 1’.
     This is used to "pick apart" the internal representation of a float
     in a portable way.

 -- Function: math.fsum (iterable)

     Return an accurate floating point sum of values in the iterable.
     Avoids loss of precision by tracking multiple intermediate partial
     sums:

          >>> sum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
          0.9999999999999999
          >>> fsum([.1, .1, .1, .1, .1, .1, .1, .1, .1, .1])
          1.0

     The algorithm’s accuracy depends on IEEE-754 arithmetic guarantees
     and the typical case where the rounding mode is half-even.  On some
     non-Windows builds, the underlying C library uses extended
     precision addition and may occasionally double-round an
     intermediate sum causing it to be off in its least significant bit.

     For further discussion and two alternative approaches, see the ASPN
     cookbook recipes for accurate floating point summation(1).

     New in version 2.6.

 -- Function: math.isinf (x)

     Check if the float _x_ is positive or negative infinity.

     New in version 2.6.

 -- Function: math.isnan (x)

     Check if the float _x_ is a NaN (not a number).  For more
     information on NaNs, see the IEEE 754 standards.

     New in version 2.6.

 -- Function: math.ldexp (x, i)

     Return ‘x * (2**i)’.  This is essentially the inverse of function
     *note frexp(): c75.

 -- Function: math.modf (x)

     Return the fractional and integer parts of _x_.  Both results carry
     the sign of _x_ and are floats.

 -- Function: math.trunc (x)

     Return the *note Real: 6f0. value _x_ truncated to an *note
     Integral: 6ef. (usually a long integer).  Uses the ‘__trunc__’
     method.

     New in version 2.6.

  Note that *note frexp(): c75. and *note modf(): c77. have a different
call/return pattern than their C equivalents: they take a single
argument and return a pair of values, rather than returning their second
return value through an ’output parameter’ (there is no such thing in
Python).

  For the *note ceil(): 32c, *note floor(): 32b, and *note modf(): c77.
functions, note that _all_ floating-point numbers of sufficiently large
magnitude are exact integers.  Python floats typically carry no more
than 53 bits of precision (the same as the platform C double type), in
which case any float _x_ with ‘abs(x) >= 2**52’ necessarily has no
fractional bits.

   ---------- Footnotes ----------

   (1) http://code.activestate.com/recipes/393090/


File: python.info,  Node: Power and logarithmic functions,  Next: Trigonometric functions,  Prev: Number-theoretic and representation functions,  Up: math --- Mathematical functions

5.9.2.2 Power and logarithmic functions
.......................................

 -- Function: math.exp (x)

     Return ‘e**x’.

 -- Function: math.expm1 (x)

     Return ‘e**x - 1’.  For small floats _x_, the subtraction in
     ‘exp(x) - 1’ can result in a significant loss of precision; the
     *note expm1(): 23b. function provides a way to compute this
     quantity to full precision:

          >>> from math import exp, expm1
          >>> exp(1e-5) - 1  # gives result accurate to 11 places
          1.0000050000069649e-05
          >>> expm1(1e-5)    # result accurate to full precision
          1.0000050000166668e-05

     New in version 2.7.

 -- Function: math.log (x[, base])

     With one argument, return the natural logarithm of _x_ (to base
     _e_).

     With two arguments, return the logarithm of _x_ to the given
     _base_, calculated as ‘log(x)/log(base)’.

     Changed in version 2.3: _base_ argument added.

 -- Function: math.log1p (x)

     Return the natural logarithm of _1+x_ (base _e_).  The result is
     calculated in a way which is accurate for _x_ near zero.

     New in version 2.6.

 -- Function: math.log10 (x)

     Return the base-10 logarithm of _x_.  This is usually more accurate
     than ‘log(x, 10)’.

 -- Function: math.pow (x, y)

     Return ‘x’ raised to the power ‘y’.  Exceptional cases follow Annex
     ’F’ of the C99 standard as far as possible.  In particular,
     ‘pow(1.0, x)’ and ‘pow(x, 0.0)’ always return ‘1.0’, even when ‘x’
     is a zero or a NaN. If both ‘x’ and ‘y’ are finite, ‘x’ is
     negative, and ‘y’ is not an integer then ‘pow(x, y)’ is undefined,
     and raises *note ValueError: 236.

     Unlike the built-in ‘**’ operator, *note math.pow(): c7a. converts
     both its arguments to type *note float: 1eb.  Use ‘**’ or the
     built-in *note pow(): 4b5. function for computing exact integer
     powers.

     Changed in version 2.6: The outcome of ‘1**nan’ and ‘nan**0’ was
     undefined.

 -- Function: math.sqrt (x)

     Return the square root of _x_.


File: python.info,  Node: Trigonometric functions,  Next: Angular conversion,  Prev: Power and logarithmic functions,  Up: math --- Mathematical functions

5.9.2.3 Trigonometric functions
...............................

 -- Function: math.acos (x)

     Return the arc cosine of _x_, in radians.

 -- Function: math.asin (x)

     Return the arc sine of _x_, in radians.

 -- Function: math.atan (x)

     Return the arc tangent of _x_, in radians.

 -- Function: math.atan2 (y, x)

     Return ‘atan(y / x)’, in radians.  The result is between ‘-pi’ and
     ‘pi’.  The vector in the plane from the origin to point ‘(x, y)’
     makes this angle with the positive X axis.  The point of *note
     atan2(): c80. is that the signs of both inputs are known to it, so
     it can compute the correct quadrant for the angle.  For example,
     ‘atan(1)’ and ‘atan2(1, 1)’ are both ‘pi/4’, but ‘atan2(-1, -1)’ is
     ‘-3*pi/4’.

 -- Function: math.cos (x)

     Return the cosine of _x_ radians.

 -- Function: math.hypot (x, y)

     Return the Euclidean norm, ‘sqrt(x*x + y*y)’.  This is the length
     of the vector from the origin to point ‘(x, y)’.

 -- Function: math.sin (x)

     Return the sine of _x_ radians.

 -- Function: math.tan (x)

     Return the tangent of _x_ radians.


File: python.info,  Node: Angular conversion,  Next: Hyperbolic functions,  Prev: Trigonometric functions,  Up: math --- Mathematical functions

5.9.2.4 Angular conversion
..........................

 -- Function: math.degrees (x)

     Converts angle _x_ from radians to degrees.

 -- Function: math.radians (x)

     Converts angle _x_ from degrees to radians.


File: python.info,  Node: Hyperbolic functions,  Next: Special functions,  Prev: Angular conversion,  Up: math --- Mathematical functions

5.9.2.5 Hyperbolic functions
............................

 -- Function: math.acosh (x)

     Return the inverse hyperbolic cosine of _x_.

     New in version 2.6.

 -- Function: math.asinh (x)

     Return the inverse hyperbolic sine of _x_.

     New in version 2.6.

 -- Function: math.atanh (x)

     Return the inverse hyperbolic tangent of _x_.

     New in version 2.6.

 -- Function: math.cosh (x)

     Return the hyperbolic cosine of _x_.

 -- Function: math.sinh (x)

     Return the hyperbolic sine of _x_.

 -- Function: math.tanh (x)

     Return the hyperbolic tangent of _x_.


File: python.info,  Node: Special functions,  Next: Constants,  Prev: Hyperbolic functions,  Up: math --- Mathematical functions

5.9.2.6 Special functions
.........................

 -- Function: math.erf (x)

     Return the error function at _x_.

     New in version 2.7.

 -- Function: math.erfc (x)

     Return the complementary error function at _x_.

     New in version 2.7.

 -- Function: math.gamma (x)

     Return the Gamma function at _x_.

     New in version 2.7.

 -- Function: math.lgamma (x)

     Return the natural logarithm of the absolute value of the Gamma
     function at _x_.

     New in version 2.7.


File: python.info,  Node: Constants,  Prev: Special functions,  Up: math --- Mathematical functions

5.9.2.7 Constants
.................

 -- Data: math.pi

     The mathematical constant π = 3.141592..., to available precision.

 -- Data: math.e

     The mathematical constant e = 2.718281..., to available precision.

*CPython implementation detail:* The *note math: 10c. module consists
mostly of thin wrappers around the platform C math library functions.
Behavior in exceptional cases follows Annex F of the C99 standard where
appropriate.  The current implementation will raise *note ValueError:
236. for invalid operations like ‘sqrt(-1.0)’ or ‘log(0.0)’ (where C99
Annex F recommends signaling invalid operation or divide-by-zero), and
*note OverflowError: 2db. for results that overflow (for example,
‘exp(1000.0)’).  A NaN will not be returned from any of the functions
above unless one or more of the input arguments was a NaN; in that case,
most functions will return a NaN, but (again following C99 Annex F)
there are some exceptions to this rule, for example ‘pow(float('nan'),
0.0)’ or ‘hypot(float('nan'), float('inf'))’.

Note that Python makes no effort to distinguish signaling NaNs from
quiet NaNs, and behavior for signaling NaNs remains unspecified.
Typical behavior is to treat all NaNs as though they were quiet.

  Changed in version 2.6: Behavior in special cases now aims to follow
C99 Annex F. In earlier versions of Python the behavior in special cases
was loosely specified.

See also
........

Module *note cmath: 60.

     Complex number versions of many of these functions.


File: python.info,  Node: cmath --- Mathematical functions for complex numbers,  Next: decimal --- Decimal fixed point and floating point arithmetic,  Prev: math --- Mathematical functions,  Up: Numeric and Mathematical Modules

5.9.3 ‘cmath’ — Mathematical functions for complex numbers
----------------------------------------------------------

This module is always available.  It provides access to mathematical
functions for complex numbers.  The functions in this module accept
integers, floating-point numbers or complex numbers as arguments.  They
will also accept any Python object that has either a *note
__complex__(): 2e7. or a *note __float__(): 75a. method: these methods
are used to convert the object to a complex or floating-point number,
respectively, and the function is then applied to the result of the
conversion.

     Note: On platforms with hardware and system-level support for
     signed zeros, functions involving branch cuts are continuous on
     _both_ sides of the branch cut: the sign of the zero distinguishes
     one side of the branch cut from the other.  On platforms that do
     not support signed zeros the continuity is as specified below.

* Menu:

* Conversions to and from polar coordinates:: 
* Power and logarithmic functions: Power and logarithmic functions<2>. 
* Trigonometric functions: Trigonometric functions<2>. 
* Hyperbolic functions: Hyperbolic functions<2>. 
* Classification functions:: 
* Constants: Constants<2>. 


File: python.info,  Node: Conversions to and from polar coordinates,  Next: Power and logarithmic functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.1 Conversions to and from polar coordinates
.................................................

A Python complex number ‘z’ is stored internally using _rectangular_ or
_Cartesian_ coordinates.  It is completely determined by its _real part_
‘z.real’ and its _imaginary part_ ‘z.imag’.  In other words:

     z == z.real + z.imag*1j

  _Polar coordinates_ give an alternative way to represent a complex
number.  In polar coordinates, a complex number _z_ is defined by the
modulus _r_ and the phase angle _phi_.  The modulus _r_ is the distance
from _z_ to the origin, while the phase _phi_ is the counterclockwise
angle, measured in radians, from the positive x-axis to the line segment
that joins the origin to _z_.

  The following functions can be used to convert from the native
rectangular coordinates to polar coordinates and back.

 -- Function: cmath.phase (x)

     Return the phase of _x_ (also known as the _argument_ of _x_), as a
     float.  ‘phase(x)’ is equivalent to ‘math.atan2(x.imag, x.real)’.
     The result lies in the range [-π, π], and the branch cut for this
     operation lies along the negative real axis, continuous from above.
     On systems with support for signed zeros (which includes most
     systems in current use), this means that the sign of the result is
     the same as the sign of ‘x.imag’, even when ‘x.imag’ is zero:

          >>> phase(complex(-1.0, 0.0))
          3.1415926535897931
          >>> phase(complex(-1.0, -0.0))
          -3.1415926535897931

     New in version 2.6.

     Note: The modulus (absolute value) of a complex number _x_ can be
     computed using the built-in *note abs(): 5bf. function.  There is
     no separate *note cmath: 60. module function for this operation.

 -- Function: cmath.polar (x)

     Return the representation of _x_ in polar coordinates.  Returns a
     pair ‘(r, phi)’ where _r_ is the modulus of _x_ and phi is the
     phase of _x_.  ‘polar(x)’ is equivalent to ‘(abs(x), phase(x))’.

     New in version 2.6.

 -- Function: cmath.rect (r, phi)

     Return the complex number _x_ with polar coordinates _r_ and _phi_.
     Equivalent to ‘r * (math.cos(phi) + math.sin(phi)*1j)’.

     New in version 2.6.


File: python.info,  Node: Power and logarithmic functions<2>,  Next: Trigonometric functions<2>,  Prev: Conversions to and from polar coordinates,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.2 Power and logarithmic functions
.......................................

 -- Function: cmath.exp (x)

     Return the exponential value ‘e**x’.

 -- Function: cmath.log (x[, base])

     Returns the logarithm of _x_ to the given _base_.  If the _base_ is
     not specified, returns the natural logarithm of _x_.  There is one
     branch cut, from 0 along the negative real axis to -∞, continuous
     from above.

     Changed in version 2.4: _base_ argument added.

 -- Function: cmath.log10 (x)

     Return the base-10 logarithm of _x_.  This has the same branch cut
     as *note log(): c96.

 -- Function: cmath.sqrt (x)

     Return the square root of _x_.  This has the same branch cut as
     *note log(): c96.


File: python.info,  Node: Trigonometric functions<2>,  Next: Hyperbolic functions<2>,  Prev: Power and logarithmic functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.3 Trigonometric functions
...............................

 -- Function: cmath.acos (x)

     Return the arc cosine of _x_.  There are two branch cuts: One
     extends right from 1 along the real axis to ∞, continuous from
     below.  The other extends left from -1 along the real axis to -∞,
     continuous from above.

 -- Function: cmath.asin (x)

     Return the arc sine of _x_.  This has the same branch cuts as *note
     acos(): c9a.

 -- Function: cmath.atan (x)

     Return the arc tangent of _x_.  There are two branch cuts: One
     extends from ‘1j’ along the imaginary axis to ‘∞j’, continuous from
     the right.  The other extends from ‘-1j’ along the imaginary axis
     to ‘-∞j’, continuous from the left.

     Changed in version 2.6: direction of continuity of upper cut
     reversed

 -- Function: cmath.cos (x)

     Return the cosine of _x_.

 -- Function: cmath.sin (x)

     Return the sine of _x_.

 -- Function: cmath.tan (x)

     Return the tangent of _x_.


File: python.info,  Node: Hyperbolic functions<2>,  Next: Classification functions,  Prev: Trigonometric functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.4 Hyperbolic functions
............................

 -- Function: cmath.acosh (x)

     Return the hyperbolic arc cosine of _x_.  There is one branch cut,
     extending left from 1 along the real axis to -∞, continuous from
     above.

 -- Function: cmath.asinh (x)

     Return the hyperbolic arc sine of _x_.  There are two branch cuts:
     One extends from ‘1j’ along the imaginary axis to ‘∞j’, continuous
     from the right.  The other extends from ‘-1j’ along the imaginary
     axis to ‘-∞j’, continuous from the left.

     Changed in version 2.6: branch cuts moved to match those
     recommended by the C99 standard

 -- Function: cmath.atanh (x)

     Return the hyperbolic arc tangent of _x_.  There are two branch
     cuts: One extends from ‘1’ along the real axis to ‘∞’, continuous
     from below.  The other extends from ‘-1’ along the real axis to
     ‘-∞’, continuous from above.

     Changed in version 2.6: direction of continuity of right cut
     reversed

 -- Function: cmath.cosh (x)

     Return the hyperbolic cosine of _x_.

 -- Function: cmath.sinh (x)

     Return the hyperbolic sine of _x_.

 -- Function: cmath.tanh (x)

     Return the hyperbolic tangent of _x_.


File: python.info,  Node: Classification functions,  Next: Constants<2>,  Prev: Hyperbolic functions<2>,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.5 Classification functions
................................

 -- Function: cmath.isinf (x)

     Return _True_ if the real or the imaginary part of x is positive or
     negative infinity.

     New in version 2.6.

 -- Function: cmath.isnan (x)

     Return _True_ if the real or imaginary part of x is not a number
     (NaN).

     New in version 2.6.


File: python.info,  Node: Constants<2>,  Prev: Classification functions,  Up: cmath --- Mathematical functions for complex numbers

5.9.3.6 Constants
.................

 -- Data: cmath.pi

     The mathematical constant _π_, as a float.

 -- Data: cmath.e

     The mathematical constant _e_, as a float.

  Note that the selection of functions is similar, but not identical, to
that in module *note math: 10c.  The reason for having two modules is
that some users aren’t interested in complex numbers, and perhaps don’t
even know what they are.  They would rather have ‘math.sqrt(-1)’ raise
an exception than return a complex number.  Also note that the functions
defined in *note cmath: 60. always return a complex number, even if the
answer can be expressed as a real number (in which case the complex
number has an imaginary part of zero).

  A note on branch cuts: They are curves along which the given function
fails to be continuous.  They are a necessary feature of many complex
functions.  It is assumed that if you need to compute with complex
functions, you will understand about branch cuts.  Consult almost any
(not too elementary) book on complex variables for enlightenment.  For
information of the proper choice of branch cuts for numerical purposes,
a good reference should be the following:

See also
........

Kahan, W: Branch cuts for complex elementary functions; or, Much ado
about nothing’s sign bit.  In Iserles, A., and Powell, M. (eds.), The
state of the art in numerical analysis.  Clarendon Press (1987)
pp165-211.


File: python.info,  Node: decimal --- Decimal fixed point and floating point arithmetic,  Next: fractions --- Rational numbers,  Prev: cmath --- Mathematical functions for complex numbers,  Up: Numeric and Mathematical Modules

5.9.4 ‘decimal’ — Decimal fixed point and floating point arithmetic
-------------------------------------------------------------------

New in version 2.4.

  The *note decimal: 80. module provides support for decimal floating
point arithmetic.  It offers several advantages over the *note float:
1eb. datatype:

   * Decimal "is based on a floating-point model which was designed with
     people in mind, and necessarily has a paramount guiding principle –
     computers must provide an arithmetic that works in the same way as
     the arithmetic that people learn at school."  – excerpt from the
     decimal arithmetic specification.

   * Decimal numbers can be represented exactly.  In contrast, numbers
     like ‘1.1’ and ‘2.2’ do not have exact representations in binary
     floating point.  End users typically would not expect ‘1.1 + 2.2’
     to display as ‘3.3000000000000003’ as it does with binary floating
     point.

   * The exactness carries over into arithmetic.  In decimal floating
     point, ‘0.1 + 0.1 + 0.1 - 0.3’ is exactly equal to zero.  In binary
     floating point, the result is ‘5.5511151231257827e-017’.  While
     near to zero, the differences prevent reliable equality testing and
     differences can accumulate.  For this reason, decimal is preferred
     in accounting applications which have strict equality invariants.

   * The decimal module incorporates a notion of significant places so
     that ‘1.30 + 1.20’ is ‘2.50’.  The trailing zero is kept to
     indicate significance.  This is the customary presentation for
     monetary applications.  For multiplication, the "schoolbook"
     approach uses all the figures in the multiplicands.  For instance,
     ‘1.3 * 1.2’ gives ‘1.56’ while ‘1.30 * 1.20’ gives ‘1.5600’.

   * Unlike hardware based binary floating point, the decimal module has
     a user alterable precision (defaulting to 28 places) which can be
     as large as needed for a given problem:

          >>> from decimal import *
          >>> getcontext().prec = 6
          >>> Decimal(1) / Decimal(7)
          Decimal('0.142857')
          >>> getcontext().prec = 28
          >>> Decimal(1) / Decimal(7)
          Decimal('0.1428571428571428571428571429')

   * Both binary and decimal floating point are implemented in terms of
     published standards.  While the built-in float type exposes only a
     modest portion of its capabilities, the decimal module exposes all
     required parts of the standard.  When needed, the programmer has
     full control over rounding and signal handling.  This includes an
     option to enforce exact arithmetic by using exceptions to block any
     inexact operations.

   * The decimal module was designed to support "without prejudice, both
     exact unrounded decimal arithmetic (sometimes called fixed-point
     arithmetic) and rounded floating-point arithmetic."  – excerpt from
     the decimal arithmetic specification.

  The module design is centered around three concepts: the decimal
number, the context for arithmetic, and signals.

  A decimal number is immutable.  It has a sign, coefficient digits, and
an exponent.  To preserve significance, the coefficient digits do not
truncate trailing zeros.  Decimals also include special values such as
‘Infinity’, ‘-Infinity’, and ‘NaN’.  The standard also differentiates
‘-0’ from ‘+0’.

  The context for arithmetic is an environment specifying precision,
rounding rules, limits on exponents, flags indicating the results of
operations, and trap enablers which determine whether signals are
treated as exceptions.  Rounding options include ‘ROUND_CEILING’,
‘ROUND_DOWN’, ‘ROUND_FLOOR’, ‘ROUND_HALF_DOWN’, ‘ROUND_HALF_EVEN’,
‘ROUND_HALF_UP’, ‘ROUND_UP’, and ‘ROUND_05UP’.

  Signals are groups of exceptional conditions arising during the course
of computation.  Depending on the needs of the application, signals may
be ignored, considered as informational, or treated as exceptions.  The
signals in the decimal module are: *note Clamped: caf, *note
InvalidOperation: 2dc, *note DivisionByZero: cb0, *note Inexact: cb1,
*note Rounded: cb2, *note Subnormal: cb3, *note Overflow: cb4, and *note
Underflow: cb5.

  For each signal there is a flag and a trap enabler.  When a signal is
encountered, its flag is set to one, then, if the trap enabler is set to
one, an exception is raised.  Flags are sticky, so the user needs to
reset them before monitoring a calculation.

See also
........

   * IBM’s General Decimal Arithmetic Specification, The General Decimal
     Arithmetic Specification(1).

   * IEEE standard 854-1987, Unofficial IEEE 854 Text(2).

* Menu:

* Quick-start Tutorial:: 
* Decimal objects:: 
* Context objects:: 
* Signals:: 
* Floating Point Notes:: 
* Working with threads:: 
* Recipes:: 
* Decimal FAQ:: 

   ---------- Footnotes ----------

   (1) http://speleotrove.com/decimal/

   (2) http://754r.ucbtest.org/standards/854.pdf


File: python.info,  Node: Quick-start Tutorial,  Next: Decimal objects,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.1 Quick-start Tutorial
............................

The usual start to using decimals is importing the module, viewing the
current context with *note getcontext(): cb8. and, if necessary, setting
new values for precision, rounding, or enabled traps:

     >>> from decimal import *
     >>> getcontext()
     Context(prec=28, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
             capitals=1, flags=[], traps=[Overflow, DivisionByZero,
             InvalidOperation])

     >>> getcontext().prec = 7       # Set a new precision

  Decimal instances can be constructed from integers, strings, floats,
or tuples.  Construction from an integer or a float performs an exact
conversion of the value of that integer or float.  Decimal numbers
include special values such as ‘NaN’ which stands for "Not a number",
positive and negative ‘Infinity’, and ‘-0’.

     >>> getcontext().prec = 28
     >>> Decimal(10)
     Decimal('10')
     >>> Decimal('3.14')
     Decimal('3.14')
     >>> Decimal(3.14)
     Decimal('3.140000000000000124344978758017532527446746826171875')
     >>> Decimal((0, (3, 1, 4), -2))
     Decimal('3.14')
     >>> Decimal(str(2.0 ** 0.5))
     Decimal('1.41421356237')
     >>> Decimal(2) ** Decimal('0.5')
     Decimal('1.414213562373095048801688724')
     >>> Decimal('NaN')
     Decimal('NaN')
     >>> Decimal('-Infinity')
     Decimal('-Infinity')

  The significance of a new Decimal is determined solely by the number
of digits input.  Context precision and rounding only come into play
during arithmetic operations.

     >>> getcontext().prec = 6
     >>> Decimal('3.0')
     Decimal('3.0')
     >>> Decimal('3.1415926535')
     Decimal('3.1415926535')
     >>> Decimal('3.1415926535') + Decimal('2.7182818285')
     Decimal('5.85987')
     >>> getcontext().rounding = ROUND_UP
     >>> Decimal('3.1415926535') + Decimal('2.7182818285')
     Decimal('5.85988')

  Decimals interact well with much of the rest of Python.  Here is a
small decimal floating point flying circus:

     >>> data = map(Decimal, '1.34 1.87 3.45 2.35 1.00 0.03 9.25'.split())
     >>> max(data)
     Decimal('9.25')
     >>> min(data)
     Decimal('0.03')
     >>> sorted(data)
     [Decimal('0.03'), Decimal('1.00'), Decimal('1.34'), Decimal('1.87'),
      Decimal('2.35'), Decimal('3.45'), Decimal('9.25')]
     >>> sum(data)
     Decimal('19.29')
     >>> a,b,c = data[:3]
     >>> str(a)
     '1.34'
     >>> float(a)
     1.34
     >>> round(a, 1)     # round() first converts to binary floating point
     1.3
     >>> int(a)
     1
     >>> a * 5
     Decimal('6.70')
     >>> a * b
     Decimal('2.5058')
     >>> c % a
     Decimal('0.77')

  And some mathematical functions are also available to Decimal:

     >>> getcontext().prec = 28
     >>> Decimal(2).sqrt()
     Decimal('1.414213562373095048801688724')
     >>> Decimal(1).exp()
     Decimal('2.718281828459045235360287471')
     >>> Decimal('10').ln()
     Decimal('2.302585092994045684017991455')
     >>> Decimal('10').log10()
     Decimal('1')

  The ‘quantize()’ method rounds a number to a fixed exponent.  This
method is useful for monetary applications that often round results to a
fixed number of places:

     >>> Decimal('7.325').quantize(Decimal('.01'), rounding=ROUND_DOWN)
     Decimal('7.32')
     >>> Decimal('7.325').quantize(Decimal('1.'), rounding=ROUND_UP)
     Decimal('8')

  As shown above, the *note getcontext(): cb8. function accesses the
current context and allows the settings to be changed.  This approach
meets the needs of most applications.

  For more advanced work, it may be useful to create alternate contexts
using the Context() constructor.  To make an alternate active, use the
*note setcontext(): cb9. function.

  In accordance with the standard, the ‘Decimal’ module provides two
ready to use standard contexts, *note BasicContext: cba. and *note
ExtendedContext: cbb.  The former is especially useful for debugging
because many of the traps are enabled:

     >>> myothercontext = Context(prec=60, rounding=ROUND_HALF_DOWN)
     >>> setcontext(myothercontext)
     >>> Decimal(1) / Decimal(7)
     Decimal('0.142857142857142857142857142857142857142857142857142857142857')

     >>> ExtendedContext
     Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
             capitals=1, flags=[], traps=[])
     >>> setcontext(ExtendedContext)
     >>> Decimal(1) / Decimal(7)
     Decimal('0.142857143')
     >>> Decimal(42) / Decimal(0)
     Decimal('Infinity')

     >>> setcontext(BasicContext)
     >>> Decimal(42) / Decimal(0)
     Traceback (most recent call last):
       File "<pyshell#143>", line 1, in -toplevel-
         Decimal(42) / Decimal(0)
     DivisionByZero: x / 0

  Contexts also have signal flags for monitoring exceptional conditions
encountered during computations.  The flags remain set until explicitly
cleared, so it is best to clear the flags before each set of monitored
computations by using the ‘clear_flags()’ method.

     >>> setcontext(ExtendedContext)
     >>> getcontext().clear_flags()
     >>> Decimal(355) / Decimal(113)
     Decimal('3.14159292')
     >>> getcontext()
     Context(prec=9, rounding=ROUND_HALF_EVEN, Emin=-999999999, Emax=999999999,
             capitals=1, flags=[Rounded, Inexact], traps=[])

  The _flags_ entry shows that the rational approximation to ‘Pi’ was
rounded (digits beyond the context precision were thrown away) and that
the result is inexact (some of the discarded digits were non-zero).

  Individual traps are set using the dictionary in the ‘traps’ field of
a context:

     >>> setcontext(ExtendedContext)
     >>> Decimal(1) / Decimal(0)
     Decimal('Infinity')
     >>> getcontext().traps[DivisionByZero] = 1
     >>> Decimal(1) / Decimal(0)
     Traceback (most recent call last):
       File "<pyshell#112>", line 1, in -toplevel-
         Decimal(1) / Decimal(0)
     DivisionByZero: x / 0

  Most programs adjust the current context only once, at the beginning
of the program.  And, in many applications, data is converted to *note
Decimal: 1b4. with a single cast inside a loop.  With context set and
decimals created, the bulk of the program manipulates the data no
differently than with other Python numeric types.


File: python.info,  Node: Decimal objects,  Next: Context objects,  Prev: Quick-start Tutorial,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.2 Decimal objects
.......................

 -- Class: decimal.Decimal ([value[, context]])

     Construct a new *note Decimal: 1b4. object based from _value_.

     _value_ can be an integer, string, tuple, *note float: 1eb, or
     another *note Decimal: 1b4. object.  If no _value_ is given,
     returns ‘Decimal('0')’.  If _value_ is a string, it should conform
     to the decimal numeric string syntax after leading and trailing
     whitespace characters are removed:

          sign           ::=  '+' | '-'
          digit          ::=  '0' | '1' | '2' | '3' | '4' | '5' | '6' | '7' | '8' | '9'
          indicator      ::=  'e' | 'E'
          digits         ::=  digit [digit]...
          decimal-part   ::=  digits '.' [digits] | ['.'] digits
          exponent-part  ::=  indicator [sign] digits
          infinity       ::=  'Infinity' | 'Inf'
          nan            ::=  'NaN' [digits] | 'sNaN' [digits]
          numeric-value  ::=  decimal-part [exponent-part] | infinity
          numeric-string ::=  [sign] numeric-value | [sign] nan

     If _value_ is a unicode string then other Unicode decimal digits
     are also permitted where ‘digit’ appears above.  These include
     decimal digits from various other alphabets (for example,
     Arabic-Indic and Devanāgarī digits) along with the fullwidth digits
     ‘u'\uff10'’ through ‘u'\uff19'’.

     If _value_ is a *note tuple: 408, it should have three components,
     a sign (‘0’ for positive or ‘1’ for negative), a *note tuple: 408.
     of digits, and an integer exponent.  For example, ‘Decimal((0, (1,
     4, 1, 4), -3))’ returns ‘Decimal('1.414')’.

     If _value_ is a *note float: 1eb, the binary floating point value
     is losslessly converted to its exact decimal equivalent.  This
     conversion can often require 53 or more digits of precision.  For
     example, ‘Decimal(float('1.1'))’ converts to
     ‘Decimal('1.100000000000000088817841970012523233890533447265625')’.

     The _context_ precision does not affect how many digits are stored.
     That is determined exclusively by the number of digits in _value_.
     For example, ‘Decimal('3.00000')’ records all five zeros even if
     the context precision is only three.

     The purpose of the _context_ argument is determining what to do if
     _value_ is a malformed string.  If the context traps *note
     InvalidOperation: 2dc, an exception is raised; otherwise, the
     constructor returns a new Decimal with the value of ‘NaN’.

     Once constructed, *note Decimal: 1b4. objects are immutable.

     Changed in version 2.6: leading and trailing whitespace characters
     are permitted when creating a Decimal instance from a string.

     Changed in version 2.7: The argument to the constructor is now
     permitted to be a *note float: 1eb. instance.

     Decimal floating point objects share many properties with the other
     built-in numeric types such as *note float: 1eb. and *note int:
     1f2.  All of the usual math operations and special methods apply.
     Likewise, decimal objects can be copied, pickled, printed, used as
     dictionary keys, used as set elements, compared, sorted, and
     coerced to another type (such as *note float: 1eb. or *note long:
     1f3.).

     There are some small differences between arithmetic on Decimal
     objects and arithmetic on integers and floats.  When the remainder
     operator ‘%’ is applied to Decimal objects, the sign of the result
     is the sign of the _dividend_ rather than the sign of the divisor:

          >>> (-7) % 4
          1
          >>> Decimal(-7) % Decimal(4)
          Decimal('-3')

     The integer division operator ‘//’ behaves analogously, returning
     the integer part of the true quotient (truncating towards zero)
     rather than its floor, so as to preserve the usual identity ‘x ==
     (x // y) * y + x % y’:

          >>> -7 // 4
          -2
          >>> Decimal(-7) // Decimal(4)
          Decimal('-1')

     The ‘%’ and ‘//’ operators implement the ‘remainder’ and
     ‘divide-integer’ operations (respectively) as described in the
     specification.

     Decimal objects cannot generally be combined with floats in
     arithmetic operations: an attempt to add a *note Decimal: 1b4. to a
     *note float: 1eb, for example, will raise a *note TypeError: 218.
     There’s one exception to this rule: it’s possible to use Python’s
     comparison operators to compare a *note float: 1eb. instance ‘x’
     with a *note Decimal: 1b4. instance ‘y’.  Without this exception,
     comparisons between *note Decimal: 1b4. and *note float: 1eb.
     instances would follow the general rules for comparing objects of
     different types described in the *note Expressions: 76e. section of
     the reference manual, leading to confusing results.

     Changed in version 2.7: A comparison between a *note float: 1eb.
     instance ‘x’ and a *note Decimal: 1b4. instance ‘y’ now returns a
     result based on the values of ‘x’ and ‘y’.  In earlier versions ‘x
     < y’ returned the same (arbitrary) result for any *note Decimal:
     1b4. instance ‘x’ and any *note float: 1eb. instance ‘y’.

     In addition to the standard numeric properties, decimal floating
     point objects also have a number of specialized methods:

      -- Method: adjusted ()

          Return the adjusted exponent after shifting out the
          coefficient’s rightmost digits until only the lead digit
          remains: ‘Decimal('321e+5').adjusted()’ returns seven.  Used
          for determining the position of the most significant digit
          with respect to the decimal point.

      -- Method: as_tuple ()

          Return a *note named tuple: a1f. representation of the number:
          ‘DecimalTuple(sign, digits, exponent)’.

          Changed in version 2.6: Use a named tuple.

      -- Method: canonical ()

          Return the canonical encoding of the argument.  Currently, the
          encoding of a *note Decimal: 1b4. instance is always
          canonical, so this operation returns its argument unchanged.

          New in version 2.6.

      -- Method: compare (other[, context])

          Compare the values of two Decimal instances.  This operation
          behaves in the same way as the usual comparison method *note
          __cmp__(): 221, except that *note compare(): cc1. returns a
          Decimal instance rather than an integer, and if either operand
          is a NaN then the result is a NaN:

               a or b is a NaN ==> Decimal('NaN')
               a < b           ==> Decimal('-1')
               a == b          ==> Decimal('0')
               a > b           ==> Decimal('1')

      -- Method: compare_signal (other[, context])

          This operation is identical to the *note compare(): cc1.
          method, except that all NaNs signal.  That is, if neither
          operand is a signaling NaN then any quiet NaN operand is
          treated as though it were a signaling NaN.

          New in version 2.6.

      -- Method: compare_total (other)

          Compare two operands using their abstract representation
          rather than their numerical value.  Similar to the *note
          compare(): cc1. method, but the result gives a total ordering
          on *note Decimal: 1b4. instances.  Two *note Decimal: 1b4.
          instances with the same numeric value but different
          representations compare unequal in this ordering:

               >>> Decimal('12.0').compare_total(Decimal('12'))
               Decimal('-1')

          Quiet and signaling NaNs are also included in the total
          ordering.  The result of this function is ‘Decimal('0')’ if
          both operands have the same representation, ‘Decimal('-1')’ if
          the first operand is lower in the total order than the second,
          and ‘Decimal('1')’ if the first operand is higher in the total
          order than the second operand.  See the specification for
          details of the total order.

          New in version 2.6.

      -- Method: compare_total_mag (other)

          Compare two operands using their abstract representation
          rather than their value as in *note compare_total(): cc3, but
          ignoring the sign of each operand.  ‘x.compare_total_mag(y)’
          is equivalent to ‘x.copy_abs().compare_total(y.copy_abs())’.

          New in version 2.6.

      -- Method: conjugate ()

          Just returns self, this method is only to comply with the
          Decimal Specification.

          New in version 2.6.

      -- Method: copy_abs ()

          Return the absolute value of the argument.  This operation is
          unaffected by the context and is quiet: no flags are changed
          and no rounding is performed.

          New in version 2.6.

      -- Method: copy_negate ()

          Return the negation of the argument.  This operation is
          unaffected by the context and is quiet: no flags are changed
          and no rounding is performed.

          New in version 2.6.

      -- Method: copy_sign (other)

          Return a copy of the first operand with the sign set to be the
          same as the sign of the second operand.  For example:

               >>> Decimal('2.3').copy_sign(Decimal('-1.5'))
               Decimal('-2.3')

          This operation is unaffected by the context and is quiet: no
          flags are changed and no rounding is performed.

          New in version 2.6.

      -- Method: exp ([context])

          Return the value of the (natural) exponential function ‘e**x’
          at the given number.  The result is correctly rounded using
          the ‘ROUND_HALF_EVEN’ rounding mode.

               >>> Decimal(1).exp()
               Decimal('2.718281828459045235360287471')
               >>> Decimal(321).exp()
               Decimal('2.561702493119680037517373933E+139')

          New in version 2.6.

      -- Method: from_float (f)

          Classmethod that converts a float to a decimal number,
          exactly.

          Note ‘Decimal.from_float(0.1)’ is not the same as
          ‘Decimal(’0.1’)’.  Since 0.1 is not exactly representable in
          binary floating point, the value is stored as the nearest
          representable value which is ‘0x1.999999999999ap-4’.  That
          equivalent value in decimal is
          ‘0.1000000000000000055511151231257827021181583404541015625’.

               Note: From Python 2.7 onwards, a *note Decimal: 1b4.
               instance can also be constructed directly from a *note
               float: 1eb.

               >>> Decimal.from_float(0.1)
               Decimal('0.1000000000000000055511151231257827021181583404541015625')
               >>> Decimal.from_float(float('nan'))
               Decimal('NaN')
               >>> Decimal.from_float(float('inf'))
               Decimal('Infinity')
               >>> Decimal.from_float(float('-inf'))
               Decimal('-Infinity')

          New in version 2.7.

      -- Method: fma (other, third[, context])

          Fused multiply-add.  Return self*other+third with no rounding
          of the intermediate product self*other.

               >>> Decimal(2).fma(3, 5)
               Decimal('11')

          New in version 2.6.

      -- Method: is_canonical ()

          Return *note True: 3b0. if the argument is canonical and *note
          False: 3b1. otherwise.  Currently, a *note Decimal: 1b4.
          instance is always canonical, so this operation always returns
          *note True: 3b0.

          New in version 2.6.

      -- Method: is_finite ()

          Return *note True: 3b0. if the argument is a finite number,
          and *note False: 3b1. if the argument is an infinity or a NaN.

          New in version 2.6.

      -- Method: is_infinite ()

          Return *note True: 3b0. if the argument is either positive or
          negative infinity and *note False: 3b1. otherwise.

          New in version 2.6.

      -- Method: is_nan ()

          Return *note True: 3b0. if the argument is a (quiet or
          signaling) NaN and *note False: 3b1. otherwise.

          New in version 2.6.

      -- Method: is_normal ()

          Return *note True: 3b0. if the argument is a _normal_ finite
          non-zero number with an adjusted exponent greater than or
          equal to _Emin_.  Return *note False: 3b1. if the argument is
          zero, subnormal, infinite or a NaN. Note, the term _normal_ is
          used here in a different sense with the *note normalize():
          cd0. method which is used to create canonical values.

          New in version 2.6.

      -- Method: is_qnan ()

          Return *note True: 3b0. if the argument is a quiet NaN, and
          *note False: 3b1. otherwise.

          New in version 2.6.

      -- Method: is_signed ()

          Return *note True: 3b0. if the argument has a negative sign
          and *note False: 3b1. otherwise.  Note that zeros and NaNs can
          both carry signs.

          New in version 2.6.

      -- Method: is_snan ()

          Return *note True: 3b0. if the argument is a signaling NaN and
          *note False: 3b1. otherwise.

          New in version 2.6.

      -- Method: is_subnormal ()

          Return *note True: 3b0. if the argument is subnormal, and
          *note False: 3b1. otherwise.  A number is subnormal is if it
          is nonzero, finite, and has an adjusted exponent less than
          _Emin_.

          New in version 2.6.

      -- Method: is_zero ()

          Return *note True: 3b0. if the argument is a (positive or
          negative) zero and *note False: 3b1. otherwise.

          New in version 2.6.

      -- Method: ln ([context])

          Return the natural (base e) logarithm of the operand.  The
          result is correctly rounded using the ‘ROUND_HALF_EVEN’
          rounding mode.

          New in version 2.6.

      -- Method: log10 ([context])

          Return the base ten logarithm of the operand.  The result is
          correctly rounded using the ‘ROUND_HALF_EVEN’ rounding mode.

          New in version 2.6.

      -- Method: logb ([context])

          For a nonzero number, return the adjusted exponent of its
          operand as a *note Decimal: 1b4. instance.  If the operand is
          a zero then ‘Decimal('-Infinity')’ is returned and the *note
          DivisionByZero: cb0. flag is raised.  If the operand is an
          infinity then ‘Decimal('Infinity')’ is returned.

          New in version 2.6.

      -- Method: logical_and (other[, context])

          *note logical_and(): cd9. is a logical operation which takes
          two _logical operands_ (see *note Logical operands: cda.).
          The result is the digit-wise ‘and’ of the two operands.

          New in version 2.6.

      -- Method: logical_invert ([context])

          *note logical_invert(): cdb. is a logical operation.  The
          result is the digit-wise inversion of the operand.

          New in version 2.6.

      -- Method: logical_or (other[, context])

          *note logical_or(): cdc. is a logical operation which takes
          two _logical operands_ (see *note Logical operands: cda.).
          The result is the digit-wise ‘or’ of the two operands.

          New in version 2.6.

      -- Method: logical_xor (other[, context])

          *note logical_xor(): cdd. is a logical operation which takes
          two _logical operands_ (see *note Logical operands: cda.).
          The result is the digit-wise exclusive or of the two operands.

          New in version 2.6.

      -- Method: max (other[, context])

          Like ‘max(self, other)’ except that the context rounding rule
          is applied before returning and that ‘NaN’ values are either
          signaled or ignored (depending on the context and whether they
          are signaling or quiet).

      -- Method: max_mag (other[, context])

          Similar to the *note max(): cde. method, but the comparison is
          done using the absolute values of the operands.

          New in version 2.6.

      -- Method: min (other[, context])

          Like ‘min(self, other)’ except that the context rounding rule
          is applied before returning and that ‘NaN’ values are either
          signaled or ignored (depending on the context and whether they
          are signaling or quiet).

      -- Method: min_mag (other[, context])

          Similar to the *note min(): ce0. method, but the comparison is
          done using the absolute values of the operands.

          New in version 2.6.

      -- Method: next_minus ([context])

          Return the largest number representable in the given context
          (or in the current thread’s context if no context is given)
          that is smaller than the given operand.

          New in version 2.6.

      -- Method: next_plus ([context])

          Return the smallest number representable in the given context
          (or in the current thread’s context if no context is given)
          that is larger than the given operand.

          New in version 2.6.

      -- Method: next_toward (other[, context])

          If the two operands are unequal, return the number closest to
          the first operand in the direction of the second operand.  If
          both operands are numerically equal, return a copy of the
          first operand with the sign set to be the same as the sign of
          the second operand.

          New in version 2.6.

      -- Method: normalize ([context])

          Normalize the number by stripping the rightmost trailing zeros
          and converting any result equal to ‘Decimal('0')’ to
          ‘Decimal('0e0')’.  Used for producing canonical values for
          attributes of an equivalence class.  For example,
          ‘Decimal('32.100')’ and ‘Decimal('0.321000e+2')’ both
          normalize to the equivalent value ‘Decimal('32.1')’.

      -- Method: number_class ([context])

          Return a string describing the _class_ of the operand.  The
          returned value is one of the following ten strings.

             * ‘"-Infinity"’, indicating that the operand is negative
               infinity.

             * ‘"-Normal"’, indicating that the operand is a negative
               normal number.

             * ‘"-Subnormal"’, indicating that the operand is negative
               and subnormal.

             * ‘"-Zero"’, indicating that the operand is a negative
               zero.

             * ‘"+Zero"’, indicating that the operand is a positive
               zero.

             * ‘"+Subnormal"’, indicating that the operand is positive
               and subnormal.

             * ‘"+Normal"’, indicating that the operand is a positive
               normal number.

             * ‘"+Infinity"’, indicating that the operand is positive
               infinity.

             * ‘"NaN"’, indicating that the operand is a quiet NaN (Not
               a Number).

             * ‘"sNaN"’, indicating that the operand is a signaling NaN.

          New in version 2.6.

      -- Method: quantize (exp[, rounding[, context[, watchexp]]])

          Return a value equal to the first operand after rounding and
          having the exponent of the second operand.

               >>> Decimal('1.41421356').quantize(Decimal('1.000'))
               Decimal('1.414')

          Unlike other operations, if the length of the coefficient
          after the quantize operation would be greater than precision,
          then an *note InvalidOperation: 2dc. is signaled.  This
          guarantees that, unless there is an error condition, the
          quantized exponent is always equal to that of the right-hand
          operand.

          Also unlike other operations, quantize never signals
          Underflow, even if the result is subnormal and inexact.

          If the exponent of the second operand is larger than that of
          the first then rounding may be necessary.  In this case, the
          rounding mode is determined by the ‘rounding’ argument if
          given, else by the given ‘context’ argument; if neither
          argument is given the rounding mode of the current thread’s
          context is used.

          If _watchexp_ is set (default), then an error is returned
          whenever the resulting exponent is greater than ‘Emax’ or less
          than ‘Etiny’.

      -- Method: radix ()

          Return ‘Decimal(10)’, the radix (base) in which the *note
          Decimal: 1b4. class does all its arithmetic.  Included for
          compatibility with the specification.

          New in version 2.6.

      -- Method: remainder_near (other[, context])

          Return the remainder from dividing _self_ by _other_.  This
          differs from ‘self % other’ in that the sign of the remainder
          is chosen so as to minimize its absolute value.  More
          precisely, the return value is ‘self - n * other’ where ‘n’ is
          the integer nearest to the exact value of ‘self / other’, and
          if two integers are equally near then the even one is chosen.

          If the result is zero then its sign will be the sign of
          _self_.

               >>> Decimal(18).remainder_near(Decimal(10))
               Decimal('-2')
               >>> Decimal(25).remainder_near(Decimal(10))
               Decimal('5')
               >>> Decimal(35).remainder_near(Decimal(10))
               Decimal('-5')

      -- Method: rotate (other[, context])

          Return the result of rotating the digits of the first operand
          by an amount specified by the second operand.  The second
          operand must be an integer in the range -precision through
          precision.  The absolute value of the second operand gives the
          number of places to rotate.  If the second operand is positive
          then rotation is to the left; otherwise rotation is to the
          right.  The coefficient of the first operand is padded on the
          left with zeros to length precision if necessary.  The sign
          and exponent of the first operand are unchanged.

          New in version 2.6.

      -- Method: same_quantum (other[, context])

          Test whether self and other have the same exponent or whether
          both are ‘NaN’.

      -- Method: scaleb (other[, context])

          Return the first operand with exponent adjusted by the second.
          Equivalently, return the first operand multiplied by
          ‘10**other’.  The second operand must be an integer.

          New in version 2.6.

      -- Method: shift (other[, context])

          Return the result of shifting the digits of the first operand
          by an amount specified by the second operand.  The second
          operand must be an integer in the range -precision through
          precision.  The absolute value of the second operand gives the
          number of places to shift.  If the second operand is positive
          then the shift is to the left; otherwise the shift is to the
          right.  Digits shifted into the coefficient are zeros.  The
          sign and exponent of the first operand are unchanged.

          New in version 2.6.

      -- Method: sqrt ([context])

          Return the square root of the argument to full precision.

      -- Method: to_eng_string ([context])

          Convert to an engineering-type string.

          Engineering notation has an exponent which is a multiple of 3,
          so there are up to 3 digits left of the decimal place.  For
          example, converts ‘Decimal('123E+1')’ to ‘Decimal('1.23E+3')’

      -- Method: to_integral ([rounding[, context]])

          Identical to the *note to_integral_value(): cf0. method.  The
          ‘to_integral’ name has been kept for compatibility with older
          versions.

      -- Method: to_integral_exact ([rounding[, context]])

          Round to the nearest integer, signaling *note Inexact: cb1. or
          *note Rounded: cb2. as appropriate if rounding occurs.  The
          rounding mode is determined by the ‘rounding’ parameter if
          given, else by the given ‘context’.  If neither parameter is
          given then the rounding mode of the current context is used.

          New in version 2.6.

      -- Method: to_integral_value ([rounding[, context]])

          Round to the nearest integer without signaling *note Inexact:
          cb1. or *note Rounded: cb2.  If given, applies _rounding_;
          otherwise, uses the rounding method in either the supplied
          _context_ or the current context.

          Changed in version 2.6: renamed from ‘to_integral’ to
          ‘to_integral_value’.  The old name remains valid for
          compatibility.

* Menu:

* Logical operands:: 


File: python.info,  Node: Logical operands,  Up: Decimal objects

5.9.4.3 Logical operands
........................

The ‘logical_and()’, ‘logical_invert()’, ‘logical_or()’, and
‘logical_xor()’ methods expect their arguments to be _logical operands_.
A _logical operand_ is a *note Decimal: 1b4. instance whose exponent and
sign are both zero, and whose digits are all either ‘0’ or ‘1’.


File: python.info,  Node: Context objects,  Next: Signals,  Prev: Decimal objects,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.4 Context objects
.......................

Contexts are environments for arithmetic operations.  They govern
precision, set rules for rounding, determine which signals are treated
as exceptions, and limit the range for exponents.

  Each thread has its own current context which is accessed or changed
using the *note getcontext(): cb8. and *note setcontext(): cb9.
functions:

 -- Function: decimal.getcontext ()

     Return the current context for the active thread.

 -- Function: decimal.setcontext (c)

     Set the current context for the active thread to _c_.

  Beginning with Python 2.5, you can also use the *note with: 1c0.
statement and the *note localcontext(): 926. function to temporarily
change the active context.

 -- Function: decimal.localcontext ([c])

     Return a context manager that will set the current context for the
     active thread to a copy of _c_ on entry to the with-statement and
     restore the previous context when exiting the with-statement.  If
     no context is specified, a copy of the current context is used.

     New in version 2.5.

     For example, the following code sets the current decimal precision
     to 42 places, performs a calculation, and then automatically
     restores the previous context:

          from decimal import localcontext

          with localcontext() as ctx:
              ctx.prec = 42   # Perform a high precision calculation
              s = calculate_something()
          s = +s  # Round the final result back to the default precision

          with localcontext(BasicContext):      # temporarily use the BasicContext
              print Decimal(1) / Decimal(7)
              print Decimal(355) / Decimal(113)

  New contexts can also be created using the *note Context: 213.
constructor described below.  In addition, the module provides three
pre-made contexts:

 -- Class: decimal.BasicContext

     This is a standard context defined by the General Decimal
     Arithmetic Specification.  Precision is set to nine.  Rounding is
     set to ‘ROUND_HALF_UP’.  All flags are cleared.  All traps are
     enabled (treated as exceptions) except *note Inexact: cb1, *note
     Rounded: cb2, and *note Subnormal: cb3.

     Because many of the traps are enabled, this context is useful for
     debugging.

 -- Class: decimal.ExtendedContext

     This is a standard context defined by the General Decimal
     Arithmetic Specification.  Precision is set to nine.  Rounding is
     set to ‘ROUND_HALF_EVEN’.  All flags are cleared.  No traps are
     enabled (so that exceptions are not raised during computations).

     Because the traps are disabled, this context is useful for
     applications that prefer to have result value of ‘NaN’ or
     ‘Infinity’ instead of raising exceptions.  This allows an
     application to complete a run in the presence of conditions that
     would otherwise halt the program.

 -- Class: decimal.DefaultContext

     This context is used by the *note Context: 213. constructor as a
     prototype for new contexts.  Changing a field (such a precision)
     has the effect of changing the default for new contexts created by
     the *note Context: 213. constructor.

     This context is most useful in multi-threaded environments.
     Changing one of the fields before threads are started has the
     effect of setting system-wide defaults.  Changing the fields after
     threads have started is not recommended as it would require thread
     synchronization to prevent race conditions.

     In single threaded environments, it is preferable to not use this
     context at all.  Instead, simply create contexts explicitly as
     described below.

     The default values are precision=28, rounding=ROUND_HALF_EVEN, and
     enabled traps for Overflow, InvalidOperation, and DivisionByZero.

  In addition to the three supplied contexts, new contexts can be
created with the *note Context: 213. constructor.

 -- Class: decimal.Context (prec=None, rounding=None, traps=None,
          flags=None, Emin=None, Emax=None, capitals=1)

     Creates a new context.  If a field is not specified or is *note
     None: 39a, the default values are copied from the *note
     DefaultContext: cf5.  If the _flags_ field is not specified or is
     *note None: 39a, all flags are cleared.

     The _prec_ field is a positive integer that sets the precision for
     arithmetic operations in the context.

     The _rounding_ option is one of:

        * ‘ROUND_CEILING’ (towards ‘Infinity’),

        * ‘ROUND_DOWN’ (towards zero),

        * ‘ROUND_FLOOR’ (towards ‘-Infinity’),

        * ‘ROUND_HALF_DOWN’ (to nearest with ties going towards zero),

        * ‘ROUND_HALF_EVEN’ (to nearest with ties going to nearest even
          integer),

        * ‘ROUND_HALF_UP’ (to nearest with ties going away from zero),
          or

        * ‘ROUND_UP’ (away from zero).

        * ‘ROUND_05UP’ (away from zero if last digit after rounding
          towards zero would have been 0 or 5; otherwise towards zero)

     The _traps_ and _flags_ fields list any signals to be set.
     Generally, new contexts should only set traps and leave the flags
     clear.

     The _Emin_ and _Emax_ fields are integers specifying the outer
     limits allowable for exponents.

     The _capitals_ field is either ‘0’ or ‘1’ (the default).  If set to
     ‘1’, exponents are printed with a capital ‘E’; otherwise, a
     lowercase ‘e’ is used: ‘Decimal('6.02e+23')’.

     Changed in version 2.6: The ‘ROUND_05UP’ rounding mode was added.

     The *note Context: 213. class defines several general purpose
     methods as well as a large number of methods for doing arithmetic
     directly in a given context.  In addition, for each of the *note
     Decimal: 1b4. methods described above (with the exception of the
     ‘adjusted()’ and ‘as_tuple()’ methods) there is a corresponding
     *note Context: 213. method.  For example, for a *note Context: 213.
     instance ‘C’ and *note Decimal: 1b4. instance ‘x’, ‘C.exp(x)’ is
     equivalent to ‘x.exp(context=C)’.  Each *note Context: 213. method
     accepts a Python integer (an instance of *note int: 1f2. or *note
     long: 1f3.) anywhere that a Decimal instance is accepted.

      -- Method: clear_flags ()

          Resets all of the flags to ‘0’.

      -- Method: copy ()

          Return a duplicate of the context.

      -- Method: copy_decimal (num)

          Return a copy of the Decimal instance num.

      -- Method: create_decimal (num)

          Creates a new Decimal instance from _num_ but using _self_ as
          context.  Unlike the *note Decimal: 1b4. constructor, the
          context precision, rounding method, flags, and traps are
          applied to the conversion.

          This is useful because constants are often given to a greater
          precision than is needed by the application.  Another benefit
          is that rounding immediately eliminates unintended effects
          from digits beyond the current precision.  In the following
          example, using unrounded inputs means that adding zero to a
          sum can change the result:

               >>> getcontext().prec = 3
               >>> Decimal('3.4445') + Decimal('1.0023')
               Decimal('4.45')
               >>> Decimal('3.4445') + Decimal(0) + Decimal('1.0023')
               Decimal('4.44')

          This method implements the to-number operation of the IBM
          specification.  If the argument is a string, no leading or
          trailing whitespace is permitted.

      -- Method: create_decimal_from_float (f)

          Creates a new Decimal instance from a float _f_ but rounding
          using _self_ as the context.  Unlike the *note
          Decimal.from_float(): 212. class method, the context
          precision, rounding method, flags, and traps are applied to
          the conversion.

               >>> context = Context(prec=5, rounding=ROUND_DOWN)
               >>> context.create_decimal_from_float(math.pi)
               Decimal('3.1415')
               >>> context = Context(prec=5, traps=[Inexact])
               >>> context.create_decimal_from_float(math.pi)
               Traceback (most recent call last):
                   ...
               Inexact: None

          New in version 2.7.

      -- Method: Etiny ()

          Returns a value equal to ‘Emin - prec + 1’ which is the
          minimum exponent value for subnormal results.  When underflow
          occurs, the exponent is set to *note Etiny: cfb.

      -- Method: Etop ()

          Returns a value equal to ‘Emax - prec + 1’.

     The usual approach to working with decimals is to create *note
     Decimal: 1b4. instances and then apply arithmetic operations which
     take place within the current context for the active thread.  An
     alternative approach is to use context methods for calculating
     within a specific context.  The methods are similar to those for
     the *note Decimal: 1b4. class and are only briefly recounted here.

      -- Method: abs (x)

          Returns the absolute value of _x_.

      -- Method: add (x, y)

          Return the sum of _x_ and _y_.

      -- Method: canonical (x)

          Returns the same Decimal object _x_.

      -- Method: compare (x, y)

          Compares _x_ and _y_ numerically.

      -- Method: compare_signal (x, y)

          Compares the values of the two operands numerically.

      -- Method: compare_total (x, y)

          Compares two operands using their abstract representation.

      -- Method: compare_total_mag (x, y)

          Compares two operands using their abstract representation,
          ignoring sign.

      -- Method: copy_abs (x)

          Returns a copy of _x_ with the sign set to 0.

      -- Method: copy_negate (x)

          Returns a copy of _x_ with the sign inverted.

      -- Method: copy_sign (x, y)

          Copies the sign from _y_ to _x_.

      -- Method: divide (x, y)

          Return _x_ divided by _y_.

      -- Method: divide_int (x, y)

          Return _x_ divided by _y_, truncated to an integer.

      -- Method: divmod (x, y)

          Divides two numbers and returns the integer part of the
          result.

      -- Method: exp (x)

          Returns ‘e ** x’.

      -- Method: fma (x, y, z)

          Returns _x_ multiplied by _y_, plus _z_.

      -- Method: is_canonical (x)

          Returns ‘True’ if _x_ is canonical; otherwise returns ‘False’.

      -- Method: is_finite (x)

          Returns ‘True’ if _x_ is finite; otherwise returns ‘False’.

      -- Method: is_infinite (x)

          Returns ‘True’ if _x_ is infinite; otherwise returns ‘False’.

      -- Method: is_nan (x)

          Returns ‘True’ if _x_ is a qNaN or sNaN; otherwise returns
          ‘False’.

      -- Method: is_normal (x)

          Returns ‘True’ if _x_ is a normal number; otherwise returns
          ‘False’.

      -- Method: is_qnan (x)

          Returns ‘True’ if _x_ is a quiet NaN; otherwise returns
          ‘False’.

      -- Method: is_signed (x)

          Returns ‘True’ if _x_ is negative; otherwise returns ‘False’.

      -- Method: is_snan (x)

          Returns ‘True’ if _x_ is a signaling NaN; otherwise returns
          ‘False’.

      -- Method: is_subnormal (x)

          Returns ‘True’ if _x_ is subnormal; otherwise returns ‘False’.

      -- Method: is_zero (x)

          Returns ‘True’ if _x_ is a zero; otherwise returns ‘False’.

      -- Method: ln (x)

          Returns the natural (base e) logarithm of _x_.

      -- Method: log10 (x)

          Returns the base 10 logarithm of _x_.

      -- Method: logb (x)

          Returns the exponent of the magnitude of the operand’s MSD.

      -- Method: logical_and (x, y)

          Applies the logical operation _and_ between each operand’s
          digits.

      -- Method: logical_invert (x)

          Invert all the digits in _x_.

      -- Method: logical_or (x, y)

          Applies the logical operation _or_ between each operand’s
          digits.

      -- Method: logical_xor (x, y)

          Applies the logical operation _xor_ between each operand’s
          digits.

      -- Method: max (x, y)

          Compares two values numerically and returns the maximum.

      -- Method: max_mag (x, y)

          Compares the values numerically with their sign ignored.

      -- Method: min (x, y)

          Compares two values numerically and returns the minimum.

      -- Method: min_mag (x, y)

          Compares the values numerically with their sign ignored.

      -- Method: minus (x)

          Minus corresponds to the unary prefix minus operator in
          Python.

      -- Method: multiply (x, y)

          Return the product of _x_ and _y_.

      -- Method: next_minus (x)

          Returns the largest representable number smaller than _x_.

      -- Method: next_plus (x)

          Returns the smallest representable number larger than _x_.

      -- Method: next_toward (x, y)

          Returns the number closest to _x_, in direction towards _y_.

      -- Method: normalize (x)

          Reduces _x_ to its simplest form.

      -- Method: number_class (x)

          Returns an indication of the class of _x_.

      -- Method: plus (x)

          Plus corresponds to the unary prefix plus operator in Python.
          This operation applies the context precision and rounding, so
          it is _not_ an identity operation.

      -- Method: power (x, y[, modulo])

          Return ‘x’ to the power of ‘y’, reduced modulo ‘modulo’ if
          given.

          With two arguments, compute ‘x**y’.  If ‘x’ is negative then
          ‘y’ must be integral.  The result will be inexact unless ‘y’
          is integral and the result is finite and can be expressed
          exactly in ’precision’ digits.  The result should always be
          correctly rounded, using the rounding mode of the current
          thread’s context.

          With three arguments, compute ‘(x**y) % modulo’.  For the
          three argument form, the following restrictions on the
          arguments hold:

                  - all three arguments must be integral

                  - ‘y’ must be nonnegative

                  - at least one of ‘x’ or ‘y’ must be nonzero

                  - ‘modulo’ must be nonzero and have at most
                    ’precision’ digits

          The value resulting from ‘Context.power(x, y, modulo)’ is
          equal to the value that would be obtained by computing ‘(x**y)
          % modulo’ with unbounded precision, but is computed more
          efficiently.  The exponent of the result is zero, regardless
          of the exponents of ‘x’, ‘y’ and ‘modulo’.  The result is
          always exact.

          Changed in version 2.6: ‘y’ may now be nonintegral in ‘x**y’.
          Stricter requirements for the three-argument version.

      -- Method: quantize (x, y)

          Returns a value equal to _x_ (rounded), having the exponent of
          _y_.

      -- Method: radix ()

          Just returns 10, as this is Decimal, :)

      -- Method: remainder (x, y)

          Returns the remainder from integer division.

          The sign of the result, if non-zero, is the same as that of
          the original dividend.

      -- Method: remainder_near (x, y)

          Returns ‘x - y * n’, where _n_ is the integer nearest the
          exact value of ‘x / y’ (if the result is 0 then its sign will
          be the sign of _x_).

      -- Method: rotate (x, y)

          Returns a rotated copy of _x_, _y_ times.

      -- Method: same_quantum (x, y)

          Returns ‘True’ if the two operands have the same exponent.

      -- Method: scaleb (x, y)

          Returns the first operand after adding the second value its
          exp.

      -- Method: shift (x, y)

          Returns a shifted copy of _x_, _y_ times.

      -- Method: sqrt (x)

          Square root of a non-negative number to context precision.

      -- Method: subtract (x, y)

          Return the difference between _x_ and _y_.

      -- Method: to_eng_string (x)

          Converts a number to a string, using scientific notation.

      -- Method: to_integral_exact (x)

          Rounds to an integer.

      -- Method: to_sci_string (x)

          Converts a number to a string using scientific notation.


File: python.info,  Node: Signals,  Next: Floating Point Notes,  Prev: Context objects,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.5 Signals
...............

Signals represent conditions that arise during computation.  Each
corresponds to one context flag and one context trap enabler.

  The context flag is set whenever the condition is encountered.  After
the computation, flags may be checked for informational purposes (for
instance, to determine whether a computation was exact).  After checking
the flags, be sure to clear all flags before starting the next
computation.

  If the context’s trap enabler is set for the signal, then the
condition causes a Python exception to be raised.  For example, if the
*note DivisionByZero: cb0. trap is set, then a *note DivisionByZero:
cb0. exception is raised upon encountering the condition.

 -- Class: decimal.Clamped

     Altered an exponent to fit representation constraints.

     Typically, clamping occurs when an exponent falls outside the
     context’s ‘Emin’ and ‘Emax’ limits.  If possible, the exponent is
     reduced to fit by adding zeros to the coefficient.

 -- Class: decimal.DecimalException

     Base class for other signals and a subclass of *note
     ArithmeticError: 947.

 -- Class: decimal.DivisionByZero

     Signals the division of a non-infinite number by zero.

     Can occur with division, modulo division, or when raising a number
     to a negative power.  If this signal is not trapped, returns
     ‘Infinity’ or ‘-Infinity’ with the sign determined by the inputs to
     the calculation.

 -- Class: decimal.Inexact

     Indicates that rounding occurred and the result is not exact.

     Signals when non-zero digits were discarded during rounding.  The
     rounded result is returned.  The signal flag or trap is used to
     detect when results are inexact.

 -- Class: decimal.InvalidOperation

     An invalid operation was performed.

     Indicates that an operation was requested that does not make sense.
     If not trapped, returns ‘NaN’.  Possible causes include:

          Infinity - Infinity
          0 * Infinity
          Infinity / Infinity
          x % 0
          Infinity % x
          x._rescale( non-integer )
          sqrt(-x) and x > 0
          0 ** 0
          x ** (non-integer)
          x ** Infinity

 -- Class: decimal.Overflow

     Numerical overflow.

     Indicates the exponent is larger than ‘Emax’ after rounding has
     occurred.  If not trapped, the result depends on the rounding mode,
     either pulling inward to the largest representable finite number or
     rounding outward to ‘Infinity’.  In either case, *note Inexact:
     cb1. and *note Rounded: cb2. are also signaled.

 -- Class: decimal.Rounded

     Rounding occurred though possibly no information was lost.

     Signaled whenever rounding discards digits; even if those digits
     are zero (such as rounding ‘5.00’ to ‘5.0’).  If not trapped,
     returns the result unchanged.  This signal is used to detect loss
     of significant digits.

 -- Class: decimal.Subnormal

     Exponent was lower than ‘Emin’ prior to rounding.

     Occurs when an operation result is subnormal (the exponent is too
     small).  If not trapped, returns the result unchanged.

 -- Class: decimal.Underflow

     Numerical underflow with result rounded to zero.

     Occurs when a subnormal result is pushed to zero by rounding.
     *note Inexact: cb1. and *note Subnormal: cb3. are also signaled.

  The following table summarizes the hierarchy of signals:

     exceptions.ArithmeticError(exceptions.StandardError)
         DecimalException
             Clamped
             DivisionByZero(DecimalException, exceptions.ZeroDivisionError)
             Inexact
                 Overflow(Inexact, Rounded)
                 Underflow(Inexact, Rounded, Subnormal)
             InvalidOperation
             Rounded
             Subnormal


File: python.info,  Node: Floating Point Notes,  Next: Working with threads,  Prev: Signals,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.6 Floating Point Notes
............................

* Menu:

* Mitigating round-off error with increased precision:: 
* Special values:: 


File: python.info,  Node: Mitigating round-off error with increased precision,  Next: Special values,  Up: Floating Point Notes

5.9.4.7 Mitigating round-off error with increased precision
...........................................................

The use of decimal floating point eliminates decimal representation
error (making it possible to represent ‘0.1’ exactly); however, some
operations can still incur round-off error when non-zero digits exceed
the fixed precision.

  The effects of round-off error can be amplified by the addition or
subtraction of nearly offsetting quantities resulting in loss of
significance.  Knuth provides two instructive examples where rounded
floating point arithmetic with insufficient precision causes the
breakdown of the associative and distributive properties of addition:

     # Examples from Seminumerical Algorithms, Section 4.2.2.
     >>> from decimal import Decimal, getcontext
     >>> getcontext().prec = 8

     >>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
     >>> (u + v) + w
     Decimal('9.5111111')
     >>> u + (v + w)
     Decimal('10')

     >>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
     >>> (u*v) + (u*w)
     Decimal('0.01')
     >>> u * (v+w)
     Decimal('0.0060000')

  The *note decimal: 80. module makes it possible to restore the
identities by expanding the precision sufficiently to avoid loss of
significance:

     >>> getcontext().prec = 20
     >>> u, v, w = Decimal(11111113), Decimal(-11111111), Decimal('7.51111111')
     >>> (u + v) + w
     Decimal('9.51111111')
     >>> u + (v + w)
     Decimal('9.51111111')
     >>>
     >>> u, v, w = Decimal(20000), Decimal(-6), Decimal('6.0000003')
     >>> (u*v) + (u*w)
     Decimal('0.0060000')
     >>> u * (v+w)
     Decimal('0.0060000')


File: python.info,  Node: Special values,  Prev: Mitigating round-off error with increased precision,  Up: Floating Point Notes

5.9.4.8 Special values
......................

The number system for the *note decimal: 80. module provides special
values including ‘NaN’, ‘sNaN’, ‘-Infinity’, ‘Infinity’, and two zeros,
‘+0’ and ‘-0’.

  Infinities can be constructed directly with: ‘Decimal('Infinity')’.
Also, they can arise from dividing by zero when the *note
DivisionByZero: cb0. signal is not trapped.  Likewise, when the *note
Overflow: cb4. signal is not trapped, infinity can result from rounding
beyond the limits of the largest representable number.

  The infinities are signed (affine) and can be used in arithmetic
operations where they get treated as very large, indeterminate numbers.
For instance, adding a constant to infinity gives another infinite
result.

  Some operations are indeterminate and return ‘NaN’, or if the *note
InvalidOperation: 2dc. signal is trapped, raise an exception.  For
example, ‘0/0’ returns ‘NaN’ which means "not a number".  This variety
of ‘NaN’ is quiet and, once created, will flow through other
computations always resulting in another ‘NaN’.  This behavior can be
useful for a series of computations that occasionally have missing
inputs — it allows the calculation to proceed while flagging specific
results as invalid.

  A variant is ‘sNaN’ which signals rather than remaining quiet after
every operation.  This is a useful return value when an invalid result
needs to interrupt a calculation for special handling.

  The behavior of Python’s comparison operators can be a little
surprising where a ‘NaN’ is involved.  A test for equality where one of
the operands is a quiet or signaling ‘NaN’ always returns *note False:
3b1. (even when doing ‘Decimal('NaN')==Decimal('NaN')’), while a test
for inequality always returns *note True: 3b0.  An attempt to compare
two Decimals using any of the ‘<’, ‘<=’, ‘>’ or ‘>=’ operators will
raise the *note InvalidOperation: 2dc. signal if either operand is a
‘NaN’, and return *note False: 3b1. if this signal is not trapped.  Note
that the General Decimal Arithmetic specification does not specify the
behavior of direct comparisons; these rules for comparisons involving a
‘NaN’ were taken from the IEEE 854 standard (see Table 3 in section
5.7).  To ensure strict standards-compliance, use the ‘compare()’ and
‘compare-signal()’ methods instead.

  The signed zeros can result from calculations that underflow.  They
keep the sign that would have resulted if the calculation had been
carried out to greater precision.  Since their magnitude is zero, both
positive and negative zeros are treated as equal and their sign is
informational.

  In addition to the two signed zeros which are distinct yet equal,
there are various representations of zero with differing precisions yet
equivalent in value.  This takes a bit of getting used to.  For an eye
accustomed to normalized floating point representations, it is not
immediately obvious that the following calculation returns a value equal
to zero:

     >>> 1 / Decimal('Infinity')
     Decimal('0E-1000000026')


File: python.info,  Node: Working with threads,  Next: Recipes,  Prev: Floating Point Notes,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.9 Working with threads
............................

The *note getcontext(): cb8. function accesses a different *note
Context: 213. object for each thread.  Having separate thread contexts
means that threads may make changes (such as ‘getcontext.prec=10’)
without interfering with other threads.

  Likewise, the *note setcontext(): cb9. function automatically assigns
its target to the current thread.

  If *note setcontext(): cb9. has not been called before *note
getcontext(): cb8, then *note getcontext(): cb8. will automatically
create a new context for use in the current thread.

  The new context is copied from a prototype context called
_DefaultContext_.  To control the defaults so that each thread will use
the same values throughout the application, directly modify the
_DefaultContext_ object.  This should be done _before_ any threads are
started so that there won’t be a race condition between threads calling
*note getcontext(): cb8.  For example:

     # Set applicationwide defaults for all threads about to be launched
     DefaultContext.prec = 12
     DefaultContext.rounding = ROUND_DOWN
     DefaultContext.traps = ExtendedContext.traps.copy()
     DefaultContext.traps[InvalidOperation] = 1
     setcontext(DefaultContext)

     # Afterwards, the threads can be started
     t1.start()
     t2.start()
     t3.start()
      . . .


File: python.info,  Node: Recipes,  Next: Decimal FAQ,  Prev: Working with threads,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.10 Recipes
................

Here are a few recipes that serve as utility functions and that
demonstrate ways to work with the *note Decimal: 1b4. class:

     def moneyfmt(value, places=2, curr='', sep=',', dp='.',
                  pos='', neg='-', trailneg=''):
         """Convert Decimal to a money formatted string.

         places:  required number of places after the decimal point
         curr:    optional currency symbol before the sign (may be blank)
         sep:     optional grouping separator (comma, period, space, or blank)
         dp:      decimal point indicator (comma or period)
                  only specify as blank when places is zero
         pos:     optional sign for positive numbers: '+', space or blank
         neg:     optional sign for negative numbers: '-', '(', space or blank
         trailneg:optional trailing minus indicator:  '-', ')', space or blank

         >>> d = Decimal('-1234567.8901')
         >>> moneyfmt(d, curr='$')
         '-$1,234,567.89'
         >>> moneyfmt(d, places=0, sep='.', dp='', neg='', trailneg='-')
         '1.234.568-'
         >>> moneyfmt(d, curr='$', neg='(', trailneg=')')
         '($1,234,567.89)'
         >>> moneyfmt(Decimal(123456789), sep=' ')
         '123 456 789.00'
         >>> moneyfmt(Decimal('-0.02'), neg='<', trailneg='>')
         '<0.02>'

         """
         q = Decimal(10) ** -places      # 2 places --> '0.01'
         sign, digits, exp = value.quantize(q).as_tuple()
         result = []
         digits = map(str, digits)
         build, next = result.append, digits.pop
         if sign:
             build(trailneg)
         for i in range(places):
             build(next() if digits else '0')
         build(dp)
         if not digits:
             build('0')
         i = 0
         while digits:
             build(next())
             i += 1
             if i == 3 and digits:
                 i = 0
                 build(sep)
         build(curr)
         build(neg if sign else pos)
         return ''.join(reversed(result))

     def pi():
         """Compute Pi to the current precision.

         >>> print pi()
         3.141592653589793238462643383

         """
         getcontext().prec += 2  # extra digits for intermediate steps
         three = Decimal(3)      # substitute "three=3.0" for regular floats
         lasts, t, s, n, na, d, da = 0, three, 3, 1, 0, 0, 24
         while s != lasts:
             lasts = s
             n, na = n+na, na+8
             d, da = d+da, da+32
             t = (t * n) / d
             s += t
         getcontext().prec -= 2
         return +s               # unary plus applies the new precision

     def exp(x):
         """Return e raised to the power of x.  Result type matches input type.

         >>> print exp(Decimal(1))
         2.718281828459045235360287471
         >>> print exp(Decimal(2))
         7.389056098930650227230427461
         >>> print exp(2.0)
         7.38905609893
         >>> print exp(2+0j)
         (7.38905609893+0j)

         """
         getcontext().prec += 2
         i, lasts, s, fact, num = 0, 0, 1, 1, 1
         while s != lasts:
             lasts = s
             i += 1
             fact *= i
             num *= x
             s += num / fact
         getcontext().prec -= 2
         return +s

     def cos(x):
         """Return the cosine of x as measured in radians.

         >>> print cos(Decimal('0.5'))
         0.8775825618903727161162815826
         >>> print cos(0.5)
         0.87758256189
         >>> print cos(0.5+0j)
         (0.87758256189+0j)

         """
         getcontext().prec += 2
         i, lasts, s, fact, num, sign = 0, 0, 1, 1, 1, 1
         while s != lasts:
             lasts = s
             i += 2
             fact *= i * (i-1)
             num *= x * x
             sign *= -1
             s += num / fact * sign
         getcontext().prec -= 2
         return +s

     def sin(x):
         """Return the sine of x as measured in radians.

         >>> print sin(Decimal('0.5'))
         0.4794255386042030002732879352
         >>> print sin(0.5)
         0.479425538604
         >>> print sin(0.5+0j)
         (0.479425538604+0j)

         """
         getcontext().prec += 2
         i, lasts, s, fact, num, sign = 1, 0, x, 1, x, 1
         while s != lasts:
             lasts = s
             i += 2
             fact *= i * (i-1)
             num *= x * x
             sign *= -1
             s += num / fact * sign
         getcontext().prec -= 2
         return +s


File: python.info,  Node: Decimal FAQ,  Prev: Recipes,  Up: decimal --- Decimal fixed point and floating point arithmetic

5.9.4.11 Decimal FAQ
....................

Q. It is cumbersome to type ‘decimal.Decimal('1234.5')’.  Is there a way
to minimize typing when using the interactive interpreter?

  A. Some users abbreviate the constructor to just a single letter:

     >>> D = decimal.Decimal
     >>> D('1.23') + D('3.45')
     Decimal('4.68')

  Q. In a fixed-point application with two decimal places, some inputs
have many places and need to be rounded.  Others are not supposed to
have excess digits and need to be validated.  What methods should be
used?

  A. The ‘quantize()’ method rounds to a fixed number of decimal places.
If the *note Inexact: cb1. trap is set, it is also useful for
validation:

     >>> TWOPLACES = Decimal(10) ** -2       # same as Decimal('0.01')

     >>> # Round to two places
     >>> Decimal('3.214').quantize(TWOPLACES)
     Decimal('3.21')

     >>> # Validate that a number does not exceed two places
     >>> Decimal('3.21').quantize(TWOPLACES, context=Context(traps=[Inexact]))
     Decimal('3.21')

     >>> Decimal('3.214').quantize(TWOPLACES, context=Context(traps=[Inexact]))
     Traceback (most recent call last):
        ...
     Inexact: None

  Q. Once I have valid two place inputs, how do I maintain that
invariant throughout an application?

  A. Some operations like addition, subtraction, and multiplication by
an integer will automatically preserve fixed point.  Others operations,
like division and non-integer multiplication, will change the number of
decimal places and need to be followed-up with a ‘quantize()’ step:

     >>> a = Decimal('102.72')           # Initial fixed-point values
     >>> b = Decimal('3.17')
     >>> a + b                           # Addition preserves fixed-point
     Decimal('105.89')
     >>> a - b
     Decimal('99.55')
     >>> a * 42                          # So does integer multiplication
     Decimal('4314.24')
     >>> (a * b).quantize(TWOPLACES)     # Must quantize non-integer multiplication
     Decimal('325.62')
     >>> (b / a).quantize(TWOPLACES)     # And quantize division
     Decimal('0.03')

  In developing fixed-point applications, it is convenient to define
functions to handle the ‘quantize()’ step:

     >>> def mul(x, y, fp=TWOPLACES):
     ...     return (x * y).quantize(fp)
     >>> def div(x, y, fp=TWOPLACES):
     ...     return (x / y).quantize(fp)

     >>> mul(a, b)                       # Automatically preserve fixed-point
     Decimal('325.62')
     >>> div(b, a)
     Decimal('0.03')

  Q. There are many ways to express the same value.  The numbers ‘200’,
‘200.000’, ‘2E2’, and ‘02E+4’ all have the same value at various
precisions.  Is there a way to transform them to a single recognizable
canonical value?

  A. The ‘normalize()’ method maps all equivalent values to a single
representative:

     >>> values = map(Decimal, '200 200.000 2E2 .02E+4'.split())
     >>> [v.normalize() for v in values]
     [Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2'), Decimal('2E+2')]

  Q. Some decimal values always print with exponential notation.  Is
there a way to get a non-exponential representation?

  A. For some values, exponential notation is the only way to express
the number of significant places in the coefficient.  For example,
expressing ‘5.0E+3’ as ‘5000’ keeps the value constant but cannot show
the original’s two-place significance.

  If an application does not care about tracking significance, it is
easy to remove the exponent and trailing zeros, losing significance, but
keeping the value unchanged:

     def remove_exponent(d):
         '''Remove exponent and trailing zeros.

         >>> remove_exponent(Decimal('5E+3'))
         Decimal('5000')

         '''
         return d.quantize(Decimal(1)) if d == d.to_integral() else d.normalize()

  Q. Is there a way to convert a regular float to a *note Decimal: 1b4.?

  A. Yes, any binary floating point number can be exactly expressed as a
Decimal though an exact conversion may take more precision than
intuition would suggest:

     >>> Decimal(math.pi)
     Decimal('3.141592653589793115997963468544185161590576171875')

  Q. Within a complex calculation, how can I make sure that I haven’t
gotten a spurious result because of insufficient precision or rounding
anomalies.

  A. The decimal module makes it easy to test results.  A best practice
is to re-run calculations using greater precision and with various
rounding modes.  Widely differing results indicate insufficient
precision, rounding mode issues, ill-conditioned inputs, or a
numerically unstable algorithm.

  Q. I noticed that context precision is applied to the results of
operations but not to the inputs.  Is there anything to watch out for
when mixing values of different precisions?

  A. Yes.  The principle is that all values are considered to be exact
and so is the arithmetic on those values.  Only the results are rounded.
The advantage for inputs is that "what you type is what you get".  A
disadvantage is that the results can look odd if you forget that the
inputs haven’t been rounded:

     >>> getcontext().prec = 3
     >>> Decimal('3.104') + Decimal('2.104')
     Decimal('5.21')
     >>> Decimal('3.104') + Decimal('0.000') + Decimal('2.104')
     Decimal('5.20')

  The solution is either to increase precision or to force rounding of
inputs using the unary plus operation:

     >>> getcontext().prec = 3
     >>> +Decimal('1.23456789')      # unary plus triggers rounding
     Decimal('1.23')

  Alternatively, inputs can be rounded upon creation using the *note
Context.create_decimal(): cf9. method:

     >>> Context(prec=5, rounding=ROUND_DOWN).create_decimal('1.2345678')
     Decimal('1.2345')


File: python.info,  Node: fractions --- Rational numbers,  Next: random --- Generate pseudo-random numbers,  Prev: decimal --- Decimal fixed point and floating point arithmetic,  Up: Numeric and Mathematical Modules

5.9.5 ‘fractions’ — Rational numbers
------------------------------------

New in version 2.6.

  *Source code:* Lib/fractions.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note fractions: d6. module provides support for rational number
arithmetic.

  A Fraction instance can be constructed from a pair of integers, from
another rational number, or from a string.

 -- Class: fractions.Fraction (numerator=0, denominator=1)

 -- Class: fractions.Fraction (other_fraction)

 -- Class: fractions.Fraction (float)

 -- Class: fractions.Fraction (decimal)

 -- Class: fractions.Fraction (string)

     The first version requires that _numerator_ and _denominator_ are
     instances of *note numbers.Rational: 32a. and returns a new *note
     Fraction: 217. instance with value ‘numerator/denominator’.  If
     _denominator_ is ‘0’, it raises a *note ZeroDivisionError: 5ac.
     The second version requires that _other_fraction_ is an instance of
     *note numbers.Rational: 32a. and returns a *note Fraction: 217.
     instance with the same value.  The next two versions accept either
     a *note float: 1eb. or a *note decimal.Decimal: 1b4. instance, and
     return a *note Fraction: 217. instance with exactly the same value.
     Note that due to the usual issues with binary floating-point (see
     *note Floating Point Arithmetic; Issues and Limitations: 624.), the
     argument to ‘Fraction(1.1)’ is not exactly equal to 11/10, and so
     ‘Fraction(1.1)’ does _not_ return ‘Fraction(11, 10)’ as one might
     expect.  (But see the documentation for the *note
     limit_denominator(): d44. method below.)  The last version of the
     constructor expects a string or unicode instance.  The usual form
     for this instance is:

          [sign] numerator ['/' denominator]

     where the optional ‘sign’ may be either ’+’ or ’-’ and ‘numerator’
     and ‘denominator’ (if present) are strings of decimal digits.  In
     addition, any string that represents a finite value and is accepted
     by the *note float: 1eb. constructor is also accepted by the *note
     Fraction: 217. constructor.  In either form the input string may
     also have leading and/or trailing whitespace.  Here are some
     examples:

          >>> from fractions import Fraction
          >>> Fraction(16, -10)
          Fraction(-8, 5)
          >>> Fraction(123)
          Fraction(123, 1)
          >>> Fraction()
          Fraction(0, 1)
          >>> Fraction('3/7')
          Fraction(3, 7)
          >>> Fraction(' -3/7 ')
          Fraction(-3, 7)
          >>> Fraction('1.414213 \t\n')
          Fraction(1414213, 1000000)
          >>> Fraction('-.125')
          Fraction(-1, 8)
          >>> Fraction('7e-6')
          Fraction(7, 1000000)
          >>> Fraction(2.25)
          Fraction(9, 4)
          >>> Fraction(1.1)
          Fraction(2476979795053773, 2251799813685248)
          >>> from decimal import Decimal
          >>> Fraction(Decimal('1.1'))
          Fraction(11, 10)

     The *note Fraction: 217. class inherits from the abstract base
     class *note numbers.Rational: 32a, and implements all of the
     methods and operations from that class.  *note Fraction: 217.
     instances are hashable, and should be treated as immutable.  In
     addition, *note Fraction: 217. has the following methods:

     Changed in version 2.7: The *note Fraction: 217. constructor now
     accepts *note float: 1eb. and *note decimal.Decimal: 1b4.
     instances.

      -- Method: from_float (flt)

          This class method constructs a *note Fraction: 217.
          representing the exact value of _flt_, which must be a *note
          float: 1eb.  Beware that ‘Fraction.from_float(0.3)’ is not the
          same value as ‘Fraction(3, 10)’

               Note: From Python 2.7 onwards, you can also construct a
               *note Fraction: 217. instance directly from a *note
               float: 1eb.

      -- Method: from_decimal (dec)

          This class method constructs a *note Fraction: 217.
          representing the exact value of _dec_, which must be a *note
          decimal.Decimal: 1b4.

               Note: From Python 2.7 onwards, you can also construct a
               *note Fraction: 217. instance directly from a *note
               decimal.Decimal: 1b4. instance.

      -- Method: limit_denominator (max_denominator=1000000)

          Finds and returns the closest *note Fraction: 217. to ‘self’
          that has denominator at most max_denominator.  This method is
          useful for finding rational approximations to a given
          floating-point number:

               >>> from fractions import Fraction
               >>> Fraction('3.1415926535897932').limit_denominator(1000)
               Fraction(355, 113)

          or for recovering a rational number that’s represented as a
          float:

               >>> from math import pi, cos
               >>> Fraction(cos(pi/3))
               Fraction(4503599627370497, 9007199254740992)
               >>> Fraction(cos(pi/3)).limit_denominator()
               Fraction(1, 2)
               >>> Fraction(1.1).limit_denominator()
               Fraction(11, 10)

 -- Function: fractions.gcd (a, b)

     Return the greatest common divisor of the integers _a_ and _b_.  If
     either _a_ or _b_ is nonzero, then the absolute value of ‘gcd(a,
     b)’ is the largest integer that divides both _a_ and _b_.
     ‘gcd(a,b)’ has the same sign as _b_ if _b_ is nonzero; otherwise it
     takes the sign of _a_.  ‘gcd(0, 0)’ returns ‘0’.

See also
........

Module *note numbers: 125.

     The abstract base classes making up the numeric tower.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/fractions.py


File: python.info,  Node: random --- Generate pseudo-random numbers,  Next: itertools --- Functions creating iterators for efficient looping,  Prev: fractions --- Rational numbers,  Up: Numeric and Mathematical Modules

5.9.6 ‘random’ — Generate pseudo-random numbers
-----------------------------------------------

*Source code:* Lib/random.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module implements pseudo-random number generators for various
distributions.

  For integers, uniform selection from a range.  For sequences, uniform
selection of a random element, a function to generate a random
permutation of a list in-place, and a function for random sampling
without replacement.

  On the real line, there are functions to compute uniform, normal
(Gaussian), lognormal, negative exponential, gamma, and beta
distributions.  For generating distributions of angles, the von Mises
distribution is available.

  Almost all module functions depend on the basic function *note
random(): 142, which generates a random float uniformly in the semi-open
range [0.0, 1.0).  Python uses the Mersenne Twister as the core
generator.  It produces 53-bit precision floats and has a period of
2**19937-1.  The underlying implementation in C is both fast and
threadsafe.  The Mersenne Twister is one of the most extensively tested
random number generators in existence.  However, being completely
deterministic, it is not suitable for all purposes, and is completely
unsuitable for cryptographic purposes.

  The functions supplied by this module are actually bound methods of a
hidden instance of the ‘random.Random’ class.  You can instantiate your
own instances of ‘Random’ to get generators that don’t share state.
This is especially useful for multi-threaded programs, creating a
different instance of ‘Random’ for each thread, and using the *note
jumpahead(): d4a. method to make it likely that the generated sequences
seen by each thread don’t overlap.

  Class ‘Random’ can also be subclassed if you want to use a different
basic generator of your own devising: in that case, override the *note
random(): 142, *note seed(): d4b, *note getstate(): d4c, *note
setstate(): d4d. and *note jumpahead(): d4a. methods.  Optionally, a new
generator can supply a *note getrandbits(): d4e. method — this allows
*note randrange(): d4f. to produce selections over an arbitrarily large
range.

  New in version 2.4: the *note getrandbits(): d4e. method.

  As an example of subclassing, the *note random: 142. module provides
the *note WichmannHill: d50. class that implements an alternative
generator in pure Python.  The class provides a backward compatible way
to reproduce results from earlier versions of Python, which used the
Wichmann-Hill algorithm as the core generator.  Note that this
Wichmann-Hill generator can no longer be recommended: its period is too
short by contemporary standards, and the sequence generated is known to
fail some stringent randomness tests.  See the references below for a
recent variant that repairs these flaws.

  Changed in version 2.3: MersenneTwister replaced Wichmann-Hill as the
default generator.

  The *note random: 142. module also provides the *note SystemRandom:
d51. class which uses the system function *note os.urandom(): d52. to
generate random numbers from sources provided by the operating system.

     Warning: The pseudo-random generators of this module should not be
     used for security purposes.  Use *note os.urandom(): d52. or *note
     SystemRandom: d51. if you require a cryptographically secure
     pseudo-random number generator.

  Bookkeeping functions:

 -- Function: random.seed ([x])

     Initialize the basic random number generator.  Optional argument
     _x_ can be any *note hashable: 6f5. object.  If _x_ is omitted or
     ‘None’, current system time is used; current system time is also
     used to initialize the generator when the module is first imported.
     If randomness sources are provided by the operating system, they
     are used instead of the system time (see the *note os.urandom():
     d52. function for details on availability).

     Changed in version 2.4: formerly, operating system resources were
     not used.

 -- Function: random.getstate ()

     Return an object capturing the current internal state of the
     generator.  This object can be passed to *note setstate(): d4d. to
     restore the state.

     New in version 2.1.

     Changed in version 2.6: State values produced in Python 2.6 cannot
     be loaded into earlier versions.

 -- Function: random.setstate (state)

     _state_ should have been obtained from a previous call to *note
     getstate(): d4c, and *note setstate(): d4d. restores the internal
     state of the generator to what it was at the time *note getstate():
     d4c. was called.

     New in version 2.1.

 -- Function: random.jumpahead (n)

     Change the internal state to one different from and likely far away
     from the current state.  _n_ is a non-negative integer which is
     used to scramble the current state vector.  This is most useful in
     multi-threaded programs, in conjunction with multiple instances of
     the ‘Random’ class: *note setstate(): d4d. or *note seed(): d4b.
     can be used to force all instances into the same internal state,
     and then *note jumpahead(): d4a. can be used to force the
     instances’ states far apart.

     New in version 2.1.

     Changed in version 2.3: Instead of jumping to a specific state, _n_
     steps ahead, ‘jumpahead(n)’ jumps to another state likely to be
     separated by many steps.

 -- Function: random.getrandbits (k)

     Returns a python *note long: 1f3. int with _k_ random bits.  This
     method is supplied with the MersenneTwister generator and some
     other generators may also provide it as an optional part of the
     API. When available, *note getrandbits(): d4e. enables *note
     randrange(): d4f. to handle arbitrarily large ranges.

     New in version 2.4.

  Functions for integers:

 -- Function: random.randrange (stop)

 -- Function: random.randrange (start, stop[, step])

     Return a randomly selected element from ‘range(start, stop, step)’.
     This is equivalent to ‘choice(range(start, stop, step))’, but
     doesn’t actually build a range object.

     New in version 1.5.2.

 -- Function: random.randint (a, b)

     Return a random integer _N_ such that ‘a <= N <= b’.

  Functions for sequences:

 -- Function: random.choice (seq)

     Return a random element from the non-empty sequence _seq_.  If
     _seq_ is empty, raises *note IndexError: 4e1.

 -- Function: random.shuffle (x[, random])

     Shuffle the sequence _x_ in place.  The optional argument _random_
     is a 0-argument function returning a random float in [0.0, 1.0); by
     default, this is the function *note random(): 142.

     Note that for even rather small ‘len(x)’, the total number of
     permutations of _x_ is larger than the period of most random number
     generators; this implies that most permutations of a long sequence
     can never be generated.

 -- Function: random.sample (population, k)

     Return a _k_ length list of unique elements chosen from the
     population sequence.  Used for random sampling without replacement.

     New in version 2.3.

     Returns a new list containing elements from the population while
     leaving the original population unchanged.  The resulting list is
     in selection order so that all sub-slices will also be valid random
     samples.  This allows raffle winners (the sample) to be partitioned
     into grand prize and second place winners (the subslices).

     Members of the population need not be *note hashable: 6f5. or
     unique.  If the population contains repeats, then each occurrence
     is a possible selection in the sample.

     To choose a sample from a range of integers, use an *note xrange():
     45b. object as an argument.  This is especially fast and space
     efficient for sampling from a large population:
     ‘sample(xrange(10000000), 60)’.

  The following functions generate specific real-valued distributions.
Function parameters are named after the corresponding variables in the
distribution’s equation, as used in common mathematical practice; most
of these equations can be found in any statistics text.

 -- Function: random.random ()

     Return the next random floating point number in the range [0.0,
     1.0).

 -- Function: random.uniform (a, b)

     Return a random floating point number _N_ such that ‘a <= N <= b’
     for ‘a <= b’ and ‘b <= N <= a’ for ‘b < a’.

     The end-point value ‘b’ may or may not be included in the range
     depending on floating-point rounding in the equation ‘a + (b-a) *
     random()’.

 -- Function: random.triangular (low, high, mode)

     Return a random floating point number _N_ such that ‘low <= N <=
     high’ and with the specified _mode_ between those bounds.  The
     _low_ and _high_ bounds default to zero and one.  The _mode_
     argument defaults to the midpoint between the bounds, giving a
     symmetric distribution.

     New in version 2.6.

 -- Function: random.betavariate (alpha, beta)

     Beta distribution.  Conditions on the parameters are ‘alpha > 0’
     and ‘beta > 0’.  Returned values range between 0 and 1.

 -- Function: random.expovariate (lambd)

     Exponential distribution.  _lambd_ is 1.0 divided by the desired
     mean.  It should be nonzero.  (The parameter would be called
     "lambda", but that is a reserved word in Python.)  Returned values
     range from 0 to positive infinity if _lambd_ is positive, and from
     negative infinity to 0 if _lambd_ is negative.

 -- Function: random.gammavariate (alpha, beta)

     Gamma distribution.  (_Not_ the gamma function!)  Conditions on the
     parameters are ‘alpha > 0’ and ‘beta > 0’.

     The probability distribution function is:

                    x ** (alpha - 1) * math.exp(-x / beta)
          pdf(x) =  --------------------------------------
                      math.gamma(alpha) * beta ** alpha

 -- Function: random.gauss (mu, sigma)

     Gaussian distribution.  _mu_ is the mean, and _sigma_ is the
     standard deviation.  This is slightly faster than the *note
     normalvariate(): d5e. function defined below.

 -- Function: random.lognormvariate (mu, sigma)

     Log normal distribution.  If you take the natural logarithm of this
     distribution, you’ll get a normal distribution with mean _mu_ and
     standard deviation _sigma_.  _mu_ can have any value, and _sigma_
     must be greater than zero.

 -- Function: random.normalvariate (mu, sigma)

     Normal distribution.  _mu_ is the mean, and _sigma_ is the standard
     deviation.

 -- Function: random.vonmisesvariate (mu, kappa)

     _mu_ is the mean angle, expressed in radians between 0 and 2*_pi_,
     and _kappa_ is the concentration parameter, which must be greater
     than or equal to zero.  If _kappa_ is equal to zero, this
     distribution reduces to a uniform random angle over the range 0 to
     2*_pi_.

 -- Function: random.paretovariate (alpha)

     Pareto distribution.  _alpha_ is the shape parameter.

 -- Function: random.weibullvariate (alpha, beta)

     Weibull distribution.  _alpha_ is the scale parameter and _beta_ is
     the shape parameter.

  Alternative Generators:

 -- Class: random.WichmannHill ([seed])

     Class that implements the Wichmann-Hill algorithm as the core
     generator.  Has all of the same methods as ‘Random’ plus the *note
     whseed(): d63. method described below.  Because this class is
     implemented in pure Python, it is not threadsafe and may require
     locks between calls.  The period of the generator is
     6,953,607,871,644 which is small enough to require care that two
     independent random sequences do not overlap.

 -- Function: random.whseed ([x])

     This is obsolete, supplied for bit-level compatibility with
     versions of Python prior to 2.1.  See *note seed(): d4b. for
     details.  *note whseed(): d63. does not guarantee that distinct
     integer arguments yield distinct internal states, and can yield no
     more than about 2**24 distinct internal states in all.

 -- Class: random.SystemRandom ([seed])

     Class that uses the *note os.urandom(): d52. function for
     generating random numbers from sources provided by the operating
     system.  Not available on all systems.  Does not rely on software
     state and sequences are not reproducible.  Accordingly, the *note
     seed(): d4b. and *note jumpahead(): d4a. methods have no effect and
     are ignored.  The *note getstate(): d4c. and *note setstate(): d4d.
     methods raise *note NotImplementedError: 94e. if called.

     New in version 2.4.

  Examples of basic usage:

     >>> random.random()        # Random float x, 0.0 <= x < 1.0
     0.37444887175646646
     >>> random.uniform(1, 10)  # Random float x, 1.0 <= x < 10.0
     1.1800146073117523
     >>> random.randint(1, 10)  # Integer from 1 to 10, endpoints included
     7
     >>> random.randrange(0, 101, 2)  # Even integer from 0 to 100
     26
     >>> random.choice('abcdefghij')  # Choose a random element
     'c'

     >>> items = [1, 2, 3, 4, 5, 6, 7]
     >>> random.shuffle(items)
     >>> items
     [7, 3, 2, 5, 6, 4, 1]

     >>> random.sample([1, 2, 3, 4, 5],  3)  # Choose 3 elements
     [4, 1, 5]

See also
........

M. Matsumoto and T. Nishimura, "Mersenne Twister: A 623-dimensionally
equidistributed uniform pseudorandom number generator", ACM Transactions
on Modeling and Computer Simulation Vol.  8, No.  1, January pp.3-30
1998.

  Wichmann, B. A. & Hill, I. D., "Algorithm AS 183: An efficient and
portable pseudo-random number generator", Applied Statistics 31 (1982)
188-190.

  Complementary-Multiply-with-Carry recipe(2) for a compatible
alternative random number generator with a long period and comparatively
simple update operations.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/random.py

   (2) http://code.activestate.com/recipes/576707/


File: python.info,  Node: itertools --- Functions creating iterators for efficient looping,  Next: functools --- Higher-order functions and operations on callable objects,  Prev: random --- Generate pseudo-random numbers,  Up: Numeric and Mathematical Modules

5.9.7 ‘itertools’ — Functions creating iterators for efficient looping
----------------------------------------------------------------------

New in version 2.3.

  This module implements a number of *note iterator: 87f. building
blocks inspired by constructs from APL, Haskell, and SML. Each has been
recast in a form suitable for Python.

  The module standardizes a core set of fast, memory efficient tools
that are useful by themselves or in combination.  Together, they form an
"iterator algebra" making it possible to construct specialized tools
succinctly and efficiently in pure Python.

  For instance, SML provides a tabulation tool: ‘tabulate(f)’ which
produces a sequence ‘f(0), f(1), ...’.  The same effect can be achieved
in Python by combining *note imap(): d66. and *note count(): 234. to
form ‘imap(f, count())’.

  These tools and their built-in counterparts also work well with the
high-speed functions in the *note operator: 126. module.  For example,
the multiplication operator can be mapped across two vectors to form an
efficient dot-product: ‘sum(imap(operator.mul, vector1, vector2))’.

  *Infinite Iterators:*

Iterator               Arguments             Results                                               Example
                                                                                                   
-------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                                   
*note count(): 234.    start, [step]         start, start+step, start+2*step, ...                  ‘count(10) --> 10 11 12 13 14 ...’
                                                                                                   
                                                                                                   
*note cycle(): d67.    p                     p0, p1, ...  plast, p0, p1, ...                       ‘cycle('ABCD') --> A B C D A B C D ...’
                                                                                                   
                                                                                                   
*note repeat(): b6f.   elem [,n]             elem, elem, elem, ...  endlessly or up to n times     ‘repeat(10, 3) --> 10 10 10’
                                                                                                   

  *Iterators terminating on the shortest input sequence:*

Iterator                 Arguments                        Results                                               Example
                                                                                                                
----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
                                                                                                                
*note chain(): 88e.      p, q, ...                        p0, p1, ...  plast, q0, q1, ...                       ‘chain('ABC', 'DEF') --> A B C D E F’
                                                                                                                
                                                                                                                
*note compress(): d68.   data, selectors                  (d[0] if s[0]), (d[1] if s[1]), ...                   ‘compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F’
                                                                                                                
                                                                                                                
*note dropwhile():       pred, seq                        seq[n], seq[n+1], starting when pred fails            ‘dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1’
d69.                                                                                                            

*note groupby(): d6a.    iterable[, keyfunc]              sub-iterators grouped by value of keyfunc(v)
                                                          
                                                                                                                
*note ifilter(): 881.    pred, seq                        elements of seq where pred(elem) is true              ‘ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9’
                                                                                                                
                                                                                                                
*note ifilterfalse():    pred, seq                        elements of seq where pred(elem) is false             ‘ifilterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8’
882.                                                                                                            

*note islice(): 3c1.     seq, [start,] stop [, step]      elements from seq[start:stop:step]                    ‘islice('ABCDEFG', 2, None) --> C D E F G’
                                                                                                                
                                                                                                                
*note imap(): d66.       func, p, q, ...                  func(p0, q0), func(p1, q1), ...                       ‘imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000’
                                                                                                                
                                                                                                                
*note starmap(): d6b.    func, seq                        func(*seq[0]), func(*seq[1]), ...                     ‘starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000’
                                                                                                                
                                                                                                                
*note tee(): d6c.        it, n                            it1, it2, ...  itn splits one iterator into n
                                                          
                                                                                                                
*note takewhile():       pred, seq                        seq[0], seq[1], until pred fails                      ‘takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4’
d6d.                                                                                                            

*note izip(): 406.       p, q, ...                        (p[0], q[0]), (p[1], q[1]), ...                       ‘izip('ABCD', 'xy') --> Ax By’
                                                                                                                
                                                                                                                
*note izip_longest():    p, q, ...                        (p[0], q[0]), (p[1], q[1]), ...                       ‘izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-’
d6e.                                                                                                            

  *Combinatoric generators:*

Iterator                                           Arguments                Results
                                                                            
----------------------------------------------------------------------------------------------------------------------------------------------
                                                                            
*note product(): 235.                              p, q, ...  [repeat=1]    cartesian product, equivalent to a nested for-loop
                                                                            
                                                                            
*note permutations(): d6f.                         p[, r]                   r-length tuples, all possible orderings, no repeated elements
                                                                            
                                                                            
*note combinations(): 233.                         p, r                     r-length tuples, in sorted order, no repeated elements
                                                                            
                                                                            
*note combinations_with_replacement(): b5f.        p, r                     r-length tuples, in sorted order, with repeated elements
                                                                            
                                                                            
‘product('ABCD', repeat=2)’                                                 ‘AA AB AC AD BA BB BC BD CA CB CC CD DA DB DC DD’
                                                                            
                                                                            
‘permutations('ABCD', 2)’                                                   ‘AB AC AD BA BC BD CA CB CD DA DB DC’
                                                                            
                                                                            
‘combinations('ABCD', 2)’                                                   ‘AB AC AD BC BD CD’
                                                                            
                                                                            
‘combinations_with_replacement('ABCD', 2)’                                  ‘AA AB AC AD BB BC BD CC CD DD’
                                                                            

* Menu:

* Itertool functions:: 
* Recipes: Recipes<2>. 


File: python.info,  Node: Itertool functions,  Next: Recipes<2>,  Up: itertools --- Functions creating iterators for efficient looping

5.9.7.1 Itertool functions
..........................

The following module functions all construct and return iterators.  Some
provide streams of infinite length, so they should only be accessed by
functions or loops that truncate the stream.

 -- Function: itertools.chain (*iterables)

     Make an iterator that returns elements from the first iterable
     until it is exhausted, then proceeds to the next iterable, until
     all of the iterables are exhausted.  Used for treating consecutive
     sequences as a single sequence.  Equivalent to:

          def chain(*iterables):
              # chain('ABC', 'DEF') --> A B C D E F
              for it in iterables:
                  for element in it:
                      yield element

 -- Class Method: chain.from_iterable (iterable)

     Alternate constructor for *note chain(): 88e.  Gets chained inputs
     from a single iterable argument that is evaluated lazily.  Roughly
     equivalent to:

          def from_iterable(iterables):
              # chain.from_iterable(['ABC', 'DEF']) --> A B C D E F
              for it in iterables:
                  for element in it:
                      yield element

     New in version 2.6.

 -- Function: itertools.combinations (iterable, r)

     Return _r_ length subsequences of elements from the input
     _iterable_.

     Combinations are emitted in lexicographic sort order.  So, if the
     input _iterable_ is sorted, the combination tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, there will be no
     repeat values in each combination.

     Equivalent to:

          def combinations(iterable, r):
              # combinations('ABCD', 2) --> AB AC AD BC BD CD
              # combinations(range(4), 3) --> 012 013 023 123
              pool = tuple(iterable)
              n = len(pool)
              if r > n:
                  return
              indices = range(r)
              yield tuple(pool[i] for i in indices)
              while True:
                  for i in reversed(range(r)):
                      if indices[i] != i + n - r:
                          break
                  else:
                      return
                  indices[i] += 1
                  for j in range(i+1, r):
                      indices[j] = indices[j-1] + 1
                  yield tuple(pool[i] for i in indices)

     The code for *note combinations(): 233. can be also expressed as a
     subsequence of *note permutations(): d6f. after filtering entries
     where the elements are not in sorted order (according to their
     position in the input pool):

          def combinations(iterable, r):
              pool = tuple(iterable)
              n = len(pool)
              for indices in permutations(range(n), r):
                  if sorted(indices) == list(indices):
                      yield tuple(pool[i] for i in indices)

     The number of items returned is ‘n! / r! / (n-r)!’ when ‘0 <= r <=
     n’ or zero when ‘r > n’.

     New in version 2.6.

 -- Function: itertools.combinations_with_replacement (iterable, r)

     Return _r_ length subsequences of elements from the input
     _iterable_ allowing individual elements to be repeated more than
     once.

     Combinations are emitted in lexicographic sort order.  So, if the
     input _iterable_ is sorted, the combination tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, the generated
     combinations will also be unique.

     Equivalent to:

          def combinations_with_replacement(iterable, r):
              # combinations_with_replacement('ABC', 2) --> AA AB AC BB BC CC
              pool = tuple(iterable)
              n = len(pool)
              if not n and r:
                  return
              indices = [0] * r
              yield tuple(pool[i] for i in indices)
              while True:
                  for i in reversed(range(r)):
                      if indices[i] != n - 1:
                          break
                  else:
                      return
                  indices[i:] = [indices[i] + 1] * (r - i)
                  yield tuple(pool[i] for i in indices)

     The code for *note combinations_with_replacement(): b5f. can be
     also expressed as a subsequence of *note product(): 235. after
     filtering entries where the elements are not in sorted order
     (according to their position in the input pool):

          def combinations_with_replacement(iterable, r):
              pool = tuple(iterable)
              n = len(pool)
              for indices in product(range(n), repeat=r):
                  if sorted(indices) == list(indices):
                      yield tuple(pool[i] for i in indices)

     The number of items returned is ‘(n+r-1)! / r! / (n-1)!’ when ‘n >
     0’.

     New in version 2.7.

 -- Function: itertools.compress (data, selectors)

     Make an iterator that filters elements from _data_ returning only
     those that have a corresponding element in _selectors_ that
     evaluates to ‘True’.  Stops when either the _data_ or _selectors_
     iterables has been exhausted.  Equivalent to:

          def compress(data, selectors):
              # compress('ABCDEF', [1,0,1,0,1,1]) --> A C E F
              return (d for d, s in izip(data, selectors) if s)

     New in version 2.7.

 -- Function: itertools.count (start=0, step=1)

     Make an iterator that returns evenly spaced values starting with
     _n_.  Often used as an argument to *note imap(): d66. to generate
     consecutive data points.  Also, used with *note izip(): 406. to add
     sequence numbers.  Equivalent to:

          def count(start=0, step=1):
              # count(10) --> 10 11 12 13 14 ...
              # count(2.5, 0.5) -> 2.5 3.0 3.5 ...
              n = start
              while True:
                  yield n
                  n += step

     When counting with floating point numbers, better accuracy can
     sometimes be achieved by substituting multiplicative code such as:
     ‘(start + step * i for i in count())’.

     Changed in version 2.7: added _step_ argument and allowed
     non-integer arguments.

 -- Function: itertools.cycle (iterable)

     Make an iterator returning elements from the iterable and saving a
     copy of each.  When the iterable is exhausted, return elements from
     the saved copy.  Repeats indefinitely.  Equivalent to:

          def cycle(iterable):
              # cycle('ABCD') --> A B C D A B C D A B C D ...
              saved = []
              for element in iterable:
                  yield element
                  saved.append(element)
              while saved:
                  for element in saved:
                        yield element

     Note, this member of the toolkit may require significant auxiliary
     storage (depending on the length of the iterable).

 -- Function: itertools.dropwhile (predicate, iterable)

     Make an iterator that drops elements from the iterable as long as
     the predicate is true; afterwards, returns every element.  Note,
     the iterator does not produce _any_ output until the predicate
     first becomes false, so it may have a lengthy start-up time.
     Equivalent to:

          def dropwhile(predicate, iterable):
              # dropwhile(lambda x: x<5, [1,4,6,4,1]) --> 6 4 1
              iterable = iter(iterable)
              for x in iterable:
                  if not predicate(x):
                      yield x
                      break
              for x in iterable:
                  yield x

 -- Function: itertools.groupby (iterable[, key])

     Make an iterator that returns consecutive keys and groups from the
     _iterable_.  The _key_ is a function computing a key value for each
     element.  If not specified or is ‘None’, _key_ defaults to an
     identity function and returns the element unchanged.  Generally,
     the iterable needs to already be sorted on the same key function.

     The operation of *note groupby(): d6a. is similar to the ‘uniq’
     filter in Unix.  It generates a break or new group every time the
     value of the key function changes (which is why it is usually
     necessary to have sorted the data using the same key function).
     That behavior differs from SQL’s GROUP BY which aggregates common
     elements regardless of their input order.

     The returned group is itself an iterator that shares the underlying
     iterable with *note groupby(): d6a.  Because the source is shared,
     when the *note groupby(): d6a. object is advanced, the previous
     group is no longer visible.  So, if that data is needed later, it
     should be stored as a list:

          groups = []
          uniquekeys = []
          data = sorted(data, key=keyfunc)
          for k, g in groupby(data, keyfunc):
              groups.append(list(g))      # Store group iterator as a list
              uniquekeys.append(k)

     *note groupby(): d6a. is equivalent to:

          class groupby(object):
              # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
              # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D
              def __init__(self, iterable, key=None):
                  if key is None:
                      key = lambda x: x
                  self.keyfunc = key
                  self.it = iter(iterable)
                  self.tgtkey = self.currkey = self.currvalue = object()
              def __iter__(self):
                  return self
              def next(self):
                  while self.currkey == self.tgtkey:
                      self.currvalue = next(self.it)    # Exit on StopIteration
                      self.currkey = self.keyfunc(self.currvalue)
                  self.tgtkey = self.currkey
                  return (self.currkey, self._grouper(self.tgtkey))
              def _grouper(self, tgtkey):
                  while self.currkey == tgtkey:
                      yield self.currvalue
                      self.currvalue = next(self.it)    # Exit on StopIteration
                      self.currkey = self.keyfunc(self.currvalue)

     New in version 2.4.

 -- Function: itertools.ifilter (predicate, iterable)

     Make an iterator that filters elements from iterable returning only
     those for which the predicate is ‘True’.  If _predicate_ is ‘None’,
     return the items that are true.  Equivalent to:

          def ifilter(predicate, iterable):
              # ifilter(lambda x: x%2, range(10)) --> 1 3 5 7 9
              if predicate is None:
                  predicate = bool
              for x in iterable:
                  if predicate(x):
                      yield x

 -- Function: itertools.ifilterfalse (predicate, iterable)

     Make an iterator that filters elements from iterable returning only
     those for which the predicate is ‘False’.  If _predicate_ is
     ‘None’, return the items that are false.  Equivalent to:

          def ifilterfalse(predicate, iterable):
              # ifilterfalse(lambda x: x%2, range(10)) --> 0 2 4 6 8
              if predicate is None:
                  predicate = bool
              for x in iterable:
                  if not predicate(x):
                      yield x

 -- Function: itertools.imap (function, *iterables)

     Make an iterator that computes the function using arguments from
     each of the iterables.  If _function_ is set to ‘None’, then *note
     imap(): d66. returns the arguments as a tuple.  Like *note map():
     304. but stops when the shortest iterable is exhausted instead of
     filling in ‘None’ for shorter iterables.  The reason for the
     difference is that infinite iterator arguments are typically an
     error for *note map(): 304. (because the output is fully evaluated)
     but represent a common and useful way of supplying arguments to
     *note imap(): d66.  Equivalent to:

          def imap(function, *iterables):
              # imap(pow, (2,3,10), (5,2,3)) --> 32 9 1000
              iterables = map(iter, iterables)
              while True:
                  args = [next(it) for it in iterables]
                  if function is None:
                      yield tuple(args)
                  else:
                      yield function(*args)

 -- Function: itertools.islice (iterable, stop)

 -- Function: itertools.islice (iterable, start, stop[, step])

     Make an iterator that returns selected elements from the iterable.
     If _start_ is non-zero, then elements from the iterable are skipped
     until start is reached.  Afterward, elements are returned
     consecutively unless _step_ is set higher than one which results in
     items being skipped.  If _stop_ is ‘None’, then iteration continues
     until the iterator is exhausted, if at all; otherwise, it stops at
     the specified position.  Unlike regular slicing, *note islice():
     3c1. does not support negative values for _start_, _stop_, or
     _step_.  Can be used to extract related fields from data where the
     internal structure has been flattened (for example, a multi-line
     report may list a name field on every third line).  Equivalent to:

          def islice(iterable, *args):
              # islice('ABCDEFG', 2) --> A B
              # islice('ABCDEFG', 2, 4) --> C D
              # islice('ABCDEFG', 2, None) --> C D E F G
              # islice('ABCDEFG', 0, None, 2) --> A C E G
              s = slice(*args)
              it = iter(xrange(s.start or 0, s.stop or sys.maxint, s.step or 1))
              nexti = next(it)
              for i, element in enumerate(iterable):
                  if i == nexti:
                      yield element
                      nexti = next(it)

     If _start_ is ‘None’, then iteration starts at zero.  If _step_ is
     ‘None’, then the step defaults to one.

     Changed in version 2.5: accept ‘None’ values for default _start_
     and _step_.

 -- Function: itertools.izip (*iterables)

     Make an iterator that aggregates elements from each of the
     iterables.  Like *note zip(): 405. except that it returns an
     iterator instead of a list.  Used for lock-step iteration over
     several iterables at a time.  Equivalent to:

          def izip(*iterables):
              # izip('ABCD', 'xy') --> Ax By
              iterators = map(iter, iterables)
              while iterators:
                  yield tuple(map(next, iterators))

     Changed in version 2.4: When no iterables are specified, returns a
     zero length iterator instead of raising a *note TypeError: 218.
     exception.

     The left-to-right evaluation order of the iterables is guaranteed.
     This makes possible an idiom for clustering a data series into
     n-length groups using ‘izip(*[iter(s)]*n)’.

     *note izip(): 406. should only be used with unequal length inputs
     when you don’t care about trailing, unmatched values from the
     longer iterables.  If those values are important, use *note
     izip_longest(): d6e. instead.

 -- Function: itertools.izip_longest (*iterables[, fillvalue])

     Make an iterator that aggregates elements from each of the
     iterables.  If the iterables are of uneven length, missing values
     are filled-in with _fillvalue_.  Iteration continues until the
     longest iterable is exhausted.  Equivalent to:

          class ZipExhausted(Exception):
              pass

          def izip_longest(*args, **kwds):
              # izip_longest('ABCD', 'xy', fillvalue='-') --> Ax By C- D-
              fillvalue = kwds.get('fillvalue')
              counter = [len(args) - 1]
              def sentinel():
                  if not counter[0]:
                      raise ZipExhausted
                  counter[0] -= 1
                  yield fillvalue
              fillers = repeat(fillvalue)
              iterators = [chain(it, sentinel(), fillers) for it in args]
              try:
                  while iterators:
                      yield tuple(map(next, iterators))
              except ZipExhausted:
                  pass

     If one of the iterables is potentially infinite, then the *note
     izip_longest(): d6e. function should be wrapped with something that
     limits the number of calls (for example *note islice(): 3c1. or
     *note takewhile(): d6d.).  If not specified, _fillvalue_ defaults
     to ‘None’.

     New in version 2.6.

 -- Function: itertools.permutations (iterable[, r])

     Return successive _r_ length permutations of elements in the
     _iterable_.

     If _r_ is not specified or is ‘None’, then _r_ defaults to the
     length of the _iterable_ and all possible full-length permutations
     are generated.

     Permutations are emitted in lexicographic sort order.  So, if the
     input _iterable_ is sorted, the permutation tuples will be produced
     in sorted order.

     Elements are treated as unique based on their position, not on
     their value.  So if the input elements are unique, there will be no
     repeat values in each permutation.

     Equivalent to:

          def permutations(iterable, r=None):
              # permutations('ABCD', 2) --> AB AC AD BA BC BD CA CB CD DA DB DC
              # permutations(range(3)) --> 012 021 102 120 201 210
              pool = tuple(iterable)
              n = len(pool)
              r = n if r is None else r
              if r > n:
                  return
              indices = range(n)
              cycles = range(n, n-r, -1)
              yield tuple(pool[i] for i in indices[:r])
              while n:
                  for i in reversed(range(r)):
                      cycles[i] -= 1
                      if cycles[i] == 0:
                          indices[i:] = indices[i+1:] + indices[i:i+1]
                          cycles[i] = n - i
                      else:
                          j = cycles[i]
                          indices[i], indices[-j] = indices[-j], indices[i]
                          yield tuple(pool[i] for i in indices[:r])
                          break
                  else:
                      return

     The code for *note permutations(): d6f. can be also expressed as a
     subsequence of *note product(): 235, filtered to exclude entries
     with repeated elements (those from the same position in the input
     pool):

          def permutations(iterable, r=None):
              pool = tuple(iterable)
              n = len(pool)
              r = n if r is None else r
              for indices in product(range(n), repeat=r):
                  if len(set(indices)) == r:
                      yield tuple(pool[i] for i in indices)

     The number of items returned is ‘n! / (n-r)!’ when ‘0 <= r <= n’ or
     zero when ‘r > n’.

     New in version 2.6.

 -- Function: itertools.product (*iterables[, repeat])

     Cartesian product of input iterables.

     Equivalent to nested for-loops in a generator expression.  For
     example, ‘product(A, B)’ returns the same as ‘((x,y) for x in A for
     y in B)’.

     The nested loops cycle like an odometer with the rightmost element
     advancing on every iteration.  This pattern creates a lexicographic
     ordering so that if the input’s iterables are sorted, the product
     tuples are emitted in sorted order.

     To compute the product of an iterable with itself, specify the
     number of repetitions with the optional _repeat_ keyword argument.
     For example, ‘product(A, repeat=4)’ means the same as ‘product(A,
     A, A, A)’.

     This function is equivalent to the following code, except that the
     actual implementation does not build up intermediate results in
     memory:

          def product(*args, **kwds):
              # product('ABCD', 'xy') --> Ax Ay Bx By Cx Cy Dx Dy
              # product(range(2), repeat=3) --> 000 001 010 011 100 101 110 111
              pools = map(tuple, args) * kwds.get('repeat', 1)
              result = [[]]
              for pool in pools:
                  result = [x+[y] for x in result for y in pool]
              for prod in result:
                  yield tuple(prod)

     New in version 2.6.

 -- Function: itertools.repeat (object[, times])

     Make an iterator that returns _object_ over and over again.  Runs
     indefinitely unless the _times_ argument is specified.  Used as
     argument to *note imap(): d66. for invariant function parameters.
     Also used with *note izip(): 406. to create constant fields in a
     tuple record.  Equivalent to:

          def repeat(object, times=None):
              # repeat(10, 3) --> 10 10 10
              if times is None:
                  while True:
                      yield object
              else:
                  for i in xrange(times):
                      yield object

     A common use for _repeat_ is to supply a stream of constant values
     to _imap_ or _zip_:

          >>> list(imap(pow, xrange(10), repeat(2)))
          [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]

 -- Function: itertools.starmap (function, iterable)

     Make an iterator that computes the function using arguments
     obtained from the iterable.  Used instead of *note imap(): d66.
     when argument parameters are already grouped in tuples from a
     single iterable (the data has been "pre-zipped").  The difference
     between *note imap(): d66. and *note starmap(): d6b. parallels the
     distinction between ‘function(a,b)’ and ‘function(*c)’.  Equivalent
     to:

          def starmap(function, iterable):
              # starmap(pow, [(2,5), (3,2), (10,3)]) --> 32 9 1000
              for args in iterable:
                  yield function(*args)

     Changed in version 2.6: Previously, *note starmap(): d6b. required
     the function arguments to be tuples.  Now, any iterable is allowed.

 -- Function: itertools.takewhile (predicate, iterable)

     Make an iterator that returns elements from the iterable as long as
     the predicate is true.  Equivalent to:

          def takewhile(predicate, iterable):
              # takewhile(lambda x: x<5, [1,4,6,4,1]) --> 1 4
              for x in iterable:
                  if predicate(x):
                      yield x
                  else:
                      break

 -- Function: itertools.tee (iterable[, n=2])

     Return _n_ independent iterators from a single iterable.
     Equivalent to:

          def tee(iterable, n=2):
              it = iter(iterable)
              deques = [collections.deque() for i in range(n)]
              def gen(mydeque):
                  while True:
                      if not mydeque:             # when the local deque is empty
                          newval = next(it)       # fetch a new value and
                          for d in deques:        # load it to all the deques
                              d.append(newval)
                      yield mydeque.popleft()
              return tuple(gen(d) for d in deques)

     Once *note tee(): d6c. has made a split, the original _iterable_
     should not be used anywhere else; otherwise, the _iterable_ could
     get advanced without the tee objects being informed.

     This itertool may require significant auxiliary storage (depending
     on how much temporary data needs to be stored).  In general, if one
     iterator uses most or all of the data before another iterator
     starts, it is faster to use *note list(): 3bc. instead of *note
     tee(): d6c.

     New in version 2.4.

