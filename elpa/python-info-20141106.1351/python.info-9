This is python.info, produced by makeinfo version 5.2 from python.texi.

     Python 2.7.8, November 06, 2014

     Georg Brandl

     Copyright © 1990-2014, Python Software Foundation

INFO-DIR-SECTION Programming
START-INFO-DIR-ENTRY
* Python: (python.info). The Python Programming Language
END-INFO-DIR-ENTRY


   Generated by Sphinx 1.1.3.


File: python.info,  Node: Recipes<2>,  Prev: Itertool functions,  Up: itertools --- Functions creating iterators for efficient looping

5.9.7.2 Recipes
...............

This section shows recipes for creating an extended toolset using the
existing itertools as building blocks.

  The extended tools offer the same high performance as the underlying
toolset.  The superior memory performance is kept by processing elements
one at a time rather than bringing the whole iterable into memory all at
once.  Code volume is kept small by linking the tools together in a
functional style which helps eliminate temporary variables.  High speed
is retained by preferring "vectorized" building blocks over the use of
for-loops and *note generator: 5dc.s which incur interpreter overhead.

     def take(n, iterable):
         "Return first n items of the iterable as a list"
         return list(islice(iterable, n))

     def tabulate(function, start=0):
         "Return function(0), function(1), ..."
         return imap(function, count(start))

     def consume(iterator, n):
         "Advance the iterator n-steps ahead. If n is none, consume entirely."
         # Use functions that consume iterators at C speed.
         if n is None:
             # feed the entire iterator into a zero-length deque
             collections.deque(iterator, maxlen=0)
         else:
             # advance to the empty slice starting at position n
             next(islice(iterator, n, n), None)

     def nth(iterable, n, default=None):
         "Returns the nth item or a default value"
         return next(islice(iterable, n, None), default)

     def quantify(iterable, pred=bool):
         "Count how many times the predicate is true"
         return sum(imap(pred, iterable))

     def padnone(iterable):
         """Returns the sequence elements and then returns None indefinitely.

         Useful for emulating the behavior of the built-in map() function.
         """
         return chain(iterable, repeat(None))

     def ncycles(iterable, n):
         "Returns the sequence elements n times"
         return chain.from_iterable(repeat(tuple(iterable), n))

     def dotproduct(vec1, vec2):
         return sum(imap(operator.mul, vec1, vec2))

     def flatten(listOfLists):
         "Flatten one level of nesting"
         return chain.from_iterable(listOfLists)

     def repeatfunc(func, times=None, *args):
         """Repeat calls to func with specified arguments.

         Example:  repeatfunc(random.random)
         """
         if times is None:
             return starmap(func, repeat(args))
         return starmap(func, repeat(args, times))

     def pairwise(iterable):
         "s -> (s0,s1), (s1,s2), (s2, s3), ..."
         a, b = tee(iterable)
         next(b, None)
         return izip(a, b)

     def grouper(iterable, n, fillvalue=None):
         "Collect data into fixed-length chunks or blocks"
         # grouper('ABCDEFG', 3, 'x') --> ABC DEF Gxx
         args = [iter(iterable)] * n
         return izip_longest(fillvalue=fillvalue, *args)

     def roundrobin(*iterables):
         "roundrobin('ABC', 'D', 'EF') --> A D E B F C"
         # Recipe credited to George Sakkis
         pending = len(iterables)
         nexts = cycle(iter(it).next for it in iterables)
         while pending:
             try:
                 for next in nexts:
                     yield next()
             except StopIteration:
                 pending -= 1
                 nexts = cycle(islice(nexts, pending))

     def powerset(iterable):
         "powerset([1,2,3]) --> () (1,) (2,) (3,) (1,2) (1,3) (2,3) (1,2,3)"
         s = list(iterable)
         return chain.from_iterable(combinations(s, r) for r in range(len(s)+1))

     def unique_everseen(iterable, key=None):
         "List unique elements, preserving order. Remember all elements ever seen."
         # unique_everseen('AAAABBBCCDAABBB') --> A B C D
         # unique_everseen('ABBCcAD', str.lower) --> A B C D
         seen = set()
         seen_add = seen.add
         if key is None:
             for element in ifilterfalse(seen.__contains__, iterable):
                 seen_add(element)
                 yield element
         else:
             for element in iterable:
                 k = key(element)
                 if k not in seen:
                     seen_add(k)
                     yield element

     def unique_justseen(iterable, key=None):
         "List unique elements, preserving order. Remember only the element just seen."
         # unique_justseen('AAAABBBCCDAABBB') --> A B C D A B
         # unique_justseen('ABBCcAD', str.lower) --> A B C A D
         return imap(next, imap(itemgetter(1), groupby(iterable, key)))

     def iter_except(func, exception, first=None):
         """ Call a function repeatedly until an exception is raised.

         Converts a call-until-exception interface to an iterator interface.
         Like __builtin__.iter(func, sentinel) but uses an exception instead
         of a sentinel to end the loop.

         Examples:
             bsddbiter = iter_except(db.next, bsddb.error, db.first)
             heapiter = iter_except(functools.partial(heappop, h), IndexError)
             dictiter = iter_except(d.popitem, KeyError)
             dequeiter = iter_except(d.popleft, IndexError)
             queueiter = iter_except(q.get_nowait, Queue.Empty)
             setiter = iter_except(s.pop, KeyError)

         """
         try:
             if first is not None:
                 yield first()
             while 1:
                 yield func()
         except exception:
             pass

     def random_product(*args, **kwds):
         "Random selection from itertools.product(*args, **kwds)"
         pools = map(tuple, args) * kwds.get('repeat', 1)
         return tuple(random.choice(pool) for pool in pools)

     def random_permutation(iterable, r=None):
         "Random selection from itertools.permutations(iterable, r)"
         pool = tuple(iterable)
         r = len(pool) if r is None else r
         return tuple(random.sample(pool, r))

     def random_combination(iterable, r):
         "Random selection from itertools.combinations(iterable, r)"
         pool = tuple(iterable)
         n = len(pool)
         indices = sorted(random.sample(xrange(n), r))
         return tuple(pool[i] for i in indices)

     def random_combination_with_replacement(iterable, r):
         "Random selection from itertools.combinations_with_replacement(iterable, r)"
         pool = tuple(iterable)
         n = len(pool)
         indices = sorted(random.randrange(n) for i in xrange(r))
         return tuple(pool[i] for i in indices)

     def tee_lookahead(t, i):
         """Inspect the i-th upcomping value from a tee object
            while leaving the tee object at its current position.

            Raise an IndexError if the underlying iterator doesn't
            have enough values.

         """
         for value in islice(t.__copy__(), i, None):
             return value
         raise IndexError(i)

  Note, many of the above recipes can be optimized by replacing global
lookups with local variables defined as default values.  For example,
the _dotproduct_ recipe can be written as:

     def dotproduct(vec1, vec2, sum=sum, imap=imap, mul=operator.mul):
         return sum(imap(mul, vec1, vec2))


File: python.info,  Node: functools --- Higher-order functions and operations on callable objects,  Next: operator --- Standard operators as functions,  Prev: itertools --- Functions creating iterators for efficient looping,  Up: Numeric and Mathematical Modules

5.9.8 ‘functools’ — Higher-order functions and operations on callable objects
-----------------------------------------------------------------------------

New in version 2.5.

  *Source code:* Lib/functools.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note functools: d9. module is for higher-order functions:
functions that act on or return other functions.  In general, any
callable object can be treated as a function for the purposes of this
module.

  The *note functools: d9. module defines the following functions:

 -- Function: functools.cmp_to_key (func)

     Transform an old-style comparison function to a key function.  Used
     with tools that accept key functions (such as *note sorted(): 223,
     *note min(): 224, *note max(): 225, *note heapq.nlargest(): b90,
     *note heapq.nsmallest(): b91, *note itertools.groupby(): d6a.).
     This function is primarily used as a transition tool for programs
     being converted to Python 3 where comparison functions are no
     longer supported.

     A comparison function is any callable that accept two arguments,
     compares them, and returns a negative number for less-than, zero
     for equality, or a positive number for greater-than.  A key
     function is a callable that accepts one argument and returns
     another value that indicates the position in the desired collation
     sequence.

     Example:

          sorted(iterable, key=cmp_to_key(locale.strcoll))  # locale-aware sort order

     New in version 2.7.

 -- Function: functools.total_ordering (cls)

     Given a class defining one or more rich comparison ordering
     methods, this class decorator supplies the rest.  This simplifies
     the effort involved in specifying all of the possible rich
     comparison operations:

     The class must define one of *note __lt__(): 21d, *note __le__():
     21e, *note __gt__(): 21f, or *note __ge__(): 220.  In addition, the
     class should supply an *note __eq__(): 21c. method.

     For example:

          @total_ordering
          class Student:
              def __eq__(self, other):
                  return ((self.lastname.lower(), self.firstname.lower()) ==
                          (other.lastname.lower(), other.firstname.lower()))
              def __lt__(self, other):
                  return ((self.lastname.lower(), self.firstname.lower()) <
                          (other.lastname.lower(), other.firstname.lower()))

     New in version 2.7.

 -- Function: functools.reduce (function, iterable[, initializer])

     This is the same function as *note reduce(): 2e9.  It is made
     available in this module to allow writing code more
     forward-compatible with Python 3.

     New in version 2.6.

 -- Function: functools.partial (func[,*args][, **keywords])

     Return a new *note partial: d77. object which when called will
     behave like _func_ called with the positional arguments _args_ and
     keyword arguments _keywords_.  If more arguments are supplied to
     the call, they are appended to _args_.  If additional keyword
     arguments are supplied, they extend and override _keywords_.
     Roughly equivalent to:

          def partial(func, *args, **keywords):
              def newfunc(*fargs, **fkeywords):
                  newkeywords = keywords.copy()
                  newkeywords.update(fkeywords)
                  return func(*(args + fargs), **newkeywords)
              newfunc.func = func
              newfunc.args = args
              newfunc.keywords = keywords
              return newfunc

     The *note partial(): d77. is used for partial function application
     which "freezes" some portion of a function’s arguments and/or
     keywords resulting in a new object with a simplified signature.
     For example, *note partial(): d77. can be used to create a callable
     that behaves like the *note int(): 1f2. function where the _base_
     argument defaults to two:

          >>> from functools import partial
          >>> basetwo = partial(int, base=2)
          >>> basetwo.__doc__ = 'Convert base 2 string to an int.'
          >>> basetwo('10010')
          18

 -- Function: functools.update_wrapper (wrapper, wrapped[, assigned][,
          updated])

     Update a _wrapper_ function to look like the _wrapped_ function.
     The optional arguments are tuples to specify which attributes of
     the original function are assigned directly to the matching
     attributes on the wrapper function and which attributes of the
     wrapper function are updated with the corresponding attributes from
     the original function.  The default values for these arguments are
     the module level constants _WRAPPER_ASSIGNMENTS_ (which assigns to
     the wrapper function’s ___name___, ___module___ and ___doc___, the
     documentation string) and _WRAPPER_UPDATES_ (which updates the
     wrapper function’s ___dict___, i.e.  the instance dictionary).

     The main intended use for this function is in *note decorator: 856.
     functions which wrap the decorated function and return the wrapper.
     If the wrapper function is not updated, the metadata of the
     returned function will reflect the wrapper definition rather than
     the original function definition, which is typically less than
     helpful.

 -- Function: functools.wraps (wrapped[, assigned][, updated])

     This is a convenience function for invoking
     ‘partial(update_wrapper, wrapped=wrapped, assigned=assigned,
     updated=updated)’ as a function decorator when defining a wrapper
     function.  For example:

          >>> from functools import wraps
          >>> def my_decorator(f):
          ...     @wraps(f)
          ...     def wrapper(*args, **kwds):
          ...         print 'Calling decorated function'
          ...         return f(*args, **kwds)
          ...     return wrapper
          ...
          >>> @my_decorator
          ... def example():
          ...     """Docstring"""
          ...     print 'Called example function'
          ...
          >>> example()
          Calling decorated function
          Called example function
          >>> example.__name__
          'example'
          >>> example.__doc__
          'Docstring'

     Without the use of this decorator factory, the name of the example
     function would have been ‘'wrapper'’, and the docstring of the
     original ‘example()’ would have been lost.

* Menu:

* partial Objects:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/functools.py


File: python.info,  Node: partial Objects,  Up: functools --- Higher-order functions and operations on callable objects

5.9.8.1 ‘partial’ Objects
.........................

*note partial: d77. objects are callable objects created by *note
partial(): d77.  They have three read-only attributes:

 -- Attribute: partial.func

     A callable object or function.  Calls to the *note partial: d77.
     object will be forwarded to *note func: d7c. with new arguments and
     keywords.

 -- Attribute: partial.args

     The leftmost positional arguments that will be prepended to the
     positional arguments provided to a *note partial: d77. object call.

 -- Attribute: partial.keywords

     The keyword arguments that will be supplied when the *note partial:
     d77. object is called.

  *note partial: d77. objects are like ‘function’ objects in that they
are callable, weak referencable, and can have attributes.  There are
some important differences.  For instance, the ‘__name__’ and ‘__doc__’
attributes are not created automatically.  Also, *note partial: d77.
objects defined in classes behave like static methods and do not
transform into bound methods during instance attribute look-up.


File: python.info,  Node: operator --- Standard operators as functions,  Prev: functools --- Higher-order functions and operations on callable objects,  Up: Numeric and Mathematical Modules

5.9.9 ‘operator’ — Standard operators as functions
--------------------------------------------------

The *note operator: 126. module exports a set of efficient functions
corresponding to the intrinsic operators of Python.  For example,
‘operator.add(x, y)’ is equivalent to the expression ‘x+y’.  The
function names are those used for special class methods; variants
without leading and trailing ‘__’ are also provided for convenience.

  The functions fall into categories that perform object comparisons,
logical operations, mathematical operations, sequence operations, and
abstract type tests.

  The object comparison functions are useful for all objects, and are
named after the rich comparison operators they support:

 -- Function: operator.lt (a, b)
 -- Function: operator.le (a, b)
 -- Function: operator.eq (a, b)
 -- Function: operator.ne (a, b)
 -- Function: operator.ge (a, b)
 -- Function: operator.gt (a, b)
 -- Function: operator.__lt__ (a, b)
 -- Function: operator.__le__ (a, b)
 -- Function: operator.__eq__ (a, b)
 -- Function: operator.__ne__ (a, b)
 -- Function: operator.__ge__ (a, b)
 -- Function: operator.__gt__ (a, b)

     Perform "rich comparisons" between _a_ and _b_.  Specifically,
     ‘lt(a, b)’ is equivalent to ‘a < b’, ‘le(a, b)’ is equivalent to ‘a
     <= b’, ‘eq(a, b)’ is equivalent to ‘a == b’, ‘ne(a, b)’ is
     equivalent to ‘a != b’, ‘gt(a, b)’ is equivalent to ‘a > b’ and
     ‘ge(a, b)’ is equivalent to ‘a >= b’.  Note that unlike the
     built-in *note cmp(): 4be, these functions can return any value,
     which may or may not be interpretable as a Boolean value.  See
     *note Comparisons: 7dc. for more information about rich
     comparisons.

     New in version 2.2.

  The logical operations are also generally applicable to all objects,
and support truth tests, identity tests, and boolean operations:

 -- Function: operator.not_ (obj)
 -- Function: operator.__not__ (obj)

     Return the outcome of *note not: 7e5. _obj_.  (Note that there is
     no *note __not__(): d8e. method for object instances; only the
     interpreter core defines this operation.  The result is affected by
     the *note __nonzero__(): 70c. and *note __len__(): 40a. methods.)

 -- Function: operator.truth (obj)

     Return *note True: 3b0. if _obj_ is true, and *note False: 3b1.
     otherwise.  This is equivalent to using the *note bool: 43c.
     constructor.

 -- Function: operator.is_ (a, b)

     Return ‘a is b’.  Tests object identity.

     New in version 2.3.

 -- Function: operator.is_not (a, b)

     Return ‘a is not b’.  Tests object identity.

     New in version 2.3.

  The mathematical and bitwise operations are the most numerous:

 -- Function: operator.abs (obj)
 -- Function: operator.__abs__ (obj)

     Return the absolute value of _obj_.

 -- Function: operator.add (a, b)
 -- Function: operator.__add__ (a, b)

     Return ‘a + b’, for _a_ and _b_ numbers.

 -- Function: operator.and_ (a, b)
 -- Function: operator.__and__ (a, b)

     Return the bitwise and of _a_ and _b_.

 -- Function: operator.div (a, b)
 -- Function: operator.__div__ (a, b)

     Return ‘a / b’ when ‘__future__.division’ is not in effect.  This
     is also known as "classic" division.

 -- Function: operator.floordiv (a, b)
 -- Function: operator.__floordiv__ (a, b)

     Return ‘a // b’.

     New in version 2.2.

 -- Function: operator.index (a)
 -- Function: operator.__index__ (a)

     Return _a_ converted to an integer.  Equivalent to ‘a.__index__()’.

     New in version 2.5.

 -- Function: operator.inv (obj)
 -- Function: operator.invert (obj)
 -- Function: operator.__inv__ (obj)
 -- Function: operator.__invert__ (obj)

     Return the bitwise inverse of the number _obj_.  This is equivalent
     to ‘~obj’.

     New in version 2.0: The names *note invert(): d9e. and *note
     __invert__(): da0.

 -- Function: operator.lshift (a, b)
 -- Function: operator.__lshift__ (a, b)

     Return _a_ shifted left by _b_.

 -- Function: operator.mod (a, b)
 -- Function: operator.__mod__ (a, b)

     Return ‘a % b’.

 -- Function: operator.mul (a, b)
 -- Function: operator.__mul__ (a, b)

     Return ‘a * b’, for _a_ and _b_ numbers.

 -- Function: operator.neg (obj)
 -- Function: operator.__neg__ (obj)

     Return _obj_ negated (‘-obj’).

 -- Function: operator.or_ (a, b)
 -- Function: operator.__or__ (a, b)

     Return the bitwise or of _a_ and _b_.

 -- Function: operator.pos (obj)
 -- Function: operator.__pos__ (obj)

     Return _obj_ positive (‘+obj’).

 -- Function: operator.pow (a, b)
 -- Function: operator.__pow__ (a, b)

     Return ‘a ** b’, for _a_ and _b_ numbers.

     New in version 2.3.

 -- Function: operator.rshift (a, b)
 -- Function: operator.__rshift__ (a, b)

     Return _a_ shifted right by _b_.

 -- Function: operator.sub (a, b)
 -- Function: operator.__sub__ (a, b)

     Return ‘a - b’.

 -- Function: operator.truediv (a, b)
 -- Function: operator.__truediv__ (a, b)

     Return ‘a / b’ when ‘__future__.division’ is in effect.  This is
     also known as "true" division.

     New in version 2.2.

 -- Function: operator.xor (a, b)
 -- Function: operator.__xor__ (a, b)

     Return the bitwise exclusive or of _a_ and _b_.

  Operations which work with sequences (some of them with mappings too)
include:

 -- Function: operator.concat (a, b)
 -- Function: operator.__concat__ (a, b)

     Return ‘a + b’ for _a_ and _b_ sequences.

 -- Function: operator.contains (a, b)
 -- Function: operator.__contains__ (a, b)

     Return the outcome of the test ‘b in a’.  Note the reversed
     operands.

     New in version 2.0: The name *note __contains__(): dba.

 -- Function: operator.countOf (a, b)

     Return the number of occurrences of _b_ in _a_.

 -- Function: operator.delitem (a, b)
 -- Function: operator.__delitem__ (a, b)

     Remove the value of _a_ at index _b_.

 -- Function: operator.delslice (a, b, c)
 -- Function: operator.__delslice__ (a, b, c)

     Delete the slice of _a_ from index _b_ to index _c-1_.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *note delitem(): dbc. with a slice index.

 -- Function: operator.getitem (a, b)
 -- Function: operator.__getitem__ (a, b)

     Return the value of _a_ at index _b_.

 -- Function: operator.getslice (a, b, c)
 -- Function: operator.__getslice__ (a, b, c)

     Return the slice of _a_ from index _b_ to index _c-1_.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *note getitem(): dc0. with a slice index.

 -- Function: operator.indexOf (a, b)

     Return the index of the first of occurrence of _b_ in _a_.

 -- Function: operator.repeat (a, b)
 -- Function: operator.__repeat__ (a, b)

     Deprecated since version 2.7: Use *note __mul__(): da6. instead.

     Return ‘a * b’ where _a_ is a sequence and _b_ is an integer.

 -- Function: operator.sequenceIncludes (...)

     Deprecated since version 2.0: Use *note contains(): db9. instead.

     Alias for *note contains(): db9.

 -- Function: operator.setitem (a, b, c)
 -- Function: operator.__setitem__ (a, b, c)

     Set the value of _a_ at index _b_ to _c_.

 -- Function: operator.setslice (a, b, c, v)
 -- Function: operator.__setslice__ (a, b, c, v)

     Set the slice of _a_ from index _b_ to index _c-1_ to the sequence
     _v_.

     Deprecated since version 2.6: This function is removed in Python
     3.x.  Use *note setitem(): dc7. with a slice index.

  Example use of operator functions:

     >>> # Elementwise multiplication
     >>> map(mul, [0, 1, 2, 3], [10, 20, 30, 40])
     [0, 20, 60, 120]

     >>> # Dot product
     >>> sum(map(mul, [0, 1, 2, 3], [10, 20, 30, 40]))
     200

  Many operations have an "in-place" version.  The following functions
provide a more primitive access to in-place operators than the usual
syntax does; for example, the *note statement: dcb. ‘x += y’ is
equivalent to ‘x = operator.iadd(x, y)’.  Another way to put it is to
say that ‘z = operator.iadd(x, y)’ is equivalent to the compound
statement ‘z = x; z += y’.

 -- Function: operator.iadd (a, b)
 -- Function: operator.__iadd__ (a, b)

     ‘a = iadd(a, b)’ is equivalent to ‘a += b’.

     New in version 2.5.

 -- Function: operator.iand (a, b)
 -- Function: operator.__iand__ (a, b)

     ‘a = iand(a, b)’ is equivalent to ‘a &= b’.

     New in version 2.5.

 -- Function: operator.iconcat (a, b)
 -- Function: operator.__iconcat__ (a, b)

     ‘a = iconcat(a, b)’ is equivalent to ‘a += b’ for _a_ and _b_
     sequences.

     New in version 2.5.

 -- Function: operator.idiv (a, b)
 -- Function: operator.__idiv__ (a, b)

     ‘a = idiv(a, b)’ is equivalent to ‘a /= b’ when
     ‘__future__.division’ is not in effect.

     New in version 2.5.

 -- Function: operator.ifloordiv (a, b)
 -- Function: operator.__ifloordiv__ (a, b)

     ‘a = ifloordiv(a, b)’ is equivalent to ‘a //= b’.

     New in version 2.5.

 -- Function: operator.ilshift (a, b)
 -- Function: operator.__ilshift__ (a, b)

     ‘a = ilshift(a, b)’ is equivalent to ‘a <<= b’.

     New in version 2.5.

 -- Function: operator.imod (a, b)
 -- Function: operator.__imod__ (a, b)

     ‘a = imod(a, b)’ is equivalent to ‘a %= b’.

     New in version 2.5.

 -- Function: operator.imul (a, b)
 -- Function: operator.__imul__ (a, b)

     ‘a = imul(a, b)’ is equivalent to ‘a *= b’.

     New in version 2.5.

 -- Function: operator.ior (a, b)
 -- Function: operator.__ior__ (a, b)

     ‘a = ior(a, b)’ is equivalent to ‘a |= b’.

     New in version 2.5.

 -- Function: operator.ipow (a, b)
 -- Function: operator.__ipow__ (a, b)

     ‘a = ipow(a, b)’ is equivalent to ‘a **= b’.

     New in version 2.5.

 -- Function: operator.irepeat (a, b)
 -- Function: operator.__irepeat__ (a, b)

     Deprecated since version 2.7: Use *note __imul__(): ddb. instead.

     ‘a = irepeat(a, b)’ is equivalent to ‘a *= b’ where _a_ is a
     sequence and _b_ is an integer.

     New in version 2.5.

 -- Function: operator.irshift (a, b)
 -- Function: operator.__irshift__ (a, b)

     ‘a = irshift(a, b)’ is equivalent to ‘a >>= b’.

     New in version 2.5.

 -- Function: operator.isub (a, b)
 -- Function: operator.__isub__ (a, b)

     ‘a = isub(a, b)’ is equivalent to ‘a -= b’.

     New in version 2.5.

 -- Function: operator.itruediv (a, b)
 -- Function: operator.__itruediv__ (a, b)

     ‘a = itruediv(a, b)’ is equivalent to ‘a /= b’ when
     ‘__future__.division’ is in effect.

     New in version 2.5.

 -- Function: operator.ixor (a, b)
 -- Function: operator.__ixor__ (a, b)

     ‘a = ixor(a, b)’ is equivalent to ‘a ^= b’.

     New in version 2.5.

  The *note operator: 126. module also defines a few predicates to test
the type of objects; however, these are not all reliable.  It is
preferable to test abstract base classes instead (see *note collections:
65. and *note numbers: 125. for details).

 -- Function: operator.isCallable (obj)

     Deprecated since version 2.0: Use ‘isinstance(x,
     collections.Callable)’ instead.

     Returns true if the object _obj_ can be called like a function,
     otherwise it returns false.  True is returned for functions, bound
     and unbound methods, class objects, and instance objects which
     support the *note __call__(): 6fa. method.

 -- Function: operator.isMappingType (obj)

     Deprecated since version 2.7: Use ‘isinstance(x,
     collections.Mapping)’ instead.

     Returns true if the object _obj_ supports the mapping interface.
     This is true for dictionaries and all instance objects defining
     *note __getitem__(): dc1.

 -- Function: operator.isNumberType (obj)

     Deprecated since version 2.7: Use ‘isinstance(x, numbers.Number)’
     instead.

     Returns true if the object _obj_ represents a number.  This is true
     for all numeric types implemented in C.

 -- Function: operator.isSequenceType (obj)

     Deprecated since version 2.7: Use ‘isinstance(x,
     collections.Sequence)’ instead.

     Returns true if the object _obj_ supports the sequence protocol.
     This returns true for all objects which define sequence methods in
     C, and for all instance objects defining *note __getitem__(): dc1.

  The *note operator: 126. module also defines tools for generalized
attribute and item lookups.  These are useful for making fast field
extractors as arguments for *note map(): 304, *note sorted(): 223, *note
itertools.groupby(): d6a, or other functions that expect a function
argument.

 -- Function: operator.attrgetter (attr)

 -- Function: operator.attrgetter (*attrs)

     Return a callable object that fetches _attr_ from its operand.  If
     more than one attribute is requested, returns a tuple of
     attributes.  The attribute names can also contain dots.  For
     example:

        * After ‘f = attrgetter('name')’, the call ‘f(b)’ returns
          ‘b.name’.

        * After ‘f = attrgetter('name', 'date')’, the call ‘f(b)’
          returns ‘(b.name, b.date)’.

        * After ‘f = attrgetter('name.first', 'name.last')’, the call
          ‘f(b)’ returns ‘(b.name.first, b.name.last)’.

     Equivalent to:

          def attrgetter(*items):
              if len(items) == 1:
                  attr = items[0]
                  def g(obj):
                      return resolve_attr(obj, attr)
              else:
                  def g(obj):
                      return tuple(resolve_attr(obj, attr) for attr in items)
              return g

          def resolve_attr(obj, attr):
              for name in attr.split("."):
                  obj = getattr(obj, name)
              return obj

     New in version 2.4.

     Changed in version 2.5: Added support for multiple attributes.

     Changed in version 2.6: Added support for dotted attributes.

 -- Function: operator.itemgetter (item)

 -- Function: operator.itemgetter (*items)

     Return a callable object that fetches _item_ from its operand using
     the operand’s *note __getitem__(): dc1. method.  If multiple items
     are specified, returns a tuple of lookup values.  For example:

        * After ‘f = itemgetter(2)’, the call ‘f(r)’ returns ‘r[2]’.

        * After ‘g = itemgetter(2, 5, 3)’, the call ‘g(r)’ returns
          ‘(r[2], r[5], r[3])’.

     Equivalent to:

          def itemgetter(*items):
              if len(items) == 1:
                  item = items[0]
                  def g(obj):
                      return obj[item]
              else:
                  def g(obj):
                      return tuple(obj[item] for item in items)
              return g

     The items can be any type accepted by the operand’s *note
     __getitem__(): dc1. method.  Dictionaries accept any hashable
     value.  Lists, tuples, and strings accept an index or a slice:

          >>> itemgetter(1)('ABCDEFG')
          'B'
          >>> itemgetter(1,3,5)('ABCDEFG')
          ('B', 'D', 'F')
          >>> itemgetter(slice(2,None))('ABCDEFG')
          'CDEFG'

     New in version 2.4.

     Changed in version 2.5: Added support for multiple item extraction.

     Example of using *note itemgetter(): dee. to retrieve specific
     fields from a tuple record:

          >>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]
          >>> getcount = itemgetter(1)
          >>> map(getcount, inventory)
          [3, 2, 5, 1]
          >>> sorted(inventory, key=getcount)
          [('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]

 -- Function: operator.methodcaller (name[, args...])

     Return a callable object that calls the method _name_ on its
     operand.  If additional arguments and/or keyword arguments are
     given, they will be given to the method as well.  For example:

        * After ‘f = methodcaller('name')’, the call ‘f(b)’ returns
          ‘b.name()’.

        * After ‘f = methodcaller('name', 'foo', bar=1)’, the call
          ‘f(b)’ returns ‘b.name('foo', bar=1)’.

     Equivalent to:

          def methodcaller(name, *args, **kwargs):
              def caller(obj):
                  return getattr(obj, name)(*args, **kwargs)
              return caller

     New in version 2.6.

* Menu:

* Mapping Operators to Functions:: 


File: python.info,  Node: Mapping Operators to Functions,  Up: operator --- Standard operators as functions

5.9.9.1 Mapping Operators to Functions
......................................

This table shows how abstract operations correspond to operator symbols
in the Python syntax and the functions in the *note operator: 126.
module.

Operation                   Syntax                        Function
                                                          
------------------------------------------------------------------------------------------------------
                                                          
Addition                    ‘a + b’                       ‘add(a, b)’
                                                          
                                                          
Concatenation               ‘seq1 + seq2’                 ‘concat(seq1, seq2)’
                                                          
                                                          
Containment Test            ‘obj in seq’                  ‘contains(seq, obj)’
                                                          
                                                          
Division                    ‘a / b’                       ‘div(a, b)’ (without
                                                          ‘__future__.division’)
                                                          
                                                          
Division                    ‘a / b’                       ‘truediv(a, b)’ (with
                                                          ‘__future__.division’)
                                                          
                                                          
Division                    ‘a // b’                      ‘floordiv(a, b)’
                                                          
                                                          
Bitwise And                 ‘a & b’                       ‘and_(a, b)’
                                                          
                                                          
Bitwise Exclusive Or        ‘a ^ b’                       ‘xor(a, b)’
                                                          
                                                          
Bitwise Inversion           ‘~ a’                         ‘invert(a)’
                                                          
                                                          
Bitwise Or                  ‘a | b’                       ‘or_(a, b)’
                                                          
                                                          
Exponentiation              ‘a ** b’                      ‘pow(a, b)’
                                                          
                                                          
Identity                    ‘a is b’                      ‘is_(a, b)’
                                                          
                                                          
Identity                    ‘a is not b’                  ‘is_not(a, b)’
                                                          
                                                          
Indexed Assignment          ‘obj[k] = v’                  ‘setitem(obj, k, v)’
                                                          
                                                          
Indexed Deletion            ‘del obj[k]’                  ‘delitem(obj, k)’
                                                          
                                                          
Indexing                    ‘obj[k]’                      ‘getitem(obj, k)’
                                                          
                                                          
Left Shift                  ‘a << b’                      ‘lshift(a, b)’
                                                          
                                                          
Modulo                      ‘a % b’                       ‘mod(a, b)’
                                                          
                                                          
Multiplication              ‘a * b’                       ‘mul(a, b)’
                                                          
                                                          
Negation (Arithmetic)       ‘- a’                         ‘neg(a)’
                                                          
                                                          
Negation (Logical)          ‘not a’                       ‘not_(a)’
                                                          
                                                          
Positive                    ‘+ a’                         ‘pos(a)’
                                                          
                                                          
Right Shift                 ‘a >> b’                      ‘rshift(a, b)’
                                                          
                                                          
Sequence Repetition         ‘seq * i’                     ‘repeat(seq, i)’
                                                          
                                                          
Slice Assignment            ‘seq[i:j] = values’           ‘setitem(seq, slice(i, j), values)’
                                                          
                                                          
Slice Deletion              ‘del seq[i:j]’                ‘delitem(seq, slice(i, j))’
                                                          
                                                          
Slicing                     ‘seq[i:j]’                    ‘getitem(seq, slice(i, j))’
                                                          
                                                          
String Formatting           ‘s % obj’                     ‘mod(s, obj)’
                                                          
                                                          
Subtraction                 ‘a - b’                       ‘sub(a, b)’
                                                          
                                                          
Truth Test                  ‘obj’                         ‘truth(obj)’
                                                          
                                                          
Ordering                    ‘a < b’                       ‘lt(a, b)’
                                                          
                                                          
Ordering                    ‘a <= b’                      ‘le(a, b)’
                                                          
                                                          
Equality                    ‘a == b’                      ‘eq(a, b)’
                                                          
                                                          
Difference                  ‘a != b’                      ‘ne(a, b)’
                                                          
                                                          
Ordering                    ‘a >= b’                      ‘ge(a, b)’
                                                          
                                                          
Ordering                    ‘a > b’                       ‘gt(a, b)’
                                                          


File: python.info,  Node: File and Directory Access,  Next: Data Persistence,  Prev: Numeric and Mathematical Modules,  Up: The Python Standard Library

5.10 File and Directory Access
==============================

The modules described in this chapter deal with disk files and
directories.  For example, there are modules for reading the properties
of files, manipulating paths in a portable way, and creating temporary
files.  The full list of modules in this chapter is:

* Menu:

* os.path: os path --- Common pathname manipulations. Common pathname manipulations
* fileinput: fileinput --- Iterate over lines from multiple input streams. Iterate over lines from multiple input streams
* stat: stat --- Interpreting stat results. Interpreting stat() results
* statvfs: statvfs --- Constants used with os statvfs. Constants used with os.statvfs()
* filecmp: filecmp --- File and Directory Comparisons. File and Directory Comparisons
* tempfile: tempfile --- Generate temporary files and directories. Generate temporary files and directories
* glob: glob --- Unix style pathname pattern expansion. Unix style pathname pattern expansion
* fnmatch: fnmatch --- Unix filename pattern matching. Unix filename pattern matching
* linecache: linecache --- Random access to text lines. Random access to text lines
* shutil: shutil --- High-level file operations. High-level file operations
* dircache: dircache --- Cached directory listings. Cached directory listings
* macpath: macpath --- Mac OS 9 path manipulation functions. Mac OS 9 path manipulation functions


File: python.info,  Node: os path --- Common pathname manipulations,  Next: fileinput --- Iterate over lines from multiple input streams,  Up: File and Directory Access

5.10.1 ‘os.path’ — Common pathname manipulations
------------------------------------------------

This module implements some useful functions on pathnames.  To read or
write files see *note open(): 2d6, and for accessing the filesystem see
the *note os: 128. module.

     Note: On Windows, many of these functions do not properly support
     UNC pathnames.  *note splitunc(): df7. and *note ismount(): df8. do
     handle them correctly.

  Unlike a unix shell, Python does not do any _automatic_ path
expansions.  Functions such as *note expanduser(): df9. and *note
expandvars(): 354. can be invoked explicitly when an application desires
shell-like path expansion.  (See also the *note glob: e3. module.)

     Note: Since different operating systems have different path name
     conventions, there are several versions of this module in the
     standard library.  The *note os.path: 129. module is always the
     path module suitable for the operating system Python is running on,
     and therefore usable for local paths.  However, you can also import
     and use the individual modules if you want to manipulate a path
     that is _always_ in one of the different formats.  They all have
     the same interface:

        * ‘posixpath’ for UNIX-style paths

        * ‘ntpath’ for Windows paths

        * *note macpath: 107. for old-style MacOS paths

        * ‘os2emxpath’ for OS/2 EMX paths

 -- Function: os.path.abspath (path)

     Return a normalized absolutized version of the pathname _path_.  On
     most platforms, this is equivalent to calling the function *note
     normpath(): 245. as follows: ‘normpath(join(os.getcwd(), path))’.

     New in version 1.5.2.

 -- Function: os.path.basename (path)

     Return the base name of pathname _path_.  This is the second
     element of the pair returned by passing _path_ to the function
     *note split(): dfb.  Note that the result of this function is
     different from the Unix *basename* program; where *basename* for
     ‘'/foo/bar/'’ returns ‘'bar'’, the *note basename(): dfa. function
     returns an empty string (‘''’).

 -- Function: os.path.commonprefix (list)

     Return the longest path prefix (taken character-by-character) that
     is a prefix of all paths in _list_.  If _list_ is empty, return the
     empty string (‘''’).  Note that this may return invalid paths
     because it works a character at a time.

 -- Function: os.path.dirname (path)

     Return the directory name of pathname _path_.  This is the first
     element of the pair returned by passing _path_ to the function
     *note split(): dfb.

 -- Function: os.path.exists (path)

     Return ‘True’ if _path_ refers to an existing path.  Returns
     ‘False’ for broken symbolic links.  On some platforms, this
     function may return ‘False’ if permission is not granted to execute
     *note os.stat(): 3c4. on the requested file, even if the _path_
     physically exists.

 -- Function: os.path.lexists (path)

     Return ‘True’ if _path_ refers to an existing path.  Returns ‘True’
     for broken symbolic links.  Equivalent to *note exists(): dfe. on
     platforms lacking *note os.lstat(): e00.

     New in version 2.4.

 -- Function: os.path.expanduser (path)

     On Unix and Windows, return the argument with an initial component
     of ‘~’ or ‘~user’ replaced by that _user_’s home directory.

     On Unix, an initial ‘~’ is replaced by the environment variable
     ‘HOME’ if it is set; otherwise the current user’s home directory is
     looked up in the password directory through the built-in module
     *note pwd: 13c.  An initial ‘~user’ is looked up directly in the
     password directory.

     On Windows, ‘HOME’ and ‘USERPROFILE’ will be used if set, otherwise
     a combination of ‘HOMEPATH’ and ‘HOMEDRIVE’ will be used.  An
     initial ‘~user’ is handled by stripping the last directory
     component from the created user path derived above.

     If the expansion fails or if the path does not begin with a tilde,
     the path is returned unchanged.

 -- Function: os.path.expandvars (path)

     Return the argument with environment variables expanded.
     Substrings of the form ‘$name’ or ‘${name}’ are replaced by the
     value of environment variable _name_.  Malformed variable names and
     references to non-existing variables are left unchanged.

     On Windows, ‘%name%’ expansions are supported in addition to
     ‘$name’ and ‘${name}’.

 -- Function: os.path.getatime (path)

     Return the time of last access of _path_.  The return value is a
     number giving the number of seconds since the epoch (see the *note
     time: 17a. module).  Raise *note os.error: e02. if the file does
     not exist or is inaccessible.

     New in version 1.5.2.

     Changed in version 2.3: If *note os.stat_float_times(): 462.
     returns ‘True’, the result is a floating point number.

 -- Function: os.path.getmtime (path)

     Return the time of last modification of _path_.  The return value
     is a number giving the number of seconds since the epoch (see the
     *note time: 17a. module).  Raise *note os.error: e02. if the file
     does not exist or is inaccessible.

     New in version 1.5.2.

     Changed in version 2.3: If *note os.stat_float_times(): 462.
     returns ‘True’, the result is a floating point number.

 -- Function: os.path.getctime (path)

     Return the system’s ctime which, on some systems (like Unix) is the
     time of the last metadata change, and, on others (like Windows), is
     the creation time for _path_.  The return value is a number giving
     the number of seconds since the epoch (see the *note time: 17a.
     module).  Raise *note os.error: e02. if the file does not exist or
     is inaccessible.

     New in version 2.3.

 -- Function: os.path.getsize (path)

     Return the size, in bytes, of _path_.  Raise *note os.error: e02.
     if the file does not exist or is inaccessible.

     New in version 1.5.2.

 -- Function: os.path.isabs (path)

     Return ‘True’ if _path_ is an absolute pathname.  On Unix, that
     means it begins with a slash, on Windows that it begins with a
     (back)slash after chopping off a potential drive letter.

 -- Function: os.path.isfile (path)

     Return ‘True’ if _path_ is an existing regular file.  This follows
     symbolic links, so both *note islink(): e08. and *note isfile():
     e07. can be true for the same path.

 -- Function: os.path.isdir (path)

     Return ‘True’ if _path_ is an existing directory.  This follows
     symbolic links, so both *note islink(): e08. and *note isdir():
     e09. can be true for the same path.

 -- Function: os.path.islink (path)

     Return ‘True’ if _path_ refers to a directory entry that is a
     symbolic link.  Always ‘False’ if symbolic links are not supported
     by the python runtime.

 -- Function: os.path.ismount (path)

     Return ‘True’ if pathname _path_ is a _mount point_: a point in a
     file system where a different file system has been mounted.  The
     function checks whether _path_’s parent, ‘path/..’, is on a
     different device than _path_, or whether ‘path/..’ and _path_ point
     to the same i-node on the same device — this should detect mount
     points for all Unix and POSIX variants.

 -- Function: os.path.join (path1[, path2[, ...]])

     Join one or more path components intelligently.  If any component
     is an absolute path, all previous components (on Windows, including
     the previous drive letter, if there was one) are thrown away, and
     joining continues.  The return value is the concatenation of
     _path1_, and optionally _path2_, etc., with exactly one directory
     separator (‘os.sep’) following each non-empty part except the last.
     (This means that an empty last part will result in a path that ends
     with a separator.)  Note that on Windows, since there is a current
     directory for each drive, ‘os.path.join("c:", "foo")’ represents a
     path relative to the current directory on drive ‘C:’ (‘c:foo’), not
     ‘c:\foo’.

 -- Function: os.path.normcase (path)

     Normalize the case of a pathname.  On Unix and Mac OS X, this
     returns the path unchanged; on case-insensitive filesystems, it
     converts the path to lowercase.  On Windows, it also converts
     forward slashes to backward slashes.

 -- Function: os.path.normpath (path)

     Normalize a pathname by collapsing redundant separators and
     up-level references so that ‘A//B’, ‘A/B/’, ‘A/./B’ and
     ‘A/foo/../B’ all become ‘A/B’.  This string manipulation may change
     the meaning of a path that contains symbolic links.  On Windows, it
     converts forward slashes to backward slashes.  To normalize case,
     use *note normcase(): e0b.

 -- Function: os.path.realpath (path)

     Return the canonical path of the specified filename, eliminating
     any symbolic links encountered in the path (if they are supported
     by the operating system).

     New in version 2.2.

 -- Function: os.path.relpath (path[, start])

     Return a relative filepath to _path_ either from the current
     directory or from an optional _start_ directory.  This is a path
     computation: the filesystem is not accessed to confirm the
     existence or nature of _path_ or _start_.

     _start_ defaults to *note os.curdir: e0e.

     Availability: Windows, Unix.

     New in version 2.6.

 -- Function: os.path.samefile (path1, path2)

     Return ‘True’ if both pathname arguments refer to the same file or
     directory (as indicated by device number and i-node number).  Raise
     an exception if a *note os.stat(): 3c4. call on either pathname
     fails.

     Availability: Unix.

 -- Function: os.path.sameopenfile (fp1, fp2)

     Return ‘True’ if the file descriptors _fp1_ and _fp2_ refer to the
     same file.

     Availability: Unix.

 -- Function: os.path.samestat (stat1, stat2)

     Return ‘True’ if the stat tuples _stat1_ and _stat2_ refer to the
     same file.  These structures may have been returned by *note
     os.fstat(): e12, *note os.lstat(): e00, or *note os.stat(): 3c4.
     This function implements the underlying comparison used by *note
     samefile(): e0f. and *note sameopenfile(): e10.

     Availability: Unix.

 -- Function: os.path.split (path)

     Split the pathname _path_ into a pair, ‘(head, tail)’ where _tail_
     is the last pathname component and _head_ is everything leading up
     to that.  The _tail_ part will never contain a slash; if _path_
     ends in a slash, _tail_ will be empty.  If there is no slash in
     _path_, _head_ will be empty.  If _path_ is empty, both _head_ and
     _tail_ are empty.  Trailing slashes are stripped from _head_ unless
     it is the root (one or more slashes only).  In all cases,
     ‘join(head, tail)’ returns a path to the same location as _path_
     (but the strings may differ).  Also see the functions *note
     dirname(): dfd. and *note basename(): dfa.

 -- Function: os.path.splitdrive (path)

     Split the pathname _path_ into a pair ‘(drive, tail)’ where _drive_
     is either a drive specification or the empty string.  On systems
     which do not use drive specifications, _drive_ will always be the
     empty string.  In all cases, ‘drive + tail’ will be the same as
     _path_.

     New in version 1.3.

 -- Function: os.path.splitext (path)

     Split the pathname _path_ into a pair ‘(root, ext)’ such that ‘root
     + ext == path’, and _ext_ is empty or begins with a period and
     contains at most one period.  Leading periods on the basename are
     ignored; ‘splitext('.cshrc')’ returns ‘('.cshrc', '')’.

     Changed in version 2.6: Earlier versions could produce an empty
     root when the only period was the first character.

 -- Function: os.path.splitunc (path)

     Split the pathname _path_ into a pair ‘(unc, rest)’ so that _unc_
     is the UNC mount point (such as ‘r'\\host\mount'’), if present, and
     _rest_ the rest of the path (such as ‘r'\path\file.ext'’).  For
     paths containing drive letters, _unc_ will always be the empty
     string.

     Availability: Windows.

 -- Function: os.path.walk (path, visit, arg)

     Calls the function _visit_ with arguments ‘(arg, dirname, names)’
     for each directory in the directory tree rooted at _path_
     (including _path_ itself, if it is a directory).  The argument
     _dirname_ specifies the visited directory, the argument _names_
     lists the files in the directory (gotten from
     ‘os.listdir(dirname)’).  The _visit_ function may modify _names_ to
     influence the set of directories visited below _dirname_, e.g.  to
     avoid visiting certain parts of the tree.  (The object referred to
     by _names_ must be modified in place, using *note del: 568. or
     slice assignment.)

          Note: Symbolic links to directories are not treated as
          subdirectories, and that *note walk(): e15. therefore will not
          visit them.  To visit linked directories you must identify
          them with ‘os.path.islink(file)’ and ‘os.path.isdir(file)’,
          and invoke *note walk(): e15. as necessary.

          Note: This function is deprecated and has been removed in
          Python 3 in favor of *note os.walk(): 353.

 -- Data: os.path.supports_unicode_filenames

     ‘True’ if arbitrary Unicode strings can be used as file names
     (within limitations imposed by the file system).

     New in version 2.3.


File: python.info,  Node: fileinput --- Iterate over lines from multiple input streams,  Next: stat --- Interpreting stat results,  Prev: os path --- Common pathname manipulations,  Up: File and Directory Access

5.10.2 ‘fileinput’ — Iterate over lines from multiple input streams
-------------------------------------------------------------------

*Source code:* Lib/fileinput.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module implements a helper class and functions to quickly write a
loop over standard input or a list of files.  If you just want to read
or write one file see *note open(): 2d6.

  The typical use is:

     import fileinput
     for line in fileinput.input():
         process(line)

  This iterates over the lines of all files listed in ‘sys.argv[1:]’,
defaulting to ‘sys.stdin’ if the list is empty.  If a filename is ‘'-'’,
it is also replaced by ‘sys.stdin’.  To specify an alternative list of
filenames, pass it as the first argument to *note input(): e18.  A
single file name is also allowed.

  All files are opened in text mode by default, but you can override
this by specifying the _mode_ parameter in the call to *note input():
e18. or *note FileInput(): e19.  If an I/O error occurs during opening
or reading a file, *note IOError: 1fa. is raised.

  If ‘sys.stdin’ is used more than once, the second and further use will
return no lines, except perhaps for interactive use, or if it has been
explicitly reset (e.g.  using ‘sys.stdin.seek(0)’).

  Empty files are opened and immediately closed; the only time their
presence in the list of filenames is noticeable at all is when the last
file opened is empty.

  Lines are returned with any newlines intact, which means that the last
line in a file may not have one.

  You can control how files are opened by providing an opening hook via
the _openhook_ parameter to *note fileinput.input(): e18. or *note
FileInput(): e19.  The hook must be a function that takes two arguments,
_filename_ and _mode_, and returns an accordingly opened file-like
object.  Two useful hooks are already provided by this module.

  The following function is the primary interface of this module:

 -- Function: fileinput.input ([files[, inplace[, backup[, bufsize[,
          mode[, openhook]]]]]])

     Create an instance of the *note FileInput: e19. class.  The
     instance will be used as global state for the functions of this
     module, and is also returned to use during iteration.  The
     parameters to this function will be passed along to the constructor
     of the *note FileInput: e19. class.

     Changed in version 2.5: Added the _mode_ and _openhook_ parameters.

  The following functions use the global state created by *note
fileinput.input(): e18.; if there is no active state, *note
RuntimeError: 39b. is raised.

 -- Function: fileinput.filename ()

     Return the name of the file currently being read.  Before the first
     line has been read, returns ‘None’.

 -- Function: fileinput.fileno ()

     Return the integer "file descriptor" for the current file.  When no
     file is opened (before the first line and between files), returns
     ‘-1’.

     New in version 2.5.

 -- Function: fileinput.lineno ()

     Return the cumulative line number of the line that has just been
     read.  Before the first line has been read, returns ‘0’.  After the
     last line of the last file has been read, returns the line number
     of that line.

 -- Function: fileinput.filelineno ()

     Return the line number in the current file.  Before the first line
     has been read, returns ‘0’.  After the last line of the last file
     has been read, returns the line number of that line within the
     file.

 -- Function: fileinput.isfirstline ()

     Returns true if the line just read is the first line of its file,
     otherwise returns false.

 -- Function: fileinput.isstdin ()

     Returns true if the last line was read from ‘sys.stdin’, otherwise
     returns false.

 -- Function: fileinput.nextfile ()

     Close the current file so that the next iteration will read the
     first line from the next file (if any); lines not read from the
     file will not count towards the cumulative line count.  The
     filename is not changed until after the first line of the next file
     has been read.  Before the first line has been read, this function
     has no effect; it cannot be used to skip the first file.  After the
     last line of the last file has been read, this function has no
     effect.

 -- Function: fileinput.close ()

     Close the sequence.

  The class which implements the sequence behavior provided by the
module is available for subclassing as well:

 -- Class: fileinput.FileInput ([files[, inplace[, backup[, bufsize[,
          mode[, openhook]]]]]])

     Class *note FileInput: e19. is the implementation; its methods
     *note filename(): e1a, *note fileno(): e1b, *note lineno(): e1c,
     *note filelineno(): e1d, *note isfirstline(): e1e, *note isstdin():
     e1f, *note nextfile(): e20. and *note close(): e21. correspond to
     the functions of the same name in the module.  In addition it has a
     *note readline(): 644. method which returns the next input line,
     and a *note __getitem__(): 44f. method which implements the
     sequence behavior.  The sequence must be accessed in strictly
     sequential order; random access and *note readline(): 644. cannot
     be mixed.

     With _mode_ you can specify which file mode will be passed to *note
     open(): 2d6.  It must be one of ‘'r'’, ‘'rU'’, ‘'U'’ and ‘'rb'’.

     The _openhook_, when given, must be a function that takes two
     arguments, _filename_ and _mode_, and returns an accordingly opened
     file-like object.  You cannot use _inplace_ and _openhook_
     together.

     Changed in version 2.5: Added the _mode_ and _openhook_ parameters.

  *Optional in-place filtering:* if the keyword argument ‘inplace=1’ is
passed to *note fileinput.input(): e18. or to the *note FileInput: e19.
constructor, the file is moved to a backup file and standard output is
directed to the input file (if a file of the same name as the backup
file already exists, it will be replaced silently).  This makes it
possible to write a filter that rewrites its input file in place.  If
the _backup_ parameter is given (typically as ‘backup='.<some
extension>'’), it specifies the extension for the backup file, and the
backup file remains around; by default, the extension is ‘'.bak'’ and it
is deleted when the output file is closed.  In-place filtering is
disabled when standard input is read.

     Note: The current implementation does not work for MS-DOS 8+3
     filesystems.

  The two following opening hooks are provided by this module:

 -- Function: fileinput.hook_compressed (filename, mode)

     Transparently opens files compressed with gzip and bzip2
     (recognized by the extensions ‘'.gz'’ and ‘'.bz2'’) using the *note
     gzip: e5. and *note bz2: 1e. modules.  If the filename extension is
     not ‘'.gz'’ or ‘'.bz2'’, the file is opened normally (ie, using
     *note open(): 2d6. without any decompression).

     Usage example: ‘fi =
     fileinput.FileInput(openhook=fileinput.hook_compressed)’

     New in version 2.5.

 -- Function: fileinput.hook_encoded (encoding)

     Returns a hook which opens each file with *note codecs.open(): a5d,
     using the given _encoding_ to read the file.

     Usage example: ‘fi =
     fileinput.FileInput(openhook=fileinput.hook_encoded("iso-8859-1"))’

          Note: With this hook, *note FileInput: e19. might return
          Unicode strings depending on the specified _encoding_.

     New in version 2.5.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/fileinput.py


File: python.info,  Node: stat --- Interpreting stat results,  Next: statvfs --- Constants used with os statvfs,  Prev: fileinput --- Iterate over lines from multiple input streams,  Up: File and Directory Access

5.10.3 ‘stat’ — Interpreting ‘stat()’ results
---------------------------------------------

*Source code:* Lib/stat.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note stat: 161. module defines constants and functions for
interpreting the results of *note os.stat(): 3c4, *note os.fstat(): e12.
and *note os.lstat(): e00. (if they exist).  For complete details about
the ‘stat()’, ‘fstat()’ and ‘lstat()’ calls, consult the documentation
for your system.

  The *note stat: 161. module defines the following functions to test
for specific file types:

 -- Function: stat.S_ISDIR (mode)

     Return non-zero if the mode is from a directory.

 -- Function: stat.S_ISCHR (mode)

     Return non-zero if the mode is from a character special device
     file.

 -- Function: stat.S_ISBLK (mode)

     Return non-zero if the mode is from a block special device file.

 -- Function: stat.S_ISREG (mode)

     Return non-zero if the mode is from a regular file.

 -- Function: stat.S_ISFIFO (mode)

     Return non-zero if the mode is from a FIFO (named pipe).

 -- Function: stat.S_ISLNK (mode)

     Return non-zero if the mode is from a symbolic link.

 -- Function: stat.S_ISSOCK (mode)

     Return non-zero if the mode is from a socket.

  Two additional functions are defined for more general manipulation of
the file’s mode:

 -- Function: stat.S_IMODE (mode)

     Return the portion of the file’s mode that can be set by *note
     os.chmod(): e2e.—that is, the file’s permission bits, plus the
     sticky bit, set-group-id, and set-user-id bits (on systems that
     support them).

 -- Function: stat.S_IFMT (mode)

     Return the portion of the file’s mode that describes the file type
     (used by the ‘S_IS*()’ functions above).

  Normally, you would use the ‘os.path.is*()’ functions for testing the
type of a file; the functions here are useful when you are doing
multiple tests of the same file and wish to avoid the overhead of the
‘stat()’ system call for each test.  These are also useful when checking
for information about a file that isn’t handled by *note os.path: 129,
like the tests for block and character devices.

  Example:

     import os, sys
     from stat import *

     def walktree(top, callback):
         '''recursively descend the directory tree rooted at top,
            calling the callback function for each regular file'''

         for f in os.listdir(top):
             pathname = os.path.join(top, f)
             mode = os.stat(pathname).st_mode
             if S_ISDIR(mode):
                 # It's a directory, recurse into it
                 walktree(pathname, callback)
             elif S_ISREG(mode):
                 # It's a file, call the callback function
                 callback(pathname)
             else:
                 # Unknown file type, print a message
                 print 'Skipping %s' % pathname

     def visitfile(file):
         print 'visiting', file

     if __name__ == '__main__':
         walktree(sys.argv[1], visitfile)

  All the variables below are simply symbolic indexes into the 10-tuple
returned by *note os.stat(): 3c4, *note os.fstat(): e12. or *note
os.lstat(): e00.

 -- Data: stat.ST_MODE

     Inode protection mode.

 -- Data: stat.ST_INO

     Inode number.

 -- Data: stat.ST_DEV

     Device inode resides on.

 -- Data: stat.ST_NLINK

     Number of links to the inode.

 -- Data: stat.ST_UID

     User id of the owner.

 -- Data: stat.ST_GID

     Group id of the owner.

 -- Data: stat.ST_SIZE

     Size in bytes of a plain file; amount of data waiting on some
     special files.

 -- Data: stat.ST_ATIME

     Time of last access.

 -- Data: stat.ST_MTIME

     Time of last modification.

 -- Data: stat.ST_CTIME

     The "ctime" as reported by the operating system.  On some systems
     (like Unix) is the time of the last metadata change, and, on others
     (like Windows), is the creation time (see platform documentation
     for details).

  The interpretation of "file size" changes according to the file type.
For plain files this is the size of the file in bytes.  For FIFOs and
sockets under most flavors of Unix (including Linux in particular), the
"size" is the number of bytes waiting to be read at the time of the call
to *note os.stat(): 3c4, *note os.fstat(): e12, or *note os.lstat():
e00.; this can sometimes be useful, especially for polling one of these
special files after a non-blocking open.  The meaning of the size field
for other character and block devices varies more, depending on the
implementation of the underlying system call.

  The variables below define the flags used in the *note ST_MODE: e30.
field.

  Use of the functions above is more portable than use of the first set
of flags:

 -- Data: stat.S_IFSOCK

     Socket.

 -- Data: stat.S_IFLNK

     Symbolic link.

 -- Data: stat.S_IFREG

     Regular file.

 -- Data: stat.S_IFBLK

     Block device.

 -- Data: stat.S_IFDIR

     Directory.

 -- Data: stat.S_IFCHR

     Character device.

 -- Data: stat.S_IFIFO

     FIFO.

  The following flags can also be used in the _mode_ argument of *note
os.chmod(): e2e.:

 -- Data: stat.S_ISUID

     Set UID bit.

 -- Data: stat.S_ISGID

     Set-group-ID bit.  This bit has several special uses.  For a
     directory it indicates that BSD semantics is to be used for that
     directory: files created there inherit their group ID from the
     directory, not from the effective group ID of the creating process,
     and directories created there will also get the *note S_ISGID: e42.
     bit set.  For a file that does not have the group execution bit
     (*note S_IXGRP: e43.) set, the set-group-ID bit indicates mandatory
     file/record locking (see also *note S_ENFMT: e44.).

 -- Data: stat.S_ISVTX

     Sticky bit.  When this bit is set on a directory it means that a
     file in that directory can be renamed or deleted only by the owner
     of the file, by the owner of the directory, or by a privileged
     process.

 -- Data: stat.S_IRWXU

     Mask for file owner permissions.

 -- Data: stat.S_IRUSR

     Owner has read permission.

 -- Data: stat.S_IWUSR

     Owner has write permission.

 -- Data: stat.S_IXUSR

     Owner has execute permission.

 -- Data: stat.S_IRWXG

     Mask for group permissions.

 -- Data: stat.S_IRGRP

     Group has read permission.

 -- Data: stat.S_IWGRP

     Group has write permission.

 -- Data: stat.S_IXGRP

     Group has execute permission.

 -- Data: stat.S_IRWXO

     Mask for permissions for others (not in group).

 -- Data: stat.S_IROTH

     Others have read permission.

 -- Data: stat.S_IWOTH

     Others have write permission.

 -- Data: stat.S_IXOTH

     Others have execute permission.

 -- Data: stat.S_ENFMT

     System V file locking enforcement.  This flag is shared with *note
     S_ISGID: e42.: file/record locking is enforced on files that do not
     have the group execution bit (*note S_IXGRP: e43.) set.

 -- Data: stat.S_IREAD

     Unix V7 synonym for *note S_IRUSR: e47.

 -- Data: stat.S_IWRITE

     Unix V7 synonym for *note S_IWUSR: e48.

 -- Data: stat.S_IEXEC

     Unix V7 synonym for *note S_IXUSR: e49.

  The following flags can be used in the _flags_ argument of *note
os.chflags(): e54.:

 -- Data: stat.UF_NODUMP

     Do not dump the file.

 -- Data: stat.UF_IMMUTABLE

     The file may not be changed.

 -- Data: stat.UF_APPEND

     The file may only be appended to.

 -- Data: stat.UF_OPAQUE

     The directory is opaque when viewed through a union stack.

 -- Data: stat.UF_NOUNLINK

     The file may not be renamed or deleted.

 -- Data: stat.UF_COMPRESSED

     The file is stored compressed (Mac OS X 10.6+).

 -- Data: stat.UF_HIDDEN

     The file should not be displayed in a GUI (Mac OS X 10.5+).

 -- Data: stat.SF_ARCHIVED

     The file may be archived.

 -- Data: stat.SF_IMMUTABLE

     The file may not be changed.

 -- Data: stat.SF_APPEND

     The file may only be appended to.

 -- Data: stat.SF_NOUNLINK

     The file may not be renamed or deleted.

 -- Data: stat.SF_SNAPSHOT

     The file is a snapshot file.

  See the *BSD or Mac OS systems man page ‘chflags(2)’ for more
information.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/stat.py


File: python.info,  Node: statvfs --- Constants used with os statvfs,  Next: filecmp --- File and Directory Comparisons,  Prev: stat --- Interpreting stat results,  Up: File and Directory Access

5.10.4 ‘statvfs’ — Constants used with ‘os.statvfs()’
-----------------------------------------------------

Deprecated since version 2.6: The *note statvfs: 162. module has been
removed in Python 3.

  The *note statvfs: 162. module defines constants so interpreting the
result if *note os.statvfs(): e63, which returns a tuple, can be made
without remembering "magic numbers."  Each of the constants defined in
this module is the _index_ of the entry in the tuple returned by *note
os.statvfs(): e63. that contains the specified information.

 -- Data: statvfs.F_BSIZE

     Preferred file system block size.

 -- Data: statvfs.F_FRSIZE

     Fundamental file system block size.

 -- Data: statvfs.F_BLOCKS

     Total number of blocks in the filesystem.

 -- Data: statvfs.F_BFREE

     Total number of free blocks.

 -- Data: statvfs.F_BAVAIL

     Free blocks available to non-super user.

 -- Data: statvfs.F_FILES

     Total number of file nodes.

 -- Data: statvfs.F_FFREE

     Total number of free file nodes.

 -- Data: statvfs.F_FAVAIL

     Free nodes available to non-super user.

 -- Data: statvfs.F_FLAG

     Flags.  System dependent: see ‘statvfs()’ man page.

 -- Data: statvfs.F_NAMEMAX

     Maximum file name length.


File: python.info,  Node: filecmp --- File and Directory Comparisons,  Next: tempfile --- Generate temporary files and directories,  Prev: statvfs --- Constants used with os statvfs,  Up: File and Directory Access

5.10.5 ‘filecmp’ — File and Directory Comparisons
-------------------------------------------------

*Source code:* Lib/filecmp.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note filecmp: cb. module defines functions to compare files and
directories, with various optional time/correctness trade-offs.  For
comparing files, see also the *note difflib: 82. module.

  The *note filecmp: cb. module defines the following functions:

 -- Function: filecmp.cmp (f1, f2[, shallow])

     Compare the files named _f1_ and _f2_, returning ‘True’ if they
     seem equal, ‘False’ otherwise.

     Unless _shallow_ is given and is false, files with identical *note
     os.stat(): 3c4. signatures are taken to be equal.

     Files that were compared using this function will not be compared
     again unless their *note os.stat(): 3c4. signature changes.

     Note that no external programs are called from this function,
     giving it portability and efficiency.

 -- Function: filecmp.cmpfiles (dir1, dir2, common[, shallow])

     Compare the files in the two directories _dir1_ and _dir2_ whose
     names are given by _common_.

     Returns three lists of file names: _match_, _mismatch_, _errors_.
     _match_ contains the list of files that match, _mismatch_ contains
     the names of those that don’t, and _errors_ lists the names of
     files which could not be compared.  Files are listed in _errors_ if
     they don’t exist in one of the directories, the user lacks
     permission to read them or if the comparison could not be done for
     some other reason.

     The _shallow_ parameter has the same meaning and default value as
     for *note filecmp.cmp(): e70.

     For example, ‘cmpfiles('a', 'b', ['c', 'd/e'])’ will compare ‘a/c’
     with ‘b/c’ and ‘a/d/e’ with ‘b/d/e’.  ‘'c'’ and ‘'d/e'’ will each
     be in one of the three returned lists.

  Example:

     >>> import filecmp
     >>> filecmp.cmp('undoc.rst', 'undoc.rst') # doctest: +SKIP
     True
     >>> filecmp.cmp('undoc.rst', 'index.rst') # doctest: +SKIP
     False

* Menu:

* The dircmp class:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/filecmp.py


File: python.info,  Node: The dircmp class,  Up: filecmp --- File and Directory Comparisons

5.10.5.1 The ‘dircmp’ class
...........................

*note dircmp: e74. instances are built using this constructor:

 -- Class: filecmp.dircmp (a, b[, ignore[, hide]])

     Construct a new directory comparison object, to compare the
     directories _a_ and _b_.  _ignore_ is a list of names to ignore,
     and defaults to ‘['RCS', 'CVS', 'tags']’.  _hide_ is a list of
     names to hide, and defaults to ‘[os.curdir, os.pardir]’.

     The *note dircmp: e74. class compares files by doing _shallow_
     comparisons as described for *note filecmp.cmp(): e70.

     The *note dircmp: e74. class provides the following methods:

      -- Method: report ()

          Print (to ‘sys.stdout’) a comparison between _a_ and _b_.

      -- Method: report_partial_closure ()

          Print a comparison between _a_ and _b_ and common immediate
          subdirectories.

      -- Method: report_full_closure ()

          Print a comparison between _a_ and _b_ and common
          subdirectories (recursively).

     The *note dircmp: e74. class offers a number of interesting
     attributes that may be used to get various bits of information
     about the directory trees being compared.

     Note that via *note __getattr__(): 331. hooks, all attributes are
     computed lazily, so there is no speed penalty if only those
     attributes which are lightweight to compute are used.

      -- Attribute: left

          The directory _a_.

      -- Attribute: right

          The directory _b_.

      -- Attribute: left_list

          Files and subdirectories in _a_, filtered by _hide_ and
          _ignore_.

      -- Attribute: right_list

          Files and subdirectories in _b_, filtered by _hide_ and
          _ignore_.

      -- Attribute: common

          Files and subdirectories in both _a_ and _b_.

      -- Attribute: left_only

          Files and subdirectories only in _a_.

      -- Attribute: right_only

          Files and subdirectories only in _b_.

      -- Attribute: common_dirs

          Subdirectories in both _a_ and _b_.

      -- Attribute: common_files

          Files in both _a_ and _b_

      -- Attribute: common_funny

          Names in both _a_ and _b_, such that the type differs between
          the directories, or names for which *note os.stat(): 3c4.
          reports an error.

      -- Attribute: same_files

          Files which are identical in both _a_ and _b_, using the
          class’s file comparison operator.

      -- Attribute: diff_files

          Files which are in both _a_ and _b_, whose contents differ
          according to the class’s file comparison operator.

      -- Attribute: funny_files

          Files which are in both _a_ and _b_, but could not be
          compared.

      -- Attribute: subdirs

          A dictionary mapping names in *note common_dirs: e7f. to *note
          dircmp: e74. objects.

  Here is a simplified example of using the ‘subdirs’ attribute to
search recursively through two directories to show common different
files:

     >>> from filecmp import dircmp
     >>> def print_diff_files(dcmp):
     ...     for name in dcmp.diff_files:
     ...         print "diff_file %s found in %s and %s" % (name, dcmp.left,
     ...               dcmp.right)
     ...     for sub_dcmp in dcmp.subdirs.values():
     ...         print_diff_files(sub_dcmp)
     ...
     >>> dcmp = dircmp('dir1', 'dir2') # doctest: +SKIP
     >>> print_diff_files(dcmp) # doctest: +SKIP


File: python.info,  Node: tempfile --- Generate temporary files and directories,  Next: glob --- Unix style pathname pattern expansion,  Prev: filecmp --- File and Directory Comparisons,  Up: File and Directory Access

5.10.6 ‘tempfile’ — Generate temporary files and directories
------------------------------------------------------------

*Source code:* Lib/tempfile.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module generates temporary files and directories.  It works on
all supported platforms.

  In version 2.3 of Python, this module was overhauled for enhanced
security.  It now provides three new functions, *note
NamedTemporaryFile(): 35a, *note mkstemp(): e88, and *note mkdtemp():
e89, which should eliminate all remaining need to use the insecure *note
mktemp(): e8a. function.  Temporary file names created by this module no
longer contain the process ID; instead a string of six random characters
is used.

  Also, all the user-callable functions now take additional arguments
which allow direct control over the location and name of temporary
files.  It is no longer necessary to use the global _tempdir_ and
_template_ variables.  To maintain backward compatibility, the argument
order is somewhat odd; it is recommended to use keyword arguments for
clarity.

  The module defines the following user-callable functions:

 -- Function: tempfile.TemporaryFile ([mode='w+b'[, bufsize=-1[,
          suffix=''[, prefix='tmp'[, dir=None]]]]])

     Return a file-like object that can be used as a temporary storage
     area.  The file is created using *note mkstemp(): e88.  It will be
     destroyed as soon as it is closed (including an implicit close when
     the object is garbage collected).  Under Unix, the directory entry
     for the file is removed immediately after the file is created.
     Other platforms do not support this; your code should not rely on a
     temporary file created using this function having or not having a
     visible name in the file system.

     The _mode_ parameter defaults to ‘'w+b'’ so that the file created
     can be read and written without being closed.  Binary mode is used
     so that it behaves consistently on all platforms without regard for
     the data that is stored.  _bufsize_ defaults to ‘-1’, meaning that
     the operating system default is used.

     The _dir_, _prefix_ and _suffix_ parameters are passed to *note
     mkstemp(): e88.

     The returned object is a true file object on POSIX platforms.  On
     other platforms, it is a file-like object whose ‘file’ attribute is
     the underlying true file object.  This file-like object can be used
     in a *note with: 1c0. statement, just like a normal file.

 -- Function: tempfile.NamedTemporaryFile ([mode='w+b'[, bufsize=-1[,
          suffix=''[, prefix='tmp'[, dir=None[, delete=True]]]]]])

     This function operates exactly as *note TemporaryFile(): e8b. does,
     except that the file is guaranteed to have a visible name in the
     file system (on Unix, the directory entry is not unlinked).  That
     name can be retrieved from the ‘name’ attribute of the file object.
     Whether the name can be used to open the file a second time, while
     the named temporary file is still open, varies across platforms (it
     can be so used on Unix; it cannot on Windows NT or later).  If
     _delete_ is true (the default), the file is deleted as soon as it
     is closed.

     The returned object is always a file-like object whose ‘file’
     attribute is the underlying true file object.  This file-like
     object can be used in a *note with: 1c0. statement, just like a
     normal file.

     New in version 2.3.

     New in version 2.6: The _delete_ parameter.

 -- Function: tempfile.SpooledTemporaryFile ([max_size=0[, mode='w+b'[,
          bufsize=-1[, suffix=''[, prefix='tmp'[, dir=None]]]]]])

     This function operates exactly as *note TemporaryFile(): e8b. does,
     except that data is spooled in memory until the file size exceeds
     _max_size_, or until the file’s ‘fileno()’ method is called, at
     which point the contents are written to disk and operation proceeds
     as with *note TemporaryFile(): e8b.  Also, it’s ‘truncate’ method
     does not accept a ‘size’ argument.

     The resulting file has one additional method, ‘rollover()’, which
     causes the file to roll over to an on-disk file regardless of its
     size.

     The returned object is a file-like object whose ‘_file’ attribute
     is either a *note StringIO: 2dd. object or a true file object,
     depending on whether ‘rollover()’ has been called.  This file-like
     object can be used in a *note with: 1c0. statement, just like a
     normal file.

     New in version 2.6.

 -- Function: tempfile.mkstemp ([suffix=''[, prefix='tmp'[, dir=None[,
          text=False]]]])

     Creates a temporary file in the most secure manner possible.  There
     are no race conditions in the file’s creation, assuming that the
     platform properly implements the *note os.O_EXCL: e8d. flag for
     *note os.open(): 5e4.  The file is readable and writable only by
     the creating user ID. If the platform uses permission bits to
     indicate whether a file is executable, the file is executable by no
     one.  The file descriptor is not inherited by child processes.

     Unlike *note TemporaryFile(): e8b, the user of *note mkstemp():
     e88. is responsible for deleting the temporary file when done with
     it.

     If _suffix_ is specified, the file name will end with that suffix,
     otherwise there will be no suffix.  *note mkstemp(): e88. does not
     put a dot between the file name and the suffix; if you need one,
     put it at the beginning of _suffix_.

     If _prefix_ is specified, the file name will begin with that
     prefix; otherwise, a default prefix is used.

     If _dir_ is specified, the file will be created in that directory;
     otherwise, a default directory is used.  The default directory is
     chosen from a platform-dependent list, but the user of the
     application can control the directory location by setting the
     _TMPDIR_, _TEMP_ or _TMP_ environment variables.  There is thus no
     guarantee that the generated filename will have any nice
     properties, such as not requiring quoting when passed to external
     commands via ‘os.popen()’.

     If _text_ is specified, it indicates whether to open the file in
     binary mode (the default) or text mode.  On some platforms, this
     makes no difference.

     *note mkstemp(): e88. returns a tuple containing an OS-level handle
     to an open file (as would be returned by *note os.open(): 5e4.) and
     the absolute pathname of that file, in that order.

     New in version 2.3.

 -- Function: tempfile.mkdtemp ([suffix=''[, prefix='tmp'[, dir=None]]])

     Creates a temporary directory in the most secure manner possible.
     There are no race conditions in the directory’s creation.  The
     directory is readable, writable, and searchable only by the
     creating user ID.

     The user of *note mkdtemp(): e89. is responsible for deleting the
     temporary directory and its contents when done with it.

     The _prefix_, _suffix_, and _dir_ arguments are the same as for
     *note mkstemp(): e88.

     *note mkdtemp(): e89. returns the absolute pathname of the new
     directory.

     New in version 2.3.

 -- Function: tempfile.mktemp ([suffix=''[, prefix='tmp'[, dir=None]]])

     Deprecated since version 2.3: Use *note mkstemp(): e88. instead.

     Return an absolute pathname of a file that did not exist at the
     time the call is made.  The _prefix_, _suffix_, and _dir_ arguments
     are the same as for *note mkstemp(): e88.

          Warning: Use of this function may introduce a security hole in
          your program.  By the time you get around to doing anything
          with the file name it returns, someone else may have beaten
          you to the punch.  *note mktemp(): e8a. usage can be replaced
          easily with *note NamedTemporaryFile(): 35a, passing it the
          ‘delete=False’ parameter:

               >>> f = NamedTemporaryFile(delete=False)
               >>> f
               <open file '<fdopen>', mode 'w+b' at 0x384698>
               >>> f.name
               '/var/folders/5q/5qTPn6xq2RaWqk+1Ytw3-U+++TI/-Tmp-/tmpG7V1Y0'
               >>> f.write("Hello World!\n")
               >>> f.close()
               >>> os.unlink(f.name)
               >>> os.path.exists(f.name)
               False

  The module uses two global variables that tell it how to construct a
temporary name.  They are initialized at the first call to any of the
functions above.  The caller may change them, but this is discouraged;
use the appropriate function arguments, instead.

 -- Data: tempfile.tempdir

     When set to a value other than ‘None’, this variable defines the
     default value for the _dir_ argument to all the functions defined
     in this module.

     If ‘tempdir’ is unset or ‘None’ at any call to any of the above
     functions, Python searches a standard list of directories and sets
     _tempdir_ to the first one which the calling user can create files
     in.  The list is:

       1. The directory named by the ‘TMPDIR’ environment variable.

       2. The directory named by the ‘TEMP’ environment variable.

       3. The directory named by the ‘TMP’ environment variable.

       4. A platform-specific location:

             * On RiscOS, the directory named by the ‘Wimp$ScrapDir’
               environment variable.

             * On Windows, the directories ‘C:\TEMP’, ‘C:\TMP’, ‘\TEMP’,
               and ‘\TMP’, in that order.

             * On all other platforms, the directories ‘/tmp’,
               ‘/var/tmp’, and ‘/usr/tmp’, in that order.

       5. As a last resort, the current working directory.

 -- Function: tempfile.gettempdir ()

     Return the directory currently selected to create temporary files
     in.  If *note tempdir: e8e. is not ‘None’, this simply returns its
     contents; otherwise, the search described above is performed, and
     the result returned.

     New in version 2.3.

 -- Data: tempfile.template

     Deprecated since version 2.0: Use *note gettempprefix(): e91.
     instead.

     When set to a value other than ‘None’, this variable defines the
     prefix of the final component of the filenames returned by *note
     mktemp(): e8a.  A string of six random letters and digits is
     appended to the prefix to make the filename unique.  The default
     prefix is ‘tmp’.

     Older versions of this module used to require that ‘template’ be
     set to ‘None’ after a call to *note os.fork(): 244.; this has not
     been necessary since version 1.5.2.

 -- Function: tempfile.gettempprefix ()

     Return the filename prefix used to create temporary files.  This
     does not contain the directory component.  Using this function is
     preferred over reading the _template_ variable directly.

     New in version 1.5.2.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/tempfile.py


File: python.info,  Node: glob --- Unix style pathname pattern expansion,  Next: fnmatch --- Unix filename pattern matching,  Prev: tempfile --- Generate temporary files and directories,  Up: File and Directory Access

5.10.7 ‘glob’ — Unix style pathname pattern expansion
-----------------------------------------------------

*Source code:* Lib/glob.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note glob: e3. module finds all the pathnames matching a
specified pattern according to the rules used by the Unix shell.  No
tilde expansion is done, but ‘*’, ‘?’, and character ranges expressed
with ‘[]’ will be correctly matched.  This is done by using the *note
os.listdir(): 2d2. and *note fnmatch.fnmatch(): e94. functions in
concert, and not by actually invoking a subshell.  Note that unlike
*note fnmatch.fnmatch(): e94, *note glob: e3. treats filenames beginning
with a dot (‘.’) as special cases.  (For tilde and shell variable
expansion, use *note os.path.expanduser(): df9. and *note
os.path.expandvars(): 354.)

  For a literal match, wrap the meta-characters in brackets.  For
example, ‘'[?]'’ matches the character ‘'?'’.

 -- Function: glob.glob (pathname)

     Return a possibly-empty list of path names that match _pathname_,
     which must be a string containing a path specification.  _pathname_
     can be either absolute (like ‘/usr/src/Python-1.5/Makefile’) or
     relative (like ‘../../Tools/*/*.gif’), and can contain shell-style
     wildcards.  Broken symlinks are included in the results (as in the
     shell).

 -- Function: glob.iglob (pathname)

     Return an *note iterator: 87f. which yields the same values as
     *note glob(): e3. without actually storing them all simultaneously.

     New in version 2.5.

  For example, consider a directory containing only the following files:
‘1.gif’, ‘2.txt’, and ‘card.gif’.  *note glob(): e3. will produce the
following results.  Notice how any leading components of the path are
preserved.

     >>> import glob
     >>> glob.glob('./[0-9].*')
     ['./1.gif', './2.txt']
     >>> glob.glob('*.gif')
     ['1.gif', 'card.gif']
     >>> glob.glob('?.gif')
     ['1.gif']

  If the directory contains files starting with ‘.’ they won’t be
matched by default.  For example, consider a directory containing
‘card.gif’ and ‘.card.gif’:

     >>> import glob
     >>> glob.glob('*.gif')
     ['card.gif']
     >>> glob.glob('.c*')
     ['.card.gif']

See also
........

Module *note fnmatch: d2.

     Shell-style filename (not path) expansion

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/glob.py


File: python.info,  Node: fnmatch --- Unix filename pattern matching,  Next: linecache --- Random access to text lines,  Prev: glob --- Unix style pathname pattern expansion,  Up: File and Directory Access

5.10.8 ‘fnmatch’ — Unix filename pattern matching
-------------------------------------------------

*Source code:* Lib/fnmatch.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module provides support for Unix shell-style wildcards, which are
_not_ the same as regular expressions (which are documented in the *note
re: 143. module).  The special characters used in shell-style wildcards
are:

Pattern          Meaning
                 
----------------------------------------------------------
                 
‘*’              matches everything
                 
                 
‘?’              matches any single character
                 
                 
‘[seq]’          matches any character in _seq_
                 
                 
‘[!seq]’         matches any character not in _seq_
                 

  For a literal match, wrap the meta-characters in brackets.  For
example, ‘'[?]'’ matches the character ‘'?'’.

  Note that the filename separator (‘'/'’ on Unix) is _not_ special to
this module.  See module *note glob: e3. for pathname expansion (*note
glob: e3. uses *note fnmatch(): d2. to match pathname segments).
Similarly, filenames starting with a period are not special for this
module, and are matched by the ‘*’ and ‘?’ patterns.

 -- Function: fnmatch.fnmatch (filename, pattern)

     Test whether the _filename_ string matches the _pattern_ string,
     returning *note True: 3b0. or *note False: 3b1.  If the operating
     system is case-insensitive, then both parameters will be normalized
     to all lower- or upper-case before the comparison is performed.
     *note fnmatchcase(): e98. can be used to perform a case-sensitive
     comparison, regardless of whether that’s standard for the operating
     system.

     This example will print all file names in the current directory
     with the extension ‘.txt’:

          import fnmatch
          import os

          for file in os.listdir('.'):
              if fnmatch.fnmatch(file, '*.txt'):
                  print file

 -- Function: fnmatch.fnmatchcase (filename, pattern)

     Test whether _filename_ matches _pattern_, returning *note True:
     3b0. or *note False: 3b1.; the comparison is case-sensitive.

 -- Function: fnmatch.filter (names, pattern)

     Return the subset of the list of _names_ that match _pattern_.  It
     is the same as ‘[n for n in names if fnmatch(n, pattern)]’, but
     implemented more efficiently.

     New in version 2.2.

 -- Function: fnmatch.translate (pattern)

     Return the shell-style _pattern_ converted to a regular expression.

     Example:

          >>> import fnmatch, re
          >>>
          >>> regex = fnmatch.translate('*.txt')
          >>> regex
          '.*\\.txt$'
          >>> reobj = re.compile(regex)
          >>> reobj.match('foobar.txt')
          <_sre.SRE_Match object at 0x...>

See also
........

Module *note glob: e3.

     Unix shell-style path expansion.

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/fnmatch.py


File: python.info,  Node: linecache --- Random access to text lines,  Next: shutil --- High-level file operations,  Prev: fnmatch --- Unix filename pattern matching,  Up: File and Directory Access

5.10.9 ‘linecache’ — Random access to text lines
------------------------------------------------

*Source code:* Lib/linecache.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note linecache: ff. module allows one to get any line from any
file, while attempting to optimize internally, using a cache, the common
case where many lines are read from a single file.  This is used by the
*note traceback: 181. module to retrieve source lines for inclusion in
the formatted traceback.

  The *note linecache: ff. module defines the following functions:

 -- Function: linecache.getline (filename, lineno[, module_globals])

     Get line _lineno_ from file named _filename_.  This function will
     never raise an exception — it will return ‘''’ on errors (the
     terminating newline character will be included for lines that are
     found).

     If a file named _filename_ is not found, the function will look for
     it in the module search path, ‘sys.path’, after first checking for
     a PEP 302(2) ‘__loader__’ in _module_globals_, in case the module
     was imported from a zipfile or other non-filesystem import source.

     New in version 2.5: The _module_globals_ parameter was added.

 -- Function: linecache.clearcache ()

     Clear the cache.  Use this function if you no longer need lines
     from files previously read using *note getline(): e9d.

 -- Function: linecache.checkcache ([filename])

     Check the cache for validity.  Use this function if files in the
     cache may have changed on disk, and you require the updated
     version.  If _filename_ is omitted, it will check all the entries
     in the cache.

  Example:

     >>> import linecache
     >>> linecache.getline('/etc/passwd', 4)
     'sys:x:3:3:sys:/dev:/bin/sh\n'

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/linecache.py

   (2) http://www.python.org/dev/peps/pep-0302


File: python.info,  Node: shutil --- High-level file operations,  Next: dircache --- Cached directory listings,  Prev: linecache --- Random access to text lines,  Up: File and Directory Access

5.10.10 ‘shutil’ — High-level file operations
---------------------------------------------

*Source code:* Lib/shutil.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  The *note shutil: 154. module offers a number of high-level operations
on files and collections of files.  In particular, functions are
provided which support file copying and removal.  For operations on
individual files, see also the *note os: 128. module.

     Warning: Even the higher-level file copying functions (*note
     shutil.copy(): ea2, *note shutil.copy2(): ea3.) can’t copy all file
     metadata.

     On POSIX platforms, this means that file owner and group are lost
     as well as ACLs.  On Mac OS, the resource fork and other metadata
     are not used.  This means that resources will be lost and file type
     and creator codes will not be correct.  On Windows, file owners,
     ACLs and alternate data streams are not copied.

* Menu:

* Directory and files operations:: 
* Archiving operations:: 

Directory and files operations

* copytree example:: 

Archiving operations

* Archiving example:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/shutil.py


File: python.info,  Node: Directory and files operations,  Next: Archiving operations,  Up: shutil --- High-level file operations

5.10.10.1 Directory and files operations
........................................

 -- Function: shutil.copyfileobj (fsrc, fdst[, length])

     Copy the contents of the file-like object _fsrc_ to the file-like
     object _fdst_.  The integer _length_, if given, is the buffer size.
     In particular, a negative _length_ value means to copy the data
     without looping over the source data in chunks; by default the data
     is read in chunks to avoid uncontrolled memory consumption.  Note
     that if the current file position of the _fsrc_ object is not 0,
     only the contents from the current file position to the end of the
     file will be copied.

 -- Function: shutil.copyfile (src, dst)

     Copy the contents (no metadata) of the file named _src_ to a file
     named _dst_.  _dst_ must be the complete target file name; look at
     *note shutil.copy(): ea2. for a copy that accepts a target
     directory path.  If _src_ and _dst_ are the same files, *note
     Error: ea7. is raised.  The destination location must be writable;
     otherwise, an *note IOError: 1fa. exception will be raised.  If
     _dst_ already exists, it will be replaced.  Special files such as
     character or block devices and pipes cannot be copied with this
     function.  _src_ and _dst_ are path names given as strings.

 -- Function: shutil.copymode (src, dst)

     Copy the permission bits from _src_ to _dst_.  The file contents,
     owner, and group are unaffected.  _src_ and _dst_ are path names
     given as strings.

 -- Function: shutil.copystat (src, dst)

     Copy the permission bits, last access time, last modification time,
     and flags from _src_ to _dst_.  The file contents, owner, and group
     are unaffected.  _src_ and _dst_ are path names given as strings.

 -- Function: shutil.copy (src, dst)

     Copy the file _src_ to the file or directory _dst_.  If _dst_ is a
     directory, a file with the same basename as _src_ is created (or
     overwritten) in the directory specified.  Permission bits are
     copied.  _src_ and _dst_ are path names given as strings.

 -- Function: shutil.copy2 (src, dst)

     Similar to *note shutil.copy(): ea2, but metadata is copied as well
     – in fact, this is just *note shutil.copy(): ea2. followed by *note
     copystat(): ea9.  This is similar to the Unix command *cp -p*.

 -- Function: shutil.ignore_patterns (*patterns)

     This factory function creates a function that can be used as a
     callable for *note copytree(): 24d.’s _ignore_ argument, ignoring
     files and directories that match one of the glob-style _patterns_
     provided.  See the example below.

     New in version 2.6.

 -- Function: shutil.copytree (src, dst, symlinks=False, ignore=None)

     Recursively copy an entire directory tree rooted at _src_.  The
     destination directory, named by _dst_, must not already exist; it
     will be created as well as missing parent directories.  Permissions
     and times of directories are copied with *note copystat(): ea9,
     individual files are copied using *note shutil.copy2(): ea3.

     If _symlinks_ is true, symbolic links in the source tree are
     represented as symbolic links in the new tree, but the metadata of
     the original links is NOT copied; if false or omitted, the contents
     and metadata of the linked files are copied to the new tree.

     If _ignore_ is given, it must be a callable that will receive as
     its arguments the directory being visited by *note copytree(): 24d,
     and a list of its contents, as returned by *note os.listdir(): 2d2.
     Since *note copytree(): 24d. is called recursively, the _ignore_
     callable will be called once for each directory that is copied.
     The callable must return a sequence of directory and file names
     relative to the current directory (i.e.  a subset of the items in
     its second argument); these names will then be ignored in the copy
     process.  *note ignore_patterns(): eaa. can be used to create such
     a callable that ignores names based on glob-style patterns.

     If exception(s) occur, an *note Error: ea7. is raised with a list
     of reasons.

     The source code for this should be considered an example rather
     than the ultimate tool.

     Changed in version 2.3: *note Error: ea7. is raised if any
     exceptions occur during copying, rather than printing a message.

     Changed in version 2.5: Create intermediate directories needed to
     create _dst_, rather than raising an error.  Copy permissions and
     times of directories using *note copystat(): ea9.

     Changed in version 2.6: Added the _ignore_ argument to be able to
     influence what is being copied.

 -- Function: shutil.rmtree (path[, ignore_errors[, onerror]])

     Delete an entire directory tree; _path_ must point to a directory
     (but not a symbolic link to a directory).  If _ignore_errors_ is
     true, errors resulting from failed removals will be ignored; if
     false or omitted, such errors are handled by calling a handler
     specified by _onerror_ or, if that is omitted, they raise an
     exception.

     If _onerror_ is provided, it must be a callable that accepts three
     parameters: _function_, _path_, and _excinfo_.  The first
     parameter, _function_, is the function which raised the exception;
     it will be *note os.path.islink(): e08, *note os.listdir(): 2d2,
     *note os.remove(): eac. or *note os.rmdir(): ead.  The second
     parameter, _path_, will be the path name passed to _function_.  The
     third parameter, _excinfo_, will be the exception information
     return by *note sys.exc_info(): 2f3.  Exceptions raised by
     _onerror_ will not be caught.

     Changed in version 2.6: Explicitly check for _path_ being a
     symbolic link and raise *note OSError: 231. in that case.

 -- Function: shutil.move (src, dst)

     Recursively move a file or directory (_src_) to another location
     (_dst_).

     If the destination is a directory or a symlink to a directory, then
     _src_ is moved inside that directory.

     The destination directory must not already exist.  If the
     destination already exists but is not a directory, it may be
     overwritten depending on *note os.rename(): eaf. semantics.

     If the destination is on the current filesystem, then *note
     os.rename(): eaf. is used.  Otherwise, _src_ is copied (using *note
     shutil.copy2(): ea3.) to _dst_ and then removed.

     New in version 2.3.

 -- Exception: shutil.Error

     This exception collects exceptions that are raised during a
     multi-file operation.  For *note copytree(): 24d, the exception
     argument is a list of 3-tuples (_srcname_, _dstname_, _exception_).

     New in version 2.3.

* Menu:

* copytree example:: 


File: python.info,  Node: copytree example,  Up: Directory and files operations

5.10.10.2 copytree example
..........................

This example is the implementation of the *note copytree(): 24d.
function, described above, with the docstring omitted.  It demonstrates
many of the other functions provided by this module.

     def copytree(src, dst, symlinks=False, ignore=None):
         names = os.listdir(src)
         if ignore is not None:
             ignored_names = ignore(src, names)
         else:
             ignored_names = set()

         os.makedirs(dst)
         errors = []
         for name in names:
             if name in ignored_names:
                 continue
             srcname = os.path.join(src, name)
             dstname = os.path.join(dst, name)
             try:
                 if symlinks and os.path.islink(srcname):
                     linkto = os.readlink(srcname)
                     os.symlink(linkto, dstname)
                 elif os.path.isdir(srcname):
                     copytree(srcname, dstname, symlinks, ignore)
                 else:
                     copy2(srcname, dstname)
                 # XXX What about devices, sockets etc.?
             except (IOError, os.error) as why:
                 errors.append((srcname, dstname, str(why)))
             # catch the Error from the recursive copytree so that we can
             # continue with other files
             except Error as err:
                 errors.extend(err.args[0])
         try:
             copystat(src, dst)
         except WindowsError:
             # can't copy file access times on Windows
             pass
         except OSError as why:
             errors.extend((src, dst, str(why)))
         if errors:
             raise Error(errors)

  Another example that uses the *note ignore_patterns(): eaa. helper:

     from shutil import copytree, ignore_patterns

     copytree(source, destination, ignore=ignore_patterns('*.pyc', 'tmp*'))

  This will copy everything except ‘.pyc’ files and files or directories
whose name starts with ‘tmp’.

  Another example that uses the _ignore_ argument to add a logging call:

     from shutil import copytree
     import logging

     def _logpath(path, names):
         logging.info('Working in %s' % path)
         return []   # nothing will be ignored

     copytree(source, destination, ignore=_logpath)


File: python.info,  Node: Archiving operations,  Prev: Directory and files operations,  Up: shutil --- High-level file operations

5.10.10.3 Archiving operations
..............................

High-level utilities to create and read compressed and archived files
are also provided.  They rely on the *note zipfile: 1ab. and *note
tarfile: 171. modules.

 -- Function: shutil.make_archive (base_name, format[, root_dir[,
          base_dir[, verbose[, dry_run[, owner[, group[, logger]]]]]]])

     Create an archive file (eg.  zip or tar) and returns its name.

     _base_name_ is the name of the file to create, including the path,
     minus any format-specific extension.  _format_ is the archive
     format: one of "zip", "tar", "bztar" or "gztar".

     _root_dir_ is a directory that will be the root directory of the
     archive; ie.  we typically chdir into _root_dir_ before creating
     the archive.

     _base_dir_ is the directory where we start archiving from; ie.
     _base_dir_ will be the common prefix of all files and directories
     in the archive.

     _root_dir_ and _base_dir_ both default to the current directory.

     _owner_ and _group_ are used when creating a tar archive.  By
     default, uses the current owner and group.

     _logger_ must be an object compatible with PEP 282(1), usually an
     instance of *note logging.Logger: 1dd.

     New in version 2.7.

 -- Function: shutil.get_archive_formats ()

     Return a list of supported formats for archiving.  Each element of
     the returned sequence is a tuple ‘(name, description)’

     By default *note shutil: 154. provides these formats:

        - _gztar_: gzip’ed tar-file

        - _bztar_: bzip2’ed tar-file

        - _tar_: uncompressed tar file

        - _zip_: ZIP file

     You can register new formats or provide your own archiver for any
     existing formats, by using *note register_archive_format(): eb5.

     New in version 2.7.

 -- Function: shutil.register_archive_format (name, function[,
          extra_args[, description]])

     Register an archiver for the format _name_.  _function_ is a
     callable that will be used to invoke the archiver.

     If given, _extra_args_ is a sequence of ‘(name, value)’ that will
     be used as extra keywords arguments when the archiver callable is
     used.

     _description_ is used by *note get_archive_formats(): eb4. which
     returns the list of archivers.  Defaults to an empty list.

     New in version 2.7.

 -- Function: shutil.unregister_archive_format (name)

     Remove the archive format _name_ from the list of supported
     formats.

     New in version 2.7.

* Menu:

* Archiving example:: 

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0282


File: python.info,  Node: Archiving example,  Up: Archiving operations

5.10.10.4 Archiving example
...........................

In this example, we create a gzip’ed tar-file archive containing all
files found in the ‘.ssh’ directory of the user:

     >>> from shutil import make_archive
     >>> import os
     >>> archive_name = os.path.expanduser(os.path.join('~', 'myarchive'))
     >>> root_dir = os.path.expanduser(os.path.join('~', '.ssh'))
     >>> make_archive(archive_name, 'gztar', root_dir)
     '/Users/tarek/myarchive.tar.gz'

  The resulting archive contains:

     $ tar -tzvf /Users/tarek/myarchive.tar.gz
     drwx------ tarek/staff       0 2010-02-01 16:23:40 ./
     -rw-r--r-- tarek/staff     609 2008-06-09 13:26:54 ./authorized_keys
     -rwxr-xr-x tarek/staff      65 2008-06-09 13:26:54 ./config
     -rwx------ tarek/staff     668 2008-06-09 13:26:54 ./id_dsa
     -rwxr-xr-x tarek/staff     609 2008-06-09 13:26:54 ./id_dsa.pub
     -rw------- tarek/staff    1675 2008-06-09 13:26:54 ./id_rsa
     -rw-r--r-- tarek/staff     397 2008-06-09 13:26:54 ./id_rsa.pub
     -rw-r--r-- tarek/staff   37192 2010-02-06 18:23:10 ./known_hosts


File: python.info,  Node: dircache --- Cached directory listings,  Next: macpath --- Mac OS 9 path manipulation functions,  Prev: shutil --- High-level file operations,  Up: File and Directory Access

5.10.11 ‘dircache’ — Cached directory listings
----------------------------------------------

Deprecated since version 2.6: The *note dircache: 83. module has been
removed in Python 3.

  The *note dircache: 83. module defines a function for reading
directory listing using a cache, and cache invalidation using the
_mtime_ of the directory.  Additionally, it defines a function to
annotate directories by appending a slash.

  The *note dircache: 83. module defines the following functions:

 -- Function: dircache.reset ()

     Resets the directory cache.

 -- Function: dircache.listdir (path)

     Return a directory listing of _path_, as gotten from *note
     os.listdir(): 2d2.  Note that unless _path_ changes, further call
     to *note listdir(): 420. will not re-read the directory structure.

     Note that the list returned should be regarded as read-only.
     (Perhaps a future version should change it to return a tuple?)

 -- Function: dircache.opendir (path)

     Same as *note listdir(): 420.  Defined for backwards compatibility.

 -- Function: dircache.annotate (head, list)

     Assume _list_ is a list of paths relative to _head_, and append, in
     place, a ‘'/'’ to each path which points to a directory.

     >>> import dircache
     >>> a = dircache.listdir('/')
     >>> a = a[:] # Copy the return value so we can change 'a'
     >>> a
     ['bin', 'boot', 'cdrom', 'dev', 'etc', 'floppy', 'home', 'initrd', 'lib', 'lost+
     found', 'mnt', 'proc', 'root', 'sbin', 'tmp', 'usr', 'var', 'vmlinuz']
     >>> dircache.annotate('/', a)
     >>> a
     ['bin/', 'boot/', 'cdrom/', 'dev/', 'etc/', 'floppy/', 'home/', 'initrd/', 'lib/
     ', 'lost+found/', 'mnt/', 'proc/', 'root/', 'sbin/', 'tmp/', 'usr/', 'var/', 'vm
     linuz']


File: python.info,  Node: macpath --- Mac OS 9 path manipulation functions,  Prev: dircache --- Cached directory listings,  Up: File and Directory Access

5.10.12 ‘macpath’ — Mac OS 9 path manipulation functions
--------------------------------------------------------

This module is the Mac OS 9 (and earlier) implementation of the *note
os.path: 129. module.  It can be used to manipulate old-style Macintosh
pathnames on Mac OS X (or any other platform).

  The following functions are available in this module: ‘normcase()’,
‘normpath()’, ‘isabs()’, ‘join()’, ‘split()’, ‘isdir()’, ‘isfile()’,
‘walk()’, ‘exists()’.  For other functions available in *note os.path:
129. dummy counterparts are available.

See also
........

Section *note File Objects: 643.

     A description of Python’s built-in file objects.

Module *note os: 128.

     Operating system interfaces, including functions to work with files
     at a lower level than the built-in file object.


File: python.info,  Node: Data Persistence,  Next: Data Compression and Archiving,  Prev: File and Directory Access,  Up: The Python Standard Library

5.11 Data Persistence
=====================

The modules described in this chapter support storing Python data in a
persistent form on disk.  The *note pickle: 12d. and *note marshal: 10b.
modules can turn many Python data types into a stream of bytes and then
recreate the objects from the bytes.  The various DBM-related modules
support a family of hash-based file formats that store a mapping of
strings to other strings.  The *note bsddb: 1c. module also provides
such disk-based string-to-string mappings based on hashing, and also
supports B-Tree and record-based formats.

  The list of modules described in this chapter is:

* Menu:

* pickle: pickle --- Python object serialization. Python object serialization
* cPickle: cPickle --- A faster pickle. A faster pickle
* copy_reg: copy_reg --- Register pickle support functions. Register pickle support functions
* shelve: shelve --- Python object persistence. Python object persistence
* marshal: marshal --- Internal Python object serialization. Internal Python object serialization
* anydbm: anydbm --- Generic access to DBM-style databases. Generic access to DBM-style databases
* whichdb: whichdb --- Guess which DBM module created a database. Guess which DBM module created a database
* dbm: dbm --- Simple "database" interface. Simple "database" interface
* gdbm: gdbm --- GNU's reinterpretation of dbm. GNU’s reinterpretation of dbm
* dbhash: dbhash --- DBM-style interface to the BSD database library. DBM-style interface to the BSD database library
* bsddb: bsddb --- Interface to Berkeley DB library. Interface to Berkeley DB library
* dumbdbm: dumbdbm --- Portable DBM implementation. Portable DBM implementation
* sqlite3: sqlite3 --- DB-API 2 0 interface for SQLite databases. DB-API 2.0 interface for SQLite databases

pickle — Python object serialization

* Relationship to other Python modules:: 
* Data stream format:: 
* Usage:: 
* What can be pickled and unpickled?:: 
* The pickle protocol:: 
* Subclassing Unpicklers:: 
* Example: Example<3>. 

The pickle protocol

* Pickling and unpickling normal class instances:: 
* Pickling and unpickling extension types:: 
* Pickling and unpickling external objects:: 

copy_reg — Register pickle support functions

* Example: Example<4>. 

shelve — Python object persistence

* Restrictions:: 
* Example: Example<5>. 

dbhash — DBM-style interface to the BSD database library

* Database Objects:: 

bsddb — Interface to Berkeley DB library

* Hash, BTree and Record Objects: Hash BTree and Record Objects. 

dumbdbm — Portable DBM implementation

* Dumbdbm Objects:: 

sqlite3 — DB-API 2.0 interface for SQLite databases

* Module functions and constants:: 
* Connection Objects:: 
* Cursor Objects:: 
* Row Objects:: 
* SQLite and Python types:: 
* Controlling Transactions:: 
* Using sqlite3 efficiently:: 
* Common issues:: 

SQLite and Python types

* Introduction: Introduction<6>. 
* Using adapters to store additional Python types in SQLite databases:: 
* Converting SQLite values to custom Python types:: 
* Default adapters and converters:: 

Using adapters to store additional Python types in SQLite databases

* Letting your object adapt itself:: 
* Registering an adapter callable:: 

Using sqlite3 efficiently

* Using shortcut methods:: 
* Accessing columns by name instead of by index:: 
* Using the connection as a context manager:: 

Common issues

* Multithreading:: 


File: python.info,  Node: pickle --- Python object serialization,  Next: cPickle --- A faster pickle,  Up: Data Persistence

5.11.1 ‘pickle’ — Python object serialization
---------------------------------------------

The *note pickle: 12d. module implements a fundamental, but powerful
algorithm for serializing and de-serializing a Python object structure.
"Pickling" is the process whereby a Python object hierarchy is converted
into a byte stream, and "unpickling" is the inverse operation, whereby a
byte stream is converted back into an object hierarchy.  Pickling (and
unpickling) is alternatively known as "serialization", "marshalling,"
(1) or "flattening", however, to avoid confusion, the terms used here
are "pickling" and "unpickling".

  This documentation describes both the *note pickle: 12d. module and
the *note cPickle: 73. module.

     Warning: The *note pickle: 12d. module is not intended to be secure
     against erroneous or maliciously constructed data.  Never unpickle
     data received from an untrusted or unauthenticated source.

* Menu:

* Relationship to other Python modules:: 
* Data stream format:: 
* Usage:: 
* What can be pickled and unpickled?:: 
* The pickle protocol:: 
* Subclassing Unpicklers:: 
* Example: Example<3>. 

   ---------- Footnotes ----------

   (1) Don’t confuse this with the *note marshal: 10b. module


File: python.info,  Node: Relationship to other Python modules,  Next: Data stream format,  Up: pickle --- Python object serialization

5.11.1.1 Relationship to other Python modules
.............................................

The *note pickle: 12d. module has an optimized cousin called the *note
cPickle: 73. module.  As its name implies, *note cPickle: 73. is written
in C, so it can be up to 1000 times faster than *note pickle: 12d.
However it does not support subclassing of the *note Pickler(): ec6. and
*note Unpickler(): ec7. classes, because in *note cPickle: 73. these are
functions, not classes.  Most applications have no need for this
functionality, and can benefit from the improved performance of *note
cPickle: 73.  Other than that, the interfaces of the two modules are
nearly identical; the common interface is described in this manual and
differences are pointed out where necessary.  In the following
discussions, we use the term "pickle" to collectively describe the *note
pickle: 12d. and *note cPickle: 73. modules.

  The data streams the two modules produce are guaranteed to be
interchangeable.

  Python has a more primitive serialization module called *note marshal:
10b, but in general *note pickle: 12d. should always be the preferred
way to serialize Python objects.  *note marshal: 10b. exists primarily
to support Python’s ‘.pyc’ files.

  The *note pickle: 12d. module differs from *note marshal: 10b. in
several significant ways:

   * The *note pickle: 12d. module keeps track of the objects it has
     already serialized, so that later references to the same object
     won’t be serialized again.  *note marshal: 10b. doesn’t do this.

     This has implications both for recursive objects and object
     sharing.  Recursive objects are objects that contain references to
     themselves.  These are not handled by marshal, and in fact,
     attempting to marshal recursive objects will crash your Python
     interpreter.  Object sharing happens when there are multiple
     references to the same object in different places in the object
     hierarchy being serialized.  *note pickle: 12d. stores such objects
     only once, and ensures that all other references point to the
     master copy.  Shared objects remain shared, which can be very
     important for mutable objects.

   * *note marshal: 10b. cannot be used to serialize user-defined
     classes and their instances.  *note pickle: 12d. can save and
     restore class instances transparently, however the class definition
     must be importable and live in the same module as when the object
     was stored.

   * The *note marshal: 10b. serialization format is not guaranteed to
     be portable across Python versions.  Because its primary job in
     life is to support ‘.pyc’ files, the Python implementers reserve
     the right to change the serialization format in non-backwards
     compatible ways should the need arise.  The *note pickle: 12d.
     serialization format is guaranteed to be backwards compatible
     across Python releases.

  Note that serialization is a more primitive notion than persistence;
although *note pickle: 12d. reads and writes file objects, it does not
handle the issue of naming persistent objects, nor the (even more
complicated) issue of concurrent access to persistent objects.  The
*note pickle: 12d. module can transform a complex object into a byte
stream and it can transform the byte stream into an object with the same
internal structure.  Perhaps the most obvious thing to do with these
byte streams is to write them onto a file, but it is also conceivable to
send them across a network or store them in a database.  The module
*note shelve: 152. provides a simple interface to pickle and unpickle
objects on DBM-style database files.


File: python.info,  Node: Data stream format,  Next: Usage,  Prev: Relationship to other Python modules,  Up: pickle --- Python object serialization

5.11.1.2 Data stream format
...........................

The data format used by *note pickle: 12d. is Python-specific.  This has
the advantage that there are no restrictions imposed by external
standards such as XDR (which can’t represent pointer sharing); however
it means that non-Python programs may not be able to reconstruct pickled
Python objects.

  By default, the *note pickle: 12d. data format uses a printable ASCII
representation.  This is slightly more voluminous than a binary
representation.  The big advantage of using printable ASCII (and of some
other characteristics of *note pickle: 12d.’s representation) is that
for debugging or recovery purposes it is possible for a human to read
the pickled file with a standard text editor.

  There are currently 3 different protocols which can be used for
pickling.

   * Protocol version 0 is the original ASCII protocol and is backwards
     compatible with earlier versions of Python.

   * Protocol version 1 is the old binary format which is also
     compatible with earlier versions of Python.

   * Protocol version 2 was introduced in Python 2.3.  It provides much
     more efficient pickling of *note new-style class: 5d1.es.

  Refer to PEP 307(1) for more information.

  If a _protocol_ is not specified, protocol 0 is used.  If _protocol_
is specified as a negative value or *note HIGHEST_PROTOCOL: 449, the
highest protocol version available will be used.

  Changed in version 2.3: Introduced the _protocol_ parameter.

  A binary format, which is slightly more efficient, can be chosen by
specifying a _protocol_ version >= 1.

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0307


File: python.info,  Node: Usage,  Next: What can be pickled and unpickled?,  Prev: Data stream format,  Up: pickle --- Python object serialization

5.11.1.3 Usage
..............

To serialize an object hierarchy, you first create a pickler, then you
call the pickler’s *note dump(): eca. method.  To de-serialize a data
stream, you first create an unpickler, then you call the unpickler’s
*note load(): ecb. method.  The *note pickle: 12d. module provides the
following constant:

 -- Data: pickle.HIGHEST_PROTOCOL

     The highest protocol version available.  This value can be passed
     as a _protocol_ value.

     New in version 2.3.

     Note: Be sure to always open pickle files created with protocols >=
     1 in binary mode.  For the old ASCII-based pickle protocol 0 you
     can use either text mode or binary mode as long as you stay
     consistent.

     A pickle file written with protocol 0 in binary mode will contain
     lone linefeeds as line terminators and therefore will look "funny"
     when viewed in Notepad or other editors which do not support this
     format.

  The *note pickle: 12d. module provides the following functions to make
the pickling process more convenient:

 -- Function: pickle.dump (obj, file[, protocol])

     Write a pickled representation of _obj_ to the open file object
     _file_.  This is equivalent to ‘Pickler(file, protocol).dump(obj)’.

     If the _protocol_ parameter is omitted, protocol 0 is used.  If
     _protocol_ is specified as a negative value or *note
     HIGHEST_PROTOCOL: 449, the highest protocol version will be used.

     Changed in version 2.3: Introduced the _protocol_ parameter.

     _file_ must have a ‘write()’ method that accepts a single string
     argument.  It can thus be a file object opened for writing, a *note
     StringIO: 164. object, or any other custom object that meets this
     interface.

 -- Function: pickle.load (file)

     Read a string from the open file object _file_ and interpret it as
     a pickle data stream, reconstructing and returning the original
     object hierarchy.  This is equivalent to ‘Unpickler(file).load()’.

     _file_ must have two methods, a ‘read()’ method that takes an
     integer argument, and a *note readline(): 144. method that requires
     no arguments.  Both methods should return a string.  Thus _file_
     can be a file object opened for reading, a *note StringIO: 164.
     object, or any other custom object that meets this interface.

     This function automatically determines whether the data stream was
     written in binary mode or not.

 -- Function: pickle.dumps (obj[, protocol])

     Return the pickled representation of the object as a string,
     instead of writing it to a file.

     If the _protocol_ parameter is omitted, protocol 0 is used.  If
     _protocol_ is specified as a negative value or *note
     HIGHEST_PROTOCOL: 449, the highest protocol version will be used.

     Changed in version 2.3: The _protocol_ parameter was added.

 -- Function: pickle.loads (string)

     Read a pickled object hierarchy from a string.  Characters in the
     string past the pickled object’s representation are ignored.

  The *note pickle: 12d. module also defines three exceptions:

 -- Exception: pickle.PickleError

     A common base class for the other exceptions defined below.  This
     inherits from *note Exception: 339.

 -- Exception: pickle.PicklingError

     This exception is raised when an unpicklable object is passed to
     the *note dump(): eca. method.

 -- Exception: pickle.UnpicklingError

     This exception is raised when there is a problem unpickling an
     object.  Note that other exceptions may also be raised during
     unpickling, including (but not necessarily limited to) *note
     AttributeError: 1f8, *note EOFError: 88a, *note ImportError: 370,
     and *note IndexError: 4e1.

  The *note pickle: 12d. module also exports two callables (1), *note
Pickler: ec6. and *note Unpickler: ec7.:

 -- Class: pickle.Pickler (file[, protocol])

     This takes a file-like object to which it will write a pickle data
     stream.

     If the _protocol_ parameter is omitted, protocol 0 is used.  If
     _protocol_ is specified as a negative value or *note
     HIGHEST_PROTOCOL: 449, the highest protocol version will be used.

     Changed in version 2.3: Introduced the _protocol_ parameter.

     _file_ must have a ‘write()’ method that accepts a single string
     argument.  It can thus be an open file object, a *note StringIO:
     164. object, or any other custom object that meets this interface.

     *note Pickler: ec6. objects define one (or two) public methods:

      -- Method: dump (obj)

          Write a pickled representation of _obj_ to the open file
          object given in the constructor.  Either the binary or ASCII
          format will be used, depending on the value of the _protocol_
          argument passed to the constructor.

      -- Method: clear_memo ()

          Clears the pickler’s "memo".  The memo is the data structure
          that remembers which objects the pickler has already seen, so
          that shared or recursive objects pickled by reference and not
          by value.  This method is useful when re-using picklers.

               Note: Prior to Python 2.3, *note clear_memo(): ed2. was
               only available on the picklers created by *note cPickle:
               73.  In the *note pickle: 12d. module, picklers have an
               instance variable called ‘memo’ which is a Python
               dictionary.  So to clear the memo for a *note pickle:
               12d. module pickler, you could do the following:

                    mypickler.memo.clear()

               Code that does not need to support older versions of
               Python should simply use *note clear_memo(): ed2.

  It is possible to make multiple calls to the *note dump(): eca. method
of the same *note Pickler: ec6. instance.  These must then be matched to
the same number of calls to the *note load(): ecb. method of the
corresponding *note Unpickler: ec7. instance.  If the same object is
pickled by multiple *note dump(): eca. calls, the *note load(): ecb.
will all yield references to the same object.  (2)

  *note Unpickler: ec7. objects are defined as:

 -- Class: pickle.Unpickler (file)

     This takes a file-like object from which it will read a pickle data
     stream.  This class automatically determines whether the data
     stream was written in binary mode or not, so it does not need a
     flag as in the *note Pickler: ec6. factory.

     _file_ must have two methods, a ‘read()’ method that takes an
     integer argument, and a *note readline(): 144. method that requires
     no arguments.  Both methods should return a string.  Thus _file_
     can be a file object opened for reading, a *note StringIO: 164.
     object, or any other custom object that meets this interface.

     *note Unpickler: ec7. objects have one (or two) public methods:

      -- Method: load ()

          Read a pickled object representation from the open file object
          given in the constructor, and return the reconstituted object
          hierarchy specified therein.

          This method automatically determines whether the data stream
          was written in binary mode or not.

      -- Method: noload ()

          This is just like *note load(): ecb. except that it doesn’t
          actually create any objects.  This is useful primarily for
          finding what’s called "persistent ids" that may be referenced
          in a pickle data stream.  See section *note The pickle
          protocol: ed5. below for more details.

          *Note:* the *note noload(): ed4. method is currently only
          available on *note Unpickler: ec7. objects created with the
          *note cPickle: 73. module.  *note pickle: 12d. module *note
          Unpickler: ec7.s do not have the *note noload(): ed4. method.

   ---------- Footnotes ----------

   (1) In the *note pickle: 12d. module these callables are classes,
which you could subclass to customize the behavior.  However, in the
*note cPickle: 73. module these callables are factory functions and so
cannot be subclassed.  One common reason to subclass is to control what
objects can actually be unpickled.  See section *note Subclassing
Unpicklers: ed0. for more details.

   (2) _Warning_: this is intended for pickling multiple objects without
intervening modifications to the objects or their parts.  If you modify
an object and then pickle it again using the same ‘Pickler’ instance,
the object is not pickled again — a reference to it is pickled and the
‘Unpickler’ will return the old value, not the modified one.  There are
two problems here: (1) detecting changes, and (2) marshalling a minimal
set of changes.  Garbage Collection may also become a problem here.


File: python.info,  Node: What can be pickled and unpickled?,  Next: The pickle protocol,  Prev: Usage,  Up: pickle --- Python object serialization

5.11.1.4 What can be pickled and unpickled?
...........................................

The following types can be pickled:

   * ‘None’, ‘True’, and ‘False’

   * integers, long integers, floating point numbers, complex numbers

   * normal and Unicode strings

   * tuples, lists, sets, and dictionaries containing only picklable
     objects

   * functions defined at the top level of a module

   * built-in functions defined at the top level of a module

   * classes that are defined at the top level of a module

   * instances of such classes whose *note __dict__: 6fe. or the result
     of calling *note __getstate__(): 44a. is picklable (see section
     *note The pickle protocol: ed5. for details).

  Attempts to pickle unpicklable objects will raise the *note
PicklingError: ece. exception; when this happens, an unspecified number
of bytes may have already been written to the underlying file.  Trying
to pickle a highly recursive data structure may exceed the maximum
recursion depth, a *note RuntimeError: 39b. will be raised in this case.
You can carefully raise this limit with *note sys.setrecursionlimit():
4e7.

  Note that functions (built-in and user-defined) are pickled by "fully
qualified" name reference, not by value.  This means that only the
function name is pickled, along with the name of the module the function
is defined in.  Neither the function’s code, nor any of its function
attributes are pickled.  Thus the defining module must be importable in
the unpickling environment, and the module must contain the named
object, otherwise an exception will be raised.  (1)

  Similarly, classes are pickled by named reference, so the same
restrictions in the unpickling environment apply.  Note that none of the
class’s code or data is pickled, so in the following example the class
attribute ‘attr’ is not restored in the unpickling environment:

     class Foo:
         attr = 'a class attr'

     picklestring = pickle.dumps(Foo)

  These restrictions are why picklable functions and classes must be
defined in the top level of a module.

  Similarly, when class instances are pickled, their class’s code and
data are not pickled along with them.  Only the instance data are
pickled.  This is done on purpose, so you can fix bugs in a class or add
methods to the class and still load objects that were created with an
earlier version of the class.  If you plan to have long-lived objects
that will see many versions of a class, it may be worthwhile to put a
version number in the objects so that suitable conversions can be made
by the class’s *note __setstate__(): 44b. method.

   ---------- Footnotes ----------

   (1) The exception raised will likely be an *note ImportError: 370. or
an *note AttributeError: 1f8. but it could be something else.


File: python.info,  Node: The pickle protocol,  Next: Subclassing Unpicklers,  Prev: What can be pickled and unpickled?,  Up: pickle --- Python object serialization

5.11.1.5 The pickle protocol
............................

This section describes the "pickling protocol" that defines the
interface between the pickler/unpickler and the objects that are being
serialized.  This protocol provides a standard way for you to define,
customize, and control how your objects are serialized and
de-serialized.  The description in this section doesn’t cover specific
customizations that you can employ to make the unpickling environment
slightly safer from untrusted pickle data streams; see section *note
Subclassing Unpicklers: ed0. for more details.

* Menu:

* Pickling and unpickling normal class instances:: 
* Pickling and unpickling extension types:: 
* Pickling and unpickling external objects:: 


File: python.info,  Node: Pickling and unpickling normal class instances,  Next: Pickling and unpickling extension types,  Up: The pickle protocol

5.11.1.6 Pickling and unpickling normal class instances
.......................................................

 -- Method: object.__getinitargs__ ()

     When a pickled class instance is unpickled, its *note __init__():
     37c. method is normally _not_ invoked.  If it is desirable that the
     *note __init__(): 37c. method be called on unpickling, an old-style
     class can define a method *note __getinitargs__(): eda, which
     should return a _tuple_ containing the arguments to be passed to
     the class constructor (*note __init__(): 37c. for example).  The
     *note __getinitargs__(): eda. method is called at pickle time; the
     tuple it returns is incorporated in the pickle for the instance.

 -- Method: object.__getnewargs__ ()

     New-style types can provide a *note __getnewargs__(): 44c. method
     that is used for protocol 2.  Implementing this method is needed if
     the type establishes some internal invariants when the instance is
     created, or if the memory allocation is affected by the values
     passed to the *note __new__(): 6f9. method for the type (as it is
     for tuples and strings).  Instances of a *note new-style class:
     5d1. ‘C’ are created using

          obj = C.__new__(C, *args)

     where _args_ is the result of calling *note __getnewargs__(): 44c.
     on the original object; if there is no *note __getnewargs__(): 44c,
     an empty tuple is assumed.

 -- Method: object.__getstate__ ()

     Classes can further influence how their instances are pickled; if
     the class defines the method *note __getstate__(): 44a, it is
     called and the return state is pickled as the contents for the
     instance, instead of the contents of the instance’s dictionary.  If
     there is no *note __getstate__(): 44a. method, the instance’s *note
     __dict__: 6fe. is pickled.

 -- Method: object.__setstate__ (state)

     Upon unpickling, if the class also defines the method *note
     __setstate__(): 44b, it is called with the unpickled state.  (1) If
     there is no *note __setstate__(): 44b. method, the pickled state
     must be a dictionary and its items are assigned to the new
     instance’s dictionary.  If a class defines both *note
     __getstate__(): 44a. and *note __setstate__(): 44b, the state
     object needn’t be a dictionary and these methods can do what they
     want.  (2)

          Note: For *note new-style class: 5d1.es, if *note
          __getstate__(): 44a. returns a false value, the *note
          __setstate__(): 44b. method will not be called.

     Note: At unpickling time, some methods like *note __getattr__():
     331, *note __getattribute__(): 33b, or *note __setattr__(): 488.
     may be called upon the instance.  In case those methods rely on
     some internal invariant being true, the type should implement
     either *note __getinitargs__(): eda. or *note __getnewargs__():
     44c. to establish such an invariant; otherwise, neither *note
     __new__(): 6f9. nor *note __init__(): 37c. will be called.

   ---------- Footnotes ----------

   (1) These methods can also be used to implement copying class
instances.

   (2) This protocol is also used by the shallow and deep copying
operations defined in the *note copy: 71. module.


File: python.info,  Node: Pickling and unpickling extension types,  Next: Pickling and unpickling external objects,  Prev: Pickling and unpickling normal class instances,  Up: The pickle protocol

5.11.1.7 Pickling and unpickling extension types
................................................

 -- Method: object.__reduce__ ()

     When the ‘Pickler’ encounters an object of a type it knows nothing
     about — such as an extension type — it looks in two places for a
     hint of how to pickle it.  One alternative is for the object to
     implement a *note __reduce__(): 3cc. method.  If provided, at
     pickling time *note __reduce__(): 3cc. will be called with no
     arguments, and it must return either a string or a tuple.

     If a string is returned, it names a global variable whose contents
     are pickled as normal.  The string returned by *note __reduce__():
     3cc. should be the object’s local name relative to its module; the
     pickle module searches the module namespace to determine the
     object’s module.

     When a tuple is returned, it must be between two and five elements
     long.  Optional elements can either be omitted, or ‘None’ can be
     provided as their value.  The contents of this tuple are pickled as
     normal and used to reconstruct the object at unpickling time.  The
     semantics of each element are:

        * A callable object that will be called to create the initial
          version of the object.  The next element of the tuple will
          provide arguments for this callable, and later elements
          provide additional state information that will subsequently be
          used to fully reconstruct the pickled data.

          In the unpickling environment this object must be either a
          class, a callable registered as a "safe constructor" (see
          below), or it must have an attribute ‘__safe_for_unpickling__’
          with a true value.  Otherwise, an ‘UnpicklingError’ will be
          raised in the unpickling environment.  Note that as usual, the
          callable itself is pickled by name.

        * A tuple of arguments for the callable object.

          Changed in version 2.5: Formerly, this argument could also be
          ‘None’.

        * Optionally, the object’s state, which will be passed to the
          object’s *note __setstate__(): 44b. method as described in
          section *note Pickling and unpickling normal class instances:
          ed9.  If the object has no *note __setstate__(): 44b. method,
          then, as above, the value must be a dictionary and it will be
          added to the object’s *note __dict__: 6fe.

        * Optionally, an iterator (and not a sequence) yielding
          successive list items.  These list items will be pickled, and
          appended to the object using either ‘obj.append(item)’ or
          ‘obj.extend(list_of_items)’.  This is primarily used for list
          subclasses, but may be used by other classes as long as they
          have ‘append()’ and ‘extend()’ methods with the appropriate
          signature.  (Whether ‘append()’ or ‘extend()’ is used depends
          on which pickle protocol version is used as well as the number
          of items to append, so both must be supported.)

        * Optionally, an iterator (not a sequence) yielding successive
          dictionary items, which should be tuples of the form ‘(key,
          value)’.  These items will be pickled and stored to the object
          using ‘obj[key] = value’.  This is primarily used for
          dictionary subclasses, but may be used by other classes as
          long as they implement *note __setitem__(): 465.

 -- Method: object.__reduce_ex__ (protocol)

     It is sometimes useful to know the protocol version when
     implementing *note __reduce__(): 3cc.  This can be done by
     implementing a method named *note __reduce_ex__(): edc. instead of
     *note __reduce__(): 3cc.  *note __reduce_ex__(): edc, when it
     exists, is called in preference over *note __reduce__(): 3cc. (you
     may still provide *note __reduce__(): 3cc. for backwards
     compatibility).  The *note __reduce_ex__(): edc. method will be
     called with a single integer argument, the protocol version.

     The *note object: 1f1. class implements both *note __reduce__():
     3cc. and *note __reduce_ex__(): edc.; however, if a subclass
     overrides *note __reduce__(): 3cc. but not *note __reduce_ex__():
     edc, the *note __reduce_ex__(): edc. implementation detects this
     and calls *note __reduce__(): 3cc.

  An alternative to implementing a *note __reduce__(): 3cc. method on
the object to be pickled, is to register the callable with the *note
copy_reg: 72. module.  This module provides a way for programs to
register "reduction functions" and constructors for user-defined types.
Reduction functions have the same semantics and interface as the *note
__reduce__(): 3cc. method described above, except that they are called
with a single argument, the object to be pickled.

  The registered constructor is deemed a "safe constructor" for purposes
of unpickling as described above.


File: python.info,  Node: Pickling and unpickling external objects,  Prev: Pickling and unpickling extension types,  Up: The pickle protocol

5.11.1.8 Pickling and unpickling external objects
.................................................

For the benefit of object persistence, the *note pickle: 12d. module
supports the notion of a reference to an object outside the pickled data
stream.  Such objects are referenced by a "persistent id", which is just
an arbitrary string of printable ASCII characters.  The resolution of
such names is not defined by the *note pickle: 12d. module; it will
delegate this resolution to user defined functions on the pickler and
unpickler.  (1)

  To define external persistent id resolution, you need to set the
‘persistent_id’ attribute of the pickler object and the
‘persistent_load’ attribute of the unpickler object.

  To pickle objects that have an external persistent id, the pickler
must have a custom ‘persistent_id()’ method that takes an object as an
argument and returns either ‘None’ or the persistent id for that object.
When ‘None’ is returned, the pickler simply pickles the object as
normal.  When a persistent id string is returned, the pickler will
pickle that string, along with a marker so that the unpickler will
recognize the string as a persistent id.

  To unpickle external objects, the unpickler must have a custom
‘persistent_load()’ function that takes a persistent id string and
returns the referenced object.

  Here’s a silly example that _might_ shed more light:

     import pickle
     from cStringIO import StringIO

     src = StringIO()
     p = pickle.Pickler(src)

     def persistent_id(obj):
         if hasattr(obj, 'x'):
             return 'the value %d' % obj.x
         else:
             return None

     p.persistent_id = persistent_id

     class Integer:
         def __init__(self, x):
             self.x = x
         def __str__(self):
             return 'My name is integer %d' % self.x

     i = Integer(7)
     print i
     p.dump(i)

     datastream = src.getvalue()
     print repr(datastream)
     dst = StringIO(datastream)

     up = pickle.Unpickler(dst)

     class FancyInteger(Integer):
         def __str__(self):
             return 'I am the integer %d' % self.x

     def persistent_load(persid):
         if persid.startswith('the value '):
             value = int(persid.split()[2])
             return FancyInteger(value)
         else:
             raise pickle.UnpicklingError, 'Invalid persistent id'

     up.persistent_load = persistent_load

     j = up.load()
     print j

  In the *note cPickle: 73. module, the unpickler’s ‘persistent_load’
attribute can also be set to a Python list, in which case, when the
unpickler reaches a persistent id, the persistent id string will simply
be appended to this list.  This functionality exists so that a pickle
data stream can be "sniffed" for object references without actually
instantiating all the objects in a pickle.  (2) Setting
‘persistent_load’ to a list is usually used in conjunction with the
‘noload()’ method on the Unpickler.

   ---------- Footnotes ----------

   (1) The actual mechanism for associating these user defined functions
is slightly different for *note pickle: 12d. and *note cPickle: 73.  The
description given here works the same for both implementations.  Users
of the *note pickle: 12d. module could also use subclassing to effect
the same results, overriding the ‘persistent_id()’ and
‘persistent_load()’ methods in the derived classes.

   (2) We’ll leave you with the image of Guido and Jim sitting around
sniffing pickles in their living rooms.


File: python.info,  Node: Subclassing Unpicklers,  Next: Example<3>,  Prev: The pickle protocol,  Up: pickle --- Python object serialization

5.11.1.9 Subclassing Unpicklers
...............................

By default, unpickling will import any class that it finds in the pickle
data.  You can control exactly what gets unpickled and what gets called
by customizing your unpickler.  Unfortunately, exactly how you do this
is different depending on whether you’re using *note pickle: 12d. or
*note cPickle: 73.  (1)

  In the *note pickle: 12d. module, you need to derive a subclass from
‘Unpickler’, overriding the ‘load_global()’ method.  ‘load_global()’
should read two lines from the pickle data stream where the first line
will the name of the module containing the class and the second line
will be the name of the instance’s class.  It then looks up the class,
possibly importing the module and digging out the attribute, then it
appends what it finds to the unpickler’s stack.  Later on, this class
will be assigned to the ‘__class__’ attribute of an empty class, as a
way of magically creating an instance without calling its class’s *note
__init__(): 37c.  Your job (should you choose to accept it), would be to
have ‘load_global()’ push onto the unpickler’s stack, a known safe
version of any class you deem safe to unpickle.  It is up to you to
produce such a class.  Or you could raise an error if you want to
disallow all unpickling of instances.  If this sounds like a hack,
you’re right.  Refer to the source code to make this work.

  Things are a little cleaner with *note cPickle: 73, but not by much.
To control what gets unpickled, you can set the unpickler’s
‘find_global’ attribute to a function or ‘None’.  If it is ‘None’ then
any attempts to unpickle instances will raise an ‘UnpicklingError’.  If
it is a function, then it should accept a module name and a class name,
and return the corresponding class object.  It is responsible for
looking up the class and performing any necessary imports, and it may
raise an error to prevent instances of the class from being unpickled.

  The moral of the story is that you should be really careful about the
source of the strings your application unpickles.

   ---------- Footnotes ----------

   (1) A word of caution: the mechanisms described here use internal
attributes and methods, which are subject to change in future versions
of Python.  We intend to someday provide a common interface for
controlling this behavior, which will work in either *note pickle: 12d.
or *note cPickle: 73.


File: python.info,  Node: Example<3>,  Prev: Subclassing Unpicklers,  Up: pickle --- Python object serialization

5.11.1.10 Example
.................

For the simplest code, use the ‘dump()’ and ‘load()’ functions.  Note
that a self-referencing list is pickled and restored correctly.

     import pickle

     data1 = {'a': [1, 2.0, 3, 4+6j],
              'b': ('string', u'Unicode string'),
              'c': None}

     selfref_list = [1, 2, 3]
     selfref_list.append(selfref_list)

     output = open('data.pkl', 'wb')

     # Pickle dictionary using protocol 0.
     pickle.dump(data1, output)

     # Pickle the list using the highest protocol available.
     pickle.dump(selfref_list, output, -1)

     output.close()

  The following example reads the resulting pickled data.  When reading
a pickle-containing file, you should open the file in binary mode
because you can’t be sure if the ASCII or binary format was used.

     import pprint, pickle

     pkl_file = open('data.pkl', 'rb')

     data1 = pickle.load(pkl_file)
     pprint.pprint(data1)

     data2 = pickle.load(pkl_file)
     pprint.pprint(data2)

     pkl_file.close()

  Here’s a larger example that shows how to modify pickling behavior for
a class.  The ‘TextReader’ class opens a text file, and returns the line
number and line contents each time its ‘readline()’ method is called.
If a ‘TextReader’ instance is pickled, all attributes _except_ the file
object member are saved.  When the instance is unpickled, the file is
reopened, and reading resumes from the last location.  The *note
__setstate__(): 44b. and *note __getstate__(): 44a. methods are used to
implement this behavior.

     #!/usr/local/bin/python

     class TextReader:
         """Print and number lines in a text file."""
         def __init__(self, file):
             self.file = file
             self.fh = open(file)
             self.lineno = 0

         def readline(self):
             self.lineno = self.lineno + 1
             line = self.fh.readline()
             if not line:
                 return None
             if line.endswith("\n"):
                 line = line[:-1]
             return "%d: %s" % (self.lineno, line)

         def __getstate__(self):
             odict = self.__dict__.copy() # copy the dict since we change it
             del odict['fh']              # remove filehandle entry
             return odict

         def __setstate__(self, dict):
             fh = open(dict['file'])      # reopen file
             count = dict['lineno']       # read from file...
             while count:                 # until line count is restored
                 fh.readline()
                 count = count - 1
             self.__dict__.update(dict)   # update attributes
             self.fh = fh                 # save the file object

  A sample usage might be something like this:

     >>> import TextReader
     >>> obj = TextReader.TextReader("TextReader.py")
     >>> obj.readline()
     '1: #!/usr/local/bin/python'
     >>> obj.readline()
     '2: '
     >>> obj.readline()
     '3: class TextReader:'
     >>> import pickle
     >>> pickle.dump(obj, open('save.p', 'wb'))

  If you want to see that *note pickle: 12d. works across Python
processes, start another Python session, before continuing.  What
follows can happen from either the same process or a new process.

     >>> import pickle
     >>> reader = pickle.load(open('save.p', 'rb'))
     >>> reader.readline()
     '4:     """Print and number lines in a text file."""'

See also
........

Module *note copy_reg: 72.

     Pickle interface constructor registration for extension types.

Module *note shelve: 152.

     Indexed databases of objects; uses *note pickle: 12d.

Module *note copy: 71.

     Shallow and deep object copying.

Module *note marshal: 10b.

     High-performance serialization of built-in types.


File: python.info,  Node: cPickle --- A faster pickle,  Next: copy_reg --- Register pickle support functions,  Prev: pickle --- Python object serialization,  Up: Data Persistence

5.11.2 ‘cPickle’ — A faster ‘pickle’
------------------------------------

The *note cPickle: 73. module supports serialization and
de-serialization of Python objects, providing an interface and
functionality nearly identical to the *note pickle: 12d. module.  There
are several differences, the most important being performance and
subclassability.

  First, *note cPickle: 73. can be up to 1000 times faster than *note
pickle: 12d. because the former is implemented in C. Second, in the
*note cPickle: 73. module the callables ‘Pickler()’ and ‘Unpickler()’
are functions, not classes.  This means that you cannot use them to
derive custom pickling and unpickling subclasses.  Most applications
have no need for this functionality and should benefit from the greatly
improved performance of the *note cPickle: 73. module.

  The pickle data stream produced by *note pickle: 12d. and *note
cPickle: 73. are identical, so it is possible to use *note pickle: 12d.
and *note cPickle: 73. interchangeably with existing pickles.  (1)

  There are additional minor differences in API between *note cPickle:
73. and *note pickle: 12d, however for most applications, they are
interchangeable.  More documentation is provided in the *note pickle:
12d. module documentation, which includes a list of the documented
differences.

   ---------- Footnotes ----------

   (1) Since the pickle data format is actually a tiny stack-oriented
programming language, and some freedom is taken in the encodings of
certain objects, it is possible that the two modules produce different
data streams for the same input objects.  However it is guaranteed that
they will always be able to read each other’s data streams.


File: python.info,  Node: copy_reg --- Register pickle support functions,  Next: shelve --- Python object persistence,  Prev: cPickle --- A faster pickle,  Up: Data Persistence

5.11.3 ‘copy_reg’ — Register ‘pickle’ support functions
-------------------------------------------------------

     Note: The *note copy_reg: 72. module has been renamed to ‘copyreg’
     in Python 3.  The *note 2to3: bdb. tool will automatically adapt
     imports when converting your sources to Python 3.

  The *note copy_reg: 72. module offers a way to define fuctions used
while pickling specific objects.  The *note pickle: 12d, *note cPickle:
73, and *note copy: 71. modules use those functions when
pickling/copying those objects.  The module provides configuration
information about object constructors which are not classes.  Such
constructors may be factory functions or class instances.

 -- Function: copy_reg.constructor (object)

     Declares _object_ to be a valid constructor.  If _object_ is not
     callable (and hence not valid as a constructor), raises *note
     TypeError: 218.

 -- Function: copy_reg.pickle (type, function[, constructor])

     Declares that _function_ should be used as a "reduction" function
     for objects of type _type_; _type_ must not be a "classic" class
     object.  (Classic classes are handled differently; see the
     documentation for the *note pickle: 12d. module for details.)
     _function_ should return either a string or a tuple containing two
     or three elements.

     The optional _constructor_ parameter, if provided, is a callable
     object which can be used to reconstruct the object when called with
     the tuple of arguments returned by _function_ at pickling time.
     *note TypeError: 218. will be raised if _object_ is a class or
     _constructor_ is not callable.

     See the *note pickle: 12d. module for more details on the interface
     expected of _function_ and _constructor_.

* Menu:

* Example: Example<4>. 


File: python.info,  Node: Example<4>,  Up: copy_reg --- Register pickle support functions

5.11.3.1 Example
................

The example below would like to show how to register a pickle function
and how it will be used:

     >>> import copy_reg, copy, pickle
     >>> class C(object):
     ...     def __init__(self, a):
     ...         self.a = a
     ...
     >>> def pickle_c(c):
     ...     print("pickling a C instance...")
     ...     return C, (c.a,)
     ...
     >>> copy_reg.pickle(C, pickle_c)
     >>> c = C(1)
     >>> d = copy.copy(c)
     pickling a C instance...
     >>> p = pickle.dumps(c)
     pickling a C instance...


File: python.info,  Node: shelve --- Python object persistence,  Next: marshal --- Internal Python object serialization,  Prev: copy_reg --- Register pickle support functions,  Up: Data Persistence

5.11.4 ‘shelve’ — Python object persistence
-------------------------------------------

*Source code:* Lib/shelve.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  A "shelf" is a persistent, dictionary-like object.  The difference
with "dbm" databases is that the values (not the keys!)  in a shelf can
be essentially arbitrary Python objects — anything that the *note
pickle: 12d. module can handle.  This includes most class instances,
recursive data types, and objects containing lots of shared sub-objects.
The keys are ordinary strings.

 -- Function: shelve.open (filename, flag='c', protocol=None,
          writeback=False)

     Open a persistent dictionary.  The filename specified is the base
     filename for the underlying database.  As a side-effect, an
     extension may be added to the filename and more than one file may
     be created.  By default, the underlying database file is opened for
     reading and writing.  The optional _flag_ parameter has the same
     interpretation as the _flag_ parameter of *note anydbm.open(): eea.

     By default, version 0 pickles are used to serialize values.  The
     version of the pickle protocol can be specified with the _protocol_
     parameter.

     Changed in version 2.3: The _protocol_ parameter was added.

     Because of Python semantics, a shelf cannot know when a mutable
     persistent-dictionary entry is modified.  By default modified
     objects are written _only_ when assigned to the shelf (see *note
     Example: eeb.).  If the optional _writeback_ parameter is set to
     _True_, all entries accessed are also cached in memory, and written
     back on *note sync(): eec. and *note close(): eed.; this can make
     it handier to mutate mutable entries in the persistent dictionary,
     but, if many entries are accessed, it can consume vast amounts of
     memory for the cache, and it can make the close operation very slow
     since all accessed entries are written back (there is no way to
     determine which accessed entries are mutable, nor which ones were
     actually mutated).

     Like file objects, shelve objects should be closed explicitly to
     ensure that the persistent data is flushed to disk.

     Warning: Because the *note shelve: 152. module is backed by *note
     pickle: 12d, it is insecure to load a shelf from an untrusted
     source.  Like with pickle, loading a shelf can execute arbitrary
     code.

  Shelf objects support all methods supported by dictionaries.  This
eases the transition from dictionary based scripts to those requiring
persistent storage.

  Two additional methods are supported:

 -- Method: Shelf.sync ()

     Write back all entries in the cache if the shelf was opened with
     _writeback_ set to *note True: 3b0.  Also empty the cache and
     synchronize the persistent dictionary on disk, if feasible.  This
     is called automatically when the shelf is closed with *note
     close(): eed.

 -- Method: Shelf.close ()

     Synchronize and close the persistent _dict_ object.  Operations on
     a closed shelf will fail with a *note ValueError: 236.

See also
........

Persistent dictionary recipe(2) with widely supported storage formats
and having the speed of native dictionaries.

* Menu:

* Restrictions:: 
* Example: Example<5>. 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/shelve.py

   (2) http://code.activestate.com/recipes/576642/


File: python.info,  Node: Restrictions,  Next: Example<5>,  Up: shelve --- Python object persistence

5.11.4.1 Restrictions
.....................

   * The choice of which database package will be used (such as *note
     dbm: 7f, *note gdbm: dc. or *note bsddb: 1c.) depends on which
     interface is available.  Therefore it is not safe to open the
     database directly using *note dbm: 7f.  The database is also
     (unfortunately) subject to the limitations of *note dbm: 7f, if it
     is used — this means that (the pickled representation of) the
     objects stored in the database should be fairly small, and in rare
     cases key collisions may cause the database to refuse updates.

   * The *note shelve: 152. module does not support _concurrent_
     read/write access to shelved objects.  (Multiple simultaneous read
     accesses are safe.)  When a program has a shelf open for writing,
     no other program should have it open for reading or writing.  Unix
     file locking can be used to solve this, but this differs across
     Unix versions and requires knowledge about the database
     implementation used.

 -- Class: shelve.Shelf (dict, protocol=None, writeback=False)

     A subclass of *note UserDict.DictMixin: c00. which stores pickled
     values in the _dict_ object.

     By default, version 0 pickles are used to serialize values.  The
     version of the pickle protocol can be specified with the _protocol_
     parameter.  See the *note pickle: 12d. documentation for a
     discussion of the pickle protocols.

     Changed in version 2.3: The _protocol_ parameter was added.

     If the _writeback_ parameter is ‘True’, the object will hold a
     cache of all entries accessed and write them back to the _dict_ at
     sync and close times.  This allows natural operations on mutable
     entries, but can consume much more memory and make sync and close
     take a long time.

 -- Class: shelve.BsdDbShelf (dict, protocol=None, writeback=False)

     A subclass of *note Shelf: eef. which exposes ‘first()’, ‘next()’,
     ‘previous()’, ‘last()’ and ‘set_location()’ which are available in
     the *note bsddb: 1c. module but not in other database modules.  The
     _dict_ object passed to the constructor must support those methods.
     This is generally accomplished by calling one of *note
     bsddb.hashopen(): ef1, *note bsddb.btopen(): ef2. or *note
     bsddb.rnopen(): ef3.  The optional _protocol_ and _writeback_
     parameters have the same interpretation as for the *note Shelf:
     eef. class.

 -- Class: shelve.DbfilenameShelf (filename, flag='c', protocol=None,
          writeback=False)

     A subclass of *note Shelf: eef. which accepts a _filename_ instead
     of a dict-like object.  The underlying file will be opened using
     *note anydbm.open(): eea.  By default, the file will be created and
     opened for both read and write.  The optional _flag_ parameter has
     the same interpretation as for the *note open(): ee9. function.
     The optional _protocol_ and _writeback_ parameters have the same
     interpretation as for the *note Shelf: eef. class.


File: python.info,  Node: Example<5>,  Prev: Restrictions,  Up: shelve --- Python object persistence

5.11.4.2 Example
................

To summarize the interface (‘key’ is a string, ‘data’ is an arbitrary
object):

     import shelve

     d = shelve.open(filename) # open -- file may get suffix added by low-level
                               # library

     d[key] = data   # store data at key (overwrites old data if
                     # using an existing key)
     data = d[key]   # retrieve a COPY of data at key (raise KeyError if no
                     # such key)
     del d[key]      # delete data stored at key (raises KeyError
                     # if no such key)
     flag = d.has_key(key)   # true if the key exists
     klist = d.keys() # a list of all existing keys (slow!)

     # as d was opened WITHOUT writeback=True, beware:
     d['xx'] = range(4)  # this works as expected, but...
     d['xx'].append(5)   # *this doesn't!* -- d['xx'] is STILL range(4)!

     # having opened d without writeback=True, you need to code carefully:
     temp = d['xx']      # extracts the copy
     temp.append(5)      # mutates the copy
     d['xx'] = temp      # stores the copy right back, to persist it

     # or, d=shelve.open(filename,writeback=True) would let you just code
     # d['xx'].append(5) and have it work as expected, BUT it would also
     # consume more memory and make the d.close() operation slower.

     d.close()       # close it

See also
........

Module *note anydbm: b.

     Generic interface to ‘dbm’-style databases.

Module *note bsddb: 1c.

     BSD ‘db’ database interface.

Module *note dbhash: 7e.

     Thin layer around the *note bsddb: 1c. which provides an *note
     open(): ef6. function like the other database modules.

Module *note dbm: 7f.

     Standard Unix database interface.

Module *note dumbdbm: b7.

     Portable implementation of the ‘dbm’ interface.

Module *note gdbm: dc.

     GNU database interface, based on the ‘dbm’ interface.

Module *note pickle: 12d.

     Object serialization used by *note shelve: 152.

Module *note cPickle: 73.

     High-performance version of *note pickle: 12d.


File: python.info,  Node: marshal --- Internal Python object serialization,  Next: anydbm --- Generic access to DBM-style databases,  Prev: shelve --- Python object persistence,  Up: Data Persistence

5.11.5 ‘marshal’ — Internal Python object serialization
-------------------------------------------------------

This module contains functions that can read and write Python values in
a binary format.  The format is specific to Python, but independent of
machine architecture issues (e.g., you can write a Python value to a
file on a PC, transport the file to a Sun, and read it back there).
Details of the format are undocumented on purpose; it may change between
Python versions (although it rarely does).  (1)

  This is not a general "persistence" module.  For general persistence
and transfer of Python objects through RPC calls, see the modules *note
pickle: 12d. and *note shelve: 152.  The *note marshal: 10b. module
exists mainly to support reading and writing the "pseudo-compiled" code
for Python modules of ‘.pyc’ files.  Therefore, the Python maintainers
reserve the right to modify the marshal format in backward incompatible
ways should the need arise.  If you’re serializing and de-serializing
Python objects, use the *note pickle: 12d. module instead – the
performance is comparable, version independence is guaranteed, and
pickle supports a substantially wider range of objects than marshal.

     Warning: The *note marshal: 10b. module is not intended to be
     secure against erroneous or maliciously constructed data.  Never
     unmarshal data received from an untrusted or unauthenticated
     source.

  Not all Python object types are supported; in general, only objects
whose value is independent from a particular invocation of Python can be
written and read by this module.  The following types are supported:
booleans, integers, long integers, floating point numbers, complex
numbers, strings, Unicode objects, tuples, lists, sets, frozensets,
dictionaries, and code objects, where it should be understood that
tuples, lists, sets, frozensets and dictionaries are only supported as
long as the values contained therein are themselves supported; and
recursive lists, sets and dictionaries should not be written (they will
cause infinite loops).  The singletons *note None: 39a, *note Ellipsis:
899. and *note StopIteration: 333. can also be marshalled and
unmarshalled.

     Warning: On machines where C’s ‘long int’ type has more than 32
     bits (such as the DEC Alpha), it is possible to create plain Python
     integers that are longer than 32 bits.  If such an integer is
     marshaled and read back in on a machine where C’s ‘long int’ type
     has only 32 bits, a Python long integer object is returned instead.
     While of a different type, the numeric value is the same.  (This
     behavior is new in Python 2.2.  In earlier versions, all but the
     least-significant 32 bits of the value were lost, and a warning
     message was printed.)

  There are functions that read/write files as well as functions
operating on strings.

  The module defines these functions:

 -- Function: marshal.dump (value, file[, version])

     Write the value on the open file.  The value must be a supported
     type.  The file must be a open file object such as ‘sys.stdout’ or
     returned by *note open(): 2d6. or *note os.popen(): 700.  It may
     not be a wrapper such as TemporaryFile on Windows.  It must be
     opened in binary mode (‘'wb'’ or ‘'w+b'’).

     If the value has (or contains an object that has) an unsupported
     type, a *note ValueError: 236. exception is raised — but garbage
     data will also be written to the file.  The object will not be
     properly read back by *note load(): efa.

     New in version 2.4: The _version_ argument indicates the data
     format that ‘dump’ should use (see below).

 -- Function: marshal.load (file)

     Read one value from the open file and return it.  If no valid value
     is read (e.g.  because the data has a different Python version’s
     incompatible marshal format), raise *note EOFError: 88a, *note
     ValueError: 236. or *note TypeError: 218.  The file must be an open
     file object opened in binary mode (‘'rb'’ or ‘'r+b'’).

          Note: If an object containing an unsupported type was
          marshalled with *note dump(): ef9, *note load(): efa. will
          substitute ‘None’ for the unmarshallable type.

 -- Function: marshal.dumps (value[, version])

     Return the string that would be written to a file by ‘dump(value,
     file)’.  The value must be a supported type.  Raise a *note
     ValueError: 236. exception if value has (or contains an object that
     has) an unsupported type.

     New in version 2.4: The _version_ argument indicates the data
     format that ‘dumps’ should use (see below).

 -- Function: marshal.loads (string)

     Convert the string to a value.  If no valid value is found, raise
     *note EOFError: 88a, *note ValueError: 236. or *note TypeError:
     218.  Extra characters in the string are ignored.

  In addition, the following constants are defined:

 -- Data: marshal.version

     Indicates the format that the module uses.  Version 0 is the
     historical format, version 1 (added in Python 2.4) shares interned
     strings and version 2 (added in Python 2.5) uses a binary format
     for floating point numbers.  The current version is 2.

     New in version 2.4.

   ---------- Footnotes ----------

   (1) The name of this module stems from a bit of terminology used by
the designers of Modula-3 (amongst others), who use the term
"marshalling" for shipping of data around in a self-contained form.
Strictly speaking, "to marshal" means to convert some data from internal
to external form (in an RPC buffer for instance) and "unmarshalling" for
the reverse process.


File: python.info,  Node: anydbm --- Generic access to DBM-style databases,  Next: whichdb --- Guess which DBM module created a database,  Prev: marshal --- Internal Python object serialization,  Up: Data Persistence

5.11.6 ‘anydbm’ — Generic access to DBM-style databases
-------------------------------------------------------

     Note: The *note anydbm: b. module has been renamed to *note dbm:
     7f. in Python 3.  The *note 2to3: bdb. tool will automatically
     adapt imports when converting your sources to Python 3.

  *note anydbm: b. is a generic interface to variants of the DBM
database — *note dbhash: 7e. (requires *note bsddb: 1c.), *note gdbm:
dc, or *note dbm: 7f.  If none of these modules is installed, the
slow-but-simple implementation in module *note dumbdbm: b7. will be
used.

 -- Function: anydbm.open (filename[, flag[, mode]])

     Open the database file _filename_ and return a corresponding
     object.

     If the database file already exists, the *note whichdb: 197. module
     is used to determine its type and the appropriate module is used;
     if it does not exist, the first module listed above that can be
     imported is used.

     The optional _flag_ argument must be one of these values:

     Value         Meaning
                   
     --------------------------------------------------------------
                   
     ‘'r'’         Open existing database for reading only
                   (default)
                   
                   
     ‘'w'’         Open existing database for reading and
                   writing
                   
                   
     ‘'c'’         Open database for reading and writing,
                   creating it if it doesn’t exist
                   
                   
     ‘'n'’         Always create a new, empty database, open for
                   reading and writing
                   

     If not specified, the default value is ‘'r'’.

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     ‘0666’ (and will be modified by the prevailing umask).

 -- Exception: anydbm.error

     A tuple containing the exceptions that can be raised by each of the
     supported modules, with a unique exception also named *note
     anydbm.error: f00. as the first item — the latter is used when
     *note anydbm.error: f00. is raised.

  The object returned by *note open(): eea. supports most of the same
functionality as dictionaries; keys and their corresponding values can
be stored, retrieved, and deleted, and the ‘has_key()’ and ‘keys()’
methods are available.  Keys and values must always be strings.

  The following example records some hostnames and a corresponding
title, and then prints out the contents of the database:

     import anydbm

     # Open database, creating it if necessary.
     db = anydbm.open('cache', 'c')

     # Record some values
     db['www.python.org'] = 'Python Website'
     db['www.cnn.com'] = 'Cable News Network'

     # Loop through contents.  Other dictionary methods
     # such as .keys(), .values() also work.
     for k, v in db.iteritems():
         print k, '\t', v

     # Storing a non-string key or value will raise an exception (most
     # likely a TypeError).
     db['www.yahoo.com'] = 4

     # Close when done.
     db.close()

  In addition to the dictionary-like methods, ‘anydbm’ objects provide
the following method:

 -- Function: anydbm.close ()

     Close the ‘anydbm’ database.

See also
........

Module *note dbhash: 7e.

     BSD ‘db’ database interface.

Module *note dbm: 7f.

     Standard Unix database interface.

Module *note dumbdbm: b7.

     Portable implementation of the ‘dbm’ interface.

Module *note gdbm: dc.

     GNU database interface, based on the ‘dbm’ interface.

Module *note shelve: 152.

     General object persistence built on top of the Python ‘dbm’
     interface.

Module *note whichdb: 197.

     Utility module used to determine the type of an existing database.


File: python.info,  Node: whichdb --- Guess which DBM module created a database,  Next: dbm --- Simple "database" interface,  Prev: anydbm --- Generic access to DBM-style databases,  Up: Data Persistence

5.11.7 ‘whichdb’ — Guess which DBM module created a database
------------------------------------------------------------

     Note: The *note whichdb: 197. module’s only function has been put
     into the *note dbm: 7f. module in Python 3.  The *note 2to3: bdb.
     tool will automatically adapt imports when converting your sources
     to Python 3.

  The single function in this module attempts to guess which of the
several simple database modules available–*note dbm: 7f, *note gdbm: dc,
or *note dbhash: 7e.–should be used to open a given file.

 -- Function: whichdb.whichdb (filename)

     Returns one of the following values: ‘None’ if the file can’t be
     opened because it’s unreadable or doesn’t exist; the empty string
     (‘''’) if the file’s format can’t be guessed; or a string
     containing the required module name, such as ‘'dbm'’ or ‘'gdbm'’.


File: python.info,  Node: dbm --- Simple "database" interface,  Next: gdbm --- GNU's reinterpretation of dbm,  Prev: whichdb --- Guess which DBM module created a database,  Up: Data Persistence

5.11.8 ‘dbm’ — Simple "database" interface
------------------------------------------

     Note: The *note dbm: 7f. module has been renamed to ‘dbm.ndbm’ in
     Python 3.  The *note 2to3: bdb. tool will automatically adapt
     imports when converting your sources to Python 3.

  The *note dbm: 7f. module provides an interface to the Unix "(n)dbm"
library.  Dbm objects behave like mappings (dictionaries), except that
keys and values are always strings.  Printing a dbm object doesn’t print
the keys and values, and the ‘items()’ and ‘values()’ methods are not
supported.

  This module can be used with the "classic" ndbm interface, the BSD DB
compatibility interface, or the GNU GDBM compatibility interface.  On
Unix, the *configure* script will attempt to locate the appropriate
header file to simplify building this module.

  The module defines the following:

 -- Exception: dbm.error

     Raised on dbm-specific errors, such as I/O errors.  *note KeyError:
     205. is raised for general mapping errors like specifying an
     incorrect key.

 -- Data: dbm.library

     Name of the ‘ndbm’ implementation library used.

 -- Function: dbm.open (filename[, flag[, mode]])

     Open a dbm database and return a dbm object.  The _filename_
     argument is the name of the database file (without the ‘.dir’ or
     ‘.pag’ extensions; note that the BSD DB implementation of the
     interface will append the extension ‘.db’ and only create one
     file).

     The optional _flag_ argument must be one of these values:

     Value         Meaning
                   
     --------------------------------------------------------------
                   
     ‘'r'’         Open existing database for reading only
                   (default)
                   
                   
     ‘'w'’         Open existing database for reading and
                   writing
                   
                   
     ‘'c'’         Open database for reading and writing,
                   creating it if it doesn’t exist
                   
                   
     ‘'n'’         Always create a new, empty database, open for
                   reading and writing
                   

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     ‘0666’ (and will be modified by the prevailing umask).

     In addition to the dictionary-like methods, ‘dbm’ objects provide
     the following method:

      -- Function: dbm.close ()

          Close the ‘dbm’ database.

See also
........

Module *note anydbm: b.

     Generic interface to ‘dbm’-style databases.

Module *note gdbm: dc.

     Similar interface to the GNU GDBM library.

Module *note whichdb: 197.

     Utility module used to determine the type of an existing database.


File: python.info,  Node: gdbm --- GNU's reinterpretation of dbm,  Next: dbhash --- DBM-style interface to the BSD database library,  Prev: dbm --- Simple "database" interface,  Up: Data Persistence

5.11.9 ‘gdbm’ — GNU’s reinterpretation of dbm
---------------------------------------------

     Note: The *note gdbm: dc. module has been renamed to ‘dbm.gnu’ in
     Python 3.  The *note 2to3: bdb. tool will automatically adapt
     imports when converting your sources to Python 3.

  This module is quite similar to the *note dbm: 7f. module, but uses
‘gdbm’ instead to provide some additional functionality.  Please note
that the file formats created by ‘gdbm’ and ‘dbm’ are incompatible.

  The *note gdbm: dc. module provides an interface to the GNU DBM
library.  ‘gdbm’ objects behave like mappings (dictionaries), except
that keys and values are always strings.  Printing a ‘gdbm’ object
doesn’t print the keys and values, and the ‘items()’ and ‘values()’
methods are not supported.

  The module defines the following constant and functions:

 -- Exception: gdbm.error

     Raised on ‘gdbm’-specific errors, such as I/O errors.  *note
     KeyError: 205. is raised for general mapping errors like specifying
     an incorrect key.

 -- Function: gdbm.open (filename[, flag[, mode]])

     Open a ‘gdbm’ database and return a ‘gdbm’ object.  The _filename_
     argument is the name of the database file.

     The optional _flag_ argument can be:

     Value         Meaning
                   
     --------------------------------------------------------------
                   
     ‘'r'’         Open existing database for reading only
                   (default)
                   
                   
     ‘'w'’         Open existing database for reading and
                   writing
                   
                   
     ‘'c'’         Open database for reading and writing,
                   creating it if it doesn’t exist
                   
                   
     ‘'n'’         Always create a new, empty database, open for
                   reading and writing
                   

     The following additional characters may be appended to the flag to
     control how the database is opened:

     Value         Meaning
                   
     ---------------------------------------------------------------
                   
     ‘'f'’         Open the database in fast mode.  Writes to the
                   database will not be synchronized.
                   
                   
     ‘'s'’         Synchronized mode.  This will cause changes to
                   the database to be immediately written to the
                   file.
                   
                   
     ‘'u'’         Do not lock database.
                   

     Not all flags are valid for all versions of ‘gdbm’.  The module
     constant ‘open_flags’ is a string of supported flag characters.
     The exception *note error: f0d. is raised if an invalid flag is
     specified.

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     ‘0666’.

  In addition to the dictionary-like methods, ‘gdbm’ objects have the
following methods:

 -- Function: gdbm.firstkey ()

     It’s possible to loop over every key in the database using this
     method and the *note nextkey(): f10. method.  The traversal is
     ordered by ‘gdbm’’s internal hash values, and won’t be sorted by
     the key values.  This method returns the starting key.

 -- Function: gdbm.nextkey (key)

     Returns the key that follows _key_ in the traversal.  The following
     code prints every key in the database ‘db’, without having to
     create a list in memory that contains them all:

          k = db.firstkey()
          while k != None:
              print k
              k = db.nextkey(k)

 -- Function: gdbm.reorganize ()

     If you have carried out a lot of deletions and would like to shrink
     the space used by the ‘gdbm’ file, this routine will reorganize the
     database.  ‘gdbm’ will not shorten the length of a database file
     except by using this reorganization; otherwise, deleted file space
     will be kept and reused as new (key, value) pairs are added.

 -- Function: gdbm.sync ()

     When the database has been opened in fast mode, this method forces
     any unwritten data to be written to the disk.

 -- Function: gdbm.close ()

     Close the ‘gdbm’ database.

See also
........

Module *note anydbm: b.

     Generic interface to ‘dbm’-style databases.

Module *note whichdb: 197.

     Utility module used to determine the type of an existing database.


File: python.info,  Node: dbhash --- DBM-style interface to the BSD database library,  Next: bsddb --- Interface to Berkeley DB library,  Prev: gdbm --- GNU's reinterpretation of dbm,  Up: Data Persistence

5.11.10 ‘dbhash’ — DBM-style interface to the BSD database library
------------------------------------------------------------------

Deprecated since version 2.6: The *note dbhash: 7e. module has been
removed in Python 3.

  The *note dbhash: 7e. module provides a function to open databases
using the BSD ‘db’ library.  This module mirrors the interface of the
other Python database modules that provide access to DBM-style
databases.  The *note bsddb: 1c. module is required to use *note dbhash:
7e.

  This module provides an exception and a function:

 -- Exception: dbhash.error

     Exception raised on database errors other than *note KeyError: 205.
     It is a synonym for ‘bsddb.error’.

 -- Function: dbhash.open (path[, flag[, mode]])

     Open a ‘db’ database and return the database object.  The _path_
     argument is the name of the database file.

     The _flag_ argument can be:

     Value         Meaning
                   
     --------------------------------------------------------------
                   
     ‘'r'’         Open existing database for reading only
                   (default)
                   
                   
     ‘'w'’         Open existing database for reading and
                   writing
                   
                   
     ‘'c'’         Open database for reading and writing,
                   creating it if it doesn’t exist
                   
                   
     ‘'n'’         Always create a new, empty database, open for
                   reading and writing
                   

     For platforms on which the BSD ‘db’ library supports locking, an
     ‘'l'’ can be appended to indicate that locking should be used.

     The optional _mode_ parameter is used to indicate the Unix
     permission bits that should be set if a new database must be
     created; this will be masked by the current umask value for the
     process.

See also
........

Module *note anydbm: b.

     Generic interface to ‘dbm’-style databases.

Module *note bsddb: 1c.

     Lower-level interface to the BSD ‘db’ library.

Module *note whichdb: 197.

     Utility module used to determine the type of an existing database.

* Menu:

* Database Objects:: 


File: python.info,  Node: Database Objects,  Up: dbhash --- DBM-style interface to the BSD database library

5.11.10.1 Database Objects
..........................

The database objects returned by *note open(): ef6. provide the methods
common to all the DBM-style databases and mapping objects.  The
following methods are available in addition to the standard methods.

 -- Method: dbhash.first ()

     It’s possible to loop over every key/value pair in the database
     using this method and the ‘next()’ method.  The traversal is
     ordered by the databases internal hash values, and won’t be sorted
     by the key values.  This method returns the starting key.

 -- Method: dbhash.last ()

     Return the last key/value pair in a database traversal.  This may
     be used to begin a reverse-order traversal; see *note previous():
     f1b.

 -- Method: dbhash.next ()

     Returns the key next key/value pair in a database traversal.  The
     following code prints every key in the database ‘db’, without
     having to create a list in memory that contains them all:

          print db.first()
          for i in xrange(1, len(db)):
              print db.next()

 -- Method: dbhash.previous ()

     Returns the previous key/value pair in a forward-traversal of the
     database.  In conjunction with *note last(): f1a, this may be used
     to implement a reverse-order traversal.

 -- Method: dbhash.sync ()

     This method forces any unwritten data to be written to the disk.


File: python.info,  Node: bsddb --- Interface to Berkeley DB library,  Next: dumbdbm --- Portable DBM implementation,  Prev: dbhash --- DBM-style interface to the BSD database library,  Up: Data Persistence

5.11.11 ‘bsddb’ — Interface to Berkeley DB library
--------------------------------------------------

Deprecated since version 2.6: The *note bsddb: 1c. module has been
removed in Python 3.

  The *note bsddb: 1c. module provides an interface to the Berkeley DB
library.  Users can create hash, btree or record based library files
using the appropriate open call.  Bsddb objects behave generally like
dictionaries.  Keys and values must be strings, however, so to use other
objects as keys or to store other kinds of objects the user must
serialize them somehow, typically using *note marshal.dumps(): efb. or
*note pickle.dumps(): 448.

  The *note bsddb: 1c. module requires a Berkeley DB library version
from 4.0 thru 4.7.

See also
........

‘http://www.jcea.es/programacion/pybsddb.htm’

     The website with documentation for the ‘bsddb.db’ Python Berkeley
     DB interface that closely mirrors the object oriented interface
     provided in Berkeley DB 4.x itself.

‘http://www.oracle.com/database/berkeley-db/’

     The Berkeley DB library.

  A more modern DB, DBEnv and DBSequence object interface is available
in the ‘bsddb.db’ module which closely matches the Berkeley DB C API
documented at the above URLs.  Additional features provided by the
‘bsddb.db’ API include fine tuning, transactions, logging, and
multiprocess concurrent database access.

  The following is a description of the legacy *note bsddb: 1c.
interface compatible with the old Python bsddb module.  Starting in
Python 2.5 this interface should be safe for multithreaded access.  The
‘bsddb.db’ API is recommended for threading users as it provides better
control.

  The *note bsddb: 1c. module defines the following functions that
create objects that access the appropriate type of Berkeley DB file.
The first two arguments of each function are the same.  For ease of
portability, only the first two arguments should be used in most
instances.

 -- Function: bsddb.hashopen (filename[, flag[, mode[, pgsize[,
          ffactor[, nelem[, cachesize[, lorder[, hflags]]]]]]]])

     Open the hash format file named _filename_.  Files never intended
     to be preserved on disk may be created by passing ‘None’ as the
     _filename_.  The optional _flag_ identifies the mode used to open
     the file.  It may be ‘'r'’ (read only), ‘'w'’ (read-write), ‘'c'’
     (read-write - create if necessary; the default) or ‘'n'’
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level ‘dbopen()’
     function.  Consult the Berkeley DB documentation for their use and
     interpretation.

 -- Function: bsddb.btopen (filename[, flag[, mode[, btflags[,
          cachesize[, maxkeypage[, minkeypage[, pgsize[, lorder]]]]]]]])

     Open the btree format file named _filename_.  Files never intended
     to be preserved on disk may be created by passing ‘None’ as the
     _filename_.  The optional _flag_ identifies the mode used to open
     the file.  It may be ‘'r'’ (read only), ‘'w'’ (read-write), ‘'c'’
     (read-write - create if necessary; the default) or ‘'n'’
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level dbopen function.
     Consult the Berkeley DB documentation for their use and
     interpretation.

 -- Function: bsddb.rnopen (filename[, flag[, mode[, rnflags[,
          cachesize[, pgsize[, lorder[, rlen[, delim[, source[,
          pad]]]]]]]]]])

     Open a DB record format file named _filename_.  Files never
     intended to be preserved on disk may be created by passing ‘None’
     as the _filename_.  The optional _flag_ identifies the mode used to
     open the file.  It may be ‘'r'’ (read only), ‘'w'’ (read-write),
     ‘'c'’ (read-write - create if necessary; the default) or ‘'n'’
     (read-write - truncate to zero length).  The other arguments are
     rarely used and are just passed to the low-level dbopen function.
     Consult the Berkeley DB documentation for their use and
     interpretation.

     Note: Beginning in 2.3 some Unix versions of Python may have a
     ‘bsddb185’ module.  This is present _only_ to allow backwards
     compatibility with systems which ship with the old Berkeley DB 1.85
     database library.  The ‘bsddb185’ module should never be used
     directly in new code.  The module has been removed in Python 3.  If
     you find you still need it look in PyPI.

See also
........

Module *note dbhash: 7e.

     DBM-style interface to the *note bsddb: 1c.

* Menu:

* Hash, BTree and Record Objects: Hash BTree and Record Objects. 


File: python.info,  Node: Hash BTree and Record Objects,  Up: bsddb --- Interface to Berkeley DB library

5.11.11.1 Hash, BTree and Record Objects
........................................

Once instantiated, hash, btree and record objects support the same
methods as dictionaries.  In addition, they support the methods listed
below.

  Changed in version 2.3.1: Added dictionary methods.

 -- Method: bsddbobject.close ()

     Close the underlying file.  The object can no longer be accessed.
     Since there is no open *note open(): 2d6. method for these objects,
     to open the file again a new *note bsddb: 1c. module open function
     must be called.

 -- Method: bsddbobject.keys ()

     Return the list of keys contained in the DB file.  The order of the
     list is unspecified and should not be relied on.  In particular,
     the order of the list returned is different for different file
     formats.

 -- Method: bsddbobject.has_key (key)

     Return ‘1’ if the DB file contains the argument as a key.

 -- Method: bsddbobject.set_location (key)

     Set the cursor to the item indicated by _key_ and return a tuple
     containing the key and its value.  For binary tree databases
     (opened using *note btopen(): ef2.), if _key_ does not actually
     exist in the database, the cursor will point to the next item in
     sorted order and return that key and value.  For other databases,
     *note KeyError: 205. will be raised if _key_ is not found in the
     database.

 -- Method: bsddbobject.first ()

     Set the cursor to the first item in the DB file and return it.  The
     order of keys in the file is unspecified, except in the case of
     B-Tree databases.  This method raises ‘bsddb.error’ if the database
     is empty.

 -- Method: bsddbobject.next ()

     Set the cursor to the next item in the DB file and return it.  The
     order of keys in the file is unspecified, except in the case of
     B-Tree databases.

 -- Method: bsddbobject.previous ()

     Set the cursor to the previous item in the DB file and return it.
     The order of keys in the file is unspecified, except in the case of
     B-Tree databases.  This is not supported on hashtable databases
     (those opened with *note hashopen(): ef1.).

 -- Method: bsddbobject.last ()

     Set the cursor to the last item in the DB file and return it.  The
     order of keys in the file is unspecified.  This is not supported on
     hashtable databases (those opened with *note hashopen(): ef1.).
     This method raises ‘bsddb.error’ if the database is empty.

 -- Method: bsddbobject.sync ()

     Synchronize the database on disk.

  Example:

     >>> import bsddb
     >>> db = bsddb.btopen('spam.db', 'c')
     >>> for i in range(10): db['%d'%i] = '%d'% (i*i)
     ...
     >>> db['3']
     '9'
     >>> db.keys()
     ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']
     >>> db.first()
     ('0', '0')
     >>> db.next()
     ('1', '1')
     >>> db.last()
     ('9', '81')
     >>> db.set_location('2')
     ('2', '4')
     >>> db.previous()
     ('1', '1')
     >>> for k, v in db.iteritems():
     ...     print k, v
     0 0
     1 1
     2 4
     3 9
     4 16
     5 25
     6 36
     7 49
     8 64
     9 81
     >>> '8' in db
     True
     >>> db.sync()
     0


File: python.info,  Node: dumbdbm --- Portable DBM implementation,  Next: sqlite3 --- DB-API 2 0 interface for SQLite databases,  Prev: bsddb --- Interface to Berkeley DB library,  Up: Data Persistence

5.11.12 ‘dumbdbm’ — Portable DBM implementation
-----------------------------------------------

     Note: The *note dumbdbm: b7. module has been renamed to ‘dbm.dumb’
     in Python 3.  The *note 2to3: bdb. tool will automatically adapt
     imports when converting your sources to Python 3.

     Note: The *note dumbdbm: b7. module is intended as a last resort
     fallback for the *note anydbm: b. module when no more robust module
     is available.  The *note dumbdbm: b7. module is not written for
     speed and is not nearly as heavily used as the other database
     modules.

  The *note dumbdbm: b7. module provides a persistent dictionary-like
interface which is written entirely in Python.  Unlike other modules
such as *note gdbm: dc. and *note bsddb: 1c, no external library is
required.  As with other persistent mappings, the keys and values must
always be strings.

  The module defines the following:

 -- Exception: dumbdbm.error

     Raised on dumbdbm-specific errors, such as I/O errors.  *note
     KeyError: 205. is raised for general mapping errors like specifying
     an incorrect key.

 -- Function: dumbdbm.open (filename[, flag[, mode]])

     Open a dumbdbm database and return a dumbdbm object.  The
     _filename_ argument is the basename of the database file (without
     any specific extensions).  When a dumbdbm database is created,
     files with ‘.dat’ and ‘.dir’ extensions are created.

     The optional _flag_ argument is currently ignored; the database is
     always opened for update, and will be created if it does not exist.

     The optional _mode_ argument is the Unix mode of the file, used
     only when the database has to be created.  It defaults to octal
     ‘0666’ (and will be modified by the prevailing umask).

     Changed in version 2.2: The _mode_ argument was ignored in earlier
     versions.

  In addition to the dictionary-like methods, ‘dumbdm’ objects provide
the following method:

 -- Function: dumbdbm.close ()

     Close the ‘dumbdm’ database.

See also
........

Module *note anydbm: b.

     Generic interface to ‘dbm’-style databases.

Module *note dbm: 7f.

     Similar interface to the DBM/NDBM library.

Module *note gdbm: dc.

     Similar interface to the GNU GDBM library.

Module *note shelve: 152.

     Persistence module which stores non-string data.

Module *note whichdb: 197.

     Utility module used to determine the type of an existing database.

* Menu:

* Dumbdbm Objects:: 


File: python.info,  Node: Dumbdbm Objects,  Up: dumbdbm --- Portable DBM implementation

5.11.12.1 Dumbdbm Objects
.........................

In addition to the methods provided by the *note UserDict.DictMixin:
c00. class, *note dumbdbm: b7. objects provide the following methods.

 -- Method: dumbdbm.sync ()

     Synchronize the on-disk directory and data files.  This method is
     called by the *note sync(): f32. method of ‘Shelve’ objects.


File: python.info,  Node: sqlite3 --- DB-API 2 0 interface for SQLite databases,  Prev: dumbdbm --- Portable DBM implementation,  Up: Data Persistence

5.11.13 ‘sqlite3’ — DB-API 2.0 interface for SQLite databases
-------------------------------------------------------------

New in version 2.5.

  SQLite is a C library that provides a lightweight disk-based database
that doesn’t require a separate server process and allows accessing the
database using a nonstandard variant of the SQL query language.  Some
applications can use SQLite for internal data storage.  It’s also
possible to prototype an application using SQLite and then port the code
to a larger database such as PostgreSQL or Oracle.

  The sqlite3 module was written by Gerhard Häring.  It provides a SQL
interface compliant with the DB-API 2.0 specification described by PEP
249(1).

  To use the module, you must first create a *note Connection: f35.
object that represents the database.  Here the data will be stored in
the ‘example.db’ file:

     import sqlite3
     conn = sqlite3.connect('example.db')

  You can also supply the special name ‘:memory:’ to create a database
in RAM.

  Once you have a *note Connection: f35, you can create a *note Cursor:
f36. object and call its *note execute(): f37. method to perform SQL
commands:

     c = conn.cursor()

     # Create table
     c.execute('''CREATE TABLE stocks
                  (date text, trans text, symbol text, qty real, price real)''')

     # Insert a row of data
     c.execute("INSERT INTO stocks VALUES ('2006-01-05','BUY','RHAT',100,35.14)")

     # Save (commit) the changes
     conn.commit()

     # We can also close the connection if we are done with it.
     # Just be sure any changes have been committed or they will be lost.
     conn.close()

  The data you’ve saved is persistent and is available in subsequent
sessions:

     import sqlite3
     conn = sqlite3.connect('example.db')
     c = conn.cursor()

  Usually your SQL operations will need to use values from Python
variables.  You shouldn’t assemble your query using Python’s string
operations because doing so is insecure; it makes your program
vulnerable to an SQL injection attack (see ‘http://xkcd.com/327/’ for
humorous example of what can go wrong).

  Instead, use the DB-API’s parameter substitution.  Put ‘?’ as a
placeholder wherever you want to use a value, and then provide a tuple
of values as the second argument to the cursor’s *note execute(): f37.
method.  (Other database modules may use a different placeholder, such
as ‘%s’ or ‘:1’.)  For example:

     # Never do this -- insecure!
     symbol = 'RHAT'
     c.execute("SELECT * FROM stocks WHERE symbol = '%s'" % symbol)

     # Do this instead
     t = ('RHAT',)
     c.execute('SELECT * FROM stocks WHERE symbol=?', t)
     print c.fetchone()

     # Larger example that inserts many records at a time
     purchases = [('2006-03-28', 'BUY', 'IBM', 1000, 45.00),
                  ('2006-04-05', 'BUY', 'MSFT', 1000, 72.00),
                  ('2006-04-06', 'SELL', 'IBM', 500, 53.00),
                 ]
     c.executemany('INSERT INTO stocks VALUES (?,?,?,?,?)', purchases)

  To retrieve data after executing a SELECT statement, you can either
treat the cursor as an *note iterator: 87f, call the cursor’s *note
fetchone(): f38. method to retrieve a single matching row, or call *note
fetchall(): f39. to get a list of the matching rows.

  This example uses the iterator form:

     >>> for row in c.execute('SELECT * FROM stocks ORDER BY price'):
             print row

     (u'2006-01-05', u'BUY', u'RHAT', 100, 35.14)
     (u'2006-03-28', u'BUY', u'IBM', 1000, 45.0)
     (u'2006-04-06', u'SELL', u'IBM', 500, 53.0)
     (u'2006-04-05', u'BUY', u'MSFT', 1000, 72.0)

See also
........

‘https://github.com/ghaering/pysqlite’

     The pysqlite web page – sqlite3 is developed externally under the
     name "pysqlite".

‘http://www.sqlite.org’

     The SQLite web page; the documentation describes the syntax and the
     available data types for the supported SQL dialect.

‘http://www.w3schools.com/sql/’

     Tutorial, reference and examples for learning SQL syntax.

PEP 249(2) - Database API Specification 2.0

     PEP written by Marc-André Lemburg.

* Menu:

* Module functions and constants:: 
* Connection Objects:: 
* Cursor Objects:: 
* Row Objects:: 
* SQLite and Python types:: 
* Controlling Transactions:: 
* Using sqlite3 efficiently:: 
* Common issues:: 

   ---------- Footnotes ----------

   (1) http://www.python.org/dev/peps/pep-0249

   (2) http://www.python.org/dev/peps/pep-0249


File: python.info,  Node: Module functions and constants,  Next: Connection Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.1 Module functions and constants
........................................

 -- Data: sqlite3.version

     The version number of this module, as a string.  This is not the
     version of the SQLite library.

 -- Data: sqlite3.version_info

     The version number of this module, as a tuple of integers.  This is
     not the version of the SQLite library.

 -- Data: sqlite3.sqlite_version

     The version number of the run-time SQLite library, as a string.

 -- Data: sqlite3.sqlite_version_info

     The version number of the run-time SQLite library, as a tuple of
     integers.

 -- Data: sqlite3.PARSE_DECLTYPES

     This constant is meant to be used with the _detect_types_ parameter
     of the *note connect(): f41. function.

     Setting it makes the *note sqlite3: 15f. module parse the declared
     type for each column it returns.  It will parse out the first word
     of the declared type, i.  e.  for "integer primary key", it will
     parse out "integer", or for "number(10)" it will parse out
     "number".  Then for that column, it will look into the converters
     dictionary and use the converter function registered for that type
     there.

 -- Data: sqlite3.PARSE_COLNAMES

     This constant is meant to be used with the _detect_types_ parameter
     of the *note connect(): f41. function.

     Setting this makes the SQLite interface parse the column name for
     each column it returns.  It will look for a string formed [mytype]
     in there, and then decide that ’mytype’ is the type of the column.
     It will try to find an entry of ’mytype’ in the converters
     dictionary and then use the converter function found there to
     return the value.  The column name found in *note
     Cursor.description: f43. is only the first word of the column name,
     i.  e.  if you use something like ‘'as "x [datetime]"'’ in your
     SQL, then we will parse out everything until the first blank for
     the column name: the column name would simply be "x".

 -- Function: sqlite3.connect (database[, timeout, detect_types,
          isolation_level, check_same_thread, factory,
          cached_statements])

     Opens a connection to the SQLite database file _database_.  You can
     use ‘":memory:"’ to open a database connection to a database that
     resides in RAM instead of on disk.

     When a database is accessed by multiple connections, and one of the
     processes modifies the database, the SQLite database is locked
     until that transaction is committed.  The _timeout_ parameter
     specifies how long the connection should wait for the lock to go
     away until raising an exception.  The default for the timeout
     parameter is 5.0 (five seconds).

     For the _isolation_level_ parameter, please see the *note
     Connection.isolation_level: f44. property of *note Connection: f35.
     objects.

     SQLite natively supports only the types TEXT, INTEGER, REAL, BLOB
     and NULL. If you want to use other types you must add support for
     them yourself.  The _detect_types_ parameter and the using custom
     *converters* registered with the module-level *note
     register_converter(): f45. function allow you to easily do that.

     _detect_types_ defaults to 0 (i.  e.  off, no type detection), you
     can set it to any combination of *note PARSE_DECLTYPES: f40. and
     *note PARSE_COLNAMES: f42. to turn type detection on.

     By default, the *note sqlite3: 15f. module uses its *note
     Connection: f35. class for the connect call.  You can, however,
     subclass the *note Connection: f35. class and make *note connect():
     f41. use your class instead by providing your class for the
     _factory_ parameter.

     Consult the section *note SQLite and Python types: f46. of this
     manual for details.

     The *note sqlite3: 15f. module internally uses a statement cache to
     avoid SQL parsing overhead.  If you want to explicitly set the
     number of statements that are cached for the connection, you can
     set the _cached_statements_ parameter.  The currently implemented
     default is to cache 100 statements.

 -- Function: sqlite3.register_converter (typename, callable)

     Registers a callable to convert a bytestring from the database into
     a custom Python type.  The callable will be invoked for all
     database values that are of the type _typename_.  Confer the
     parameter _detect_types_ of the *note connect(): f41. function for
     how the type detection works.  Note that the case of _typename_ and
     the name of the type in your query must match!

 -- Function: sqlite3.register_adapter (type, callable)

     Registers a callable to convert the custom Python type _type_ into
     one of SQLite’s supported types.  The callable _callable_ accepts
     as single parameter the Python value, and must return a value of
     the following types: int, long, float, str (UTF-8 encoded), unicode
     or buffer.

 -- Function: sqlite3.complete_statement (sql)

     Returns *note True: 3b0. if the string _sql_ contains one or more
     complete SQL statements terminated by semicolons.  It does not
     verify that the SQL is syntactically correct, only that there are
     no unclosed string literals and the statement is terminated by a
     semicolon.

     This can be used to build a shell for SQLite, as in the following
     example:

          # A minimal SQLite shell for experiments

          import sqlite3

          con = sqlite3.connect(":memory:")
          con.isolation_level = None
          cur = con.cursor()

          buffer = ""

          print "Enter your SQL commands to execute in sqlite3."
          print "Enter a blank line to exit."

          while True:
              line = raw_input()
              if line == "":
                  break
              buffer += line
              if sqlite3.complete_statement(buffer):
                  try:
                      buffer = buffer.strip()
                      cur.execute(buffer)

                      if buffer.lstrip().upper().startswith("SELECT"):
                          print cur.fetchall()
                  except sqlite3.Error as e:
                      print "An error occurred:", e.args[0]
                  buffer = ""

          con.close()


 -- Function: sqlite3.enable_callback_tracebacks (flag)

     By default you will not get any tracebacks in user-defined
     functions, aggregates, converters, authorizer callbacks etc.  If
     you want to debug them, you can call this function with _flag_ set
     to ‘True’.  Afterwards, you will get tracebacks from callbacks on
     ‘sys.stderr’.  Use *note False: 3b1. to disable the feature again.


File: python.info,  Node: Connection Objects,  Next: Cursor Objects,  Prev: Module functions and constants,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.2 Connection Objects
............................

 -- Class: sqlite3.Connection

     A SQLite database connection has the following attributes and
     methods:

      -- Attribute: isolation_level

          Get or set the current isolation level.  *note None: 39a. for
          autocommit mode or one of "DEFERRED", "IMMEDIATE" or
          "EXCLUSIVE". See section *note Controlling Transactions: f4c.
          for a more detailed explanation.

      -- Method: cursor ([cursorClass])

          The cursor method accepts a single optional parameter
          _cursorClass_.  If supplied, this must be a custom cursor
          class that extends *note sqlite3.Cursor: f36.

      -- Method: commit ()

          This method commits the current transaction.  If you don’t
          call this method, anything you did since the last call to
          ‘commit()’ is not visible from other database connections.  If
          you wonder why you don’t see the data you’ve written to the
          database, please check you didn’t forget to call this method.

      -- Method: rollback ()

          This method rolls back any changes to the database since the
          last call to *note commit(): f4e.

      -- Method: close ()

          This closes the database connection.  Note that this does not
          automatically call *note commit(): f4e.  If you just close
          your database connection without calling *note commit(): f4e.
          first, your changes will be lost!

      -- Method: execute (sql[, parameters])

          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor’s *note execute: f37. method with the parameters given.

      -- Method: executemany (sql[, parameters])

          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor’s *note executemany: f53. method with the parameters
          given.

      -- Method: executescript (sql_script)

          This is a nonstandard shortcut that creates an intermediate
          cursor object by calling the cursor method, then calls the
          cursor’s *note executescript: f55. method with the parameters
          given.

      -- Method: create_function (name, num_params, func)

          Creates a user-defined function that you can later use from
          within SQL statements under the function name _name_.
          _num_params_ is the number of parameters the function accepts,
          and _func_ is a Python callable that is called as the SQL
          function.

          The function can return any of the types supported by SQLite:
          unicode, str, int, long, float, buffer and None.

          Example:

               import sqlite3
               import md5

               def md5sum(t):
                   return md5.md5(t).hexdigest()

               con = sqlite3.connect(":memory:")
               con.create_function("md5", 1, md5sum)
               cur = con.cursor()
               cur.execute("select md5(?)", ("foo",))
               print cur.fetchone()[0]


      -- Method: create_aggregate (name, num_params, aggregate_class)

          Creates a user-defined aggregate function.

          The aggregate class must implement a ‘step’ method, which
          accepts the number of parameters _num_params_, and a
          ‘finalize’ method which will return the final result of the
          aggregate.

          The ‘finalize’ method can return any of the types supported by
          SQLite: unicode, str, int, long, float, buffer and None.

          Example:

               import sqlite3

               class MySum:
                   def __init__(self):
                       self.count = 0

                   def step(self, value):
                       self.count += value

                   def finalize(self):
                       return self.count

               con = sqlite3.connect(":memory:")
               con.create_aggregate("mysum", 1, MySum)
               cur = con.cursor()
               cur.execute("create table test(i)")
               cur.execute("insert into test(i) values (1)")
               cur.execute("insert into test(i) values (2)")
               cur.execute("select mysum(i) from test")
               print cur.fetchone()[0]


      -- Method: create_collation (name, callable)

          Creates a collation with the specified _name_ and _callable_.
          The callable will be passed two string arguments.  It should
          return -1 if the first is ordered lower than the second, 0 if
          they are ordered equal and 1 if the first is ordered higher
          than the second.  Note that this controls sorting (ORDER BY in
          SQL) so your comparisons don’t affect other SQL operations.

          Note that the callable will get its parameters as Python
          bytestrings, which will normally be encoded in UTF-8.

          The following example shows a custom collation that sorts "the
          wrong way":

               import sqlite3

               def collate_reverse(string1, string2):
                   return -cmp(string1, string2)

               con = sqlite3.connect(":memory:")
               con.create_collation("reverse", collate_reverse)

               cur = con.cursor()
               cur.execute("create table test(x)")
               cur.executemany("insert into test(x) values (?)", [("a",), ("b",)])
               cur.execute("select x from test order by x collate reverse")
               for row in cur:
                   print row
               con.close()


          To remove a collation, call ‘create_collation’ with None as
          callable:

               con.create_collation("reverse", None)

      -- Method: interrupt ()

          You can call this method from a different thread to abort any
          queries that might be executing on the connection.  The query
          will then abort and the caller will get an exception.

      -- Method: set_authorizer (authorizer_callback)

          This routine registers a callback.  The callback is invoked
          for each attempt to access a column of a table in the
          database.  The callback should return ‘SQLITE_OK’ if access is
          allowed, ‘SQLITE_DENY’ if the entire SQL statement should be
          aborted with an error and ‘SQLITE_IGNORE’ if the column should
          be treated as a NULL value.  These constants are available in
          the *note sqlite3: 15f. module.

          The first argument to the callback signifies what kind of
          operation is to be authorized.  The second and third argument
          will be arguments or *note None: 39a. depending on the first
          argument.  The 4th argument is the name of the database
          ("main", "temp", etc.)  if applicable.  The 5th argument is
          the name of the inner-most trigger or view that is responsible
          for the access attempt or *note None: 39a. if this access
          attempt is directly from input SQL code.

          Please consult the SQLite documentation about the possible
          values for the first argument and the meaning of the second
          and third argument depending on the first one.  All necessary
          constants are available in the *note sqlite3: 15f. module.

      -- Method: set_progress_handler (handler, n)

          This routine registers a callback.  The callback is invoked
          for every _n_ instructions of the SQLite virtual machine.
          This is useful if you want to get called from SQLite during
          long-running operations, for example to update a GUI.

          If you want to clear any previously installed progress
          handler, call the method with *note None: 39a. for _handler_.

          New in version 2.6.

      -- Method: enable_load_extension (enabled)

          This routine allows/disallows the SQLite engine to load SQLite
          extensions from shared libraries.  SQLite extensions can
          define new functions, aggregates or whole new virtual table
          implementations.  One well-known extension is the
          fulltext-search extension distributed with SQLite.

          Loadable extensions are disabled by default.  See (1).

          New in version 2.7.

               import sqlite3

               con = sqlite3.connect(":memory:")

               # enable extension loading
               con.enable_load_extension(True)

               # Load the fulltext search extension
               con.execute("select load_extension('./fts3.so')")

               # alternatively you can load the extension using an API call:
               # con.load_extension("./fts3.so")

               # disable extension laoding again
               con.enable_load_extension(False)

               # example from SQLite wiki
               con.execute("create virtual table recipe using fts3(name, ingredients)")
               con.executescript("""
                   insert into recipe (name, ingredients) values ('broccoli stew', 'broccoli peppers cheese tomatoes');
                   insert into recipe (name, ingredients) values ('pumpkin stew', 'pumpkin onions garlic celery');
                   insert into recipe (name, ingredients) values ('broccoli pie', 'broccoli cheese onions flour');
                   insert into recipe (name, ingredients) values ('pumpkin pie', 'pumpkin sugar flour butter');
                   """)
               for row in con.execute("select rowid, name, ingredients from recipe where name match 'pie'"):
                   print row


      -- Method: load_extension (path)

          This routine loads a SQLite extension from a shared library.
          You have to enable extension loading with *note
          enable_load_extension(): f5c. before you can use this routine.

          Loadable extensions are disabled by default.  See (2).

          New in version 2.7.

      -- Attribute: row_factory

          You can change this attribute to a callable that accepts the
          cursor and the original row as a tuple and will return the
          real result row.  This way, you can implement more advanced
          ways of returning results, such as returning an object that
          can also access columns by name.

          Example:

               import sqlite3

               def dict_factory(cursor, row):
                   d = {}
                   for idx, col in enumerate(cursor.description):
                       d[col[0]] = row[idx]
                   return d

               con = sqlite3.connect(":memory:")
               con.row_factory = dict_factory
               cur = con.cursor()
               cur.execute("select 1 as a")
               print cur.fetchone()["a"]


          If returning a tuple doesn’t suffice and you want name-based
          access to columns, you should consider setting *note
          row_factory: f5d. to the highly-optimized *note sqlite3.Row:
          f5e. type.  *note Row: f5e. provides both index-based and
          case-insensitive name-based access to columns with almost no
          memory overhead.  It will probably be better than your own
          custom dictionary-based approach or even a db_row based
          solution.

      -- Attribute: text_factory

          Using this attribute you can control what objects are returned
          for the ‘TEXT’ data type.  By default, this attribute is set
          to *note unicode: 1f5. and the *note sqlite3: 15f. module will
          return Unicode objects for ‘TEXT’.  If you want to return
          bytestrings instead, you can set it to *note str: 1ea.

          For efficiency reasons, there’s also a way to return Unicode
          objects only for non-ASCII data, and bytestrings otherwise.
          To activate it, set this attribute to
          ‘sqlite3.OptimizedUnicode’.

          You can also set it to any other callable that accepts a
          single bytestring parameter and returns the resulting object.

          See the following example code for illustration:

               import sqlite3

               con = sqlite3.connect(":memory:")
               cur = con.cursor()

               AUSTRIA = u"\xd6sterreich"

               # by default, rows are returned as Unicode
               cur.execute("select ?", (AUSTRIA,))
               row = cur.fetchone()
               assert row[0] == AUSTRIA

               # but we can make sqlite3 always return bytestrings ...
               con.text_factory = str
               cur.execute("select ?", (AUSTRIA,))
               row = cur.fetchone()
               assert type(row[0]) is str
               # the bytestrings will be encoded in UTF-8, unless you stored garbage in the
               # database ...
               assert row[0] == AUSTRIA.encode("utf-8")

               # we can also implement a custom text_factory ...
               # here we implement one that will ignore Unicode characters that cannot be
               # decoded from UTF-8
               con.text_factory = lambda x: unicode(x, "utf-8", "ignore")
               cur.execute("select ?", ("this is latin1 and would normally create errors" +
                                        u"\xe4\xf6\xfc".encode("latin1"),))
               row = cur.fetchone()
               assert type(row[0]) is unicode

               # sqlite3 offers a built-in optimized text_factory that will return bytestring
               # objects, if the data is in ASCII only, and otherwise return unicode objects
               con.text_factory = sqlite3.OptimizedUnicode
               cur.execute("select ?", (AUSTRIA,))
               row = cur.fetchone()
               assert type(row[0]) is unicode

               cur.execute("select ?", ("Germany",))
               row = cur.fetchone()
               assert type(row[0]) is str


      -- Attribute: total_changes

          Returns the total number of database rows that have been
          modified, inserted, or deleted since the database connection
          was opened.

      -- Attribute: iterdump

          Returns an iterator to dump the database in an SQL text
          format.  Useful when saving an in-memory database for later
          restoration.  This function provides the same capabilities as
          the ‘.dump’ command in the *sqlite3* shell.

          New in version 2.6.

          Example:

               # Convert file existing_db.db to SQL dump file dump.sql
               import sqlite3, os

               con = sqlite3.connect('existing_db.db')
               with open('dump.sql', 'w') as f:
                   for line in con.iterdump():
                       f.write('%s\n' % line)

   ---------- Footnotes ----------

   (1) The sqlite3 module is not built with loadable extension support
by default, because some platforms (notably Mac OS X) have SQLite
libraries which are compiled without this feature.  To get loadable
extension support, you must modify setup.py and remove the line that
sets SQLITE_OMIT_LOAD_EXTENSION.

   (2) The sqlite3 module is not built with loadable extension support
by default, because some platforms (notably Mac OS X) have SQLite
libraries which are compiled without this feature.  To get loadable
extension support, you must modify setup.py and remove the line that
sets SQLITE_OMIT_LOAD_EXTENSION.


File: python.info,  Node: Cursor Objects,  Next: Row Objects,  Prev: Connection Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.3 Cursor Objects
........................

 -- Class: sqlite3.Cursor

     A *note Cursor: f36. instance has the following attributes and
     methods.

      -- Method: execute (sql[, parameters])

          Executes an SQL statement.  The SQL statement may be
          parameterized (i.  e.  placeholders instead of SQL literals).
          The *note sqlite3: 15f. module supports two kinds of
          placeholders: question marks (qmark style) and named
          placeholders (named style).

          Here’s an example of both styles:

               import sqlite3

               con = sqlite3.connect(":memory:")
               cur = con.cursor()
               cur.execute("create table people (name_last, age)")

               who = "Yeltsin"
               age = 72

               # This is the qmark style:
               cur.execute("insert into people values (?, ?)", (who, age))

               # And this is the named style:
               cur.execute("select * from people where name_last=:who and age=:age", {"who": who, "age": age})

               print cur.fetchone()


          *note execute(): f37. will only execute a single SQL
          statement.  If you try to execute more than one statement with
          it, it will raise a Warning.  Use *note executescript(): f55.
          if you want to execute multiple SQL statements with one call.

      -- Method: executemany (sql, seq_of_parameters)

          Executes an SQL command against all parameter sequences or
          mappings found in the sequence _sql_.  The *note sqlite3: 15f.
          module also allows using an *note iterator: 87f. yielding
          parameters instead of a sequence.

               import sqlite3

               class IterChars:
                   def __init__(self):
                       self.count = ord('a')

                   def __iter__(self):
                       return self

                   def next(self):
                       if self.count > ord('z'):
                           raise StopIteration
                       self.count += 1
                       return (chr(self.count - 1),) # this is a 1-tuple

               con = sqlite3.connect(":memory:")
               cur = con.cursor()
               cur.execute("create table characters(c)")

               theIter = IterChars()
               cur.executemany("insert into characters(c) values (?)", theIter)

               cur.execute("select c from characters")
               print cur.fetchall()


          Here’s a shorter example using a *note generator: 5dc.:

               import sqlite3
               import string

               def char_generator():
                   for c in string.lowercase:
                       yield (c,)

               con = sqlite3.connect(":memory:")
               cur = con.cursor()
               cur.execute("create table characters(c)")

               cur.executemany("insert into characters(c) values (?)", char_generator())

               cur.execute("select c from characters")
               print cur.fetchall()


      -- Method: executescript (sql_script)

          This is a nonstandard convenience method for executing
          multiple SQL statements at once.  It issues a ‘COMMIT’
          statement first, then executes the SQL script it gets as a
          parameter.

          _sql_script_ can be a bytestring or a Unicode string.

          Example:

               import sqlite3

               con = sqlite3.connect(":memory:")
               cur = con.cursor()
               cur.executescript("""
                   create table person(
                       firstname,
                       lastname,
                       age
                   );

                   create table book(
                       title,
                       author,
                       published
                   );

                   insert into book(title, author, published)
                   values (
                       'Dirk Gently''s Holistic Detective Agency',
                       'Douglas Adams',
                       1987
                   );
                   """)


      -- Method: fetchone ()

          Fetches the next row of a query result set, returning a single
          sequence, or *note None: 39a. when no more data is available.

      -- Method: fetchmany ([size=cursor.arraysize])

          Fetches the next set of rows of a query result, returning a
          list.  An empty list is returned when no more rows are
          available.

          The number of rows to fetch per call is specified by the
          _size_ parameter.  If it is not given, the cursor’s arraysize
          determines the number of rows to be fetched.  The method
          should try to fetch as many rows as indicated by the size
          parameter.  If this is not possible due to the specified
          number of rows not being available, fewer rows may be
          returned.

          Note there are performance considerations involved with the
          _size_ parameter.  For optimal performance, it is usually best
          to use the arraysize attribute.  If the _size_ parameter is
          used, then it is best for it to retain the same value from one
          *note fetchmany(): f64. call to the next.

      -- Method: fetchall ()

          Fetches all (remaining) rows of a query result, returning a
          list.  Note that the cursor’s arraysize attribute can affect
          the performance of this operation.  An empty list is returned
          when no rows are available.

      -- Attribute: rowcount

          Although the *note Cursor: f36. class of the *note sqlite3:
          15f. module implements this attribute, the database engine’s
          own support for the determination of "rows affected"/"rows
          selected" is quirky.

          For *note executemany(): f53. statements, the number of
          modifications are summed up into *note rowcount: f65.

          As required by the Python DB API Spec, the *note rowcount:
          f65. attribute "is -1 in case no ‘executeXX()’ has been
          performed on the cursor or the rowcount of the last operation
          is not determinable by the interface".  This includes ‘SELECT’
          statements because we cannot determine the number of rows a
          query produced until all rows were fetched.

          With SQLite versions before 3.6.5, *note rowcount: f65. is set
          to 0 if you make a ‘DELETE FROM table’ without any condition.

      -- Attribute: lastrowid

          This read-only attribute provides the rowid of the last
          modified row.  It is only set if you issued a ‘INSERT’
          statement using the *note execute(): f37. method.  For
          operations other than ‘INSERT’ or when *note executemany():
          f53. is called, *note lastrowid: f66. is set to *note None:
          39a.

      -- Attribute: description

          This read-only attribute provides the column names of the last
          query.  To remain compatible with the Python DB API, it
          returns a 7-tuple for each column where the last six items of
          each tuple are *note None: 39a.

          It is set for ‘SELECT’ statements without any matching rows as
          well.


File: python.info,  Node: Row Objects,  Next: SQLite and Python types,  Prev: Cursor Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.4 Row Objects
.....................

 -- Class: sqlite3.Row

     A *note Row: f5e. instance serves as a highly optimized *note
     row_factory: f5d. for *note Connection: f35. objects.  It tries to
     mimic a tuple in most of its features.

     It supports mapping access by column name and index, iteration,
     representation, equality testing and *note len(): 520.

     If two *note Row: f5e. objects have exactly the same columns and
     their members are equal, they compare equal.

     Changed in version 2.6: Added iteration and equality (hashability).

      -- Method: keys ()

          This method returns a list of column names.  Immediately after
          a query, it is the first member of each tuple in *note
          Cursor.description: f43.

          New in version 2.6.

  Let’s assume we initialize a table as in the example given above:

     conn = sqlite3.connect(":memory:")
     c = conn.cursor()
     c.execute('''create table stocks
     (date text, trans text, symbol text,
      qty real, price real)''')
     c.execute("""insert into stocks
               values ('2006-01-05','BUY','RHAT',100,35.14)""")
     conn.commit()
     c.close()

  Now we plug *note Row: f5e. in:

     >>> conn.row_factory = sqlite3.Row
     >>> c = conn.cursor()
     >>> c.execute('select * from stocks')
     <sqlite3.Cursor object at 0x7f4e7dd8fa80>
     >>> r = c.fetchone()
     >>> type(r)
     <type 'sqlite3.Row'>
     >>> r
     (u'2006-01-05', u'BUY', u'RHAT', 100.0, 35.14)
     >>> len(r)
     5
     >>> r[2]
     u'RHAT'
     >>> r.keys()
     ['date', 'trans', 'symbol', 'qty', 'price']
     >>> r['qty']
     100.0
     >>> for member in r:
     ...     print member
     ...
     2006-01-05
     BUY
     RHAT
     100.0
     35.14


File: python.info,  Node: SQLite and Python types,  Next: Controlling Transactions,  Prev: Row Objects,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.5 SQLite and Python types
.................................

* Menu:

* Introduction: Introduction<6>. 
* Using adapters to store additional Python types in SQLite databases:: 
* Converting SQLite values to custom Python types:: 
* Default adapters and converters:: 


File: python.info,  Node: Introduction<6>,  Next: Using adapters to store additional Python types in SQLite databases,  Up: SQLite and Python types

5.11.13.6 Introduction
......................

SQLite natively supports the following types: ‘NULL’, ‘INTEGER’, ‘REAL’,
‘TEXT’, ‘BLOB’.

  The following Python types can thus be sent to SQLite without any
problem:

Python type                       SQLite type
                                  
----------------------------------------------------
                                  
*note None: 39a.                  ‘NULL’
                                  
                                  
*note int: 1f2.                   ‘INTEGER’
                                  
                                  
*note long: 1f3.                  ‘INTEGER’
                                  
                                  
*note float: 1eb.                 ‘REAL’
                                  
                                  
*note str: 1ea. (UTF8-encoded)    ‘TEXT’
                                  
                                  
*note unicode: 1f5.               ‘TEXT’
                                  
                                  
*note buffer: 316.                ‘BLOB’
                                  

  This is how SQLite types are converted to Python types by default:

SQLite type       Python type
                  
---------------------------------------------------------------------
                  
‘NULL’            *note None: 39a.
                  
                  
‘INTEGER’         *note int: 1f2. or *note long: 1f3, depending on
                  size
                  
                  
‘REAL’            *note float: 1eb.
                  
                  
‘TEXT’            depends on *note text_factory: f5f, *note
                  unicode: 1f5. by default
                  
                  
‘BLOB’            *note buffer: 316.
                  

  The type system of the *note sqlite3: 15f. module is extensible in two
ways: you can store additional Python types in a SQLite database via
object adaptation, and you can let the *note sqlite3: 15f. module
convert SQLite types to different Python types via converters.


File: python.info,  Node: Using adapters to store additional Python types in SQLite databases,  Next: Converting SQLite values to custom Python types,  Prev: Introduction<6>,  Up: SQLite and Python types

5.11.13.7 Using adapters to store additional Python types in SQLite databases
.............................................................................

As described before, SQLite supports only a limited set of types
natively.  To use other Python types with SQLite, you must *adapt* them
to one of the sqlite3 module’s supported types for SQLite: one of
NoneType, int, long, float, str, unicode, buffer.

  There are two ways to enable the *note sqlite3: 15f. module to adapt a
custom Python type to one of the supported ones.

* Menu:

* Letting your object adapt itself:: 
* Registering an adapter callable:: 


File: python.info,  Node: Letting your object adapt itself,  Next: Registering an adapter callable,  Up: Using adapters to store additional Python types in SQLite databases

5.11.13.8 Letting your object adapt itself
..........................................

This is a good approach if you write the class yourself.  Let’s suppose
you have a class like this:

     class Point(object):
         def __init__(self, x, y):
             self.x, self.y = x, y

  Now you want to store the point in a single SQLite column.  First
you’ll have to choose one of the supported types first to be used for
representing the point.  Let’s just use str and separate the coordinates
using a semicolon.  Then you need to give your class a method
‘__conform__(self, protocol)’ which must return the converted value.
The parameter _protocol_ will be ‘PrepareProtocol’.

     import sqlite3

     class Point(object):
         def __init__(self, x, y):
             self.x, self.y = x, y

         def __conform__(self, protocol):
             if protocol is sqlite3.PrepareProtocol:
                 return "%f;%f" % (self.x, self.y)

     con = sqlite3.connect(":memory:")
     cur = con.cursor()

     p = Point(4.0, -3.2)
     cur.execute("select ?", (p,))
     print cur.fetchone()[0]



File: python.info,  Node: Registering an adapter callable,  Prev: Letting your object adapt itself,  Up: Using adapters to store additional Python types in SQLite databases

5.11.13.9 Registering an adapter callable
.........................................

The other possibility is to create a function that converts the type to
the string representation and register the function with *note
register_adapter(): f47.

     Note: The type/class to adapt must be a *note new-style class: 5d1,
     i.  e.  it must have *note object: 1f1. as one of its bases.

     import sqlite3

     class Point(object):
         def __init__(self, x, y):
             self.x, self.y = x, y

     def adapt_point(point):
         return "%f;%f" % (point.x, point.y)

     sqlite3.register_adapter(Point, adapt_point)

     con = sqlite3.connect(":memory:")
     cur = con.cursor()

     p = Point(4.0, -3.2)
     cur.execute("select ?", (p,))
     print cur.fetchone()[0]


  The *note sqlite3: 15f. module has two default adapters for Python’s
built-in *note datetime.date: 35d. and *note datetime.datetime: 2da.
types.  Now let’s suppose we want to store *note datetime.datetime: 2da.
objects not in ISO representation, but as a Unix timestamp.

     import sqlite3
     import datetime, time

     def adapt_datetime(ts):
         return time.mktime(ts.timetuple())

     sqlite3.register_adapter(datetime.datetime, adapt_datetime)

     con = sqlite3.connect(":memory:")
     cur = con.cursor()

     now = datetime.datetime.now()
     cur.execute("select ?", (now,))
     print cur.fetchone()[0]



File: python.info,  Node: Converting SQLite values to custom Python types,  Next: Default adapters and converters,  Prev: Using adapters to store additional Python types in SQLite databases,  Up: SQLite and Python types

5.11.13.10 Converting SQLite values to custom Python types
..........................................................

Writing an adapter lets you send custom Python types to SQLite.  But to
make it really useful we need to make the Python to SQLite to Python
roundtrip work.

  Enter converters.

  Let’s go back to the ‘Point’ class.  We stored the x and y coordinates
separated via semicolons as strings in SQLite.

  First, we’ll define a converter function that accepts the string as a
parameter and constructs a ‘Point’ object from it.

     Note: Converter functions *always* get called with a string, no
     matter under which data type you sent the value to SQLite.

     def convert_point(s):
         x, y = map(float, s.split(";"))
         return Point(x, y)

  Now you need to make the *note sqlite3: 15f. module know that what you
select from the database is actually a point.  There are two ways of
doing this:

   * Implicitly via the declared type

   * Explicitly via the column name

  Both ways are described in section *note Module functions and
constants: f3b, in the entries for the constants *note PARSE_DECLTYPES:
f40. and *note PARSE_COLNAMES: f42.

  The following example illustrates both approaches.

     import sqlite3

     class Point(object):
         def __init__(self, x, y):
             self.x, self.y = x, y

         def __repr__(self):
             return "(%f;%f)" % (self.x, self.y)

     def adapt_point(point):
         return "%f;%f" % (point.x, point.y)

     def convert_point(s):
         x, y = map(float, s.split(";"))
         return Point(x, y)

     # Register the adapter
     sqlite3.register_adapter(Point, adapt_point)

     # Register the converter
     sqlite3.register_converter("point", convert_point)

     p = Point(4.0, -3.2)

     #########################
     # 1) Using declared types
     con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES)
     cur = con.cursor()
     cur.execute("create table test(p point)")

     cur.execute("insert into test(p) values (?)", (p,))
     cur.execute("select p from test")
     print "with declared types:", cur.fetchone()[0]
     cur.close()
     con.close()

     #######################
     # 1) Using column names
     con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_COLNAMES)
     cur = con.cursor()
     cur.execute("create table test(p)")

     cur.execute("insert into test(p) values (?)", (p,))
     cur.execute('select p as "p [point]" from test')
     print "with column names:", cur.fetchone()[0]
     cur.close()
     con.close()



File: python.info,  Node: Default adapters and converters,  Prev: Converting SQLite values to custom Python types,  Up: SQLite and Python types

5.11.13.11 Default adapters and converters
..........................................

There are default adapters for the date and datetime types in the
datetime module.  They will be sent as ISO dates/ISO timestamps to
SQLite.

  The default converters are registered under the name "date" for *note
datetime.date: 35d. and under the name "timestamp" for *note
datetime.datetime: 2da.

  This way, you can use date/timestamps from Python without any
additional fiddling in most cases.  The format of the adapters is also
compatible with the experimental SQLite date/time functions.

  The following example demonstrates this.

     import sqlite3
     import datetime

     con = sqlite3.connect(":memory:", detect_types=sqlite3.PARSE_DECLTYPES|sqlite3.PARSE_COLNAMES)
     cur = con.cursor()
     cur.execute("create table test(d date, ts timestamp)")

     today = datetime.date.today()
     now = datetime.datetime.now()

     cur.execute("insert into test(d, ts) values (?, ?)", (today, now))
     cur.execute("select d, ts from test")
     row = cur.fetchone()
     print today, "=>", row[0], type(row[0])
     print now, "=>", row[1], type(row[1])

     cur.execute('select current_date as "d [date]", current_timestamp as "ts [timestamp]"')
     row = cur.fetchone()
     print "current_date", row[0], type(row[0])
     print "current_timestamp", row[1], type(row[1])


  If a timestamp stored in SQLite has a fractional part longer than 6
numbers, its value will be truncated to microsecond precision by the
timestamp converter.


File: python.info,  Node: Controlling Transactions,  Next: Using sqlite3 efficiently,  Prev: SQLite and Python types,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.12 Controlling Transactions
...................................

By default, the *note sqlite3: 15f. module opens transactions implicitly
before a Data Modification Language (DML) statement (i.e.
‘INSERT’/‘UPDATE’/‘DELETE’/‘REPLACE’), and commits transactions
implicitly before a non-DML, non-query statement (i.  e.  anything other
than ‘SELECT’ or the aforementioned).

  So if you are within a transaction and issue a command like ‘CREATE
TABLE ...’, ‘VACUUM’, ‘PRAGMA’, the *note sqlite3: 15f. module will
commit implicitly before executing that command.  There are two reasons
for doing that.  The first is that some of these commands don’t work
within transactions.  The other reason is that sqlite3 needs to keep
track of the transaction state (if a transaction is active or not).

  You can control which kind of ‘BEGIN’ statements sqlite3 implicitly
executes (or none at all) via the _isolation_level_ parameter to the
*note connect(): f41. call, or via the ‘isolation_level’ property of
connections.

  If you want *autocommit mode*, then set ‘isolation_level’ to None.

  Otherwise leave it at its default, which will result in a plain
"BEGIN" statement, or set it to one of SQLite’s supported isolation
levels: "DEFERRED", "IMMEDIATE" or "EXCLUSIVE".


File: python.info,  Node: Using sqlite3 efficiently,  Next: Common issues,  Prev: Controlling Transactions,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.13 Using ‘sqlite3’ efficiently
......................................

* Menu:

* Using shortcut methods:: 
* Accessing columns by name instead of by index:: 
* Using the connection as a context manager:: 


File: python.info,  Node: Using shortcut methods,  Next: Accessing columns by name instead of by index,  Up: Using sqlite3 efficiently

5.11.13.14 Using shortcut methods
.................................

Using the nonstandard ‘execute()’, ‘executemany()’ and ‘executescript()’
methods of the *note Connection: f35. object, your code can be written
more concisely because you don’t have to create the (often superfluous)
*note Cursor: f36. objects explicitly.  Instead, the *note Cursor: f36.
objects are created implicitly and these shortcut methods return the
cursor objects.  This way, you can execute a ‘SELECT’ statement and
iterate over it directly using only a single call on the *note
Connection: f35. object.

     import sqlite3

     persons = [
         ("Hugo", "Boss"),
         ("Calvin", "Klein")
         ]

     con = sqlite3.connect(":memory:")

     # Create the table
     con.execute("create table person(firstname, lastname)")

     # Fill the table
     con.executemany("insert into person(firstname, lastname) values (?, ?)", persons)

     # Print the table contents
     for row in con.execute("select firstname, lastname from person"):
         print row

     print "I just deleted", con.execute("delete from person").rowcount, "rows"



File: python.info,  Node: Accessing columns by name instead of by index,  Next: Using the connection as a context manager,  Prev: Using shortcut methods,  Up: Using sqlite3 efficiently

5.11.13.15 Accessing columns by name instead of by index
........................................................

One useful feature of the *note sqlite3: 15f. module is the built-in
*note sqlite3.Row: f5e. class designed to be used as a row factory.

  Rows wrapped with this class can be accessed both by index (like
tuples) and case-insensitively by name:

     import sqlite3

     con = sqlite3.connect(":memory:")
     con.row_factory = sqlite3.Row

     cur = con.cursor()
     cur.execute("select 'John' as name, 42 as age")
     for row in cur:
         assert row[0] == row["name"]
         assert row["name"] == row["nAmE"]
         assert row[1] == row["age"]
         assert row[1] == row["AgE"]



File: python.info,  Node: Using the connection as a context manager,  Prev: Accessing columns by name instead of by index,  Up: Using sqlite3 efficiently

5.11.13.16 Using the connection as a context manager
....................................................

New in version 2.6.

  Connection objects can be used as context managers that automatically
commit or rollback transactions.  In the event of an exception, the
transaction is rolled back; otherwise, the transaction is committed:

     import sqlite3

     con = sqlite3.connect(":memory:")
     con.execute("create table person (id integer primary key, firstname varchar unique)")

     # Successful, con.commit() is called automatically afterwards
     with con:
         con.execute("insert into person(firstname) values (?)", ("Joe",))

     # con.rollback() is called after the with block finishes with an exception, the
     # exception is still raised and must be caught
     try:
         with con:
             con.execute("insert into person(firstname) values (?)", ("Joe",))
     except sqlite3.IntegrityError:
         print "couldn't add Joe twice"



File: python.info,  Node: Common issues,  Prev: Using sqlite3 efficiently,  Up: sqlite3 --- DB-API 2 0 interface for SQLite databases

5.11.13.17 Common issues
........................

* Menu:

* Multithreading:: 


File: python.info,  Node: Multithreading,  Up: Common issues

5.11.13.18 Multithreading
.........................

Older SQLite versions had issues with sharing connections between
threads.  That’s why the Python module disallows sharing connections and
cursors between threads.  If you still try to do so, you will get an
exception at runtime.

  The only exception is calling the *note interrupt(): f59. method,
which only makes sense to call from a different thread.


File: python.info,  Node: Data Compression and Archiving,  Next: File Formats,  Prev: Data Persistence,  Up: The Python Standard Library

5.12 Data Compression and Archiving
===================================

The modules described in this chapter support data compression with the
zlib, gzip, and bzip2 algorithms, and the creation of ZIP- and
tar-format archives.  See also *note Archiving operations: eb2. provided
by the *note shutil: 154. module.

* Menu:

* zlib: zlib --- Compression compatible with gzip. Compression compatible with gzip
* gzip: gzip --- Support for gzip files. Support for gzip files
* bz2: bz2 --- Compression compatible with bzip2. Compression compatible with bzip2
* zipfile: zipfile --- Work with ZIP archives. Work with ZIP archives
* tarfile: tarfile --- Read and write tar archive files. Read and write tar archive files


File: python.info,  Node: zlib --- Compression compatible with gzip,  Next: gzip --- Support for gzip files,  Up: Data Compression and Archiving

5.12.1 ‘zlib’ — Compression compatible with *gzip*
--------------------------------------------------

For applications that require data compression, the functions in this
module allow compression and decompression, using the zlib library.  The
zlib library has its own home page at ‘http://www.zlib.net’.  There are
known incompatibilities between the Python module and versions of the
zlib library earlier than 1.1.3; 1.1.3 has a security vulnerability, so
we recommend using 1.1.4 or later.

  zlib’s functions have many options and often need to be used in a
particular order.  This documentation doesn’t attempt to cover all of
the permutations; consult the zlib manual at
‘http://www.zlib.net/manual.html’ for authoritative information.

  For reading and writing ‘.gz’ files see the *note gzip: e5. module.

  The available exception and functions in this module are:

 -- Exception: zlib.error

     Exception raised on compression and decompression errors.

 -- Function: zlib.adler32 (data[, value])

     Computes a Adler-32 checksum of _data_.  (An Adler-32 checksum is
     almost as reliable as a CRC32 but can be computed much more
     quickly.)  If _value_ is present, it is used as the starting value
     of the checksum; otherwise, a fixed default value is used.  This
     allows computing a running checksum over the concatenation of
     several inputs.  The algorithm is not cryptographically strong, and
     should not be used for authentication or digital signatures.  Since
     the algorithm is designed for use as a checksum algorithm, it is
     not suitable for use as a general hash algorithm.

     This function always returns an integer object.

     Note: To generate the same numeric value across all Python versions
     and platforms use adler32(data) & 0xffffffff.  If you are only
     using the checksum in packed binary format this is not necessary as
     the return value is the correct 32bit binary representation
     regardless of sign.

  Changed in version 2.6: The return value is in the range [-2**31,
2**31-1] regardless of platform.  In older versions the value is signed
on some platforms and unsigned on others.

  Changed in version 3.0: The return value is unsigned and in the range
[0, 2**32-1] regardless of platform.

 -- Function: zlib.compress (string[, level])

     Compresses the data in _string_, returning a string contained
     compressed data.  _level_ is an integer from ‘0’ to ‘9’ controlling
     the level of compression; ‘1’ is fastest and produces the least
     compression, ‘9’ is slowest and produces the most.  ‘0’ is no
     compression.  The default value is ‘6’.  Raises the *note error:
     f7d. exception if any error occurs.

 -- Function: zlib.compressobj ([level[, method[, wbits[, memlevel[,
          strategy]]]]])

     Returns a compression object, to be used for compressing data
     streams that won’t fit into memory at once.  _level_ is an integer
     from ‘0’ to ‘9’ controlling the level of compression; ‘1’ is
     fastest and produces the least compression, ‘9’ is slowest and
     produces the most.  ‘0’ is no compression.  The default value is
     ‘6’.

     _method_ is the compression algorithm.  Currently, the only
     supported value is ‘DEFLATED’.

     _wbits_ is the base two logarithm of the size of the window buffer.
     This should be an integer from ‘8’ to ‘15’.  Higher values give
     better compression, but use more memory.  The default is 15.

     _memlevel_ controls the amount of memory used for internal
     compression state.  Valid values range from ‘1’ to ‘9’.  Higher
     values using more memory, but are faster and produce smaller
     output.  The default is 8.

     _strategy_ is used to tune the compression algorithm.  Possible
     values are ‘Z_DEFAULT_STRATEGY’, ‘Z_FILTERED’, and
     ‘Z_HUFFMAN_ONLY’.  The default is ‘Z_DEFAULT_STRATEGY’.

 -- Function: zlib.crc32 (data[, value])

     Computes a CRC (Cyclic Redundancy Check) checksum of _data_.  If
     _value_ is present, it is used as the starting value of the
     checksum; otherwise, a fixed default value is used.  This allows
     computing a running checksum over the concatenation of several
     inputs.  The algorithm is not cryptographically strong, and should
     not be used for authentication or digital signatures.  Since the
     algorithm is designed for use as a checksum algorithm, it is not
     suitable for use as a general hash algorithm.

     This function always returns an integer object.

     Note: To generate the same numeric value across all Python versions
     and platforms use crc32(data) & 0xffffffff.  If you are only using
     the checksum in packed binary format this is not necessary as the
     return value is the correct 32bit binary representation regardless
     of sign.

  Changed in version 2.6: The return value is in the range [-2**31,
2**31-1] regardless of platform.  In older versions the value would be
signed on some platforms and unsigned on others.

  Changed in version 3.0: The return value is unsigned and in the range
[0, 2**32-1] regardless of platform.

 -- Function: zlib.decompress (string[, wbits[, bufsize]])

     Decompresses the data in _string_, returning a string containing
     the uncompressed data.  The _wbits_ parameter controls the size of
     the window buffer, and is discussed further below.  If _bufsize_ is
     given, it is used as the initial size of the output buffer.  Raises
     the *note error: f7d. exception if any error occurs.

     The absolute value of _wbits_ is the base two logarithm of the size
     of the history buffer (the "window size") used when compressing
     data.  Its absolute value should be between 8 and 15 for the most
     recent versions of the zlib library, larger values resulting in
     better compression at the expense of greater memory usage.  When
     decompressing a stream, _wbits_ must not be smaller than the size
     originally used to compress the stream; using a too-small value
     will result in an exception.  The default value is therefore the
     highest value, 15.  When _wbits_ is negative, the standard *gzip*
     header is suppressed.

     _bufsize_ is the initial size of the buffer used to hold
     decompressed data.  If more space is required, the buffer size will
     be increased as needed, so you don’t have to get this value exactly
     right; tuning it will only save a few calls to ‘malloc()’.  The
     default size is 16384.

 -- Function: zlib.decompressobj ([wbits])

     Returns a decompression object, to be used for decompressing data
     streams that won’t fit into memory at once.  The _wbits_ parameter
     controls the size of the window buffer.

  Compression objects support the following methods:

 -- Method: Compress.compress (string)

     Compress _string_, returning a string containing compressed data
     for at least part of the data in _string_.  This data should be
     concatenated to the output produced by any preceding calls to the
     *note compress(): a96. method.  Some input may be kept in internal
     buffers for later processing.

 -- Method: Compress.flush ([mode])

     All pending input is processed, and a string containing the
     remaining compressed output is returned.  _mode_ can be selected
     from the constants ‘Z_SYNC_FLUSH’, ‘Z_FULL_FLUSH’, or ‘Z_FINISH’,
     defaulting to ‘Z_FINISH’.  ‘Z_SYNC_FLUSH’ and ‘Z_FULL_FLUSH’ allow
     compressing further strings of data, while ‘Z_FINISH’ finishes the
     compressed stream and prevents compressing any more data.  After
     calling *note flush(): f83. with _mode_ set to ‘Z_FINISH’, the
     *note compress(): a96. method cannot be called again; the only
     realistic action is to delete the object.

 -- Method: Compress.copy ()

     Returns a copy of the compression object.  This can be used to
     efficiently compress a set of data that share a common initial
     prefix.

     New in version 2.5.

  Decompression objects support the following methods, and two
attributes:

 -- Attribute: Decompress.unused_data

     A string which contains any bytes past the end of the compressed
     data.  That is, this remains ‘""’ until the last byte that contains
     compression data is available.  If the whole string turned out to
     contain compressed data, this is ‘""’, the empty string.

     The only way to determine where a string of compressed data ends is
     by actually decompressing it.  This means that when compressed data
     is contained part of a larger file, you can only find the end of it
     by reading data and feeding it followed by some non-empty string
     into a decompression object’s *note decompress(): a97. method until
     the *note unused_data: f85. attribute is no longer the empty
     string.

 -- Attribute: Decompress.unconsumed_tail

     A string that contains any data that was not consumed by the last
     *note decompress(): a97. call because it exceeded the limit for the
     uncompressed data buffer.  This data has not yet been seen by the
     zlib machinery, so you must feed it (possibly with further data
     concatenated to it) back to a subsequent *note decompress(): a97.
     method call in order to get correct output.

 -- Method: Decompress.decompress (string[, max_length])

     Decompress _string_, returning a string containing the uncompressed
     data corresponding to at least part of the data in _string_.  This
     data should be concatenated to the output produced by any preceding
     calls to the *note decompress(): a97. method.  Some of the input
     data may be preserved in internal buffers for later processing.

     If the optional parameter _max_length_ is supplied then the return
     value will be no longer than _max_length_.  This may mean that not
     all of the compressed input can be processed; and unconsumed data
     will be stored in the attribute *note unconsumed_tail: f86.  This
     string must be passed to a subsequent call to *note decompress():
     a97. if decompression is to continue.  If _max_length_ is not
     supplied then the whole input is decompressed, and *note
     unconsumed_tail: f86. is an empty string.

 -- Method: Decompress.flush ([length])

     All pending input is processed, and a string containing the
     remaining uncompressed output is returned.  After calling *note
     flush(): f88, the *note decompress(): a97. method cannot be called
     again; the only realistic action is to delete the object.

     The optional parameter _length_ sets the initial size of the output
     buffer.

 -- Method: Decompress.copy ()

     Returns a copy of the decompression object.  This can be used to
     save the state of the decompressor midway through the data stream
     in order to speed up random seeks into the stream at a future
     point.

     New in version 2.5.

See also
........

Module *note gzip: e5.

     Reading and writing *gzip*-format files.

‘http://www.zlib.net’

     The zlib library home page.

‘http://www.zlib.net/manual.html’

     The zlib manual explains the semantics and usage of the library’s
     many functions.


File: python.info,  Node: gzip --- Support for gzip files,  Next: bz2 --- Compression compatible with bzip2,  Prev: zlib --- Compression compatible with gzip,  Up: Data Compression and Archiving

5.12.2 ‘gzip’ — Support for *gzip* files
----------------------------------------

*Source code:* Lib/gzip.py(1)

    * * * * * * * * * * * * * * * * * * * * * * * * * * * * * * 

  This module provides a simple interface to compress and decompress
files just like the GNU programs *gzip* and *gunzip* would.

  The data compression is provided by the *note zlib: 1ad. module.

  The *note gzip: e5. module provides the *note GzipFile: 227. class
which is modeled after Python’s File Object.  The *note GzipFile: 227.
class reads and writes *gzip*-format files, automatically compressing or
decompressing the data so that it looks like an ordinary file object.

  Note that additional file formats which can be decompressed by the
*gzip* and *gunzip* programs, such as those produced by *compress* and
*pack*, are not supported by this module.

  The module defines the following items:

 -- Class: gzip.GzipFile ([filename[, mode[, compresslevel[, fileobj[,
          mtime]]]]])

     Constructor for the *note GzipFile: 227. class, which simulates
     most of the methods of a file object, with the exception of the
     ‘readinto()’ and ‘truncate()’ methods.  At least one of _fileobj_
     and _filename_ must be given a non-trivial value.

     The new class instance is based on _fileobj_, which can be a
     regular file, a *note StringIO: 2dd. object, or any other object
     which simulates a file.  It defaults to ‘None’, in which case
     _filename_ is opened to provide a file object.

     When _fileobj_ is not ‘None’, the _filename_ argument is only used
     to be included in the *gzip* file header, which may include the
     original filename of the uncompressed file.  It defaults to the
     filename of _fileobj_, if discernible; otherwise, it defaults to
     the empty string, and in this case the original filename is not
     included in the header.

     The _mode_ argument can be any of ‘'r'’, ‘'rb'’, ‘'a'’, ‘'ab'’,
     ‘'w'’, or ‘'wb'’, depending on whether the file will be read or
     written.  The default is the mode of _fileobj_ if discernible;
     otherwise, the default is ‘'rb'’.  If not given, the ’b’ flag will
     be added to the mode to ensure the file is opened in binary mode
     for cross-platform portability.

     The _compresslevel_ argument is an integer from ‘0’ to ‘9’
     controlling the level of compression; ‘1’ is fastest and produces
     the least compression, and ‘9’ is slowest and produces the most
     compression.  ‘0’ is no compression.  The default is ‘9’.

     The _mtime_ argument is an optional numeric timestamp to be written
     to the stream when compressing.  All *gzip* compressed streams are
     required to contain a timestamp.  If omitted or ‘None’, the current
     time is used.  This module ignores the timestamp when
     decompressing; however, some programs, such as *gunzip*, make use
     of it.  The format of the timestamp is the same as that of the
     return value of ‘time.time()’ and of the ‘st_mtime’ attribute of
     the object returned by ‘os.stat()’.

     Calling a *note GzipFile: 227. object’s ‘close()’ method does not
     close _fileobj_, since you might wish to append more material after
     the compressed data.  This also allows you to pass a *note
     StringIO: 2dd. object opened for writing as _fileobj_, and retrieve
     the resulting memory buffer using the *note StringIO: 164. object’s
     *note getvalue(): a2f. method.

     *note GzipFile: 227. supports iteration and the *note with: 1c0.
     statement.

     Changed in version 2.7: Support for the *note with: 1c0. statement
     was added.

     Changed in version 2.7: Support for zero-padded files was added.

     New in version 2.7: The _mtime_ argument.

 -- Function: gzip.open (filename[, mode[, compresslevel]])

     This is a shorthand for ‘GzipFile(filename,’ ‘mode,’
     ‘compresslevel)’.  The _filename_ argument is required; _mode_
     defaults to ‘'rb'’ and _compresslevel_ defaults to ‘9’.

* Menu:

* Examples of usage:: 

   ---------- Footnotes ----------

   (1) http://hg.python.org/cpython/file/2.7/Lib/gzip.py


File: python.info,  Node: Examples of usage,  Up: gzip --- Support for gzip files

5.12.2.1 Examples of usage
..........................

Example of how to read a compressed file:

     import gzip
     f = gzip.open('file.txt.gz', 'rb')
     file_content = f.read()
     f.close()

  Example of how to create a compressed GZIP file:

     import gzip
     content = "Lots of content here"
     f = gzip.open('file.txt.gz', 'wb')
     f.write(content)
     f.close()

  Example of how to GZIP compress an existing file:

     import gzip
     f_in = open('file.txt', 'rb')
     f_out = gzip.open('file.txt.gz', 'wb')
     f_out.writelines(f_in)
     f_out.close()
     f_in.close()

See also
........

Module *note zlib: 1ad.

     The basic data compression module needed to support the *gzip* file
     format.


File: python.info,  Node: bz2 --- Compression compatible with bzip2,  Next: zipfile --- Work with ZIP archives,  Prev: gzip --- Support for gzip files,  Up: Data Compression and Archiving

5.12.3 ‘bz2’ — Compression compatible with *bzip2*
--------------------------------------------------

New in version 2.3.

  This module provides a comprehensive interface for the bz2 compression
library.  It implements a complete file interface, one-shot
(de)compression functions, and types for sequential (de)compression.

  Here is a summary of the features offered by the bz2 module:

   * *note BZ2File: 204. class implements a complete file interface,
     including *note readline(): f91, *note readlines(): f92, *note
     writelines(): f93, *note seek(): f94, etc;

   * *note BZ2File: 204. class implements emulated *note seek(): f94.
     support;

   * *note BZ2File: 204. class implements universal newline support;

   * *note BZ2File: 204. class offers an optimized line iteration using
     the readahead algorithm borrowed from file objects;

   * Sequential (de)compression supported by *note BZ2Compressor: f95.
     and *note BZ2Decompressor: f96. classes;

   * One-shot (de)compression supported by *note compress(): a8e. and
     *note decompress(): a8f. functions;

   * Thread safety uses individual locking mechanism.

* Menu:

* (De)compression of files: De compression of files. 
* Sequential (de)compression: Sequential de compression. 
* One-shot (de)compression: One-shot de compression. 


File: python.info,  Node: De compression of files,  Next: Sequential de compression,  Up: bz2 --- Compression compatible with bzip2

5.12.3.1 (De)compression of files
.................................

Handling of compressed files is offered by the *note BZ2File: 204.
class.

 -- Class: bz2.BZ2File (filename[, mode[, buffering[, compresslevel]]])

     Open a bz2 file.  Mode can be either ‘'r'’ or ‘'w'’, for reading
     (default) or writing.  When opened for writing, the file will be
     created if it doesn’t exist, and truncated otherwise.  If
     _buffering_ is given, ‘0’ means unbuffered, and larger numbers
     specify the buffer size; the default is ‘0’.  If _compresslevel_ is
     given, it must be a number between ‘1’ and ‘9’; the default is ‘9’.
     Add a ‘'U'’ to mode to open the file for input in *note universal
     newlines: 315. mode.  Any line ending in the input file will be
     seen as a ‘'\n'’ in Python.  Also, a file so opened gains the
     attribute ‘newlines’; the value for this attribute is one of ‘None’
     (no newline read yet), ‘'\r'’, ‘'\n'’, ‘'\r\n'’ or a tuple
     containing all the newline types seen.  Universal newlines are
     available only when reading.  Instances support iteration in the
     same way as normal *note file: 1f9. instances.

     *note BZ2File: 204. supports the *note with: 1c0. statement.

     Changed in version 2.7: Support for the *note with: 1c0. statement
     was added.

          Note: This class does not support input files containing
          multiple streams (such as those produced by the *pbzip2*
          tool).  When reading such an input file, only the first stream
          will be accessible.  If you require support for multi-stream
          files, consider using the third-party ‘bz2file’ module
          (available from PyPI(1)). This module provides a backport of
          Python 3.3’s *note BZ2File: 204. class, which does support
          multi-stream files.

      -- Method: close ()

          Close the file.  Sets data attribute ‘closed’ to true.  A
          closed file cannot be used for further I/O operations.  *note
          close(): f98. may be called more than once without error.

      -- Method: read ([size])

          Read at most _size_ uncompressed bytes, returned as a string.
          If the _size_ argument is negative or omitted, read until EOF
          is reached.

      -- Method: readline ([size])

          Return the next line from the file, as a string, retaining
          newline.  A non-negative _size_ argument limits the maximum
          number of bytes to return (an incomplete line may be returned
          then).  Return an empty string at EOF.

      -- Method: readlines ([size])

          Return a list of lines read.  The optional _size_ argument, if
          given, is an approximate bound on the total number of bytes in
          the lines returned.

      -- Method: xreadlines ()

          For backward compatibility.  *note BZ2File: 204. objects now
          include the performance optimizations previously implemented
          in the ‘xreadlines’ module.

          Deprecated since version 2.3: This exists only for
          compatibility with the method by this name on *note file: 1f9.
          objects, which is deprecated.  Use ‘for line in file’ instead.

      -- Method: seek (offset[, whence])

          Move to new file position.  Argument _offset_ is a byte count.
          Optional argument _whence_ defaults to ‘os.SEEK_SET’ or ‘0’
          (offset from start of file; offset should be ‘>= 0’); other
          values are ‘os.SEEK_CUR’ or ‘1’ (move relative to current
          position; offset can be positive or negative), and
          ‘os.SEEK_END’ or ‘2’ (move relative to end of file; offset is
          usually negative, although many platforms allow seeking beyond
          the end of a file).

          Note that seeking of bz2 files is emulated, and depending on
          the parameters the operation may be extremely slow.

      -- Method: tell ()

          Return the current file position, an integer (may be a long
          integer).

      -- Method: write (data)

          Write string _data_ to file.  Note that due to buffering,
          *note close(): f98. may be needed before the file on disk
          reflects the data written.

      -- Method: writelines (sequence_of_strings)

          Write the sequence of strings to the file.  Note that newlines
          are not added.  The sequence can be any iterable object
          producing strings.  This is equivalent to calling write() for
          each string.

   ---------- Footnotes ----------

   (1) http://pypi.python.org/pypi/bz2file


File: python.info,  Node: Sequential de compression,  Next: One-shot de compression,  Prev: De compression of files,  Up: bz2 --- Compression compatible with bzip2

5.12.3.2 Sequential (de)compression
...................................

Sequential compression and decompression is done using the classes *note
BZ2Compressor: f95. and *note BZ2Decompressor: f96.

 -- Class: bz2.BZ2Compressor ([compresslevel])

     Create a new compressor object.  This object may be used to
     compress data sequentially.  If you want to compress data in one
     shot, use the *note compress(): a8e. function instead.  The
     _compresslevel_ parameter, if given, must be a number between ‘1’
     and ‘9’; the default is ‘9’.

      -- Method: compress (data)

          Provide more data to the compressor object.  It will return
          chunks of compressed data whenever possible.  When you’ve
          finished providing data to compress, call the *note flush():
          f9f. method to finish the compression process, and return what
          is left in internal buffers.

      -- Method: flush ()

          Finish the compression process and return what is left in
          internal buffers.  You must not use the compressor object
          after calling this method.

 -- Class: bz2.BZ2Decompressor

     Create a new decompressor object.  This object may be used to
     decompress data sequentially.  If you want to decompress data in
     one shot, use the *note decompress(): a8f. function instead.

      -- Method: decompress (data)

          Provide more data to the decompressor object.  It will return
          chunks of decompressed data whenever possible.  If you try to
          decompress data after the end of stream is found, *note
          EOFError: 88a. will be raised.  If any data was found after
          the end of stream, it’ll be ignored and saved in ‘unused_data’
          attribute.


File: python.info,  Node: One-shot de compression,  Prev: Sequential de compression,  Up: bz2 --- Compression compatible with bzip2

5.12.3.3 One-shot (de)compression
.................................

One-shot compression and decompression is provided through the *note
compress(): a8e. and *note decompress(): a8f. functions.

 -- Function: bz2.compress (data[, compresslevel])

     Compress _data_ in one shot.  If you want to compress data
     sequentially, use an instance of *note BZ2Compressor: f95. instead.
     The _compresslevel_ parameter, if given, must be a number between
     ‘1’ and ‘9’; the default is ‘9’.

 -- Function: bz2.decompress (data)

     Decompress _data_ in one shot.  If you want to decompress data
     sequentially, use an instance of *note BZ2Decompressor: f96.
     instead.

